{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1576148328509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "k3LWJrdjDSJy",
    "outputId": "748de6e4-fd9b-426e-d7db-b02b51ed8e51"
   },
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:35:33.331717: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-20 23:35:33.331776: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLeQXXYjCcVm"
   },
   "outputs": [],
   "source": [
    "used_digits = [5,7]\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images'\n",
    "model_g = 'model_dcgan-b{}_g.h5'.format(batch_size)\n",
    "model_d = 'model_dcgan-b{}_d.h5'.format(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (A) Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(n_noise, ), activation=\"tanh\"))\n",
    "    model.add(Dense(32 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Reshape((7, 7, 32), input_shape=(7 * 7 * 32,)))\n",
    "    model.add(UpSampling2D(size=(2, 2))) # (A1)\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     input_shape=(28, 28, 1),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"tanh\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (B) Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5 # (B1)\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjAEL8P8CcV0"
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    generator.load_weights(\"generator\")\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176294,
     "status": "ok",
     "timestamp": 1576148503868,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "00ea9935-7deb-4110-81bb-cd1c312a3a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anhvu/.local/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:35:41.987544: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-20 23:35:41.987603: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-20 23:35:41.987644: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anhvu): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:35:42.741747: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'images/0_0.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_54920/2289666423.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(BATCH_SIZE)\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mimg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mimg_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ds21/lib/python3.9/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2153\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2154\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2155\u001b[0;31m                 \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w+b\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'images/0_0.png'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176290,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "9077a4b0-a66a-4946-eb3c-f5f70f1d5452"
   },
   "outputs": [],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176283,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "669f9caf-ccc0-46ef-ed8c-c46b1a28d5ad"
   },
   "outputs": [],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate(batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_with_keras-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
