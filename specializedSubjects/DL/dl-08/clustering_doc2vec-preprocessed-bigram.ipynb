{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample program for clustering of documents with doc2vec  \n",
    "- Consider Bi-gram  \n",
    "- Apply preprocess_string to content strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_in = 'newsgroups5-2.csv'\n",
    "min_count = 10\n",
    "min_words = 50\n",
    "\n",
    "embed_size = 300\n",
    "model_file = 'doc2vec_newsgroups5-2.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read CSV file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(csv_in, delimiter=',', skiprows=0, header=0)\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete too short docs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ df['content'].map(lambda x: len(x.split())) >= min_words ]\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of documents in each category  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['target'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove stop_words, punctuations, etc.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = df['content'].map(preprocess_string)\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Bi-gram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for i in range(len(df)):\n",
    "    #print(i, df.at[i, 'content'])\n",
    "    words.append(df.at[i, 'content'])\n",
    "    #print(len(words))  # debug\n",
    "#print(words[:5])  # debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "phrases_bi = Phrases(words, min_count=30, threshold=10.0)\n",
    "bigram = Phraser(phrases_bi)\n",
    "df['content'] = df['content'].map(lambda x: bigram[x])\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test of bigram  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bigram[ ['new', 'york'] ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assign docID according to its category  \n",
    "- docID = 'd' + number, such as d0, d1, ..., d1000, d1001, ...\n",
    " - number = target * 1000 + j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docID = []\n",
    "j = np.zeros(len(df['target'].value_counts()))\n",
    "for i in range(len(df)):\n",
    "    tgt = df.at[i, 'target']\n",
    "    # base of document ID:\n",
    "    #   0 for documents of target 0, 1000 for documents of target 1,\n",
    "    #   2000 for documents of target 2, ...\n",
    "    docID.append('d'+str(int(tgt*1000+j[tgt])))\n",
    "    # increment j for target \"tgt\"\n",
    "    j[tgt] += 1\n",
    "df['docID'] = docID\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of Doc2Vec  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for i in range(len(df)):\n",
    "    c = df.at[i, 'content']\n",
    "    doc_id = df.at[i, 'docID']\n",
    "    # make TaggedDocument\n",
    "    td = TaggedDocument(words=c, tags=[doc_id])\n",
    "    docs.append(td)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculation of doc vectors  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#model = Doc2Vec(documents=docs, vector_size=embed_size,\n",
    "#                min_count=min_count, dm=0, epochs=20) # PV-DBOW\n",
    "model = Doc2Vec(documents=docs, vector_size=embed_size,\n",
    "                min_count=min_count, dm=1, epochs=20)  # PV-DM\n",
    "print(model)\n",
    "\n",
    "model.init_sims(replace=True)\n",
    "model.save(model_file)\n",
    " \n",
    "# If you want to read saved model\n",
    "# model = Doc2Vec.load('doc2vec.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Check word set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model.wv.vocab.keys()))  # number of words\n",
    "print(list(model.wv.vocab.keys())[:10])  # show first 10 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvecs = model.docvecs.vectors_docs\n",
    "print(docvecs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow method to determine the number of clusters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "max_cls = 7\n",
    "distortions = []\n",
    "for i in range(1, max_cls+1):\n",
    "    print(i)\n",
    "    km = KMeans(n_clusters=i)\n",
    "    km.fit(docvecs)\n",
    "    distortions.append(km.inertia_)\n",
    "plt.plot(range(1, max_cls+1), distortions, marker='o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Distortion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cls = 5\n",
    "km = KMeans(n_clusters=n_cls, random_state=7)\n",
    "cls = km.fit_predict(docvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check correspondence of target and clusters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pd.crosstab(df['target'], cls))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization using PCA  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Y_pca = pca.fit_transform(docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"PCA (colored by cluster ID)\")\n",
    "marker = '.'\n",
    "for i in range(n_cls):\n",
    "    y1 = Y_pca[ cls==i ]\n",
    "    plt.scatter(y1[:, 0], y1[:, 1], marker=marker, label=i)\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of PCA colored by target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "plt.title(\"PCA (colored by target)\")\n",
    "marker = '.'\n",
    "for i in range(n_cls):\n",
    "    y1 = Y_pca[ df['target']==i ]\n",
    "    plt.scatter(y1[:, 0], y1[:, 1], marker=marker, label=i)\n",
    "\n",
    "plt.xlabel('PCA1')\n",
    "plt.ylabel('PCA2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization using t-SNE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "Y_tsne = TSNE(n_components=2,\n",
    "              perplexity=30, n_iter=500,\n",
    "              random_state=0).fit_transform(docvecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "plt.title(\"t-SNE (colored by cluster ID)\")\n",
    "marker = '.'\n",
    "for i in range(n_cls):\n",
    "    y1 = Y_tsne[ cls==i ]\n",
    "    plt.scatter(y1[:, 0], y1[:, 1], marker=marker, label=i)\n",
    "    \n",
    "plt.xlabel('t-SNE1')\n",
    "plt.ylabel('t-SNE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of t-SNE colored by target  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,7))\n",
    "plt.title(\"t-SNE (colord by target)\")\n",
    "marker = '.'\n",
    "for i in range(n_cls):\n",
    "    y1 = Y_tsne[ df['target']==i ]\n",
    "    plt.scatter(y1[:, 0], y1[:, 1], marker=marker, label=i)\n",
    "    \n",
    "plt.xlabel('t-SNE1')\n",
    "plt.ylabel('t-SNE2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
