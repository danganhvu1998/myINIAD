{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample notebook for CNN learning  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout,Flatten,Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w=56\n",
    "work_dir='data/dogs_cats'\n",
    "npy_data_base='dogs_cats-data'\n",
    "npy_labels_base='dogs_cats-labels'\n",
    "classes=['dogs','cats']\n",
    "num_classes=len(classes)\n",
    "\n",
    "model_file=\"dogs_cats-model-w{0}.h5\".format(w)\n",
    "history_file=\"dogs_cats-history-w{0}.csv\".format(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read train/test data from npy file\n",
    "X: 0-1 (float16), y: one-hot encoding  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode=\"train\"\n",
    "npy_data_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_data_base,mode,w)\n",
    "npy_labels_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_labels_base,mode,w)\n",
    "X_train=np.load(npy_data_file).astype(\"float16\")\n",
    "X_train/=255\n",
    "y_train=np.load(npy_labels_file)\n",
    "y_train=to_categorical(y_train,num_classes)\n",
    "\n",
    "mode=\"test\"\n",
    "npy_data_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_data_base,mode,w)\n",
    "npy_labels_file=\"{0}/{1}-{2}-w{3}.npy\".format(work_dir,npy_labels_base,mode,w)\n",
    "X_test=np.load(npy_data_file).astype(\"float16\")\n",
    "X_test/=255\n",
    "y_test=np.load(npy_labels_file)\n",
    "y_test=to_categorical(y_test,num_classes)\n",
    "\n",
    "print( X_train.shape )\n",
    "print( y_train.shape )\n",
    "print( X_test.shape )\n",
    "print( y_test.shape )\n",
    "img_rows=X_train.shape[1]\n",
    "img_cols=X_train.shape[2]\n",
    "img_channels=X_train.shape[3]\n",
    "print(\"image_size:\", img_rows, img_cols)\n",
    "print(\"image_channels:\", img_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build CNN structure  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(img_rows,img_cols,img_channels)\n",
    "model=Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training of CNN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "n_epochs=40\n",
    "val_split=0.2\n",
    "batch_size=128\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "cl=CSVLogger(history_file)\n",
    "#fit_log=model.fit(X_train, y_train, batch_size=batch_size,\n",
    "#                  epochs=n_epochs, validation_split=val_split,\n",
    "#                  callbacks=[cl])\n",
    "#if you want to use early stopping, uncomment the following lines\n",
    "es=EarlyStopping(monitor='val_loss',patience=7,verbose=1)\n",
    "fit_log=model.fit(X_train, y_train, batch_size=batch_size,\n",
    "                  epochs=n_epochs, validation_split=val_split,\n",
    "                  callbacks=[cl, es])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of loss/accuracy during training  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_log.history['loss'], label='train')\n",
    "plt.plot(fit_log.history['val_loss'], label='valid')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(fit_log.history['accuracy'], label='train')\n",
    "plt.plot(fit_log.history['val_accuracy'], label='valid')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of loss/accuracy during training (from history file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h=np.loadtxt(history_file, delimiter=',', skiprows=1)\n",
    "epoch=h[:,0]\n",
    "acc=h[:,1]\n",
    "loss=h[:,2]\n",
    "val_acc=h[:,3]\n",
    "val_loss=h[:,4]\n",
    "\n",
    "plt.plot(epoch, loss, label='train')\n",
    "plt.plot(epoch, val_loss, label='valid')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(epoch, acc, label='train')\n",
    "plt.plot(epoch, val_acc, label='valid')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy against test data (Generalization performance)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score=model.evaluate(X_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
