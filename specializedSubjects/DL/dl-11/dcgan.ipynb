{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1576148328509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "k3LWJrdjDSJy",
    "outputId": "748de6e4-fd9b-426e-d7db-b02b51ed8e51"
   },
   "source": [
    "### Sample program for DCGAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLeQXXYjCcVm"
   },
   "outputs": [],
   "source": [
    "used_digits = [4,8]\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images'\n",
    "model_g = 'model_dcgan-b{}_g.h5'.format(batch_size)\n",
    "model_d = 'model_dcgan-b{}_d.h5'.format(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove old img_dir and create new one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1576148329857,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "IOF5fZwICcVo",
    "outputId": "5c1cc125-a086-4060-de5a-21adba1d64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OK\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(img_dir):\n",
    "    shutil.rmtree(img_dir)\n",
    "\n",
    "cnt = 10\n",
    "while cnt > 0:\n",
    "    try:\n",
    "        os.makedirs(img_dir)\n",
    "        break\n",
    "    except:\n",
    "        sleep(1)\n",
    "    cnt -= 1\n",
    "    \n",
    "if cnt <= 0:\n",
    "    print('Cannot mkdir:', img_dir)\n",
    "else:\n",
    "    print('mkdir: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(n_noise, ), activation=\"tanh\"))\n",
    "    model.add(Dense(32 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Reshape((7, 7, 32), input_shape=(7 * 7 * 32,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     input_shape=(28, 28, 1),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"tanh\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjAEL8P8CcV0"
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    generator.load_weights(\"generator\")\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176294,
     "status": "ok",
     "timestamp": 1576148503868,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "00ea9935-7deb-4110-81bb-cd1c312a3a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.907354  g_loss: 0.345442\n",
      "batch 1  d_loss: 0.561648  g_loss: 0.317500\n",
      "batch 2  d_loss: 0.579032  g_loss: 0.494862\n",
      "batch 3  d_loss: 0.462686  g_loss: 0.945871\n",
      "batch 4  d_loss: 0.349043  g_loss: 1.732489\n",
      "batch 5  d_loss: 0.250366  g_loss: 2.859324\n",
      "batch 6  d_loss: 0.180040  g_loss: 3.796990\n",
      "batch 7  d_loss: 0.212602  g_loss: 4.314776\n",
      "batch 8  d_loss: 0.131865  g_loss: 4.835903\n",
      "batch 9  d_loss: 0.126713  g_loss: 5.069409\n",
      "batch 10  d_loss: 0.084639  g_loss: 5.593263\n",
      "batch 11  d_loss: 0.246620  g_loss: 5.988260\n",
      "batch 12  d_loss: 0.419414  g_loss: 7.142318\n",
      "batch 13  d_loss: 0.236809  g_loss: 7.464239\n",
      "batch 14  d_loss: 0.258980  g_loss: 7.698951\n",
      "batch 15  d_loss: 0.358742  g_loss: 7.556085\n",
      "batch 16  d_loss: 0.886415  g_loss: 6.477520\n",
      "batch 17  d_loss: 0.781369  g_loss: 5.480601\n",
      "batch 18  d_loss: 0.704438  g_loss: 4.591381\n",
      "batch 19  d_loss: 0.784443  g_loss: 3.719917\n",
      "batch 20  d_loss: 0.409291  g_loss: 3.562066\n",
      "batch 21  d_loss: 0.349305  g_loss: 3.777467\n",
      "batch 22  d_loss: 0.689596  g_loss: 3.826141\n",
      "batch 23  d_loss: 0.486238  g_loss: 4.026875\n",
      "batch 24  d_loss: 0.909840  g_loss: 4.682442\n",
      "batch 25  d_loss: 0.615992  g_loss: 4.101264\n",
      "batch 26  d_loss: 0.503535  g_loss: 3.715873\n",
      "batch 27  d_loss: 0.399453  g_loss: 3.825498\n",
      "batch 28  d_loss: 0.216909  g_loss: 3.783310\n",
      "batch 29  d_loss: 0.256612  g_loss: 3.988400\n",
      "batch 30  d_loss: 0.203210  g_loss: 4.310909\n",
      "batch 31  d_loss: 0.196883  g_loss: 4.804489\n",
      "batch 32  d_loss: 0.227932  g_loss: 5.074258\n",
      "batch 33  d_loss: 0.207365  g_loss: 4.913100\n",
      "batch 34  d_loss: 0.264913  g_loss: 4.898565\n",
      "batch 35  d_loss: 0.156722  g_loss: 5.517028\n",
      "batch 36  d_loss: 0.171152  g_loss: 4.689542\n",
      "batch 37  d_loss: 0.116090  g_loss: 4.721521\n",
      "batch 38  d_loss: 0.129730  g_loss: 4.435281\n",
      "batch 39  d_loss: 0.110616  g_loss: 4.827210\n",
      "batch 40  d_loss: 0.075163  g_loss: 4.625505\n",
      "batch 41  d_loss: 0.066270  g_loss: 4.733369\n",
      "batch 42  d_loss: 0.070236  g_loss: 4.133402\n",
      "batch 43  d_loss: 0.105493  g_loss: 4.572740\n",
      "batch 44  d_loss: 0.089921  g_loss: 4.912097\n",
      "batch 45  d_loss: 0.113104  g_loss: 4.926074\n",
      "Epoch is 1\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.061108  g_loss: 5.007776\n",
      "batch 1  d_loss: 0.043100  g_loss: 5.422559\n",
      "batch 2  d_loss: 0.059477  g_loss: 5.038057\n",
      "batch 3  d_loss: 0.061386  g_loss: 4.856327\n",
      "batch 4  d_loss: 0.070170  g_loss: 5.526470\n",
      "batch 5  d_loss: 0.027243  g_loss: 5.149046\n",
      "batch 6  d_loss: 0.074650  g_loss: 5.076595\n",
      "batch 7  d_loss: 0.031900  g_loss: 5.265614\n",
      "batch 8  d_loss: 0.058461  g_loss: 5.112497\n",
      "batch 9  d_loss: 0.052818  g_loss: 4.835930\n",
      "batch 10  d_loss: 0.038338  g_loss: 5.626024\n",
      "batch 11  d_loss: 0.021498  g_loss: 5.352968\n",
      "batch 12  d_loss: 0.028154  g_loss: 6.004715\n",
      "batch 13  d_loss: 0.022528  g_loss: 5.385234\n",
      "batch 14  d_loss: 0.031767  g_loss: 5.323647\n",
      "batch 15  d_loss: 0.054371  g_loss: 5.164471\n",
      "batch 16  d_loss: 0.016777  g_loss: 5.585611\n",
      "batch 17  d_loss: 0.024213  g_loss: 5.684378\n",
      "batch 18  d_loss: 0.024836  g_loss: 4.954093\n",
      "batch 19  d_loss: 0.017334  g_loss: 5.011976\n",
      "batch 20  d_loss: 0.022232  g_loss: 5.327246\n",
      "batch 21  d_loss: 0.025775  g_loss: 4.750220\n",
      "batch 22  d_loss: 0.021372  g_loss: 5.020466\n",
      "batch 23  d_loss: 0.024645  g_loss: 4.784283\n",
      "batch 24  d_loss: 0.027373  g_loss: 5.123446\n",
      "batch 25  d_loss: 0.014714  g_loss: 4.964807\n",
      "batch 26  d_loss: 0.034696  g_loss: 5.612948\n",
      "batch 27  d_loss: 0.023200  g_loss: 5.439936\n",
      "batch 28  d_loss: 0.018833  g_loss: 5.162940\n",
      "batch 29  d_loss: 0.036069  g_loss: 5.403412\n",
      "batch 30  d_loss: 0.041399  g_loss: 4.954855\n",
      "batch 31  d_loss: 0.028755  g_loss: 4.713804\n",
      "batch 32  d_loss: 0.059274  g_loss: 4.546247\n",
      "batch 33  d_loss: 0.039533  g_loss: 4.716692\n",
      "batch 34  d_loss: 0.041233  g_loss: 4.560390\n",
      "batch 35  d_loss: 0.037513  g_loss: 4.918894\n",
      "batch 36  d_loss: 0.083996  g_loss: 5.403342\n",
      "batch 37  d_loss: 0.029903  g_loss: 5.313362\n",
      "batch 38  d_loss: 0.048481  g_loss: 5.482864\n",
      "batch 39  d_loss: 0.040201  g_loss: 5.581846\n",
      "batch 40  d_loss: 0.051988  g_loss: 5.810972\n",
      "batch 41  d_loss: 0.045409  g_loss: 5.828926\n",
      "batch 42  d_loss: 0.074137  g_loss: 6.444818\n",
      "batch 43  d_loss: 0.050065  g_loss: 6.911425\n",
      "batch 44  d_loss: 0.073822  g_loss: 7.274832\n",
      "batch 45  d_loss: 0.026916  g_loss: 7.164699\n",
      "Epoch is 2\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.087062  g_loss: 6.830012\n",
      "batch 1  d_loss: 0.092932  g_loss: 6.841912\n",
      "batch 2  d_loss: 0.069200  g_loss: 7.199865\n",
      "batch 3  d_loss: 0.095101  g_loss: 7.402639\n",
      "batch 4  d_loss: 0.173994  g_loss: 7.119765\n",
      "batch 5  d_loss: 0.145640  g_loss: 7.851064\n",
      "batch 6  d_loss: 0.173261  g_loss: 6.689176\n",
      "batch 7  d_loss: 0.111020  g_loss: 7.041304\n",
      "batch 8  d_loss: 0.138719  g_loss: 8.271138\n",
      "batch 9  d_loss: 0.122887  g_loss: 8.039869\n",
      "batch 10  d_loss: 0.145051  g_loss: 8.083700\n",
      "batch 11  d_loss: 0.151941  g_loss: 6.837395\n",
      "batch 12  d_loss: 0.098011  g_loss: 8.068592\n",
      "batch 13  d_loss: 0.123599  g_loss: 8.887746\n",
      "batch 14  d_loss: 0.179580  g_loss: 6.861534\n",
      "batch 15  d_loss: 0.183758  g_loss: 7.752797\n",
      "batch 16  d_loss: 0.133535  g_loss: 8.844880\n",
      "batch 17  d_loss: 0.368634  g_loss: 5.993320\n",
      "batch 18  d_loss: 0.432514  g_loss: 6.825475\n",
      "batch 19  d_loss: 0.181188  g_loss: 7.728777\n",
      "batch 20  d_loss: 0.257840  g_loss: 6.889626\n",
      "batch 21  d_loss: 0.201322  g_loss: 5.583172\n",
      "batch 22  d_loss: 0.285691  g_loss: 5.599035\n",
      "batch 23  d_loss: 0.262237  g_loss: 8.461419\n",
      "batch 24  d_loss: 0.360185  g_loss: 7.711303\n",
      "batch 25  d_loss: 0.289991  g_loss: 4.894745\n",
      "batch 26  d_loss: 0.268208  g_loss: 3.864822\n",
      "batch 27  d_loss: 0.339327  g_loss: 5.146578\n",
      "batch 28  d_loss: 0.220747  g_loss: 7.408728\n",
      "batch 29  d_loss: 0.795968  g_loss: 5.479394\n",
      "batch 30  d_loss: 0.418410  g_loss: 2.667858\n",
      "batch 31  d_loss: 0.489323  g_loss: 3.062578\n",
      "batch 32  d_loss: 0.425139  g_loss: 4.813793\n",
      "batch 33  d_loss: 0.202438  g_loss: 5.717252\n",
      "batch 34  d_loss: 0.327091  g_loss: 4.422390\n",
      "batch 35  d_loss: 0.204571  g_loss: 2.950511\n",
      "batch 36  d_loss: 0.451078  g_loss: 3.071786\n",
      "batch 37  d_loss: 0.254222  g_loss: 4.983005\n",
      "batch 38  d_loss: 0.176865  g_loss: 5.671115\n",
      "batch 39  d_loss: 0.327121  g_loss: 4.556976\n",
      "batch 40  d_loss: 0.158894  g_loss: 2.878076\n",
      "batch 41  d_loss: 0.251351  g_loss: 2.141681\n",
      "batch 42  d_loss: 0.331509  g_loss: 3.576431\n",
      "batch 43  d_loss: 0.188215  g_loss: 4.809279\n",
      "batch 44  d_loss: 0.270196  g_loss: 3.990240\n",
      "batch 45  d_loss: 0.089656  g_loss: 3.610261\n",
      "Epoch is 3\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.195859  g_loss: 3.062942\n",
      "batch 1  d_loss: 0.118375  g_loss: 3.904285\n",
      "batch 2  d_loss: 0.227806  g_loss: 4.257178\n",
      "batch 3  d_loss: 0.118117  g_loss: 4.445891\n",
      "batch 4  d_loss: 0.294586  g_loss: 4.007745\n",
      "batch 5  d_loss: 0.222390  g_loss: 3.430059\n",
      "batch 6  d_loss: 0.214379  g_loss: 3.961639\n",
      "batch 7  d_loss: 1.090891  g_loss: 2.295181\n",
      "batch 8  d_loss: 0.576510  g_loss: 2.871899\n",
      "batch 9  d_loss: 0.327910  g_loss: 4.672545\n",
      "batch 10  d_loss: 0.094405  g_loss: 5.894161\n",
      "batch 11  d_loss: 0.541778  g_loss: 5.011513\n",
      "batch 12  d_loss: 0.319098  g_loss: 3.020873\n",
      "batch 13  d_loss: 0.214145  g_loss: 2.406692\n",
      "batch 14  d_loss: 0.429742  g_loss: 2.605820\n",
      "batch 15  d_loss: 0.204704  g_loss: 3.574290\n",
      "batch 16  d_loss: 0.197591  g_loss: 4.291786\n",
      "batch 17  d_loss: 0.669951  g_loss: 4.018779\n",
      "batch 18  d_loss: 0.250330  g_loss: 1.960599\n",
      "batch 19  d_loss: 0.422062  g_loss: 2.889805\n",
      "batch 20  d_loss: 0.367470  g_loss: 3.887858\n",
      "batch 21  d_loss: 0.534090  g_loss: 4.249310\n",
      "batch 22  d_loss: 0.252598  g_loss: 3.943369\n",
      "batch 23  d_loss: 0.235563  g_loss: 4.074883\n",
      "batch 24  d_loss: 0.174695  g_loss: 4.476861\n",
      "batch 25  d_loss: 0.448659  g_loss: 4.086496\n",
      "batch 26  d_loss: 0.208360  g_loss: 4.269779\n",
      "batch 27  d_loss: 0.289150  g_loss: 5.236452\n",
      "batch 28  d_loss: 0.254613  g_loss: 5.805617\n",
      "batch 29  d_loss: 0.649000  g_loss: 4.807391\n",
      "batch 30  d_loss: 0.520385  g_loss: 3.899756\n",
      "batch 31  d_loss: 0.325567  g_loss: 3.285039\n",
      "batch 32  d_loss: 0.492845  g_loss: 3.238604\n",
      "batch 33  d_loss: 0.354927  g_loss: 3.391815\n",
      "batch 34  d_loss: 0.225534  g_loss: 4.544197\n",
      "batch 35  d_loss: 0.341292  g_loss: 3.945754\n",
      "batch 36  d_loss: 0.655892  g_loss: 2.997020\n",
      "batch 37  d_loss: 0.538169  g_loss: 3.030181\n",
      "batch 38  d_loss: 0.259424  g_loss: 3.436395\n",
      "batch 39  d_loss: 0.244912  g_loss: 4.104305\n",
      "batch 40  d_loss: 0.319924  g_loss: 4.856566\n",
      "batch 41  d_loss: 0.787606  g_loss: 3.418521\n",
      "batch 42  d_loss: 0.417318  g_loss: 2.514565\n",
      "batch 43  d_loss: 0.324880  g_loss: 2.605714\n",
      "batch 44  d_loss: 0.431821  g_loss: 3.211394\n",
      "batch 45  d_loss: 0.309506  g_loss: 4.300014\n",
      "Epoch is 4\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.337355  g_loss: 4.474726\n",
      "batch 1  d_loss: 0.360980  g_loss: 3.786803\n",
      "batch 2  d_loss: 0.647532  g_loss: 3.023663\n",
      "batch 3  d_loss: 0.384948  g_loss: 2.870398\n",
      "batch 4  d_loss: 0.640629  g_loss: 1.991589\n",
      "batch 5  d_loss: 0.807189  g_loss: 3.168863\n",
      "batch 6  d_loss: 0.570294  g_loss: 3.830011\n",
      "batch 7  d_loss: 1.167375  g_loss: 2.553255\n",
      "batch 8  d_loss: 0.640934  g_loss: 1.874421\n",
      "batch 9  d_loss: 0.581722  g_loss: 2.138264\n",
      "batch 10  d_loss: 0.387546  g_loss: 2.550333\n",
      "batch 11  d_loss: 0.434161  g_loss: 3.269219\n",
      "batch 12  d_loss: 0.470730  g_loss: 2.947762\n",
      "batch 13  d_loss: 0.310468  g_loss: 2.621694\n",
      "batch 14  d_loss: 0.408573  g_loss: 2.174077\n",
      "batch 15  d_loss: 0.472576  g_loss: 1.824091\n",
      "batch 16  d_loss: 0.268965  g_loss: 2.027534\n",
      "batch 17  d_loss: 0.420576  g_loss: 2.366118\n",
      "batch 18  d_loss: 0.286729  g_loss: 2.783166\n",
      "batch 19  d_loss: 0.240880  g_loss: 2.618719\n",
      "batch 20  d_loss: 0.533992  g_loss: 2.741453\n",
      "batch 21  d_loss: 0.405506  g_loss: 1.833830\n",
      "batch 22  d_loss: 0.316301  g_loss: 1.993622\n",
      "batch 23  d_loss: 0.268305  g_loss: 1.954121\n",
      "batch 24  d_loss: 0.367356  g_loss: 3.122502\n",
      "batch 25  d_loss: 0.212231  g_loss: 3.623505\n",
      "batch 26  d_loss: 0.320553  g_loss: 3.240364\n",
      "batch 27  d_loss: 0.208748  g_loss: 2.662642\n",
      "batch 28  d_loss: 0.280557  g_loss: 1.590772\n",
      "batch 29  d_loss: 0.329022  g_loss: 1.721596\n",
      "batch 30  d_loss: 0.373897  g_loss: 2.068294\n",
      "batch 31  d_loss: 0.254829  g_loss: 2.487702\n",
      "batch 32  d_loss: 0.378428  g_loss: 3.315194\n",
      "batch 33  d_loss: 0.293422  g_loss: 3.151629\n",
      "batch 34  d_loss: 0.235605  g_loss: 2.847829\n",
      "batch 35  d_loss: 0.390601  g_loss: 3.039341\n",
      "batch 36  d_loss: 0.532198  g_loss: 2.177510\n",
      "batch 37  d_loss: 0.460823  g_loss: 1.996185\n",
      "batch 38  d_loss: 0.425882  g_loss: 1.886674\n",
      "batch 39  d_loss: 0.298508  g_loss: 2.717094\n",
      "batch 40  d_loss: 0.257729  g_loss: 3.600437\n",
      "batch 41  d_loss: 0.397469  g_loss: 3.418087\n",
      "batch 42  d_loss: 0.331083  g_loss: 2.669338\n",
      "batch 43  d_loss: 0.338180  g_loss: 1.782993\n",
      "batch 44  d_loss: 0.282261  g_loss: 1.244421\n",
      "batch 45  d_loss: 0.522697  g_loss: 1.585522\n",
      "Epoch is 5\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.415304  g_loss: 2.885792\n",
      "batch 1  d_loss: 0.158705  g_loss: 3.982958\n",
      "batch 2  d_loss: 0.593228  g_loss: 3.770858\n",
      "batch 3  d_loss: 0.475664  g_loss: 2.489337\n",
      "batch 4  d_loss: 0.322871  g_loss: 1.613335\n",
      "batch 5  d_loss: 0.324866  g_loss: 1.041141\n",
      "batch 6  d_loss: 0.486703  g_loss: 1.889579\n",
      "batch 7  d_loss: 0.436853  g_loss: 2.618115\n",
      "batch 8  d_loss: 0.246637  g_loss: 3.218610\n",
      "batch 9  d_loss: 0.255788  g_loss: 3.846087\n",
      "batch 10  d_loss: 0.165366  g_loss: 3.754830\n",
      "batch 11  d_loss: 0.412749  g_loss: 3.253198\n",
      "batch 12  d_loss: 0.290518  g_loss: 2.513976\n",
      "batch 13  d_loss: 0.199859  g_loss: 2.105502\n",
      "batch 14  d_loss: 0.283808  g_loss: 1.906319\n",
      "batch 15  d_loss: 0.361925  g_loss: 2.143132\n",
      "batch 16  d_loss: 0.269134  g_loss: 2.915400\n",
      "batch 17  d_loss: 0.302617  g_loss: 3.170299\n",
      "batch 18  d_loss: 0.308975  g_loss: 2.771178\n",
      "batch 19  d_loss: 0.187906  g_loss: 2.785743\n",
      "batch 20  d_loss: 0.382292  g_loss: 2.201116\n",
      "batch 21  d_loss: 0.352915  g_loss: 1.636343\n",
      "batch 22  d_loss: 0.376555  g_loss: 2.085672\n",
      "batch 23  d_loss: 0.382380  g_loss: 2.398252\n",
      "batch 24  d_loss: 0.261249  g_loss: 3.107659\n",
      "batch 25  d_loss: 0.478525  g_loss: 3.016409\n",
      "batch 26  d_loss: 0.321977  g_loss: 2.713361\n",
      "batch 27  d_loss: 0.227175  g_loss: 1.947864\n",
      "batch 28  d_loss: 0.326524  g_loss: 2.154490\n",
      "batch 29  d_loss: 0.554036  g_loss: 2.024453\n",
      "batch 30  d_loss: 0.506102  g_loss: 2.571644\n",
      "batch 31  d_loss: 0.357032  g_loss: 2.480905\n",
      "batch 32  d_loss: 0.601105  g_loss: 2.167111\n",
      "batch 33  d_loss: 0.312430  g_loss: 1.269260\n",
      "batch 34  d_loss: 0.380559  g_loss: 1.604340\n",
      "batch 35  d_loss: 0.355348  g_loss: 2.190341\n",
      "batch 36  d_loss: 0.594172  g_loss: 2.133811\n",
      "batch 37  d_loss: 0.335054  g_loss: 1.737497\n",
      "batch 38  d_loss: 0.312699  g_loss: 1.806876\n",
      "batch 39  d_loss: 0.417915  g_loss: 2.126033\n",
      "batch 40  d_loss: 0.391785  g_loss: 2.743650\n",
      "batch 41  d_loss: 0.551757  g_loss: 1.894160\n",
      "batch 42  d_loss: 0.229925  g_loss: 1.489715\n",
      "batch 43  d_loss: 0.461910  g_loss: 1.661516\n",
      "batch 44  d_loss: 0.576640  g_loss: 1.639926\n",
      "batch 45  d_loss: 0.322805  g_loss: 2.027818\n",
      "Epoch is 6\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.358283  g_loss: 3.234751\n",
      "batch 1  d_loss: 0.261817  g_loss: 3.161172\n",
      "batch 2  d_loss: 0.494533  g_loss: 2.670020\n",
      "batch 3  d_loss: 0.352457  g_loss: 2.195040\n",
      "batch 4  d_loss: 0.417999  g_loss: 1.762050\n",
      "batch 5  d_loss: 0.328871  g_loss: 2.102468\n",
      "batch 6  d_loss: 0.466334  g_loss: 2.367686\n",
      "batch 7  d_loss: 0.744013  g_loss: 2.171303\n",
      "batch 8  d_loss: 0.432523  g_loss: 1.674172\n",
      "batch 9  d_loss: 0.391688  g_loss: 1.764201\n",
      "batch 10  d_loss: 0.273229  g_loss: 2.259654\n",
      "batch 11  d_loss: 0.470009  g_loss: 2.949953\n",
      "batch 12  d_loss: 0.511429  g_loss: 2.192757\n",
      "batch 13  d_loss: 0.355999  g_loss: 1.760566\n",
      "batch 14  d_loss: 0.378631  g_loss: 1.488364\n",
      "batch 15  d_loss: 0.326648  g_loss: 1.590885\n",
      "batch 16  d_loss: 0.450534  g_loss: 1.766204\n",
      "batch 17  d_loss: 0.598585  g_loss: 1.907462\n",
      "batch 18  d_loss: 0.392598  g_loss: 2.127486\n",
      "batch 19  d_loss: 0.269626  g_loss: 2.099328\n",
      "batch 20  d_loss: 0.494328  g_loss: 1.862292\n",
      "batch 21  d_loss: 0.392026  g_loss: 1.818194\n",
      "batch 22  d_loss: 0.439296  g_loss: 1.470784\n",
      "batch 23  d_loss: 0.372236  g_loss: 1.755587\n",
      "batch 24  d_loss: 0.338980  g_loss: 2.446723\n",
      "batch 25  d_loss: 0.358519  g_loss: 2.194171\n",
      "batch 26  d_loss: 0.466547  g_loss: 2.049852\n",
      "batch 27  d_loss: 0.299056  g_loss: 1.568600\n",
      "batch 28  d_loss: 0.441951  g_loss: 1.740370\n",
      "batch 29  d_loss: 0.454991  g_loss: 1.765694\n",
      "batch 30  d_loss: 0.319506  g_loss: 1.787890\n",
      "batch 31  d_loss: 0.302539  g_loss: 2.091571\n",
      "batch 32  d_loss: 0.488352  g_loss: 2.173647\n",
      "batch 33  d_loss: 0.302454  g_loss: 2.030045\n",
      "batch 34  d_loss: 0.299401  g_loss: 2.144203\n",
      "batch 35  d_loss: 0.326965  g_loss: 1.836343\n",
      "batch 36  d_loss: 0.522900  g_loss: 1.748060\n",
      "batch 37  d_loss: 0.464070  g_loss: 1.541857\n",
      "batch 38  d_loss: 0.258350  g_loss: 2.084553\n",
      "batch 39  d_loss: 0.275657  g_loss: 2.435594\n",
      "batch 40  d_loss: 0.290891  g_loss: 3.018058\n",
      "batch 41  d_loss: 0.431166  g_loss: 2.534075\n",
      "batch 42  d_loss: 0.273342  g_loss: 2.090557\n",
      "batch 43  d_loss: 0.334302  g_loss: 2.121980\n",
      "batch 44  d_loss: 0.363736  g_loss: 1.816666\n",
      "batch 45  d_loss: 0.304022  g_loss: 2.851917\n",
      "Epoch is 7\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.366051  g_loss: 2.258974\n",
      "batch 1  d_loss: 0.267172  g_loss: 2.608795\n",
      "batch 2  d_loss: 0.374364  g_loss: 2.325721\n",
      "batch 3  d_loss: 0.376794  g_loss: 1.961818\n",
      "batch 4  d_loss: 0.493514  g_loss: 1.900085\n",
      "batch 5  d_loss: 0.445618  g_loss: 1.914728\n",
      "batch 6  d_loss: 0.428997  g_loss: 2.244692\n",
      "batch 7  d_loss: 0.945717  g_loss: 1.216749\n",
      "batch 8  d_loss: 0.836735  g_loss: 1.612662\n",
      "batch 9  d_loss: 0.476759  g_loss: 2.475871\n",
      "batch 10  d_loss: 0.350214  g_loss: 2.583378\n",
      "batch 11  d_loss: 0.511066  g_loss: 1.930393\n",
      "batch 12  d_loss: 0.290649  g_loss: 1.329405\n",
      "batch 13  d_loss: 0.312037  g_loss: 1.491752\n",
      "batch 14  d_loss: 0.375614  g_loss: 1.660680\n",
      "batch 15  d_loss: 0.351444  g_loss: 2.538195\n",
      "batch 16  d_loss: 0.315929  g_loss: 2.175569\n",
      "batch 17  d_loss: 0.447610  g_loss: 1.829263\n",
      "batch 18  d_loss: 0.424174  g_loss: 1.745416\n",
      "batch 19  d_loss: 0.281577  g_loss: 2.004642\n",
      "batch 20  d_loss: 0.499208  g_loss: 2.196242\n",
      "batch 21  d_loss: 0.530849  g_loss: 2.105121\n",
      "batch 22  d_loss: 0.426588  g_loss: 1.377357\n",
      "batch 23  d_loss: 0.432737  g_loss: 1.281313\n",
      "batch 24  d_loss: 0.450765  g_loss: 1.827208\n",
      "batch 25  d_loss: 0.432452  g_loss: 2.243145\n",
      "batch 26  d_loss: 0.436937  g_loss: 2.355075\n",
      "batch 27  d_loss: 0.429054  g_loss: 1.665577\n",
      "batch 28  d_loss: 0.554291  g_loss: 1.876383\n",
      "batch 29  d_loss: 0.477038  g_loss: 1.190811\n",
      "batch 30  d_loss: 0.426884  g_loss: 1.772866\n",
      "batch 31  d_loss: 0.446555  g_loss: 1.812125\n",
      "batch 32  d_loss: 0.561202  g_loss: 2.017530\n",
      "batch 33  d_loss: 0.380364  g_loss: 1.622293\n",
      "batch 34  d_loss: 0.473814  g_loss: 2.013483\n",
      "batch 35  d_loss: 0.540717  g_loss: 1.940724\n",
      "batch 36  d_loss: 0.620057  g_loss: 1.786877\n",
      "batch 37  d_loss: 0.701515  g_loss: 1.555074\n",
      "batch 38  d_loss: 0.407947  g_loss: 1.285453\n",
      "batch 39  d_loss: 0.503102  g_loss: 1.660505\n",
      "batch 40  d_loss: 0.565319  g_loss: 1.797391\n",
      "batch 41  d_loss: 0.488086  g_loss: 2.019389\n",
      "batch 42  d_loss: 0.471662  g_loss: 1.539645\n",
      "batch 43  d_loss: 0.542190  g_loss: 1.302756\n",
      "batch 44  d_loss: 0.408785  g_loss: 1.105635\n",
      "batch 45  d_loss: 0.483509  g_loss: 1.210842\n",
      "Epoch is 8\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.440028  g_loss: 1.840735\n",
      "batch 1  d_loss: 0.294122  g_loss: 2.326426\n",
      "batch 2  d_loss: 0.496934  g_loss: 2.405256\n",
      "batch 3  d_loss: 0.389008  g_loss: 2.123364\n",
      "batch 4  d_loss: 0.444007  g_loss: 1.447074\n",
      "batch 5  d_loss: 0.300414  g_loss: 1.159461\n",
      "batch 6  d_loss: 0.372011  g_loss: 1.202959\n",
      "batch 7  d_loss: 0.444616  g_loss: 1.651453\n",
      "batch 8  d_loss: 0.316262  g_loss: 2.227975\n",
      "batch 9  d_loss: 0.250023  g_loss: 2.794307\n",
      "batch 10  d_loss: 0.196383  g_loss: 3.130052\n",
      "batch 11  d_loss: 0.375296  g_loss: 2.544435\n",
      "batch 12  d_loss: 0.339943  g_loss: 2.102159\n",
      "batch 13  d_loss: 0.214068  g_loss: 1.892901\n",
      "batch 14  d_loss: 0.215120  g_loss: 1.438220\n",
      "batch 15  d_loss: 0.320694  g_loss: 1.685689\n",
      "batch 16  d_loss: 0.265211  g_loss: 2.424219\n",
      "batch 17  d_loss: 0.348064  g_loss: 2.550421\n",
      "batch 18  d_loss: 0.280482  g_loss: 2.921145\n",
      "batch 19  d_loss: 0.202733  g_loss: 2.935562\n",
      "batch 20  d_loss: 0.435262  g_loss: 2.191141\n",
      "batch 21  d_loss: 0.417518  g_loss: 1.673974\n",
      "batch 22  d_loss: 0.278774  g_loss: 1.595757\n",
      "batch 23  d_loss: 0.309362  g_loss: 1.719888\n",
      "batch 24  d_loss: 0.276124  g_loss: 2.441802\n",
      "batch 25  d_loss: 0.317641  g_loss: 2.886325\n",
      "batch 26  d_loss: 0.488181  g_loss: 2.301496\n",
      "batch 27  d_loss: 0.252301  g_loss: 2.015099\n",
      "batch 28  d_loss: 0.405858  g_loss: 1.684941\n",
      "batch 29  d_loss: 0.632065  g_loss: 1.073451\n",
      "batch 30  d_loss: 0.555951  g_loss: 1.723027\n",
      "batch 31  d_loss: 0.485830  g_loss: 2.253395\n",
      "batch 32  d_loss: 0.730743  g_loss: 1.903245\n",
      "batch 33  d_loss: 0.502059  g_loss: 1.192978\n",
      "batch 34  d_loss: 0.512965  g_loss: 0.851816\n",
      "batch 35  d_loss: 0.593146  g_loss: 1.053564\n",
      "batch 36  d_loss: 0.898714  g_loss: 1.812064\n",
      "batch 37  d_loss: 0.617686  g_loss: 1.646775\n",
      "batch 38  d_loss: 0.380720  g_loss: 1.778843\n",
      "batch 39  d_loss: 0.463353  g_loss: 1.652731\n",
      "batch 40  d_loss: 0.471250  g_loss: 1.369143\n",
      "batch 41  d_loss: 0.378944  g_loss: 1.571420\n",
      "batch 42  d_loss: 0.317281  g_loss: 1.805163\n",
      "batch 43  d_loss: 0.301608  g_loss: 2.163112\n",
      "batch 44  d_loss: 0.411079  g_loss: 1.924422\n",
      "batch 45  d_loss: 0.260822  g_loss: 1.772566\n",
      "Epoch is 9\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.309135  g_loss: 2.166018\n",
      "batch 1  d_loss: 0.329261  g_loss: 1.965900\n",
      "batch 2  d_loss: 0.331240  g_loss: 2.769164\n",
      "batch 3  d_loss: 0.304064  g_loss: 2.313629\n",
      "batch 4  d_loss: 0.381266  g_loss: 1.797618\n",
      "batch 5  d_loss: 0.343786  g_loss: 1.335797\n",
      "batch 6  d_loss: 0.472464  g_loss: 1.560536\n",
      "batch 7  d_loss: 0.650520  g_loss: 1.652341\n",
      "batch 8  d_loss: 0.424558  g_loss: 1.513880\n",
      "batch 9  d_loss: 0.305684  g_loss: 2.260551\n",
      "batch 10  d_loss: 0.343933  g_loss: 2.337204\n",
      "batch 11  d_loss: 0.520033  g_loss: 1.913257\n",
      "batch 12  d_loss: 0.458243  g_loss: 1.269051\n",
      "batch 13  d_loss: 0.468002  g_loss: 1.072711\n",
      "batch 14  d_loss: 0.454408  g_loss: 1.369691\n",
      "batch 15  d_loss: 0.592556  g_loss: 1.605303\n",
      "batch 16  d_loss: 0.537585  g_loss: 1.661101\n",
      "batch 17  d_loss: 0.625396  g_loss: 1.587141\n",
      "batch 18  d_loss: 0.522062  g_loss: 1.042464\n",
      "batch 19  d_loss: 0.414283  g_loss: 1.286005\n",
      "batch 20  d_loss: 0.602970  g_loss: 1.151407\n",
      "batch 21  d_loss: 0.534629  g_loss: 1.584271\n",
      "batch 22  d_loss: 0.377134  g_loss: 2.193232\n",
      "batch 23  d_loss: 0.422573  g_loss: 2.091835\n",
      "batch 24  d_loss: 0.385287  g_loss: 1.837737\n",
      "batch 25  d_loss: 0.357552  g_loss: 1.706180\n",
      "batch 26  d_loss: 0.372677  g_loss: 1.601810\n",
      "batch 27  d_loss: 0.314535  g_loss: 1.640679\n",
      "batch 28  d_loss: 0.364966  g_loss: 2.089362\n",
      "batch 29  d_loss: 0.360721  g_loss: 2.153821\n",
      "batch 30  d_loss: 0.358866  g_loss: 2.261398\n",
      "batch 31  d_loss: 0.294275  g_loss: 2.421107\n",
      "batch 32  d_loss: 0.389453  g_loss: 1.824724\n",
      "batch 33  d_loss: 0.461259  g_loss: 1.698352\n",
      "batch 34  d_loss: 0.320717  g_loss: 1.840630\n",
      "batch 35  d_loss: 0.438127  g_loss: 2.190472\n",
      "batch 36  d_loss: 0.504468  g_loss: 2.526298\n",
      "batch 37  d_loss: 0.487160  g_loss: 2.227283\n",
      "batch 38  d_loss: 0.435807  g_loss: 1.979058\n",
      "batch 39  d_loss: 0.436816  g_loss: 1.962319\n",
      "batch 40  d_loss: 0.492313  g_loss: 1.660260\n",
      "batch 41  d_loss: 0.702089  g_loss: 1.259466\n",
      "batch 42  d_loss: 0.567268  g_loss: 1.614585\n",
      "batch 43  d_loss: 0.431119  g_loss: 2.062900\n",
      "batch 44  d_loss: 0.764739  g_loss: 1.148544\n",
      "batch 45  d_loss: 0.461287  g_loss: 1.605045\n",
      "Epoch is 10\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.382374  g_loss: 2.284960\n",
      "batch 1  d_loss: 0.234006  g_loss: 2.655778\n",
      "batch 2  d_loss: 0.417572  g_loss: 2.234620\n",
      "batch 3  d_loss: 0.299530  g_loss: 1.741709\n",
      "batch 4  d_loss: 0.289996  g_loss: 1.329323\n",
      "batch 5  d_loss: 0.327773  g_loss: 1.924967\n",
      "batch 6  d_loss: 0.270086  g_loss: 2.420295\n",
      "batch 7  d_loss: 0.523892  g_loss: 2.459923\n",
      "batch 8  d_loss: 0.261831  g_loss: 2.342573\n",
      "batch 9  d_loss: 0.248739  g_loss: 2.364409\n",
      "batch 10  d_loss: 0.142948  g_loss: 3.299798\n",
      "batch 11  d_loss: 0.326059  g_loss: 3.222699\n",
      "batch 12  d_loss: 0.283574  g_loss: 3.274497\n",
      "batch 13  d_loss: 0.180503  g_loss: 2.657255\n",
      "batch 14  d_loss: 0.234428  g_loss: 2.128838\n",
      "batch 15  d_loss: 0.291845  g_loss: 2.086585\n",
      "batch 16  d_loss: 0.204874  g_loss: 2.628828\n",
      "batch 17  d_loss: 0.383669  g_loss: 3.140246\n",
      "batch 18  d_loss: 0.235666  g_loss: 2.637792\n",
      "batch 19  d_loss: 0.250173  g_loss: 2.792902\n",
      "batch 20  d_loss: 0.261602  g_loss: 2.578217\n",
      "batch 21  d_loss: 0.324966  g_loss: 2.768202\n",
      "batch 22  d_loss: 0.245194  g_loss: 2.593300\n",
      "batch 23  d_loss: 0.250662  g_loss: 2.405686\n",
      "batch 24  d_loss: 0.239973  g_loss: 2.673616\n",
      "batch 25  d_loss: 0.429650  g_loss: 2.448830\n",
      "batch 26  d_loss: 0.393411  g_loss: 2.081769\n",
      "batch 27  d_loss: 0.418361  g_loss: 1.605001\n",
      "batch 28  d_loss: 0.387410  g_loss: 1.940073\n",
      "batch 29  d_loss: 0.698902  g_loss: 1.638216\n",
      "batch 30  d_loss: 0.674742  g_loss: 2.116090\n",
      "batch 31  d_loss: 0.654987  g_loss: 2.401661\n",
      "batch 32  d_loss: 0.689294  g_loss: 1.774227\n",
      "batch 33  d_loss: 0.530837  g_loss: 1.172340\n",
      "batch 34  d_loss: 0.488097  g_loss: 1.347680\n",
      "batch 35  d_loss: 0.423069  g_loss: 1.808375\n",
      "batch 36  d_loss: 0.742459  g_loss: 2.000028\n",
      "batch 37  d_loss: 0.849581  g_loss: 1.243673\n",
      "batch 38  d_loss: 0.535409  g_loss: 0.940494\n",
      "batch 39  d_loss: 0.513799  g_loss: 1.326125\n",
      "batch 40  d_loss: 0.567711  g_loss: 2.426069\n",
      "batch 41  d_loss: 0.518740  g_loss: 2.199744\n",
      "batch 42  d_loss: 0.545902  g_loss: 1.494589\n",
      "batch 43  d_loss: 0.391492  g_loss: 1.104254\n",
      "batch 44  d_loss: 0.478021  g_loss: 1.260918\n",
      "batch 45  d_loss: 0.459434  g_loss: 1.630573\n",
      "Epoch is 11\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.343255  g_loss: 1.852658\n",
      "batch 1  d_loss: 0.363281  g_loss: 1.963233\n",
      "batch 2  d_loss: 0.392448  g_loss: 1.948038\n",
      "batch 3  d_loss: 0.346638  g_loss: 1.922721\n",
      "batch 4  d_loss: 0.335345  g_loss: 1.536578\n",
      "batch 5  d_loss: 0.311953  g_loss: 1.222083\n",
      "batch 6  d_loss: 0.347682  g_loss: 1.512493\n",
      "batch 7  d_loss: 0.760437  g_loss: 1.663053\n",
      "batch 8  d_loss: 0.421663  g_loss: 1.766970\n",
      "batch 9  d_loss: 0.328881  g_loss: 2.024673\n",
      "batch 10  d_loss: 0.268085  g_loss: 2.239499\n",
      "batch 11  d_loss: 0.413726  g_loss: 2.043194\n",
      "batch 12  d_loss: 0.291257  g_loss: 1.733791\n",
      "batch 13  d_loss: 0.273921  g_loss: 1.493755\n",
      "batch 14  d_loss: 0.384395  g_loss: 1.791794\n",
      "batch 15  d_loss: 0.343466  g_loss: 1.857682\n",
      "batch 16  d_loss: 0.296630  g_loss: 2.232337\n",
      "batch 17  d_loss: 0.525120  g_loss: 2.148049\n",
      "batch 18  d_loss: 0.260835  g_loss: 1.780847\n",
      "batch 19  d_loss: 0.297695  g_loss: 1.681304\n",
      "batch 20  d_loss: 0.366180  g_loss: 1.578052\n",
      "batch 21  d_loss: 0.410136  g_loss: 2.027060\n",
      "batch 22  d_loss: 0.414235  g_loss: 1.975706\n",
      "batch 23  d_loss: 0.438926  g_loss: 2.324930\n",
      "batch 24  d_loss: 0.402955  g_loss: 1.660569\n",
      "batch 25  d_loss: 0.547809  g_loss: 1.684458\n",
      "batch 26  d_loss: 0.470858  g_loss: 1.062405\n",
      "batch 27  d_loss: 0.466819  g_loss: 1.198118\n",
      "batch 28  d_loss: 0.678955  g_loss: 1.199131\n",
      "batch 29  d_loss: 0.575006  g_loss: 1.819559\n",
      "batch 30  d_loss: 0.604274  g_loss: 1.700662\n",
      "batch 31  d_loss: 0.539625  g_loss: 1.277191\n",
      "batch 32  d_loss: 0.668488  g_loss: 1.094936\n",
      "batch 33  d_loss: 0.599507  g_loss: 0.831275\n",
      "batch 34  d_loss: 0.582728  g_loss: 1.129335\n",
      "batch 35  d_loss: 0.551801  g_loss: 1.551383\n",
      "batch 36  d_loss: 0.506865  g_loss: 1.643776\n",
      "batch 37  d_loss: 0.492681  g_loss: 1.577297\n",
      "batch 38  d_loss: 0.398133  g_loss: 1.515801\n",
      "batch 39  d_loss: 0.357505  g_loss: 1.748972\n",
      "batch 40  d_loss: 0.352201  g_loss: 1.848526\n",
      "batch 41  d_loss: 0.409170  g_loss: 1.649087\n",
      "batch 42  d_loss: 0.284146  g_loss: 1.540481\n",
      "batch 43  d_loss: 0.281957  g_loss: 1.655384\n",
      "batch 44  d_loss: 0.237188  g_loss: 2.075088\n",
      "batch 45  d_loss: 0.211214  g_loss: 2.273354\n",
      "Epoch is 12\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.189639  g_loss: 2.599985\n",
      "batch 1  d_loss: 0.264623  g_loss: 2.563683\n",
      "batch 2  d_loss: 0.282144  g_loss: 2.335780\n",
      "batch 3  d_loss: 0.228493  g_loss: 2.171048\n",
      "batch 4  d_loss: 0.183662  g_loss: 1.830148\n",
      "batch 5  d_loss: 0.262376  g_loss: 1.866416\n",
      "batch 6  d_loss: 0.279062  g_loss: 2.120118\n",
      "batch 7  d_loss: 0.282132  g_loss: 2.402473\n",
      "batch 8  d_loss: 0.244377  g_loss: 2.843245\n",
      "batch 9  d_loss: 0.136863  g_loss: 3.422284\n",
      "batch 10  d_loss: 0.132830  g_loss: 3.285916\n",
      "batch 11  d_loss: 0.366667  g_loss: 2.725671\n",
      "batch 12  d_loss: 0.299370  g_loss: 1.886963\n",
      "batch 13  d_loss: 0.367962  g_loss: 1.819050\n",
      "batch 14  d_loss: 0.283492  g_loss: 1.989592\n",
      "batch 15  d_loss: 0.351356  g_loss: 2.569246\n",
      "batch 16  d_loss: 0.314975  g_loss: 2.782780\n",
      "batch 17  d_loss: 0.438032  g_loss: 2.269007\n",
      "batch 18  d_loss: 0.321936  g_loss: 1.857176\n",
      "batch 19  d_loss: 0.334544  g_loss: 1.998965\n",
      "batch 20  d_loss: 0.530104  g_loss: 2.061692\n",
      "batch 21  d_loss: 0.469251  g_loss: 2.024118\n",
      "batch 22  d_loss: 0.325219  g_loss: 1.849989\n",
      "batch 23  d_loss: 0.448646  g_loss: 2.057052\n",
      "batch 24  d_loss: 0.408342  g_loss: 1.588463\n",
      "batch 25  d_loss: 0.660179  g_loss: 1.465795\n",
      "batch 26  d_loss: 0.582731  g_loss: 1.791003\n",
      "batch 27  d_loss: 0.441498  g_loss: 1.852133\n",
      "batch 28  d_loss: 0.491194  g_loss: 1.255509\n",
      "batch 29  d_loss: 0.733417  g_loss: 0.882533\n",
      "batch 30  d_loss: 0.658082  g_loss: 1.799955\n",
      "batch 31  d_loss: 0.759795  g_loss: 1.552440\n",
      "batch 32  d_loss: 0.689519  g_loss: 1.019040\n",
      "batch 33  d_loss: 0.617553  g_loss: 1.506746\n",
      "batch 34  d_loss: 0.390405  g_loss: 2.189282\n",
      "batch 35  d_loss: 0.415089  g_loss: 1.923797\n",
      "batch 36  d_loss: 0.571011  g_loss: 1.206899\n",
      "batch 37  d_loss: 0.476567  g_loss: 1.090363\n",
      "batch 38  d_loss: 0.296763  g_loss: 1.461299\n",
      "batch 39  d_loss: 0.325398  g_loss: 2.277304\n",
      "batch 40  d_loss: 0.336742  g_loss: 2.897133\n",
      "batch 41  d_loss: 0.438778  g_loss: 2.523227\n",
      "batch 42  d_loss: 0.216252  g_loss: 1.761211\n",
      "batch 43  d_loss: 0.404944  g_loss: 1.678780\n",
      "batch 44  d_loss: 0.334622  g_loss: 1.979795\n",
      "batch 45  d_loss: 0.254064  g_loss: 2.450110\n",
      "Epoch is 13\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.249393  g_loss: 3.289204\n",
      "batch 1  d_loss: 0.169213  g_loss: 3.133092\n",
      "batch 2  d_loss: 0.370100  g_loss: 3.229996\n",
      "batch 3  d_loss: 0.238496  g_loss: 2.919976\n",
      "batch 4  d_loss: 0.263272  g_loss: 2.055871\n",
      "batch 5  d_loss: 0.273481  g_loss: 2.373864\n",
      "batch 6  d_loss: 0.409292  g_loss: 2.442523\n",
      "batch 7  d_loss: 0.492579  g_loss: 2.137952\n",
      "batch 8  d_loss: 0.391901  g_loss: 1.789972\n",
      "batch 9  d_loss: 0.371937  g_loss: 2.071076\n",
      "batch 10  d_loss: 0.255347  g_loss: 2.435875\n",
      "batch 11  d_loss: 0.377437  g_loss: 2.350491\n",
      "batch 12  d_loss: 0.469566  g_loss: 2.414901\n",
      "batch 13  d_loss: 0.278735  g_loss: 2.087771\n",
      "batch 14  d_loss: 0.347571  g_loss: 1.814115\n",
      "batch 15  d_loss: 0.283191  g_loss: 1.557731\n",
      "batch 16  d_loss: 0.392416  g_loss: 1.663462\n",
      "batch 17  d_loss: 0.587984  g_loss: 1.358670\n",
      "batch 18  d_loss: 0.450879  g_loss: 1.557897\n",
      "batch 19  d_loss: 0.400732  g_loss: 2.103550\n",
      "batch 20  d_loss: 0.451635  g_loss: 2.225121\n",
      "batch 21  d_loss: 0.332244  g_loss: 1.949647\n",
      "batch 22  d_loss: 0.480072  g_loss: 1.428700\n",
      "batch 23  d_loss: 0.448760  g_loss: 1.238058\n",
      "batch 24  d_loss: 0.405979  g_loss: 1.377107\n",
      "batch 25  d_loss: 0.406597  g_loss: 1.616140\n",
      "batch 26  d_loss: 0.443246  g_loss: 2.034037\n",
      "batch 27  d_loss: 0.369605  g_loss: 1.645111\n",
      "batch 28  d_loss: 0.409163  g_loss: 1.198418\n",
      "batch 29  d_loss: 0.390742  g_loss: 1.104562\n",
      "batch 30  d_loss: 0.499351  g_loss: 1.447170\n",
      "batch 31  d_loss: 0.406321  g_loss: 1.781580\n",
      "batch 32  d_loss: 0.432274  g_loss: 2.177211\n",
      "batch 33  d_loss: 0.415903  g_loss: 1.652026\n",
      "batch 34  d_loss: 0.516140  g_loss: 1.451683\n",
      "batch 35  d_loss: 0.475024  g_loss: 0.871136\n",
      "batch 36  d_loss: 0.513422  g_loss: 0.937512\n",
      "batch 37  d_loss: 0.533948  g_loss: 1.595076\n",
      "batch 38  d_loss: 0.301547  g_loss: 1.987154\n",
      "batch 39  d_loss: 0.351438  g_loss: 2.194385\n",
      "batch 40  d_loss: 0.370688  g_loss: 2.102023\n",
      "batch 41  d_loss: 0.439444  g_loss: 1.696536\n",
      "batch 42  d_loss: 0.398427  g_loss: 1.371215\n",
      "batch 43  d_loss: 0.270004  g_loss: 1.430714\n",
      "batch 44  d_loss: 0.367391  g_loss: 1.565240\n",
      "batch 45  d_loss: 0.236858  g_loss: 2.020594\n",
      "Epoch is 14\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.270448  g_loss: 2.435110\n",
      "batch 1  d_loss: 0.250960  g_loss: 2.432807\n",
      "batch 2  d_loss: 0.352530  g_loss: 2.029268\n",
      "batch 3  d_loss: 0.293299  g_loss: 1.336665\n",
      "batch 4  d_loss: 0.353608  g_loss: 1.264129\n",
      "batch 5  d_loss: 0.530194  g_loss: 1.727914\n",
      "batch 6  d_loss: 0.393908  g_loss: 2.296366\n",
      "batch 7  d_loss: 0.879371  g_loss: 2.365485\n",
      "batch 8  d_loss: 0.540309  g_loss: 2.137408\n",
      "batch 9  d_loss: 0.392062  g_loss: 1.795666\n",
      "batch 10  d_loss: 0.294395  g_loss: 1.405855\n",
      "batch 11  d_loss: 0.518250  g_loss: 1.547848\n",
      "batch 12  d_loss: 0.422564  g_loss: 1.659873\n",
      "batch 13  d_loss: 0.374081  g_loss: 1.912902\n",
      "batch 14  d_loss: 0.464012  g_loss: 1.763780\n",
      "batch 15  d_loss: 0.427314  g_loss: 1.402422\n",
      "batch 16  d_loss: 0.378087  g_loss: 1.196166\n",
      "batch 17  d_loss: 0.533058  g_loss: 0.849925\n",
      "batch 18  d_loss: 0.514229  g_loss: 1.340724\n",
      "batch 19  d_loss: 0.331777  g_loss: 1.886505\n",
      "batch 20  d_loss: 0.604927  g_loss: 1.958512\n",
      "batch 21  d_loss: 0.536694  g_loss: 1.468957\n",
      "batch 22  d_loss: 0.494229  g_loss: 1.331440\n",
      "batch 23  d_loss: 0.476630  g_loss: 1.001187\n",
      "batch 24  d_loss: 0.411532  g_loss: 1.362017\n",
      "batch 25  d_loss: 0.527547  g_loss: 1.278463\n",
      "batch 26  d_loss: 0.520138  g_loss: 1.328944\n",
      "batch 27  d_loss: 0.537897  g_loss: 1.566756\n",
      "batch 28  d_loss: 0.527979  g_loss: 1.380358\n",
      "batch 29  d_loss: 0.405087  g_loss: 1.465028\n",
      "batch 30  d_loss: 0.408961  g_loss: 1.196000\n",
      "batch 31  d_loss: 0.485389  g_loss: 1.167943\n",
      "batch 32  d_loss: 0.497773  g_loss: 1.393728\n",
      "batch 33  d_loss: 0.418658  g_loss: 1.459558\n",
      "batch 34  d_loss: 0.452376  g_loss: 1.698230\n",
      "batch 35  d_loss: 0.435861  g_loss: 1.274875\n",
      "batch 36  d_loss: 0.512712  g_loss: 1.475783\n",
      "batch 37  d_loss: 0.505332  g_loss: 1.348278\n",
      "batch 38  d_loss: 0.350748  g_loss: 1.962180\n",
      "batch 39  d_loss: 0.320794  g_loss: 2.027073\n",
      "batch 40  d_loss: 0.335596  g_loss: 2.313890\n",
      "batch 41  d_loss: 0.449771  g_loss: 1.869209\n",
      "batch 42  d_loss: 0.342793  g_loss: 1.433643\n",
      "batch 43  d_loss: 0.300087  g_loss: 1.622974\n",
      "batch 44  d_loss: 0.374370  g_loss: 2.100921\n",
      "batch 45  d_loss: 0.203907  g_loss: 2.670908\n",
      "Epoch is 15\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.275840  g_loss: 2.625662\n",
      "batch 1  d_loss: 0.252767  g_loss: 2.435791\n",
      "batch 2  d_loss: 0.292279  g_loss: 1.850048\n",
      "batch 3  d_loss: 0.267665  g_loss: 1.364104\n",
      "batch 4  d_loss: 0.320796  g_loss: 1.784898\n",
      "batch 5  d_loss: 0.351481  g_loss: 2.534001\n",
      "batch 6  d_loss: 0.264547  g_loss: 2.484876\n",
      "batch 7  d_loss: 0.581790  g_loss: 1.766261\n",
      "batch 8  d_loss: 0.360605  g_loss: 1.645720\n",
      "batch 9  d_loss: 0.274830  g_loss: 1.545432\n",
      "batch 10  d_loss: 0.261223  g_loss: 2.528789\n",
      "batch 11  d_loss: 0.444345  g_loss: 2.290765\n",
      "batch 12  d_loss: 0.372139  g_loss: 2.153784\n",
      "batch 13  d_loss: 0.321563  g_loss: 1.498182\n",
      "batch 14  d_loss: 0.327207  g_loss: 1.509186\n",
      "batch 15  d_loss: 0.442456  g_loss: 1.591326\n",
      "batch 16  d_loss: 0.357542  g_loss: 1.858592\n",
      "batch 17  d_loss: 0.486306  g_loss: 1.519653\n",
      "batch 18  d_loss: 0.369421  g_loss: 1.695691\n",
      "batch 19  d_loss: 0.296853  g_loss: 1.677814\n",
      "batch 20  d_loss: 0.485851  g_loss: 1.688406\n",
      "batch 21  d_loss: 0.424217  g_loss: 1.673941\n",
      "batch 22  d_loss: 0.421224  g_loss: 1.419638\n",
      "batch 23  d_loss: 0.391844  g_loss: 1.831471\n",
      "batch 24  d_loss: 0.260602  g_loss: 2.076520\n",
      "batch 25  d_loss: 0.364237  g_loss: 2.081609\n",
      "batch 26  d_loss: 0.374107  g_loss: 1.683216\n",
      "batch 27  d_loss: 0.276141  g_loss: 1.232273\n",
      "batch 28  d_loss: 0.401523  g_loss: 1.286329\n",
      "batch 29  d_loss: 0.540042  g_loss: 1.685015\n",
      "batch 30  d_loss: 0.483320  g_loss: 1.606393\n",
      "batch 31  d_loss: 0.309383  g_loss: 1.678860\n",
      "batch 32  d_loss: 0.280471  g_loss: 1.844964\n",
      "batch 33  d_loss: 0.335733  g_loss: 1.663460\n",
      "batch 34  d_loss: 0.285992  g_loss: 1.477106\n",
      "batch 35  d_loss: 0.306067  g_loss: 1.505195\n",
      "batch 36  d_loss: 0.417617  g_loss: 2.172825\n",
      "batch 37  d_loss: 0.394862  g_loss: 1.926036\n",
      "batch 38  d_loss: 0.275226  g_loss: 1.816103\n",
      "batch 39  d_loss: 0.213921  g_loss: 1.993524\n",
      "batch 40  d_loss: 0.309253  g_loss: 1.990706\n",
      "batch 41  d_loss: 0.256357  g_loss: 1.772683\n",
      "batch 42  d_loss: 0.340026  g_loss: 2.251205\n",
      "batch 43  d_loss: 0.274601  g_loss: 2.199208\n",
      "batch 44  d_loss: 0.249889  g_loss: 2.315524\n",
      "batch 45  d_loss: 0.187116  g_loss: 2.412327\n",
      "Epoch is 16\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.161753  g_loss: 2.770871\n",
      "batch 1  d_loss: 0.173561  g_loss: 2.735430\n",
      "batch 2  d_loss: 0.247286  g_loss: 2.265825\n",
      "batch 3  d_loss: 0.220724  g_loss: 2.311721\n",
      "batch 4  d_loss: 0.302485  g_loss: 2.008221\n",
      "batch 5  d_loss: 0.279414  g_loss: 2.097315\n",
      "batch 6  d_loss: 0.265806  g_loss: 2.119554\n",
      "batch 7  d_loss: 0.626967  g_loss: 1.779445\n",
      "batch 8  d_loss: 0.420399  g_loss: 1.479789\n",
      "batch 9  d_loss: 0.432170  g_loss: 2.640134\n",
      "batch 10  d_loss: 0.194128  g_loss: 2.941960\n",
      "batch 11  d_loss: 0.616477  g_loss: 2.431341\n",
      "batch 12  d_loss: 0.424916  g_loss: 1.276768\n",
      "batch 13  d_loss: 0.370214  g_loss: 1.384410\n",
      "batch 14  d_loss: 0.360433  g_loss: 1.743838\n",
      "batch 15  d_loss: 0.358827  g_loss: 1.867728\n",
      "batch 16  d_loss: 0.348929  g_loss: 2.068256\n",
      "batch 17  d_loss: 0.557596  g_loss: 2.009441\n",
      "batch 18  d_loss: 0.522215  g_loss: 1.711389\n",
      "batch 19  d_loss: 0.263818  g_loss: 1.552990\n",
      "batch 20  d_loss: 0.410632  g_loss: 1.366322\n",
      "batch 21  d_loss: 0.451505  g_loss: 1.607138\n",
      "batch 22  d_loss: 0.362011  g_loss: 1.965538\n",
      "batch 23  d_loss: 0.334011  g_loss: 2.121673\n",
      "batch 24  d_loss: 0.345190  g_loss: 1.660207\n",
      "batch 25  d_loss: 0.325640  g_loss: 1.417744\n",
      "batch 26  d_loss: 0.424716  g_loss: 1.744557\n",
      "batch 27  d_loss: 0.309209  g_loss: 2.503531\n",
      "batch 28  d_loss: 0.425843  g_loss: 2.540567\n",
      "batch 29  d_loss: 0.502125  g_loss: 2.034840\n",
      "batch 30  d_loss: 0.248420  g_loss: 1.436726\n",
      "batch 31  d_loss: 0.375696  g_loss: 1.128617\n",
      "batch 32  d_loss: 0.389356  g_loss: 1.364934\n",
      "batch 33  d_loss: 0.542774  g_loss: 2.080516\n",
      "batch 34  d_loss: 0.373585  g_loss: 2.397320\n",
      "batch 35  d_loss: 0.395716  g_loss: 1.820993\n",
      "batch 36  d_loss: 0.420660  g_loss: 1.941736\n",
      "batch 37  d_loss: 0.379220  g_loss: 1.129817\n",
      "batch 38  d_loss: 0.353207  g_loss: 1.919803\n",
      "batch 39  d_loss: 0.265564  g_loss: 2.542513\n",
      "batch 40  d_loss: 0.212890  g_loss: 2.774209\n",
      "batch 41  d_loss: 0.414582  g_loss: 2.368074\n",
      "batch 42  d_loss: 0.240377  g_loss: 1.654631\n",
      "batch 43  d_loss: 0.269301  g_loss: 1.683141\n",
      "batch 44  d_loss: 0.298184  g_loss: 2.218929\n",
      "batch 45  d_loss: 0.168392  g_loss: 2.877494\n",
      "Epoch is 17\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.215866  g_loss: 3.260490\n",
      "batch 1  d_loss: 0.263870  g_loss: 3.281671\n",
      "batch 2  d_loss: 0.346486  g_loss: 2.269495\n",
      "batch 3  d_loss: 0.279166  g_loss: 1.668414\n",
      "batch 4  d_loss: 0.236395  g_loss: 1.320930\n",
      "batch 5  d_loss: 0.290844  g_loss: 1.966527\n",
      "batch 6  d_loss: 0.225970  g_loss: 2.334915\n",
      "batch 7  d_loss: 0.363940  g_loss: 2.490101\n",
      "batch 8  d_loss: 0.286472  g_loss: 2.209782\n",
      "batch 9  d_loss: 0.193752  g_loss: 2.045566\n",
      "batch 10  d_loss: 0.305080  g_loss: 2.142967\n",
      "batch 11  d_loss: 0.342631  g_loss: 2.195161\n",
      "batch 12  d_loss: 0.280404  g_loss: 2.389012\n",
      "batch 13  d_loss: 0.303129  g_loss: 2.329258\n",
      "batch 14  d_loss: 0.413364  g_loss: 1.756285\n",
      "batch 15  d_loss: 0.416748  g_loss: 1.263114\n",
      "batch 16  d_loss: 0.420393  g_loss: 1.988756\n",
      "batch 17  d_loss: 0.411734  g_loss: 2.232422\n",
      "batch 18  d_loss: 0.364880  g_loss: 2.248679\n",
      "batch 19  d_loss: 0.332246  g_loss: 2.085025\n",
      "batch 20  d_loss: 0.427329  g_loss: 1.312680\n",
      "batch 21  d_loss: 0.380476  g_loss: 1.408218\n",
      "batch 22  d_loss: 0.282177  g_loss: 1.908972\n",
      "batch 23  d_loss: 0.298801  g_loss: 2.531513\n",
      "batch 24  d_loss: 0.224436  g_loss: 2.509688\n",
      "batch 25  d_loss: 0.350066  g_loss: 2.090701\n",
      "batch 26  d_loss: 0.364448  g_loss: 1.838659\n",
      "batch 27  d_loss: 0.242835  g_loss: 1.887012\n",
      "batch 28  d_loss: 0.299204  g_loss: 2.056093\n",
      "batch 29  d_loss: 0.313791  g_loss: 1.998621\n",
      "batch 30  d_loss: 0.294558  g_loss: 2.210589\n",
      "batch 31  d_loss: 0.172605  g_loss: 1.980332\n",
      "batch 32  d_loss: 0.214566  g_loss: 2.076848\n",
      "batch 33  d_loss: 0.196369  g_loss: 2.801902\n",
      "batch 34  d_loss: 0.258016  g_loss: 2.415902\n",
      "batch 35  d_loss: 0.200394  g_loss: 2.300641\n",
      "batch 36  d_loss: 0.438182  g_loss: 1.792773\n",
      "batch 37  d_loss: 0.463731  g_loss: 1.539960\n",
      "batch 38  d_loss: 0.431910  g_loss: 2.036657\n",
      "batch 39  d_loss: 0.290325  g_loss: 2.787359\n",
      "batch 40  d_loss: 0.207259  g_loss: 3.743843\n",
      "batch 41  d_loss: 0.549107  g_loss: 3.256956\n",
      "batch 42  d_loss: 0.323787  g_loss: 1.712972\n",
      "batch 43  d_loss: 0.305174  g_loss: 1.314711\n",
      "batch 44  d_loss: 0.260521  g_loss: 2.085745\n",
      "batch 45  d_loss: 0.213717  g_loss: 2.860818\n",
      "Epoch is 18\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.216003  g_loss: 3.782783\n",
      "batch 1  d_loss: 0.413821  g_loss: 3.363193\n",
      "batch 2  d_loss: 0.299889  g_loss: 2.275877\n",
      "batch 3  d_loss: 0.188869  g_loss: 1.897965\n",
      "batch 4  d_loss: 0.343692  g_loss: 1.825021\n",
      "batch 5  d_loss: 0.224914  g_loss: 2.240719\n",
      "batch 6  d_loss: 0.199302  g_loss: 2.797647\n",
      "batch 7  d_loss: 0.879101  g_loss: 2.162611\n",
      "batch 8  d_loss: 0.489932  g_loss: 1.477301\n",
      "batch 9  d_loss: 0.338900  g_loss: 1.413461\n",
      "batch 10  d_loss: 0.304601  g_loss: 2.068538\n",
      "batch 11  d_loss: 0.334039  g_loss: 2.191093\n",
      "batch 12  d_loss: 0.366777  g_loss: 2.313523\n",
      "batch 13  d_loss: 0.329886  g_loss: 1.737793\n",
      "batch 14  d_loss: 0.252936  g_loss: 1.426197\n",
      "batch 15  d_loss: 0.327221  g_loss: 1.239490\n",
      "batch 16  d_loss: 0.340355  g_loss: 1.297341\n",
      "batch 17  d_loss: 0.392809  g_loss: 1.908093\n",
      "batch 18  d_loss: 0.319021  g_loss: 1.789135\n",
      "batch 19  d_loss: 0.285208  g_loss: 2.286269\n",
      "batch 20  d_loss: 0.517707  g_loss: 1.817924\n",
      "batch 21  d_loss: 0.284279  g_loss: 1.669118\n",
      "batch 22  d_loss: 0.314126  g_loss: 1.544857\n",
      "batch 23  d_loss: 0.349762  g_loss: 1.436375\n",
      "batch 24  d_loss: 0.311664  g_loss: 1.827679\n",
      "batch 25  d_loss: 0.310031  g_loss: 2.309037\n",
      "batch 26  d_loss: 0.281042  g_loss: 2.132030\n",
      "batch 27  d_loss: 0.200531  g_loss: 1.927308\n",
      "batch 28  d_loss: 0.253585  g_loss: 1.753960\n",
      "batch 29  d_loss: 0.353918  g_loss: 1.515766\n",
      "batch 30  d_loss: 0.334005  g_loss: 1.926178\n",
      "batch 31  d_loss: 0.314272  g_loss: 2.026277\n",
      "batch 32  d_loss: 0.226191  g_loss: 1.987906\n",
      "batch 33  d_loss: 0.306873  g_loss: 1.971845\n",
      "batch 34  d_loss: 0.345289  g_loss: 1.822026\n",
      "batch 35  d_loss: 0.270309  g_loss: 1.781121\n",
      "batch 36  d_loss: 0.476194  g_loss: 1.581791\n",
      "batch 37  d_loss: 0.429037  g_loss: 1.397639\n",
      "batch 38  d_loss: 0.437616  g_loss: 1.758006\n",
      "batch 39  d_loss: 0.186594  g_loss: 2.427439\n",
      "batch 40  d_loss: 0.184801  g_loss: 2.898751\n",
      "batch 41  d_loss: 0.354757  g_loss: 2.687462\n",
      "batch 42  d_loss: 0.446635  g_loss: 2.031954\n",
      "batch 43  d_loss: 0.251140  g_loss: 2.154044\n",
      "batch 44  d_loss: 0.270951  g_loss: 2.266251\n",
      "batch 45  d_loss: 0.220411  g_loss: 2.291551\n",
      "Epoch is 19\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.202126  g_loss: 2.986321\n",
      "batch 1  d_loss: 0.209986  g_loss: 3.706560\n",
      "batch 2  d_loss: 0.411991  g_loss: 2.864096\n",
      "batch 3  d_loss: 0.190250  g_loss: 1.191199\n",
      "batch 4  d_loss: 0.297974  g_loss: 1.534842\n",
      "batch 5  d_loss: 0.366529  g_loss: 1.937075\n",
      "batch 6  d_loss: 0.245754  g_loss: 2.886664\n",
      "batch 7  d_loss: 0.717969  g_loss: 3.217664\n",
      "batch 8  d_loss: 0.472093  g_loss: 2.604897\n",
      "batch 9  d_loss: 0.260952  g_loss: 2.304236\n",
      "batch 10  d_loss: 0.229372  g_loss: 1.836184\n",
      "batch 11  d_loss: 0.386468  g_loss: 1.425004\n",
      "batch 12  d_loss: 0.374680  g_loss: 1.637810\n",
      "batch 13  d_loss: 0.351887  g_loss: 2.317726\n",
      "batch 14  d_loss: 0.257424  g_loss: 2.478693\n",
      "batch 15  d_loss: 0.415630  g_loss: 2.167208\n",
      "batch 16  d_loss: 0.300027  g_loss: 2.026577\n",
      "batch 17  d_loss: 0.459771  g_loss: 1.499084\n",
      "batch 18  d_loss: 0.319241  g_loss: 1.314167\n",
      "batch 19  d_loss: 0.343729  g_loss: 1.814707\n",
      "batch 20  d_loss: 0.365812  g_loss: 2.089147\n",
      "batch 21  d_loss: 0.322609  g_loss: 2.425147\n",
      "batch 22  d_loss: 0.352780  g_loss: 2.662421\n",
      "batch 23  d_loss: 0.381173  g_loss: 2.098851\n",
      "batch 24  d_loss: 0.273369  g_loss: 1.758196\n",
      "batch 25  d_loss: 0.281714  g_loss: 1.334450\n",
      "batch 26  d_loss: 0.320806  g_loss: 1.554921\n",
      "batch 27  d_loss: 0.269311  g_loss: 1.792989\n",
      "batch 28  d_loss: 0.311144  g_loss: 1.988102\n",
      "batch 29  d_loss: 0.382634  g_loss: 2.369450\n",
      "batch 30  d_loss: 0.364137  g_loss: 1.776963\n",
      "batch 31  d_loss: 0.264170  g_loss: 1.643476\n",
      "batch 32  d_loss: 0.279090  g_loss: 1.547686\n",
      "batch 33  d_loss: 0.360047  g_loss: 1.794958\n",
      "batch 34  d_loss: 0.266479  g_loss: 2.264591\n",
      "batch 35  d_loss: 0.241556  g_loss: 2.447138\n",
      "batch 36  d_loss: 0.404946  g_loss: 1.738553\n",
      "batch 37  d_loss: 0.401326  g_loss: 1.461877\n",
      "batch 38  d_loss: 0.329022  g_loss: 1.843032\n",
      "batch 39  d_loss: 0.275352  g_loss: 2.207340\n",
      "batch 40  d_loss: 0.300684  g_loss: 2.965246\n",
      "batch 41  d_loss: 0.354979  g_loss: 2.660911\n",
      "batch 42  d_loss: 0.355801  g_loss: 1.887615\n",
      "batch 43  d_loss: 0.260382  g_loss: 1.640819\n",
      "batch 44  d_loss: 0.359715  g_loss: 2.174586\n",
      "batch 45  d_loss: 0.187457  g_loss: 2.355062\n",
      "Epoch is 20\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.176339  g_loss: 2.864087\n",
      "batch 1  d_loss: 0.297874  g_loss: 2.958817\n",
      "batch 2  d_loss: 0.328852  g_loss: 2.422956\n",
      "batch 3  d_loss: 0.300080  g_loss: 1.889845\n",
      "batch 4  d_loss: 0.281974  g_loss: 1.366018\n",
      "batch 5  d_loss: 0.260492  g_loss: 1.643031\n",
      "batch 6  d_loss: 0.227304  g_loss: 1.973144\n",
      "batch 7  d_loss: 0.719423  g_loss: 2.159848\n",
      "batch 8  d_loss: 0.463468  g_loss: 1.893357\n",
      "batch 9  d_loss: 0.240743  g_loss: 2.344730\n",
      "batch 10  d_loss: 0.270272  g_loss: 2.072787\n",
      "batch 11  d_loss: 0.434635  g_loss: 1.878247\n",
      "batch 12  d_loss: 0.352925  g_loss: 1.669316\n",
      "batch 13  d_loss: 0.332921  g_loss: 1.604428\n",
      "batch 14  d_loss: 0.392879  g_loss: 1.496475\n",
      "batch 15  d_loss: 0.280256  g_loss: 1.474768\n",
      "batch 16  d_loss: 0.419758  g_loss: 2.160234\n",
      "batch 17  d_loss: 0.417295  g_loss: 2.091974\n",
      "batch 18  d_loss: 0.291075  g_loss: 2.039588\n",
      "batch 19  d_loss: 0.268279  g_loss: 1.673860\n",
      "batch 20  d_loss: 0.404323  g_loss: 1.288017\n",
      "batch 21  d_loss: 0.303454  g_loss: 1.240219\n",
      "batch 22  d_loss: 0.276089  g_loss: 1.576327\n",
      "batch 23  d_loss: 0.246695  g_loss: 1.870110\n",
      "batch 24  d_loss: 0.236712  g_loss: 2.064381\n",
      "batch 25  d_loss: 0.237013  g_loss: 2.080521\n",
      "batch 26  d_loss: 0.288943  g_loss: 1.727944\n",
      "batch 27  d_loss: 0.181037  g_loss: 1.830787\n",
      "batch 28  d_loss: 0.246996  g_loss: 1.714347\n",
      "batch 29  d_loss: 0.274777  g_loss: 1.551415\n",
      "batch 30  d_loss: 0.275099  g_loss: 1.832573\n",
      "batch 31  d_loss: 0.326217  g_loss: 2.321802\n",
      "batch 32  d_loss: 0.227936  g_loss: 2.597821\n",
      "batch 33  d_loss: 0.406520  g_loss: 2.038877\n",
      "batch 34  d_loss: 0.348349  g_loss: 1.755012\n",
      "batch 35  d_loss: 0.236280  g_loss: 1.585440\n",
      "batch 36  d_loss: 0.419353  g_loss: 1.811533\n",
      "batch 37  d_loss: 0.422959  g_loss: 1.801445\n",
      "batch 38  d_loss: 0.264421  g_loss: 2.622816\n",
      "batch 39  d_loss: 0.189454  g_loss: 2.623542\n",
      "batch 40  d_loss: 0.249401  g_loss: 2.880065\n",
      "batch 41  d_loss: 0.295308  g_loss: 2.662194\n",
      "batch 42  d_loss: 0.314430  g_loss: 1.803320\n",
      "batch 43  d_loss: 0.194805  g_loss: 1.777682\n",
      "batch 44  d_loss: 0.269374  g_loss: 1.400439\n",
      "batch 45  d_loss: 0.203199  g_loss: 2.161959\n",
      "Epoch is 21\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.179704  g_loss: 2.751332\n",
      "batch 1  d_loss: 0.169092  g_loss: 3.369067\n",
      "batch 2  d_loss: 0.373063  g_loss: 3.111112\n",
      "batch 3  d_loss: 0.263295  g_loss: 2.718077\n",
      "batch 4  d_loss: 0.249437  g_loss: 1.769907\n",
      "batch 5  d_loss: 0.276446  g_loss: 1.316592\n",
      "batch 6  d_loss: 0.359330  g_loss: 2.078365\n",
      "batch 7  d_loss: 0.712945  g_loss: 2.697840\n",
      "batch 8  d_loss: 0.459968  g_loss: 2.654010\n",
      "batch 9  d_loss: 0.215070  g_loss: 2.465974\n",
      "batch 10  d_loss: 0.191727  g_loss: 1.896133\n",
      "batch 11  d_loss: 0.358618  g_loss: 1.372985\n",
      "batch 12  d_loss: 0.369010  g_loss: 1.274734\n",
      "batch 13  d_loss: 0.352430  g_loss: 1.335145\n",
      "batch 14  d_loss: 0.362936  g_loss: 2.173110\n",
      "batch 15  d_loss: 0.382791  g_loss: 2.362923\n",
      "batch 16  d_loss: 0.311953  g_loss: 2.090604\n",
      "batch 17  d_loss: 0.366484  g_loss: 2.137578\n",
      "batch 18  d_loss: 0.200370  g_loss: 1.546789\n",
      "batch 19  d_loss: 0.268232  g_loss: 1.584931\n",
      "batch 20  d_loss: 0.381440  g_loss: 2.055759\n",
      "batch 21  d_loss: 0.213393  g_loss: 2.186292\n",
      "batch 22  d_loss: 0.251827  g_loss: 2.655121\n",
      "batch 23  d_loss: 0.290285  g_loss: 2.213356\n",
      "batch 24  d_loss: 0.252680  g_loss: 2.107796\n",
      "batch 25  d_loss: 0.293160  g_loss: 1.748782\n",
      "batch 26  d_loss: 0.293098  g_loss: 1.915502\n",
      "batch 27  d_loss: 0.243047  g_loss: 2.056599\n",
      "batch 28  d_loss: 0.278940  g_loss: 2.540401\n",
      "batch 29  d_loss: 0.298391  g_loss: 2.564477\n",
      "batch 30  d_loss: 0.223993  g_loss: 2.681303\n",
      "batch 31  d_loss: 0.313568  g_loss: 1.848203\n",
      "batch 32  d_loss: 0.311464  g_loss: 1.679358\n",
      "batch 33  d_loss: 0.343923  g_loss: 1.834678\n",
      "batch 34  d_loss: 0.270650  g_loss: 2.288385\n",
      "batch 35  d_loss: 0.189974  g_loss: 2.214071\n",
      "batch 36  d_loss: 0.236835  g_loss: 2.273911\n",
      "batch 37  d_loss: 0.326956  g_loss: 2.156190\n",
      "batch 38  d_loss: 0.166642  g_loss: 1.977033\n",
      "batch 39  d_loss: 0.188324  g_loss: 2.080229\n",
      "batch 40  d_loss: 0.190907  g_loss: 2.435024\n",
      "batch 41  d_loss: 0.259723  g_loss: 2.926495\n",
      "batch 42  d_loss: 0.289549  g_loss: 2.824324\n",
      "batch 43  d_loss: 0.227746  g_loss: 2.750726\n",
      "batch 44  d_loss: 0.175782  g_loss: 2.429717\n",
      "batch 45  d_loss: 0.206363  g_loss: 2.605160\n",
      "Epoch is 22\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.206127  g_loss: 2.429974\n",
      "batch 1  d_loss: 0.201848  g_loss: 3.204506\n",
      "batch 2  d_loss: 0.192819  g_loss: 2.034134\n",
      "batch 3  d_loss: 0.180390  g_loss: 2.737870\n",
      "batch 4  d_loss: 0.246115  g_loss: 2.039439\n",
      "batch 5  d_loss: 0.216869  g_loss: 2.599914\n",
      "batch 6  d_loss: 0.208359  g_loss: 2.471183\n",
      "batch 7  d_loss: 0.570013  g_loss: 1.919608\n",
      "batch 8  d_loss: 0.448356  g_loss: 1.327188\n",
      "batch 9  d_loss: 0.275459  g_loss: 2.174003\n",
      "batch 10  d_loss: 0.221345  g_loss: 2.839876\n",
      "batch 11  d_loss: 0.385012  g_loss: 2.517575\n",
      "batch 12  d_loss: 0.400396  g_loss: 1.791206\n",
      "batch 13  d_loss: 0.285512  g_loss: 1.251851\n",
      "batch 14  d_loss: 0.321931  g_loss: 1.439648\n",
      "batch 15  d_loss: 0.301082  g_loss: 1.919827\n",
      "batch 16  d_loss: 0.247827  g_loss: 2.415607\n",
      "batch 17  d_loss: 0.290246  g_loss: 2.665170\n",
      "batch 18  d_loss: 0.293244  g_loss: 2.107513\n",
      "batch 19  d_loss: 0.315833  g_loss: 2.035489\n",
      "batch 20  d_loss: 0.363179  g_loss: 1.884655\n",
      "batch 21  d_loss: 0.224688  g_loss: 1.775384\n",
      "batch 22  d_loss: 0.284756  g_loss: 2.393419\n",
      "batch 23  d_loss: 0.228568  g_loss: 2.446627\n",
      "batch 24  d_loss: 0.222750  g_loss: 2.380908\n",
      "batch 25  d_loss: 0.265101  g_loss: 2.210128\n",
      "batch 26  d_loss: 0.203602  g_loss: 2.104406\n",
      "batch 27  d_loss: 0.150678  g_loss: 1.783633\n",
      "batch 28  d_loss: 0.255477  g_loss: 1.949853\n",
      "batch 29  d_loss: 0.360345  g_loss: 1.897119\n",
      "batch 30  d_loss: 0.335709  g_loss: 2.446616\n",
      "batch 31  d_loss: 0.210568  g_loss: 2.604606\n",
      "batch 32  d_loss: 0.192085  g_loss: 2.621195\n",
      "batch 33  d_loss: 0.383975  g_loss: 2.646572\n",
      "batch 34  d_loss: 0.310965  g_loss: 2.103401\n",
      "batch 35  d_loss: 0.220562  g_loss: 1.341309\n",
      "batch 36  d_loss: 0.480089  g_loss: 1.667079\n",
      "batch 37  d_loss: 0.464834  g_loss: 2.006807\n",
      "batch 38  d_loss: 0.311689  g_loss: 2.505387\n",
      "batch 39  d_loss: 0.216158  g_loss: 3.112349\n",
      "batch 40  d_loss: 0.221664  g_loss: 2.360799\n",
      "batch 41  d_loss: 0.359783  g_loss: 2.277023\n",
      "batch 42  d_loss: 0.247626  g_loss: 1.707364\n",
      "batch 43  d_loss: 0.225781  g_loss: 1.633083\n",
      "batch 44  d_loss: 0.380276  g_loss: 2.209599\n",
      "batch 45  d_loss: 0.165040  g_loss: 2.674217\n",
      "Epoch is 23\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.184879  g_loss: 3.069484\n",
      "batch 1  d_loss: 0.206896  g_loss: 3.092000\n",
      "batch 2  d_loss: 0.239791  g_loss: 2.434330\n",
      "batch 3  d_loss: 0.232411  g_loss: 2.122348\n",
      "batch 4  d_loss: 0.236697  g_loss: 2.111192\n",
      "batch 5  d_loss: 0.271782  g_loss: 2.216431\n",
      "batch 6  d_loss: 0.204127  g_loss: 2.280202\n",
      "batch 7  d_loss: 0.491436  g_loss: 2.419475\n",
      "batch 8  d_loss: 0.311269  g_loss: 2.186920\n",
      "batch 9  d_loss: 0.245600  g_loss: 2.748084\n",
      "batch 10  d_loss: 0.252028  g_loss: 2.602200\n",
      "batch 11  d_loss: 0.281855  g_loss: 2.408356\n",
      "batch 12  d_loss: 0.267292  g_loss: 2.584762\n",
      "batch 13  d_loss: 0.251820  g_loss: 2.155249\n",
      "batch 14  d_loss: 0.291580  g_loss: 1.681011\n",
      "batch 15  d_loss: 0.372025  g_loss: 1.876407\n",
      "batch 16  d_loss: 0.324185  g_loss: 2.386055\n",
      "batch 17  d_loss: 0.290194  g_loss: 2.539363\n",
      "batch 18  d_loss: 0.294816  g_loss: 3.198585\n",
      "batch 19  d_loss: 0.330682  g_loss: 2.433853\n",
      "batch 20  d_loss: 0.329755  g_loss: 1.816385\n",
      "batch 21  d_loss: 0.259020  g_loss: 1.977049\n",
      "batch 22  d_loss: 0.194854  g_loss: 1.983832\n",
      "batch 23  d_loss: 0.228856  g_loss: 2.813956\n",
      "batch 24  d_loss: 0.174517  g_loss: 3.589461\n",
      "batch 25  d_loss: 0.461179  g_loss: 2.884088\n",
      "batch 26  d_loss: 0.243918  g_loss: 1.884066\n",
      "batch 27  d_loss: 0.230023  g_loss: 1.442606\n",
      "batch 28  d_loss: 0.418687  g_loss: 2.502370\n",
      "batch 29  d_loss: 0.346106  g_loss: 2.763284\n",
      "batch 30  d_loss: 0.247017  g_loss: 3.153006\n",
      "batch 31  d_loss: 0.314393  g_loss: 2.325515\n",
      "batch 32  d_loss: 0.193804  g_loss: 1.922127\n",
      "batch 33  d_loss: 0.294402  g_loss: 2.138894\n",
      "batch 34  d_loss: 0.280504  g_loss: 2.358137\n",
      "batch 35  d_loss: 0.320374  g_loss: 3.331515\n",
      "batch 36  d_loss: 0.651360  g_loss: 2.715076\n",
      "batch 37  d_loss: 0.524403  g_loss: 1.274594\n",
      "batch 38  d_loss: 0.294912  g_loss: 0.899255\n",
      "batch 39  d_loss: 0.494368  g_loss: 2.027188\n",
      "batch 40  d_loss: 0.294753  g_loss: 2.889847\n",
      "batch 41  d_loss: 0.348146  g_loss: 3.461330\n",
      "batch 42  d_loss: 0.440632  g_loss: 2.691645\n",
      "batch 43  d_loss: 0.256880  g_loss: 2.238453\n",
      "batch 44  d_loss: 0.264340  g_loss: 1.994856\n",
      "batch 45  d_loss: 0.270388  g_loss: 1.438563\n",
      "Epoch is 24\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.310751  g_loss: 1.787806\n",
      "batch 1  d_loss: 0.217363  g_loss: 2.423594\n",
      "batch 2  d_loss: 0.236374  g_loss: 2.649480\n",
      "batch 3  d_loss: 0.235454  g_loss: 2.821929\n",
      "batch 4  d_loss: 0.283568  g_loss: 2.369230\n",
      "batch 5  d_loss: 0.222843  g_loss: 2.038124\n",
      "batch 6  d_loss: 0.174087  g_loss: 1.567041\n",
      "batch 7  d_loss: 0.463122  g_loss: 1.453812\n",
      "batch 8  d_loss: 0.403409  g_loss: 1.586112\n",
      "batch 9  d_loss: 0.279584  g_loss: 2.171236\n",
      "batch 10  d_loss: 0.229541  g_loss: 2.925950\n",
      "batch 11  d_loss: 0.364925  g_loss: 2.902033\n",
      "batch 12  d_loss: 0.472764  g_loss: 2.771087\n",
      "batch 13  d_loss: 0.316112  g_loss: 2.034976\n",
      "batch 14  d_loss: 0.274598  g_loss: 1.344437\n",
      "batch 15  d_loss: 0.305832  g_loss: 1.609912\n",
      "batch 16  d_loss: 0.345939  g_loss: 1.724654\n",
      "batch 17  d_loss: 0.325197  g_loss: 2.021776\n",
      "batch 18  d_loss: 0.276240  g_loss: 2.576519\n",
      "batch 19  d_loss: 0.286694  g_loss: 2.686302\n",
      "batch 20  d_loss: 0.333445  g_loss: 2.508830\n",
      "batch 21  d_loss: 0.185280  g_loss: 2.230982\n",
      "batch 22  d_loss: 0.311265  g_loss: 2.084513\n",
      "batch 23  d_loss: 0.215148  g_loss: 1.930866\n",
      "batch 24  d_loss: 0.255431  g_loss: 1.996351\n",
      "batch 25  d_loss: 0.247309  g_loss: 2.359772\n",
      "batch 26  d_loss: 0.263957  g_loss: 2.551377\n",
      "batch 27  d_loss: 0.198778  g_loss: 2.218426\n",
      "batch 28  d_loss: 0.317717  g_loss: 2.192359\n",
      "batch 29  d_loss: 0.373595  g_loss: 2.092210\n",
      "batch 30  d_loss: 0.140915  g_loss: 2.550867\n",
      "batch 31  d_loss: 0.256949  g_loss: 2.162729\n",
      "batch 32  d_loss: 0.260958  g_loss: 2.932424\n",
      "batch 33  d_loss: 0.249606  g_loss: 2.735474\n",
      "batch 34  d_loss: 0.310029  g_loss: 2.630726\n",
      "batch 35  d_loss: 0.197698  g_loss: 1.747312\n",
      "batch 36  d_loss: 0.378037  g_loss: 1.674201\n",
      "batch 37  d_loss: 0.438648  g_loss: 1.505346\n",
      "batch 38  d_loss: 0.276642  g_loss: 1.945969\n",
      "batch 39  d_loss: 0.204629  g_loss: 2.312486\n",
      "batch 40  d_loss: 0.164518  g_loss: 2.826728\n",
      "batch 41  d_loss: 0.334518  g_loss: 3.113298\n",
      "batch 42  d_loss: 0.334728  g_loss: 2.989518\n",
      "batch 43  d_loss: 0.117572  g_loss: 2.245967\n",
      "batch 44  d_loss: 0.244003  g_loss: 2.056608\n",
      "batch 45  d_loss: 0.257811  g_loss: 2.156496\n",
      "Epoch is 25\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.208388  g_loss: 2.664919\n",
      "batch 1  d_loss: 0.139164  g_loss: 3.092657\n",
      "batch 2  d_loss: 0.258974  g_loss: 3.146086\n",
      "batch 3  d_loss: 0.192904  g_loss: 2.843369\n",
      "batch 4  d_loss: 0.187308  g_loss: 2.528376\n",
      "batch 5  d_loss: 0.234893  g_loss: 2.200471\n",
      "batch 6  d_loss: 0.247937  g_loss: 2.440974\n",
      "batch 7  d_loss: 0.608105  g_loss: 1.752967\n",
      "batch 8  d_loss: 0.424610  g_loss: 2.137477\n",
      "batch 9  d_loss: 0.276083  g_loss: 2.900131\n",
      "batch 10  d_loss: 0.216736  g_loss: 2.828907\n",
      "batch 11  d_loss: 0.350290  g_loss: 2.688732\n",
      "batch 12  d_loss: 0.315430  g_loss: 2.148079\n",
      "batch 13  d_loss: 0.269874  g_loss: 1.366222\n",
      "batch 14  d_loss: 0.413344  g_loss: 1.524539\n",
      "batch 15  d_loss: 0.316704  g_loss: 1.689635\n",
      "batch 16  d_loss: 0.220565  g_loss: 1.970861\n",
      "batch 17  d_loss: 0.366971  g_loss: 2.822332\n",
      "batch 18  d_loss: 0.209424  g_loss: 2.756084\n",
      "batch 19  d_loss: 0.334162  g_loss: 2.319052\n",
      "batch 20  d_loss: 0.315244  g_loss: 1.960037\n",
      "batch 21  d_loss: 0.288019  g_loss: 1.559114\n",
      "batch 22  d_loss: 0.344996  g_loss: 2.004130\n",
      "batch 23  d_loss: 0.220167  g_loss: 2.504426\n",
      "batch 24  d_loss: 0.205041  g_loss: 2.742823\n",
      "batch 25  d_loss: 0.337512  g_loss: 2.321693\n",
      "batch 26  d_loss: 0.296315  g_loss: 1.732427\n",
      "batch 27  d_loss: 0.305249  g_loss: 1.956938\n",
      "batch 28  d_loss: 0.314302  g_loss: 2.611194\n",
      "batch 29  d_loss: 0.296152  g_loss: 2.461132\n",
      "batch 30  d_loss: 0.274265  g_loss: 3.019686\n",
      "batch 31  d_loss: 0.290618  g_loss: 2.282932\n",
      "batch 32  d_loss: 0.212286  g_loss: 1.859709\n",
      "batch 33  d_loss: 0.241978  g_loss: 1.972055\n",
      "batch 34  d_loss: 0.324283  g_loss: 1.657463\n",
      "batch 35  d_loss: 0.347539  g_loss: 2.451785\n",
      "batch 36  d_loss: 0.386775  g_loss: 2.336375\n",
      "batch 37  d_loss: 0.427957  g_loss: 1.901421\n",
      "batch 38  d_loss: 0.292048  g_loss: 1.874677\n",
      "batch 39  d_loss: 0.214474  g_loss: 2.088030\n",
      "batch 40  d_loss: 0.217197  g_loss: 2.493428\n",
      "batch 41  d_loss: 0.273787  g_loss: 2.784207\n",
      "batch 42  d_loss: 0.333544  g_loss: 2.347773\n",
      "batch 43  d_loss: 0.282263  g_loss: 2.076176\n",
      "batch 44  d_loss: 0.313650  g_loss: 2.173451\n",
      "batch 45  d_loss: 0.269403  g_loss: 1.732794\n",
      "Epoch is 26\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.266047  g_loss: 2.081790\n",
      "batch 1  d_loss: 0.272356  g_loss: 2.206333\n",
      "batch 2  d_loss: 0.253641  g_loss: 2.121262\n",
      "batch 3  d_loss: 0.259083  g_loss: 2.045775\n",
      "batch 4  d_loss: 0.287974  g_loss: 2.205509\n",
      "batch 5  d_loss: 0.301314  g_loss: 2.845220\n",
      "batch 6  d_loss: 0.233618  g_loss: 2.385530\n",
      "batch 7  d_loss: 0.541651  g_loss: 1.814538\n",
      "batch 8  d_loss: 0.544021  g_loss: 1.522525\n",
      "batch 9  d_loss: 0.236654  g_loss: 1.620061\n",
      "batch 10  d_loss: 0.326849  g_loss: 2.305115\n",
      "batch 11  d_loss: 0.420721  g_loss: 2.898184\n",
      "batch 12  d_loss: 0.431141  g_loss: 2.188685\n",
      "batch 13  d_loss: 0.325783  g_loss: 1.788266\n",
      "batch 14  d_loss: 0.382455  g_loss: 1.663343\n",
      "batch 15  d_loss: 0.364329  g_loss: 1.967203\n",
      "batch 16  d_loss: 0.390658  g_loss: 2.530764\n",
      "batch 17  d_loss: 0.303506  g_loss: 2.305260\n",
      "batch 18  d_loss: 0.263671  g_loss: 2.274151\n",
      "batch 19  d_loss: 0.213162  g_loss: 1.985092\n",
      "batch 20  d_loss: 0.269381  g_loss: 1.791111\n",
      "batch 21  d_loss: 0.228911  g_loss: 1.680059\n",
      "batch 22  d_loss: 0.221490  g_loss: 2.011206\n",
      "batch 23  d_loss: 0.214732  g_loss: 2.829880\n",
      "batch 24  d_loss: 0.168956  g_loss: 3.121495\n",
      "batch 25  d_loss: 0.354662  g_loss: 3.204912\n",
      "batch 26  d_loss: 0.232566  g_loss: 2.182106\n",
      "batch 27  d_loss: 0.133664  g_loss: 2.093775\n",
      "batch 28  d_loss: 0.302925  g_loss: 2.400439\n",
      "batch 29  d_loss: 0.254277  g_loss: 2.397118\n",
      "batch 30  d_loss: 0.195608  g_loss: 2.399826\n",
      "batch 31  d_loss: 0.134868  g_loss: 3.113605\n",
      "batch 32  d_loss: 0.227949  g_loss: 3.549782\n",
      "batch 33  d_loss: 0.240424  g_loss: 3.147886\n",
      "batch 34  d_loss: 0.355634  g_loss: 3.060421\n",
      "batch 35  d_loss: 0.182166  g_loss: 2.534049\n",
      "batch 36  d_loss: 0.358077  g_loss: 2.070894\n",
      "batch 37  d_loss: 0.343548  g_loss: 1.372004\n",
      "batch 38  d_loss: 0.366687  g_loss: 1.846261\n",
      "batch 39  d_loss: 0.325233  g_loss: 2.545017\n",
      "batch 40  d_loss: 0.123023  g_loss: 3.049272\n",
      "batch 41  d_loss: 0.327399  g_loss: 3.492274\n",
      "batch 42  d_loss: 0.424466  g_loss: 2.637985\n",
      "batch 43  d_loss: 0.261028  g_loss: 2.502094\n",
      "batch 44  d_loss: 0.320956  g_loss: 1.784328\n",
      "batch 45  d_loss: 0.342371  g_loss: 1.792479\n",
      "Epoch is 27\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.274034  g_loss: 2.111861\n",
      "batch 1  d_loss: 0.263067  g_loss: 2.470152\n",
      "batch 2  d_loss: 0.284755  g_loss: 2.751179\n",
      "batch 3  d_loss: 0.306298  g_loss: 3.006692\n",
      "batch 4  d_loss: 0.305383  g_loss: 2.837225\n",
      "batch 5  d_loss: 0.359127  g_loss: 2.407047\n",
      "batch 6  d_loss: 0.292893  g_loss: 2.337198\n",
      "batch 7  d_loss: 0.671209  g_loss: 1.921894\n",
      "batch 8  d_loss: 0.378902  g_loss: 2.046774\n",
      "batch 9  d_loss: 0.240677  g_loss: 1.834764\n",
      "batch 10  d_loss: 0.268668  g_loss: 2.020985\n",
      "batch 11  d_loss: 0.385449  g_loss: 1.797510\n",
      "batch 12  d_loss: 0.398062  g_loss: 1.594524\n",
      "batch 13  d_loss: 0.380597  g_loss: 1.984780\n",
      "batch 14  d_loss: 0.360415  g_loss: 1.766911\n",
      "batch 15  d_loss: 0.339022  g_loss: 2.074780\n",
      "batch 16  d_loss: 0.226643  g_loss: 2.305171\n",
      "batch 17  d_loss: 0.293553  g_loss: 2.308142\n",
      "batch 18  d_loss: 0.167583  g_loss: 2.475018\n",
      "batch 19  d_loss: 0.152410  g_loss: 2.485075\n",
      "batch 20  d_loss: 0.299922  g_loss: 2.724927\n",
      "batch 21  d_loss: 0.142481  g_loss: 2.790986\n",
      "batch 22  d_loss: 0.209859  g_loss: 2.853168\n",
      "batch 23  d_loss: 0.101911  g_loss: 2.743186\n",
      "batch 24  d_loss: 0.127425  g_loss: 2.902745\n",
      "batch 25  d_loss: 0.269213  g_loss: 2.912243\n",
      "batch 26  d_loss: 0.199078  g_loss: 3.221478\n",
      "batch 27  d_loss: 0.155990  g_loss: 2.835842\n",
      "batch 28  d_loss: 0.185780  g_loss: 2.689480\n",
      "batch 29  d_loss: 0.201801  g_loss: 2.850697\n",
      "batch 30  d_loss: 0.142823  g_loss: 2.778827\n",
      "batch 31  d_loss: 0.198038  g_loss: 2.401317\n",
      "batch 32  d_loss: 0.112615  g_loss: 2.542258\n",
      "batch 33  d_loss: 0.276772  g_loss: 3.198750\n",
      "batch 34  d_loss: 0.335795  g_loss: 2.418704\n",
      "batch 35  d_loss: 0.233215  g_loss: 2.348233\n",
      "batch 36  d_loss: 0.503071  g_loss: 1.569484\n",
      "batch 37  d_loss: 0.550506  g_loss: 1.595194\n",
      "batch 38  d_loss: 0.394352  g_loss: 1.865012\n",
      "batch 39  d_loss: 0.318324  g_loss: 3.241614\n",
      "batch 40  d_loss: 0.301701  g_loss: 3.295093\n",
      "batch 41  d_loss: 0.436477  g_loss: 2.794918\n",
      "batch 42  d_loss: 0.370021  g_loss: 2.133744\n",
      "batch 43  d_loss: 0.267144  g_loss: 1.894644\n",
      "batch 44  d_loss: 0.374294  g_loss: 1.667681\n",
      "batch 45  d_loss: 0.304587  g_loss: 2.550680\n",
      "Epoch is 28\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.183736  g_loss: 3.591584\n",
      "batch 1  d_loss: 0.459084  g_loss: 3.100321\n",
      "batch 2  d_loss: 0.226434  g_loss: 2.513114\n",
      "batch 3  d_loss: 0.253940  g_loss: 1.664684\n",
      "batch 4  d_loss: 0.238729  g_loss: 1.843332\n",
      "batch 5  d_loss: 0.469099  g_loss: 2.307112\n",
      "batch 6  d_loss: 0.209901  g_loss: 3.097936\n",
      "batch 7  d_loss: 0.668997  g_loss: 2.349568\n",
      "batch 8  d_loss: 0.439564  g_loss: 2.440669\n",
      "batch 9  d_loss: 0.173258  g_loss: 2.022703\n",
      "batch 10  d_loss: 0.203367  g_loss: 2.339988\n",
      "batch 11  d_loss: 0.347756  g_loss: 1.921329\n",
      "batch 12  d_loss: 0.256608  g_loss: 2.099046\n",
      "batch 13  d_loss: 0.250923  g_loss: 2.029987\n",
      "batch 14  d_loss: 0.230426  g_loss: 1.861684\n",
      "batch 15  d_loss: 0.364033  g_loss: 1.956959\n",
      "batch 16  d_loss: 0.211530  g_loss: 2.070740\n",
      "batch 17  d_loss: 0.286220  g_loss: 2.349423\n",
      "batch 18  d_loss: 0.236355  g_loss: 2.524986\n",
      "batch 19  d_loss: 0.228327  g_loss: 2.631478\n",
      "batch 20  d_loss: 0.252349  g_loss: 2.345342\n",
      "batch 21  d_loss: 0.155147  g_loss: 2.669512\n",
      "batch 22  d_loss: 0.232620  g_loss: 2.291590\n",
      "batch 23  d_loss: 0.216704  g_loss: 2.658130\n",
      "batch 24  d_loss: 0.164516  g_loss: 2.938349\n",
      "batch 25  d_loss: 0.262366  g_loss: 2.654216\n",
      "batch 26  d_loss: 0.153684  g_loss: 2.647793\n",
      "batch 27  d_loss: 0.223567  g_loss: 3.078753\n",
      "batch 28  d_loss: 0.216669  g_loss: 3.251137\n",
      "batch 29  d_loss: 0.415073  g_loss: 2.820261\n",
      "batch 30  d_loss: 0.184585  g_loss: 2.467189\n",
      "batch 31  d_loss: 0.206939  g_loss: 2.528682\n",
      "batch 32  d_loss: 0.168724  g_loss: 2.750064\n",
      "batch 33  d_loss: 0.223825  g_loss: 2.370827\n",
      "batch 34  d_loss: 0.271585  g_loss: 1.969477\n",
      "batch 35  d_loss: 0.213864  g_loss: 2.468230\n",
      "batch 36  d_loss: 0.478276  g_loss: 2.518133\n",
      "batch 37  d_loss: 0.650303  g_loss: 2.036355\n",
      "batch 38  d_loss: 0.406512  g_loss: 1.995505\n",
      "batch 39  d_loss: 0.337440  g_loss: 2.365721\n",
      "batch 40  d_loss: 0.296041  g_loss: 2.816231\n",
      "batch 41  d_loss: 0.538087  g_loss: 2.801356\n",
      "batch 42  d_loss: 0.410247  g_loss: 2.271649\n",
      "batch 43  d_loss: 0.167208  g_loss: 1.576495\n",
      "batch 44  d_loss: 0.253681  g_loss: 1.692109\n",
      "batch 45  d_loss: 0.310732  g_loss: 1.667560\n",
      "Epoch is 29\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.261474  g_loss: 2.367851\n",
      "batch 1  d_loss: 0.214737  g_loss: 2.475467\n",
      "batch 2  d_loss: 0.190035  g_loss: 2.263282\n",
      "batch 3  d_loss: 0.187309  g_loss: 2.356293\n",
      "batch 4  d_loss: 0.223867  g_loss: 2.224467\n",
      "batch 5  d_loss: 0.213893  g_loss: 2.089914\n",
      "batch 6  d_loss: 0.175908  g_loss: 1.948708\n",
      "batch 7  d_loss: 0.622501  g_loss: 1.534131\n",
      "batch 8  d_loss: 0.443720  g_loss: 1.809379\n",
      "batch 9  d_loss: 0.254573  g_loss: 2.263747\n",
      "batch 10  d_loss: 0.246556  g_loss: 2.800082\n",
      "batch 11  d_loss: 0.414855  g_loss: 2.442040\n",
      "batch 12  d_loss: 0.473655  g_loss: 2.341339\n",
      "batch 13  d_loss: 0.302658  g_loss: 2.175351\n",
      "batch 14  d_loss: 0.308797  g_loss: 1.930448\n",
      "batch 15  d_loss: 0.317151  g_loss: 1.777313\n",
      "batch 16  d_loss: 0.226265  g_loss: 2.270562\n",
      "batch 17  d_loss: 0.347964  g_loss: 2.142364\n",
      "batch 18  d_loss: 0.175287  g_loss: 2.280793\n",
      "batch 19  d_loss: 0.262081  g_loss: 2.424251\n",
      "batch 20  d_loss: 0.257862  g_loss: 1.763737\n",
      "batch 21  d_loss: 0.198367  g_loss: 1.805446\n",
      "batch 22  d_loss: 0.219587  g_loss: 1.725839\n",
      "batch 23  d_loss: 0.252220  g_loss: 2.148202\n",
      "batch 24  d_loss: 0.204584  g_loss: 2.342177\n",
      "batch 25  d_loss: 0.279599  g_loss: 2.411366\n",
      "batch 26  d_loss: 0.177039  g_loss: 2.005554\n",
      "batch 27  d_loss: 0.237572  g_loss: 2.200135\n",
      "batch 28  d_loss: 0.323282  g_loss: 2.185716\n",
      "batch 29  d_loss: 0.386374  g_loss: 1.959985\n",
      "batch 30  d_loss: 0.199020  g_loss: 1.715340\n",
      "batch 31  d_loss: 0.208728  g_loss: 2.490347\n",
      "batch 32  d_loss: 0.288619  g_loss: 3.521525\n",
      "batch 33  d_loss: 0.437216  g_loss: 3.297385\n",
      "batch 34  d_loss: 0.377661  g_loss: 2.273717\n",
      "batch 35  d_loss: 0.267898  g_loss: 1.700790\n",
      "batch 36  d_loss: 0.560154  g_loss: 1.399913\n",
      "batch 37  d_loss: 0.654023  g_loss: 1.581541\n",
      "batch 38  d_loss: 0.380925  g_loss: 2.247696\n",
      "batch 39  d_loss: 0.316279  g_loss: 2.417397\n",
      "batch 40  d_loss: 0.317789  g_loss: 2.728664\n",
      "batch 41  d_loss: 0.284319  g_loss: 2.814812\n",
      "batch 42  d_loss: 0.340200  g_loss: 1.979148\n",
      "batch 43  d_loss: 0.244882  g_loss: 1.468160\n",
      "batch 44  d_loss: 0.289283  g_loss: 1.585252\n",
      "batch 45  d_loss: 0.288533  g_loss: 1.967612\n",
      "Epoch is 30\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.191401  g_loss: 2.509248\n",
      "batch 1  d_loss: 0.259967  g_loss: 2.866598\n",
      "batch 2  d_loss: 0.208545  g_loss: 2.677921\n",
      "batch 3  d_loss: 0.277663  g_loss: 2.819358\n",
      "batch 4  d_loss: 0.270397  g_loss: 2.724830\n",
      "batch 5  d_loss: 0.264296  g_loss: 2.577595\n",
      "batch 6  d_loss: 0.213474  g_loss: 2.037236\n",
      "batch 7  d_loss: 0.641073  g_loss: 1.994164\n",
      "batch 8  d_loss: 0.461340  g_loss: 1.935651\n",
      "batch 9  d_loss: 0.192494  g_loss: 2.658085\n",
      "batch 10  d_loss: 0.252157  g_loss: 2.586495\n",
      "batch 11  d_loss: 0.423465  g_loss: 3.080743\n",
      "batch 12  d_loss: 0.457745  g_loss: 2.371674\n",
      "batch 13  d_loss: 0.319083  g_loss: 2.406197\n",
      "batch 14  d_loss: 0.364136  g_loss: 1.642862\n",
      "batch 15  d_loss: 0.401040  g_loss: 1.681384\n",
      "batch 16  d_loss: 0.237193  g_loss: 2.236059\n",
      "batch 17  d_loss: 0.251814  g_loss: 2.425491\n",
      "batch 18  d_loss: 0.154760  g_loss: 2.427183\n",
      "batch 19  d_loss: 0.287682  g_loss: 2.847089\n",
      "batch 20  d_loss: 0.331543  g_loss: 2.300451\n",
      "batch 21  d_loss: 0.206962  g_loss: 1.752306\n",
      "batch 22  d_loss: 0.276913  g_loss: 1.566612\n",
      "batch 23  d_loss: 0.286225  g_loss: 2.225615\n",
      "batch 24  d_loss: 0.184174  g_loss: 2.959738\n",
      "batch 25  d_loss: 0.264129  g_loss: 2.790206\n",
      "batch 26  d_loss: 0.276788  g_loss: 2.439374\n",
      "batch 27  d_loss: 0.160736  g_loss: 2.266877\n",
      "batch 28  d_loss: 0.248474  g_loss: 1.510488\n",
      "batch 29  d_loss: 0.331589  g_loss: 1.914747\n",
      "batch 30  d_loss: 0.261130  g_loss: 2.324723\n",
      "batch 31  d_loss: 0.292482  g_loss: 3.181901\n",
      "batch 32  d_loss: 0.252744  g_loss: 2.934000\n",
      "batch 33  d_loss: 0.314819  g_loss: 2.371725\n",
      "batch 34  d_loss: 0.310050  g_loss: 2.006620\n",
      "batch 35  d_loss: 0.302055  g_loss: 1.884122\n",
      "batch 36  d_loss: 0.437830  g_loss: 2.195670\n",
      "batch 37  d_loss: 0.483083  g_loss: 2.173997\n",
      "batch 38  d_loss: 0.324064  g_loss: 1.864360\n",
      "batch 39  d_loss: 0.361845  g_loss: 2.494264\n",
      "batch 40  d_loss: 0.319206  g_loss: 3.042644\n",
      "batch 41  d_loss: 0.609874  g_loss: 2.634545\n",
      "batch 42  d_loss: 0.400673  g_loss: 1.911291\n",
      "batch 43  d_loss: 0.322703  g_loss: 1.577343\n",
      "batch 44  d_loss: 0.297647  g_loss: 2.043869\n",
      "batch 45  d_loss: 0.338462  g_loss: 1.873114\n",
      "Epoch is 31\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.236497  g_loss: 2.702358\n",
      "batch 1  d_loss: 0.649934  g_loss: 1.932766\n",
      "batch 2  d_loss: 0.315678  g_loss: 1.833905\n",
      "batch 3  d_loss: 0.357946  g_loss: 1.241149\n",
      "batch 4  d_loss: 0.390736  g_loss: 1.703745\n",
      "batch 5  d_loss: 0.220165  g_loss: 2.432677\n",
      "batch 6  d_loss: 0.296479  g_loss: 2.489520\n",
      "batch 7  d_loss: 0.637228  g_loss: 2.278166\n",
      "batch 8  d_loss: 0.512485  g_loss: 2.074600\n",
      "batch 9  d_loss: 0.245349  g_loss: 1.535490\n",
      "batch 10  d_loss: 0.226393  g_loss: 2.059928\n",
      "batch 11  d_loss: 0.391282  g_loss: 1.884777\n",
      "batch 12  d_loss: 0.410422  g_loss: 1.650414\n",
      "batch 13  d_loss: 0.432411  g_loss: 1.431294\n",
      "batch 14  d_loss: 0.480483  g_loss: 1.427967\n",
      "batch 15  d_loss: 0.391094  g_loss: 1.714814\n",
      "batch 16  d_loss: 0.334140  g_loss: 1.893022\n",
      "batch 17  d_loss: 0.319953  g_loss: 2.245514\n",
      "batch 18  d_loss: 0.239391  g_loss: 2.448339\n",
      "batch 19  d_loss: 0.322131  g_loss: 1.991208\n",
      "batch 20  d_loss: 0.231757  g_loss: 1.832522\n",
      "batch 21  d_loss: 0.219210  g_loss: 1.706162\n",
      "batch 22  d_loss: 0.334729  g_loss: 1.633572\n",
      "batch 23  d_loss: 0.328595  g_loss: 1.755237\n",
      "batch 24  d_loss: 0.326967  g_loss: 2.269016\n",
      "batch 25  d_loss: 0.328683  g_loss: 2.235117\n",
      "batch 26  d_loss: 0.325767  g_loss: 2.227263\n",
      "batch 27  d_loss: 0.232110  g_loss: 2.118311\n",
      "batch 28  d_loss: 0.430312  g_loss: 1.883431\n",
      "batch 29  d_loss: 0.317317  g_loss: 1.748914\n",
      "batch 30  d_loss: 0.240049  g_loss: 1.782049\n",
      "batch 31  d_loss: 0.323290  g_loss: 2.197103\n",
      "batch 32  d_loss: 0.268623  g_loss: 2.082771\n",
      "batch 33  d_loss: 0.283619  g_loss: 1.901768\n",
      "batch 34  d_loss: 0.385581  g_loss: 1.684342\n",
      "batch 35  d_loss: 0.480200  g_loss: 1.933971\n",
      "batch 36  d_loss: 0.451799  g_loss: 1.447487\n",
      "batch 37  d_loss: 0.541390  g_loss: 1.504661\n",
      "batch 38  d_loss: 0.381117  g_loss: 1.358088\n",
      "batch 39  d_loss: 0.388152  g_loss: 1.967138\n",
      "batch 40  d_loss: 0.272705  g_loss: 2.149281\n",
      "batch 41  d_loss: 0.307245  g_loss: 2.690034\n",
      "batch 42  d_loss: 0.376067  g_loss: 1.873898\n",
      "batch 43  d_loss: 0.277410  g_loss: 1.976898\n",
      "batch 44  d_loss: 0.278845  g_loss: 2.079215\n",
      "batch 45  d_loss: 0.317317  g_loss: 1.459158\n",
      "Epoch is 32\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.319113  g_loss: 1.822490\n",
      "batch 1  d_loss: 0.319901  g_loss: 1.959437\n",
      "batch 2  d_loss: 0.220433  g_loss: 2.321516\n",
      "batch 3  d_loss: 0.306329  g_loss: 2.359341\n",
      "batch 4  d_loss: 0.355829  g_loss: 1.831163\n",
      "batch 5  d_loss: 0.433754  g_loss: 1.449394\n",
      "batch 6  d_loss: 0.277247  g_loss: 1.905914\n",
      "batch 7  d_loss: 0.578838  g_loss: 1.911227\n",
      "batch 8  d_loss: 0.410966  g_loss: 1.866471\n",
      "batch 9  d_loss: 0.285832  g_loss: 1.991865\n",
      "batch 10  d_loss: 0.482975  g_loss: 2.201696\n",
      "batch 11  d_loss: 0.368170  g_loss: 1.817405\n",
      "batch 12  d_loss: 0.483485  g_loss: 1.712560\n",
      "batch 13  d_loss: 0.443931  g_loss: 1.117585\n",
      "batch 14  d_loss: 0.386369  g_loss: 1.106416\n",
      "batch 15  d_loss: 0.410999  g_loss: 1.826777\n",
      "batch 16  d_loss: 0.376245  g_loss: 2.643082\n",
      "batch 17  d_loss: 0.442401  g_loss: 2.352558\n",
      "batch 18  d_loss: 0.234525  g_loss: 1.848490\n",
      "batch 19  d_loss: 0.299103  g_loss: 2.169545\n",
      "batch 20  d_loss: 0.255671  g_loss: 1.430556\n",
      "batch 21  d_loss: 0.264961  g_loss: 1.155526\n",
      "batch 22  d_loss: 0.344937  g_loss: 1.499986\n",
      "batch 23  d_loss: 0.331465  g_loss: 1.916650\n",
      "batch 24  d_loss: 0.345221  g_loss: 2.614405\n",
      "batch 25  d_loss: 0.473423  g_loss: 2.405460\n",
      "batch 26  d_loss: 0.282172  g_loss: 1.574291\n",
      "batch 27  d_loss: 0.210974  g_loss: 1.035342\n",
      "batch 28  d_loss: 0.555960  g_loss: 1.508130\n",
      "batch 29  d_loss: 0.496959  g_loss: 2.083722\n",
      "batch 30  d_loss: 0.335130  g_loss: 3.004238\n",
      "batch 31  d_loss: 0.320619  g_loss: 3.019242\n",
      "batch 32  d_loss: 0.379031  g_loss: 2.443158\n",
      "batch 33  d_loss: 0.258524  g_loss: 1.837208\n",
      "batch 34  d_loss: 0.342824  g_loss: 1.417226\n",
      "batch 35  d_loss: 0.341658  g_loss: 1.510910\n",
      "batch 36  d_loss: 0.442659  g_loss: 1.900951\n",
      "batch 37  d_loss: 0.442368  g_loss: 2.195991\n",
      "batch 38  d_loss: 0.347180  g_loss: 2.402869\n",
      "batch 39  d_loss: 0.289804  g_loss: 2.213446\n",
      "batch 40  d_loss: 0.188491  g_loss: 2.073647\n",
      "batch 41  d_loss: 0.259366  g_loss: 1.777767\n",
      "batch 42  d_loss: 0.306145  g_loss: 1.658426\n",
      "batch 43  d_loss: 0.200164  g_loss: 2.297612\n",
      "batch 44  d_loss: 0.193397  g_loss: 2.225471\n",
      "batch 45  d_loss: 0.216086  g_loss: 2.733403\n",
      "Epoch is 33\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.203534  g_loss: 2.689700\n",
      "batch 1  d_loss: 0.341280  g_loss: 1.963160\n",
      "batch 2  d_loss: 0.223248  g_loss: 1.620178\n",
      "batch 3  d_loss: 0.298154  g_loss: 1.521677\n",
      "batch 4  d_loss: 0.256470  g_loss: 2.114685\n",
      "batch 5  d_loss: 0.271107  g_loss: 2.704362\n",
      "batch 6  d_loss: 0.152049  g_loss: 3.189034\n",
      "batch 7  d_loss: 0.546552  g_loss: 2.833784\n",
      "batch 8  d_loss: 0.493124  g_loss: 2.120334\n",
      "batch 9  d_loss: 0.233371  g_loss: 1.485178\n",
      "batch 10  d_loss: 0.280449  g_loss: 1.628968\n",
      "batch 11  d_loss: 0.398557  g_loss: 1.941373\n",
      "batch 12  d_loss: 0.415153  g_loss: 2.109544\n",
      "batch 13  d_loss: 0.334534  g_loss: 1.798187\n",
      "batch 14  d_loss: 0.345194  g_loss: 1.886827\n",
      "batch 15  d_loss: 0.356435  g_loss: 1.550926\n",
      "batch 16  d_loss: 0.337316  g_loss: 1.767599\n",
      "batch 17  d_loss: 0.385256  g_loss: 1.864456\n",
      "batch 18  d_loss: 0.321629  g_loss: 2.245481\n",
      "batch 19  d_loss: 0.361425  g_loss: 2.237909\n",
      "batch 20  d_loss: 0.469063  g_loss: 1.361045\n",
      "batch 21  d_loss: 0.290141  g_loss: 1.542767\n",
      "batch 22  d_loss: 0.293983  g_loss: 2.130401\n",
      "batch 23  d_loss: 0.221001  g_loss: 2.355824\n",
      "batch 24  d_loss: 0.286281  g_loss: 2.212001\n",
      "batch 25  d_loss: 0.319693  g_loss: 1.933711\n",
      "batch 26  d_loss: 0.289869  g_loss: 1.995212\n",
      "batch 27  d_loss: 0.293612  g_loss: 1.917411\n",
      "batch 28  d_loss: 0.270784  g_loss: 2.294262\n",
      "batch 29  d_loss: 0.326207  g_loss: 2.760726\n",
      "batch 30  d_loss: 0.298846  g_loss: 2.332539\n",
      "batch 31  d_loss: 0.243057  g_loss: 2.500476\n",
      "batch 32  d_loss: 0.212522  g_loss: 2.469643\n",
      "batch 33  d_loss: 0.267061  g_loss: 2.578301\n",
      "batch 34  d_loss: 0.320109  g_loss: 2.062754\n",
      "batch 35  d_loss: 0.271288  g_loss: 2.209020\n",
      "batch 36  d_loss: 0.417673  g_loss: 2.184335\n",
      "batch 37  d_loss: 0.363895  g_loss: 1.323310\n",
      "batch 38  d_loss: 0.384792  g_loss: 1.932646\n",
      "batch 39  d_loss: 0.300715  g_loss: 2.349569\n",
      "batch 40  d_loss: 0.298886  g_loss: 3.466486\n",
      "batch 41  d_loss: 0.480994  g_loss: 3.203694\n",
      "batch 42  d_loss: 0.351733  g_loss: 2.708107\n",
      "batch 43  d_loss: 0.230635  g_loss: 2.023251\n",
      "batch 44  d_loss: 0.438668  g_loss: 2.035019\n",
      "batch 45  d_loss: 0.368577  g_loss: 2.591989\n",
      "Epoch is 34\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.316322  g_loss: 2.759930\n",
      "batch 1  d_loss: 0.481142  g_loss: 2.727391\n",
      "batch 2  d_loss: 0.370207  g_loss: 2.151856\n",
      "batch 3  d_loss: 0.275342  g_loss: 1.814679\n",
      "batch 4  d_loss: 0.337520  g_loss: 1.606069\n",
      "batch 5  d_loss: 0.362395  g_loss: 2.018476\n",
      "batch 6  d_loss: 0.312436  g_loss: 2.716289\n",
      "batch 7  d_loss: 0.935947  g_loss: 2.570652\n",
      "batch 8  d_loss: 0.647655  g_loss: 1.948575\n",
      "batch 9  d_loss: 0.258727  g_loss: 1.998275\n",
      "batch 10  d_loss: 0.301799  g_loss: 1.511428\n",
      "batch 11  d_loss: 0.458923  g_loss: 1.697029\n",
      "batch 12  d_loss: 0.478214  g_loss: 1.771851\n",
      "batch 13  d_loss: 0.441599  g_loss: 1.863381\n",
      "batch 14  d_loss: 0.305594  g_loss: 1.669927\n",
      "batch 15  d_loss: 0.247056  g_loss: 1.872656\n",
      "batch 16  d_loss: 0.413318  g_loss: 2.037052\n",
      "batch 17  d_loss: 0.324240  g_loss: 2.074979\n",
      "batch 18  d_loss: 0.200820  g_loss: 2.340401\n",
      "batch 19  d_loss: 0.276431  g_loss: 2.150935\n",
      "batch 20  d_loss: 0.215784  g_loss: 2.329735\n",
      "batch 21  d_loss: 0.177535  g_loss: 2.279304\n",
      "batch 22  d_loss: 0.222647  g_loss: 2.071573\n",
      "batch 23  d_loss: 0.265800  g_loss: 2.270251\n",
      "batch 24  d_loss: 0.235752  g_loss: 2.544303\n",
      "batch 25  d_loss: 0.328636  g_loss: 2.557866\n",
      "batch 26  d_loss: 0.278620  g_loss: 2.366981\n",
      "batch 27  d_loss: 0.194200  g_loss: 2.562258\n",
      "batch 28  d_loss: 0.301663  g_loss: 2.116419\n",
      "batch 29  d_loss: 0.321065  g_loss: 1.875728\n",
      "batch 30  d_loss: 0.196626  g_loss: 2.178468\n",
      "batch 31  d_loss: 0.272951  g_loss: 2.386312\n",
      "batch 32  d_loss: 0.273008  g_loss: 2.093049\n",
      "batch 33  d_loss: 0.303253  g_loss: 2.451250\n",
      "batch 34  d_loss: 0.237122  g_loss: 2.222809\n",
      "batch 35  d_loss: 0.376121  g_loss: 1.844268\n",
      "batch 36  d_loss: 0.406496  g_loss: 1.827958\n",
      "batch 37  d_loss: 0.408779  g_loss: 1.749706\n",
      "batch 38  d_loss: 0.418441  g_loss: 2.151188\n",
      "batch 39  d_loss: 0.296922  g_loss: 2.518991\n",
      "batch 40  d_loss: 0.362200  g_loss: 2.260207\n",
      "batch 41  d_loss: 0.318085  g_loss: 1.563093\n",
      "batch 42  d_loss: 0.365040  g_loss: 0.990004\n",
      "batch 43  d_loss: 0.349212  g_loss: 1.285575\n",
      "batch 44  d_loss: 0.339433  g_loss: 1.562037\n",
      "batch 45  d_loss: 0.312684  g_loss: 2.136633\n",
      "Epoch is 35\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.347011  g_loss: 2.769088\n",
      "batch 1  d_loss: 0.413868  g_loss: 2.557297\n",
      "batch 2  d_loss: 0.363102  g_loss: 1.727238\n",
      "batch 3  d_loss: 0.269274  g_loss: 1.089915\n",
      "batch 4  d_loss: 0.387793  g_loss: 1.199967\n",
      "batch 5  d_loss: 0.370347  g_loss: 1.456412\n",
      "batch 6  d_loss: 0.217380  g_loss: 2.480106\n",
      "batch 7  d_loss: 0.527198  g_loss: 2.784895\n",
      "batch 8  d_loss: 0.466864  g_loss: 2.765613\n",
      "batch 9  d_loss: 0.264405  g_loss: 2.478072\n",
      "batch 10  d_loss: 0.231115  g_loss: 1.828115\n",
      "batch 11  d_loss: 0.398234  g_loss: 1.560234\n",
      "batch 12  d_loss: 0.362908  g_loss: 1.347438\n",
      "batch 13  d_loss: 0.360653  g_loss: 1.316839\n",
      "batch 14  d_loss: 0.319081  g_loss: 1.838779\n",
      "batch 15  d_loss: 0.354857  g_loss: 2.556617\n",
      "batch 16  d_loss: 0.264101  g_loss: 2.421391\n",
      "batch 17  d_loss: 0.393260  g_loss: 2.391880\n",
      "batch 18  d_loss: 0.196140  g_loss: 2.334665\n",
      "batch 19  d_loss: 0.272477  g_loss: 1.916759\n",
      "batch 20  d_loss: 0.249192  g_loss: 2.111580\n",
      "batch 21  d_loss: 0.230256  g_loss: 2.029151\n",
      "batch 22  d_loss: 0.299460  g_loss: 2.158759\n",
      "batch 23  d_loss: 0.224576  g_loss: 2.249351\n",
      "batch 24  d_loss: 0.267837  g_loss: 1.760701\n",
      "batch 25  d_loss: 0.348479  g_loss: 2.281657\n",
      "batch 26  d_loss: 0.311387  g_loss: 1.935685\n",
      "batch 27  d_loss: 0.191069  g_loss: 2.463845\n",
      "batch 28  d_loss: 0.340930  g_loss: 2.562447\n",
      "batch 29  d_loss: 0.363007  g_loss: 2.029686\n",
      "batch 30  d_loss: 0.353094  g_loss: 2.301571\n",
      "batch 31  d_loss: 0.351819  g_loss: 1.950042\n",
      "batch 32  d_loss: 0.267383  g_loss: 1.779439\n",
      "batch 33  d_loss: 0.302706  g_loss: 2.402409\n",
      "batch 34  d_loss: 0.411492  g_loss: 2.810174\n",
      "batch 35  d_loss: 0.443490  g_loss: 2.594506\n",
      "batch 36  d_loss: 0.493008  g_loss: 1.592563\n",
      "batch 37  d_loss: 0.582640  g_loss: 1.871512\n",
      "batch 38  d_loss: 0.405445  g_loss: 2.222899\n",
      "batch 39  d_loss: 0.309826  g_loss: 2.610595\n",
      "batch 40  d_loss: 0.225722  g_loss: 2.540763\n",
      "batch 41  d_loss: 0.468349  g_loss: 2.367165\n",
      "batch 42  d_loss: 0.310963  g_loss: 1.886671\n",
      "batch 43  d_loss: 0.321440  g_loss: 1.870546\n",
      "batch 44  d_loss: 0.323143  g_loss: 2.041698\n",
      "batch 45  d_loss: 0.232635  g_loss: 1.940782\n",
      "Epoch is 36\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.281458  g_loss: 2.234932\n",
      "batch 1  d_loss: 0.307140  g_loss: 2.565561\n",
      "batch 2  d_loss: 0.304566  g_loss: 2.050966\n",
      "batch 3  d_loss: 0.225868  g_loss: 1.804890\n",
      "batch 4  d_loss: 0.257472  g_loss: 2.185678\n",
      "batch 5  d_loss: 0.264098  g_loss: 2.123371\n",
      "batch 6  d_loss: 0.310065  g_loss: 2.022337\n",
      "batch 7  d_loss: 0.455040  g_loss: 2.687093\n",
      "batch 8  d_loss: 0.499050  g_loss: 2.322331\n",
      "batch 9  d_loss: 0.245167  g_loss: 2.148552\n",
      "batch 10  d_loss: 0.228183  g_loss: 1.917332\n",
      "batch 11  d_loss: 0.307007  g_loss: 2.177558\n",
      "batch 12  d_loss: 0.297178  g_loss: 2.401640\n",
      "batch 13  d_loss: 0.278214  g_loss: 1.921401\n",
      "batch 14  d_loss: 0.286921  g_loss: 1.735749\n",
      "batch 15  d_loss: 0.257841  g_loss: 2.194261\n",
      "batch 16  d_loss: 0.255612  g_loss: 2.276817\n",
      "batch 17  d_loss: 0.279223  g_loss: 2.376424\n",
      "batch 18  d_loss: 0.226338  g_loss: 2.335282\n",
      "batch 19  d_loss: 0.242828  g_loss: 2.367219\n",
      "batch 20  d_loss: 0.259391  g_loss: 2.106368\n",
      "batch 21  d_loss: 0.184580  g_loss: 2.481032\n",
      "batch 22  d_loss: 0.194188  g_loss: 2.809913\n",
      "batch 23  d_loss: 0.228986  g_loss: 2.741632\n",
      "batch 24  d_loss: 0.173916  g_loss: 2.696010\n",
      "batch 25  d_loss: 0.299289  g_loss: 2.491904\n",
      "batch 26  d_loss: 0.199887  g_loss: 1.786517\n",
      "batch 27  d_loss: 0.222203  g_loss: 1.955610\n",
      "batch 28  d_loss: 0.250039  g_loss: 2.284257\n",
      "batch 29  d_loss: 0.335773  g_loss: 2.350341\n",
      "batch 30  d_loss: 0.270544  g_loss: 2.250839\n",
      "batch 31  d_loss: 0.253419  g_loss: 2.369071\n",
      "batch 32  d_loss: 0.187892  g_loss: 2.104002\n",
      "batch 33  d_loss: 0.304290  g_loss: 1.875910\n",
      "batch 34  d_loss: 0.456980  g_loss: 1.541874\n",
      "batch 35  d_loss: 0.354321  g_loss: 1.651749\n",
      "batch 36  d_loss: 0.504910  g_loss: 1.674038\n",
      "batch 37  d_loss: 0.554445  g_loss: 1.571895\n",
      "batch 38  d_loss: 0.535246  g_loss: 2.002610\n",
      "batch 39  d_loss: 0.351532  g_loss: 2.220215\n",
      "batch 40  d_loss: 0.246002  g_loss: 2.248359\n",
      "batch 41  d_loss: 0.300283  g_loss: 2.054160\n",
      "batch 42  d_loss: 0.427138  g_loss: 1.809498\n",
      "batch 43  d_loss: 0.261559  g_loss: 2.217273\n",
      "batch 44  d_loss: 0.323240  g_loss: 2.089746\n",
      "batch 45  d_loss: 0.301636  g_loss: 1.984488\n",
      "Epoch is 37\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.244008  g_loss: 2.344122\n",
      "batch 1  d_loss: 0.326047  g_loss: 2.297941\n",
      "batch 2  d_loss: 0.290390  g_loss: 2.310051\n",
      "batch 3  d_loss: 0.227558  g_loss: 2.364007\n",
      "batch 4  d_loss: 0.334377  g_loss: 2.265839\n",
      "batch 5  d_loss: 0.340125  g_loss: 2.540275\n",
      "batch 6  d_loss: 0.214915  g_loss: 2.103904\n",
      "batch 7  d_loss: 0.720651  g_loss: 2.515324\n",
      "batch 8  d_loss: 0.515597  g_loss: 2.486718\n",
      "batch 9  d_loss: 0.227594  g_loss: 2.062782\n",
      "batch 10  d_loss: 0.269906  g_loss: 1.923362\n",
      "batch 11  d_loss: 0.420338  g_loss: 1.752774\n",
      "batch 12  d_loss: 0.432533  g_loss: 1.920873\n",
      "batch 13  d_loss: 0.350833  g_loss: 1.817315\n",
      "batch 14  d_loss: 0.331449  g_loss: 1.549247\n",
      "batch 15  d_loss: 0.395971  g_loss: 1.510880\n",
      "batch 16  d_loss: 0.383688  g_loss: 1.454210\n",
      "batch 17  d_loss: 0.367273  g_loss: 1.786164\n",
      "batch 18  d_loss: 0.220531  g_loss: 2.245010\n",
      "batch 19  d_loss: 0.350703  g_loss: 2.241965\n",
      "batch 20  d_loss: 0.292373  g_loss: 1.283743\n",
      "batch 21  d_loss: 0.380617  g_loss: 1.234007\n",
      "batch 22  d_loss: 0.240687  g_loss: 1.539678\n",
      "batch 23  d_loss: 0.202005  g_loss: 1.877707\n",
      "batch 24  d_loss: 0.249221  g_loss: 2.103133\n",
      "batch 25  d_loss: 0.299370  g_loss: 2.660949\n",
      "batch 26  d_loss: 0.310121  g_loss: 2.205521\n",
      "batch 27  d_loss: 0.238459  g_loss: 2.151244\n",
      "batch 28  d_loss: 0.364780  g_loss: 1.840839\n",
      "batch 29  d_loss: 0.452432  g_loss: 2.045628\n",
      "batch 30  d_loss: 0.244986  g_loss: 2.041029\n",
      "batch 31  d_loss: 0.257423  g_loss: 2.053673\n",
      "batch 32  d_loss: 0.308678  g_loss: 2.414091\n",
      "batch 33  d_loss: 0.443806  g_loss: 2.433599\n",
      "batch 34  d_loss: 0.411524  g_loss: 2.116073\n",
      "batch 35  d_loss: 0.433368  g_loss: 1.356128\n",
      "batch 36  d_loss: 0.562034  g_loss: 1.446711\n",
      "batch 37  d_loss: 0.565833  g_loss: 1.242848\n",
      "batch 38  d_loss: 0.529217  g_loss: 1.482238\n",
      "batch 39  d_loss: 0.367444  g_loss: 2.077412\n",
      "batch 40  d_loss: 0.268164  g_loss: 2.058484\n",
      "batch 41  d_loss: 0.373261  g_loss: 1.342832\n",
      "batch 42  d_loss: 0.405285  g_loss: 1.206828\n",
      "batch 43  d_loss: 0.335557  g_loss: 1.271922\n",
      "batch 44  d_loss: 0.466747  g_loss: 1.897048\n",
      "batch 45  d_loss: 0.307610  g_loss: 2.056535\n",
      "Epoch is 38\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.223859  g_loss: 2.142884\n",
      "batch 1  d_loss: 0.325945  g_loss: 1.573890\n",
      "batch 2  d_loss: 0.314418  g_loss: 1.303242\n",
      "batch 3  d_loss: 0.265106  g_loss: 1.599777\n",
      "batch 4  d_loss: 0.319085  g_loss: 2.012293\n",
      "batch 5  d_loss: 0.300276  g_loss: 2.706082\n",
      "batch 6  d_loss: 0.165244  g_loss: 2.496585\n",
      "batch 7  d_loss: 0.597886  g_loss: 2.157050\n",
      "batch 8  d_loss: 0.447397  g_loss: 1.962332\n",
      "batch 9  d_loss: 0.226988  g_loss: 1.898137\n",
      "batch 10  d_loss: 0.306878  g_loss: 1.595718\n",
      "batch 11  d_loss: 0.358753  g_loss: 1.966470\n",
      "batch 12  d_loss: 0.613109  g_loss: 1.512111\n",
      "batch 13  d_loss: 0.547605  g_loss: 1.490856\n",
      "batch 14  d_loss: 0.403058  g_loss: 1.749947\n",
      "batch 15  d_loss: 0.344727  g_loss: 2.120646\n",
      "batch 16  d_loss: 0.318708  g_loss: 1.837494\n",
      "batch 17  d_loss: 0.358343  g_loss: 1.479142\n",
      "batch 18  d_loss: 0.329926  g_loss: 1.504432\n",
      "batch 19  d_loss: 0.290404  g_loss: 2.226836\n",
      "batch 20  d_loss: 0.372347  g_loss: 2.347692\n",
      "batch 21  d_loss: 0.310854  g_loss: 2.081284\n",
      "batch 22  d_loss: 0.301687  g_loss: 1.737154\n",
      "batch 23  d_loss: 0.280170  g_loss: 1.720328\n",
      "batch 24  d_loss: 0.291885  g_loss: 2.015329\n",
      "batch 25  d_loss: 0.268662  g_loss: 2.234600\n",
      "batch 26  d_loss: 0.268397  g_loss: 2.006653\n",
      "batch 27  d_loss: 0.221528  g_loss: 2.200356\n",
      "batch 28  d_loss: 0.327255  g_loss: 1.664294\n",
      "batch 29  d_loss: 0.309304  g_loss: 1.437489\n",
      "batch 30  d_loss: 0.317397  g_loss: 2.014834\n",
      "batch 31  d_loss: 0.283178  g_loss: 2.505285\n",
      "batch 32  d_loss: 0.250371  g_loss: 2.689445\n",
      "batch 33  d_loss: 0.473119  g_loss: 2.684917\n",
      "batch 34  d_loss: 0.327377  g_loss: 1.762101\n",
      "batch 35  d_loss: 0.351171  g_loss: 0.969117\n",
      "batch 36  d_loss: 0.540131  g_loss: 1.296981\n",
      "batch 37  d_loss: 0.449405  g_loss: 1.861583\n",
      "batch 38  d_loss: 0.524899  g_loss: 2.498157\n",
      "batch 39  d_loss: 0.429212  g_loss: 2.088113\n",
      "batch 40  d_loss: 0.368198  g_loss: 1.958785\n",
      "batch 41  d_loss: 0.294620  g_loss: 1.244935\n",
      "batch 42  d_loss: 0.387778  g_loss: 1.086931\n",
      "batch 43  d_loss: 0.320786  g_loss: 2.262294\n",
      "batch 44  d_loss: 0.391264  g_loss: 2.512827\n",
      "batch 45  d_loss: 0.289950  g_loss: 2.971280\n",
      "Epoch is 39\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.287275  g_loss: 2.787954\n",
      "batch 1  d_loss: 0.529993  g_loss: 1.649568\n",
      "batch 2  d_loss: 0.360745  g_loss: 1.763500\n",
      "batch 3  d_loss: 0.322501  g_loss: 2.069346\n",
      "batch 4  d_loss: 0.330149  g_loss: 2.544445\n",
      "batch 5  d_loss: 0.258401  g_loss: 2.579216\n",
      "batch 6  d_loss: 0.277951  g_loss: 2.439398\n",
      "batch 7  d_loss: 0.697262  g_loss: 2.281500\n",
      "batch 8  d_loss: 0.473868  g_loss: 1.687886\n",
      "batch 9  d_loss: 0.367134  g_loss: 1.801933\n",
      "batch 10  d_loss: 0.294194  g_loss: 2.113331\n",
      "batch 11  d_loss: 0.389742  g_loss: 2.620610\n",
      "batch 12  d_loss: 0.482929  g_loss: 2.412825\n",
      "batch 13  d_loss: 0.385657  g_loss: 1.987079\n",
      "batch 14  d_loss: 0.378423  g_loss: 1.644229\n",
      "batch 15  d_loss: 0.346276  g_loss: 1.621292\n",
      "batch 16  d_loss: 0.322251  g_loss: 1.365520\n",
      "batch 17  d_loss: 0.355649  g_loss: 1.729451\n",
      "batch 18  d_loss: 0.297497  g_loss: 1.806770\n",
      "batch 19  d_loss: 0.292128  g_loss: 2.288601\n",
      "batch 20  d_loss: 0.418007  g_loss: 2.121050\n",
      "batch 21  d_loss: 0.298379  g_loss: 1.514753\n",
      "batch 22  d_loss: 0.326137  g_loss: 1.541406\n",
      "batch 23  d_loss: 0.221069  g_loss: 2.138730\n",
      "batch 24  d_loss: 0.300045  g_loss: 2.413012\n",
      "batch 25  d_loss: 0.406154  g_loss: 2.604276\n",
      "batch 26  d_loss: 0.392668  g_loss: 2.276504\n",
      "batch 27  d_loss: 0.222252  g_loss: 1.678797\n",
      "batch 28  d_loss: 0.305300  g_loss: 1.480550\n",
      "batch 29  d_loss: 0.337683  g_loss: 1.717423\n",
      "batch 30  d_loss: 0.241339  g_loss: 1.796384\n",
      "batch 31  d_loss: 0.326068  g_loss: 2.651165\n",
      "batch 32  d_loss: 0.228790  g_loss: 2.392250\n",
      "batch 33  d_loss: 0.278606  g_loss: 2.563842\n",
      "batch 34  d_loss: 0.335583  g_loss: 2.059299\n",
      "batch 35  d_loss: 0.329615  g_loss: 1.695235\n",
      "batch 36  d_loss: 0.456242  g_loss: 1.535700\n",
      "batch 37  d_loss: 0.567379  g_loss: 1.830874\n",
      "batch 38  d_loss: 0.405796  g_loss: 2.249108\n",
      "batch 39  d_loss: 0.328716  g_loss: 2.220630\n",
      "batch 40  d_loss: 0.171332  g_loss: 2.113451\n",
      "batch 41  d_loss: 0.324920  g_loss: 2.016665\n",
      "batch 42  d_loss: 0.396962  g_loss: 1.998229\n",
      "batch 43  d_loss: 0.302005  g_loss: 1.746299\n",
      "batch 44  d_loss: 0.212819  g_loss: 1.879292\n",
      "batch 45  d_loss: 0.288137  g_loss: 1.924888\n",
      "Epoch is 40\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.260424  g_loss: 2.273335\n",
      "batch 1  d_loss: 0.370431  g_loss: 1.877075\n",
      "batch 2  d_loss: 0.265488  g_loss: 1.598920\n",
      "batch 3  d_loss: 0.305777  g_loss: 1.531193\n",
      "batch 4  d_loss: 0.434146  g_loss: 1.944788\n",
      "batch 5  d_loss: 0.286049  g_loss: 2.000010\n",
      "batch 6  d_loss: 0.270210  g_loss: 2.406621\n",
      "batch 7  d_loss: 0.472453  g_loss: 2.901144\n",
      "batch 8  d_loss: 0.411937  g_loss: 2.180431\n",
      "batch 9  d_loss: 0.294720  g_loss: 1.914647\n",
      "batch 10  d_loss: 0.294034  g_loss: 1.433605\n",
      "batch 11  d_loss: 0.405313  g_loss: 1.512587\n",
      "batch 12  d_loss: 0.379053  g_loss: 1.607628\n",
      "batch 13  d_loss: 0.392632  g_loss: 2.101591\n",
      "batch 14  d_loss: 0.305746  g_loss: 1.975454\n",
      "batch 15  d_loss: 0.364260  g_loss: 1.799418\n",
      "batch 16  d_loss: 0.284018  g_loss: 1.682298\n",
      "batch 17  d_loss: 0.327192  g_loss: 2.013025\n",
      "batch 18  d_loss: 0.323890  g_loss: 2.218042\n",
      "batch 19  d_loss: 0.262797  g_loss: 2.519770\n",
      "batch 20  d_loss: 0.321177  g_loss: 1.841464\n",
      "batch 21  d_loss: 0.338770  g_loss: 2.259395\n",
      "batch 22  d_loss: 0.218728  g_loss: 2.638019\n",
      "batch 23  d_loss: 0.275653  g_loss: 2.097742\n",
      "batch 24  d_loss: 0.342291  g_loss: 1.989392\n",
      "batch 25  d_loss: 0.408405  g_loss: 2.155445\n",
      "batch 26  d_loss: 0.363395  g_loss: 1.923339\n",
      "batch 27  d_loss: 0.270408  g_loss: 2.774317\n",
      "batch 28  d_loss: 0.446044  g_loss: 2.333929\n",
      "batch 29  d_loss: 0.412316  g_loss: 1.824931\n",
      "batch 30  d_loss: 0.265846  g_loss: 1.825424\n",
      "batch 31  d_loss: 0.376456  g_loss: 2.205743\n",
      "batch 32  d_loss: 0.266362  g_loss: 2.834802\n",
      "batch 33  d_loss: 0.410417  g_loss: 2.518702\n",
      "batch 34  d_loss: 0.475623  g_loss: 1.982725\n",
      "batch 35  d_loss: 0.339397  g_loss: 1.615831\n",
      "batch 36  d_loss: 0.625149  g_loss: 1.319262\n",
      "batch 37  d_loss: 0.519722  g_loss: 1.877030\n",
      "batch 38  d_loss: 0.419365  g_loss: 2.797169\n",
      "batch 39  d_loss: 0.362173  g_loss: 2.491582\n",
      "batch 40  d_loss: 0.330758  g_loss: 1.921529\n",
      "batch 41  d_loss: 0.369155  g_loss: 1.429816\n",
      "batch 42  d_loss: 0.361010  g_loss: 0.964587\n",
      "batch 43  d_loss: 0.319850  g_loss: 1.523485\n",
      "batch 44  d_loss: 0.358821  g_loss: 1.649615\n",
      "batch 45  d_loss: 0.261119  g_loss: 2.416390\n",
      "Epoch is 41\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.255051  g_loss: 2.384231\n",
      "batch 1  d_loss: 0.396922  g_loss: 1.851849\n",
      "batch 2  d_loss: 0.346149  g_loss: 1.629885\n",
      "batch 3  d_loss: 0.230255  g_loss: 1.770399\n",
      "batch 4  d_loss: 0.289861  g_loss: 1.558023\n",
      "batch 5  d_loss: 0.361493  g_loss: 1.537580\n",
      "batch 6  d_loss: 0.182809  g_loss: 2.189343\n",
      "batch 7  d_loss: 0.524831  g_loss: 2.718518\n",
      "batch 8  d_loss: 0.389517  g_loss: 2.462357\n",
      "batch 9  d_loss: 0.272380  g_loss: 1.899331\n",
      "batch 10  d_loss: 0.403718  g_loss: 1.310968\n",
      "batch 11  d_loss: 0.376635  g_loss: 1.414610\n",
      "batch 12  d_loss: 0.472413  g_loss: 1.819032\n",
      "batch 13  d_loss: 0.315077  g_loss: 2.241653\n",
      "batch 14  d_loss: 0.289867  g_loss: 2.452452\n",
      "batch 15  d_loss: 0.334020  g_loss: 2.326087\n",
      "batch 16  d_loss: 0.332975  g_loss: 1.802675\n",
      "batch 17  d_loss: 0.364353  g_loss: 1.446548\n",
      "batch 18  d_loss: 0.224254  g_loss: 1.628347\n",
      "batch 19  d_loss: 0.287207  g_loss: 2.235464\n",
      "batch 20  d_loss: 0.283038  g_loss: 2.427397\n",
      "batch 21  d_loss: 0.257326  g_loss: 2.377180\n",
      "batch 22  d_loss: 0.277375  g_loss: 2.035443\n",
      "batch 23  d_loss: 0.271009  g_loss: 1.873548\n",
      "batch 24  d_loss: 0.255519  g_loss: 1.793945\n",
      "batch 25  d_loss: 0.269777  g_loss: 2.154228\n",
      "batch 26  d_loss: 0.308369  g_loss: 2.192398\n",
      "batch 27  d_loss: 0.283176  g_loss: 2.367728\n",
      "batch 28  d_loss: 0.314365  g_loss: 2.185375\n",
      "batch 29  d_loss: 0.300208  g_loss: 2.022230\n",
      "batch 30  d_loss: 0.334888  g_loss: 2.148228\n",
      "batch 31  d_loss: 0.391803  g_loss: 2.127062\n",
      "batch 32  d_loss: 0.224044  g_loss: 2.041505\n",
      "batch 33  d_loss: 0.310241  g_loss: 2.493088\n",
      "batch 34  d_loss: 0.358910  g_loss: 2.501731\n",
      "batch 35  d_loss: 0.493413  g_loss: 1.715350\n",
      "batch 36  d_loss: 0.496409  g_loss: 1.193947\n",
      "batch 37  d_loss: 0.394104  g_loss: 1.363271\n",
      "batch 38  d_loss: 0.586923  g_loss: 1.848144\n",
      "batch 39  d_loss: 0.359027  g_loss: 2.154022\n",
      "batch 40  d_loss: 0.243084  g_loss: 2.693459\n",
      "batch 41  d_loss: 0.418384  g_loss: 2.143885\n",
      "batch 42  d_loss: 0.323693  g_loss: 1.720787\n",
      "batch 43  d_loss: 0.317523  g_loss: 1.641907\n",
      "batch 44  d_loss: 0.296467  g_loss: 1.818109\n",
      "batch 45  d_loss: 0.266592  g_loss: 2.407140\n",
      "Epoch is 42\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.305452  g_loss: 2.368624\n",
      "batch 1  d_loss: 0.411687  g_loss: 2.282375\n",
      "batch 2  d_loss: 0.268536  g_loss: 2.187895\n",
      "batch 3  d_loss: 0.269792  g_loss: 1.746132\n",
      "batch 4  d_loss: 0.342887  g_loss: 1.795107\n",
      "batch 5  d_loss: 0.397879  g_loss: 2.461830\n",
      "batch 6  d_loss: 0.239166  g_loss: 2.875589\n",
      "batch 7  d_loss: 0.665741  g_loss: 3.219472\n",
      "batch 8  d_loss: 0.550555  g_loss: 2.399557\n",
      "batch 9  d_loss: 0.293683  g_loss: 1.342043\n",
      "batch 10  d_loss: 0.368122  g_loss: 1.322394\n",
      "batch 11  d_loss: 0.501697  g_loss: 1.746097\n",
      "batch 12  d_loss: 0.439682  g_loss: 2.047307\n",
      "batch 13  d_loss: 0.364191  g_loss: 2.640937\n",
      "batch 14  d_loss: 0.318953  g_loss: 2.233180\n",
      "batch 15  d_loss: 0.421163  g_loss: 2.067836\n",
      "batch 16  d_loss: 0.323130  g_loss: 1.595787\n",
      "batch 17  d_loss: 0.304528  g_loss: 1.842739\n",
      "batch 18  d_loss: 0.400514  g_loss: 1.414281\n",
      "batch 19  d_loss: 0.407092  g_loss: 1.573657\n",
      "batch 20  d_loss: 0.291525  g_loss: 1.351891\n",
      "batch 21  d_loss: 0.322606  g_loss: 1.749918\n",
      "batch 22  d_loss: 0.204663  g_loss: 1.866734\n",
      "batch 23  d_loss: 0.273402  g_loss: 2.281029\n",
      "batch 24  d_loss: 0.257381  g_loss: 2.611301\n",
      "batch 25  d_loss: 0.350093  g_loss: 2.182920\n",
      "batch 26  d_loss: 0.225432  g_loss: 1.799855\n",
      "batch 27  d_loss: 0.248039  g_loss: 1.757207\n",
      "batch 28  d_loss: 0.369293  g_loss: 1.922741\n",
      "batch 29  d_loss: 0.443457  g_loss: 1.814829\n",
      "batch 30  d_loss: 0.198006  g_loss: 2.391156\n",
      "batch 31  d_loss: 0.384657  g_loss: 3.396091\n",
      "batch 32  d_loss: 0.308050  g_loss: 3.308604\n",
      "batch 33  d_loss: 0.376870  g_loss: 2.699890\n",
      "batch 34  d_loss: 0.279481  g_loss: 2.319288\n",
      "batch 35  d_loss: 0.314498  g_loss: 1.814417\n",
      "batch 36  d_loss: 0.613944  g_loss: 1.527151\n",
      "batch 37  d_loss: 0.627444  g_loss: 1.476642\n",
      "batch 38  d_loss: 0.481185  g_loss: 2.307913\n",
      "batch 39  d_loss: 0.372835  g_loss: 2.812349\n",
      "batch 40  d_loss: 0.244804  g_loss: 2.813488\n",
      "batch 41  d_loss: 0.354418  g_loss: 2.107245\n",
      "batch 42  d_loss: 0.304377  g_loss: 1.490009\n",
      "batch 43  d_loss: 0.303599  g_loss: 1.625313\n",
      "batch 44  d_loss: 0.292976  g_loss: 1.807863\n",
      "batch 45  d_loss: 0.214389  g_loss: 2.298051\n",
      "Epoch is 43\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.285118  g_loss: 2.405200\n",
      "batch 1  d_loss: 0.351659  g_loss: 2.240365\n",
      "batch 2  d_loss: 0.315927  g_loss: 1.700735\n",
      "batch 3  d_loss: 0.328136  g_loss: 1.112161\n",
      "batch 4  d_loss: 0.323912  g_loss: 1.578256\n",
      "batch 5  d_loss: 0.322034  g_loss: 1.953426\n",
      "batch 6  d_loss: 0.327612  g_loss: 2.213197\n",
      "batch 7  d_loss: 0.439704  g_loss: 2.609239\n",
      "batch 8  d_loss: 0.408503  g_loss: 2.488184\n",
      "batch 9  d_loss: 0.247797  g_loss: 2.086018\n",
      "batch 10  d_loss: 0.408763  g_loss: 1.586304\n",
      "batch 11  d_loss: 0.393156  g_loss: 1.260010\n",
      "batch 12  d_loss: 0.523764  g_loss: 1.254280\n",
      "batch 13  d_loss: 0.402917  g_loss: 1.794136\n",
      "batch 14  d_loss: 0.314629  g_loss: 2.569097\n",
      "batch 15  d_loss: 0.470419  g_loss: 2.740595\n",
      "batch 16  d_loss: 0.387499  g_loss: 2.395627\n",
      "batch 17  d_loss: 0.411664  g_loss: 1.768406\n",
      "batch 18  d_loss: 0.259525  g_loss: 1.692230\n",
      "batch 19  d_loss: 0.309766  g_loss: 1.342239\n",
      "batch 20  d_loss: 0.438862  g_loss: 1.332132\n",
      "batch 21  d_loss: 0.336220  g_loss: 1.805689\n",
      "batch 22  d_loss: 0.318938  g_loss: 2.284034\n",
      "batch 23  d_loss: 0.221789  g_loss: 2.652978\n",
      "batch 24  d_loss: 0.395399  g_loss: 2.538603\n",
      "batch 25  d_loss: 0.290428  g_loss: 2.007842\n",
      "batch 26  d_loss: 0.262521  g_loss: 1.462862\n",
      "batch 27  d_loss: 0.229687  g_loss: 1.358322\n",
      "batch 28  d_loss: 0.374394  g_loss: 1.510296\n",
      "batch 29  d_loss: 0.467061  g_loss: 1.908800\n",
      "batch 30  d_loss: 0.234798  g_loss: 2.033680\n",
      "batch 31  d_loss: 0.329832  g_loss: 2.735629\n",
      "batch 32  d_loss: 0.385600  g_loss: 2.399158\n",
      "batch 33  d_loss: 0.524184  g_loss: 1.726439\n",
      "batch 34  d_loss: 0.445684  g_loss: 1.187805\n",
      "batch 35  d_loss: 0.448406  g_loss: 1.320177\n",
      "batch 36  d_loss: 0.690983  g_loss: 1.392106\n",
      "batch 37  d_loss: 0.478143  g_loss: 2.212256\n",
      "batch 38  d_loss: 0.483642  g_loss: 2.339597\n",
      "batch 39  d_loss: 0.377642  g_loss: 2.528286\n",
      "batch 40  d_loss: 0.260981  g_loss: 1.569007\n",
      "batch 41  d_loss: 0.315405  g_loss: 1.704514\n",
      "batch 42  d_loss: 0.385057  g_loss: 1.786693\n",
      "batch 43  d_loss: 0.276821  g_loss: 1.502503\n",
      "batch 44  d_loss: 0.355443  g_loss: 1.899501\n",
      "batch 45  d_loss: 0.282770  g_loss: 2.120021\n",
      "Epoch is 44\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.376160  g_loss: 2.107779\n",
      "batch 1  d_loss: 0.371388  g_loss: 2.133754\n",
      "batch 2  d_loss: 0.412993  g_loss: 2.040432\n",
      "batch 3  d_loss: 0.254534  g_loss: 2.040366\n",
      "batch 4  d_loss: 0.255826  g_loss: 1.494172\n",
      "batch 5  d_loss: 0.357089  g_loss: 1.558540\n",
      "batch 6  d_loss: 0.320631  g_loss: 1.751408\n",
      "batch 7  d_loss: 0.521285  g_loss: 2.013415\n",
      "batch 8  d_loss: 0.469931  g_loss: 2.346496\n",
      "batch 9  d_loss: 0.274632  g_loss: 2.250872\n",
      "batch 10  d_loss: 0.315823  g_loss: 1.962954\n",
      "batch 11  d_loss: 0.404356  g_loss: 1.892389\n",
      "batch 12  d_loss: 0.421304  g_loss: 1.276408\n",
      "batch 13  d_loss: 0.257271  g_loss: 1.301814\n",
      "batch 14  d_loss: 0.407804  g_loss: 1.814552\n",
      "batch 15  d_loss: 0.378960  g_loss: 2.065542\n",
      "batch 16  d_loss: 0.197396  g_loss: 2.933445\n",
      "batch 17  d_loss: 0.470456  g_loss: 2.838686\n",
      "batch 18  d_loss: 0.346047  g_loss: 2.469723\n",
      "batch 19  d_loss: 0.214026  g_loss: 1.564449\n",
      "batch 20  d_loss: 0.325636  g_loss: 1.674680\n",
      "batch 21  d_loss: 0.338839  g_loss: 1.684116\n",
      "batch 22  d_loss: 0.259599  g_loss: 2.726778\n",
      "batch 23  d_loss: 0.210567  g_loss: 3.201284\n",
      "batch 24  d_loss: 0.308304  g_loss: 3.160680\n",
      "batch 25  d_loss: 0.324673  g_loss: 2.646636\n",
      "batch 26  d_loss: 0.337294  g_loss: 2.152674\n",
      "batch 27  d_loss: 0.242545  g_loss: 1.681501\n",
      "batch 28  d_loss: 0.426438  g_loss: 2.064729\n",
      "batch 29  d_loss: 0.311838  g_loss: 2.488141\n",
      "batch 30  d_loss: 0.366881  g_loss: 2.617354\n",
      "batch 31  d_loss: 0.378598  g_loss: 2.996202\n",
      "batch 32  d_loss: 0.396816  g_loss: 2.404504\n",
      "batch 33  d_loss: 0.432815  g_loss: 1.843292\n",
      "batch 34  d_loss: 0.399957  g_loss: 1.437775\n",
      "batch 35  d_loss: 0.498617  g_loss: 1.199057\n",
      "batch 36  d_loss: 0.465789  g_loss: 1.197858\n",
      "batch 37  d_loss: 0.388860  g_loss: 1.663278\n",
      "batch 38  d_loss: 0.321513  g_loss: 1.871712\n",
      "batch 39  d_loss: 0.366020  g_loss: 2.064706\n",
      "batch 40  d_loss: 0.461827  g_loss: 2.035113\n",
      "batch 41  d_loss: 0.429933  g_loss: 1.384530\n",
      "batch 42  d_loss: 0.448662  g_loss: 1.227288\n",
      "batch 43  d_loss: 0.350568  g_loss: 1.180201\n",
      "batch 44  d_loss: 0.547846  g_loss: 1.555653\n",
      "batch 45  d_loss: 0.332002  g_loss: 1.660062\n",
      "Epoch is 45\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.288718  g_loss: 1.818141\n",
      "batch 1  d_loss: 0.344169  g_loss: 2.444493\n",
      "batch 2  d_loss: 0.381243  g_loss: 2.282260\n",
      "batch 3  d_loss: 0.443740  g_loss: 1.715152\n",
      "batch 4  d_loss: 0.346756  g_loss: 1.349264\n",
      "batch 5  d_loss: 0.388689  g_loss: 1.388656\n",
      "batch 6  d_loss: 0.353931  g_loss: 1.495932\n",
      "batch 7  d_loss: 0.428845  g_loss: 1.509811\n",
      "batch 8  d_loss: 0.293560  g_loss: 1.895844\n",
      "batch 9  d_loss: 0.267932  g_loss: 2.061285\n",
      "batch 10  d_loss: 0.277237  g_loss: 2.494969\n",
      "batch 11  d_loss: 0.402337  g_loss: 1.932520\n",
      "batch 12  d_loss: 0.570497  g_loss: 1.798528\n",
      "batch 13  d_loss: 0.333538  g_loss: 1.417969\n",
      "batch 14  d_loss: 0.419522  g_loss: 1.463251\n",
      "batch 15  d_loss: 0.465174  g_loss: 1.862542\n",
      "batch 16  d_loss: 0.278797  g_loss: 2.119063\n",
      "batch 17  d_loss: 0.375021  g_loss: 2.337943\n",
      "batch 18  d_loss: 0.328005  g_loss: 2.739692\n",
      "batch 19  d_loss: 0.344387  g_loss: 2.161330\n",
      "batch 20  d_loss: 0.460644  g_loss: 1.918572\n",
      "batch 21  d_loss: 0.310372  g_loss: 1.660170\n",
      "batch 22  d_loss: 0.326825  g_loss: 1.494081\n",
      "batch 23  d_loss: 0.286233  g_loss: 2.168524\n",
      "batch 24  d_loss: 0.285126  g_loss: 2.425657\n",
      "batch 25  d_loss: 0.391494  g_loss: 2.809809\n",
      "batch 26  d_loss: 0.291741  g_loss: 2.787097\n",
      "batch 27  d_loss: 0.304955  g_loss: 2.581760\n",
      "batch 28  d_loss: 0.320939  g_loss: 2.242804\n",
      "batch 29  d_loss: 0.489428  g_loss: 2.072663\n",
      "batch 30  d_loss: 0.360000  g_loss: 2.314304\n",
      "batch 31  d_loss: 0.397862  g_loss: 2.669056\n",
      "batch 32  d_loss: 0.370593  g_loss: 2.611350\n",
      "batch 33  d_loss: 0.375382  g_loss: 2.341522\n",
      "batch 34  d_loss: 0.445792  g_loss: 2.489188\n",
      "batch 35  d_loss: 0.490755  g_loss: 2.012307\n",
      "batch 36  d_loss: 0.543206  g_loss: 1.109844\n",
      "batch 37  d_loss: 0.514327  g_loss: 1.429091\n",
      "batch 38  d_loss: 0.484612  g_loss: 2.138107\n",
      "batch 39  d_loss: 0.323806  g_loss: 2.445911\n",
      "batch 40  d_loss: 0.320122  g_loss: 3.163140\n",
      "batch 41  d_loss: 0.304068  g_loss: 1.895119\n",
      "batch 42  d_loss: 0.347511  g_loss: 2.255381\n",
      "batch 43  d_loss: 0.302997  g_loss: 1.641588\n",
      "batch 44  d_loss: 0.227169  g_loss: 1.492067\n",
      "batch 45  d_loss: 0.267809  g_loss: 1.634164\n",
      "Epoch is 46\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.283969  g_loss: 2.427758\n",
      "batch 1  d_loss: 0.382265  g_loss: 2.472786\n",
      "batch 2  d_loss: 0.363730  g_loss: 2.206110\n",
      "batch 3  d_loss: 0.176762  g_loss: 2.161059\n",
      "batch 4  d_loss: 0.373951  g_loss: 1.682334\n",
      "batch 5  d_loss: 0.312889  g_loss: 1.645787\n",
      "batch 6  d_loss: 0.264103  g_loss: 1.903828\n",
      "batch 7  d_loss: 0.441903  g_loss: 2.063294\n",
      "batch 8  d_loss: 0.385832  g_loss: 2.066879\n",
      "batch 9  d_loss: 0.327770  g_loss: 1.997225\n",
      "batch 10  d_loss: 0.512099  g_loss: 1.884850\n",
      "batch 11  d_loss: 0.439040  g_loss: 1.321671\n",
      "batch 12  d_loss: 0.381387  g_loss: 0.947030\n",
      "batch 13  d_loss: 0.432900  g_loss: 1.344979\n",
      "batch 14  d_loss: 0.369000  g_loss: 1.816368\n",
      "batch 15  d_loss: 0.275886  g_loss: 2.247633\n",
      "batch 16  d_loss: 0.334511  g_loss: 2.766808\n",
      "batch 17  d_loss: 0.388866  g_loss: 2.315259\n",
      "batch 18  d_loss: 0.275570  g_loss: 2.074423\n",
      "batch 19  d_loss: 0.340131  g_loss: 1.579760\n",
      "batch 20  d_loss: 0.257826  g_loss: 1.255583\n",
      "batch 21  d_loss: 0.302891  g_loss: 1.195808\n",
      "batch 22  d_loss: 0.339865  g_loss: 1.632225\n",
      "batch 23  d_loss: 0.208627  g_loss: 2.171792\n",
      "batch 24  d_loss: 0.245720  g_loss: 2.523767\n",
      "batch 25  d_loss: 0.301096  g_loss: 2.534994\n",
      "batch 26  d_loss: 0.352662  g_loss: 2.576652\n",
      "batch 27  d_loss: 0.246072  g_loss: 1.922003\n",
      "batch 28  d_loss: 0.355751  g_loss: 1.595707\n",
      "batch 29  d_loss: 0.339418  g_loss: 1.324741\n",
      "batch 30  d_loss: 0.296911  g_loss: 1.512841\n",
      "batch 31  d_loss: 0.289673  g_loss: 1.909435\n",
      "batch 32  d_loss: 0.290365  g_loss: 3.101613\n",
      "batch 33  d_loss: 0.379769  g_loss: 2.823625\n",
      "batch 34  d_loss: 0.360786  g_loss: 2.525289\n",
      "batch 35  d_loss: 0.388447  g_loss: 1.756911\n",
      "batch 36  d_loss: 0.531737  g_loss: 1.261937\n",
      "batch 37  d_loss: 0.522719  g_loss: 1.233255\n",
      "batch 38  d_loss: 0.376794  g_loss: 1.583335\n",
      "batch 39  d_loss: 0.348775  g_loss: 1.967680\n",
      "batch 40  d_loss: 0.222421  g_loss: 2.553977\n",
      "batch 41  d_loss: 0.413067  g_loss: 2.507777\n",
      "batch 42  d_loss: 0.328182  g_loss: 2.372064\n",
      "batch 43  d_loss: 0.294331  g_loss: 1.459686\n",
      "batch 44  d_loss: 0.316698  g_loss: 1.356995\n",
      "batch 45  d_loss: 0.351771  g_loss: 1.723780\n",
      "Epoch is 47\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.425619  g_loss: 2.241633\n",
      "batch 1  d_loss: 0.268064  g_loss: 2.707903\n",
      "batch 2  d_loss: 0.308235  g_loss: 2.843480\n",
      "batch 3  d_loss: 0.306789  g_loss: 2.264986\n",
      "batch 4  d_loss: 0.436720  g_loss: 2.073451\n",
      "batch 5  d_loss: 0.380955  g_loss: 1.671685\n",
      "batch 6  d_loss: 0.355079  g_loss: 1.699294\n",
      "batch 7  d_loss: 0.515910  g_loss: 1.706142\n",
      "batch 8  d_loss: 0.449795  g_loss: 2.088266\n",
      "batch 9  d_loss: 0.308344  g_loss: 1.865028\n",
      "batch 10  d_loss: 0.303495  g_loss: 2.105052\n",
      "batch 11  d_loss: 0.491783  g_loss: 1.816725\n",
      "batch 12  d_loss: 0.461931  g_loss: 1.470822\n",
      "batch 13  d_loss: 0.357262  g_loss: 1.783889\n",
      "batch 14  d_loss: 0.395543  g_loss: 2.007636\n",
      "batch 15  d_loss: 0.413914  g_loss: 2.243628\n",
      "batch 16  d_loss: 0.390356  g_loss: 2.291536\n",
      "batch 17  d_loss: 0.284366  g_loss: 2.298268\n",
      "batch 18  d_loss: 0.308255  g_loss: 2.364381\n",
      "batch 19  d_loss: 0.372670  g_loss: 1.816664\n",
      "batch 20  d_loss: 0.415924  g_loss: 1.881202\n",
      "batch 21  d_loss: 0.326479  g_loss: 1.293593\n",
      "batch 22  d_loss: 0.337056  g_loss: 1.425370\n",
      "batch 23  d_loss: 0.293611  g_loss: 2.407892\n",
      "batch 24  d_loss: 0.317520  g_loss: 2.602991\n",
      "batch 25  d_loss: 0.421743  g_loss: 2.666694\n",
      "batch 26  d_loss: 0.435176  g_loss: 2.214784\n",
      "batch 27  d_loss: 0.238594  g_loss: 1.981551\n",
      "batch 28  d_loss: 0.269397  g_loss: 1.451634\n",
      "batch 29  d_loss: 0.320115  g_loss: 1.593601\n",
      "batch 30  d_loss: 0.258376  g_loss: 2.000870\n",
      "batch 31  d_loss: 0.359999  g_loss: 2.502540\n",
      "batch 32  d_loss: 0.240013  g_loss: 2.824998\n",
      "batch 33  d_loss: 0.257064  g_loss: 3.308486\n",
      "batch 34  d_loss: 0.366639  g_loss: 2.599536\n",
      "batch 35  d_loss: 0.384531  g_loss: 1.343240\n",
      "batch 36  d_loss: 0.431581  g_loss: 0.839580\n",
      "batch 37  d_loss: 0.648734  g_loss: 0.952964\n",
      "batch 38  d_loss: 0.544444  g_loss: 1.785820\n",
      "batch 39  d_loss: 0.321114  g_loss: 2.953682\n",
      "batch 40  d_loss: 0.330642  g_loss: 3.779419\n",
      "batch 41  d_loss: 0.458995  g_loss: 2.967722\n",
      "batch 42  d_loss: 0.486191  g_loss: 2.177366\n",
      "batch 43  d_loss: 0.311028  g_loss: 1.577976\n",
      "batch 44  d_loss: 0.409136  g_loss: 1.354802\n",
      "batch 45  d_loss: 0.309749  g_loss: 2.119646\n",
      "Epoch is 48\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.289755  g_loss: 2.168166\n",
      "batch 1  d_loss: 0.299910  g_loss: 2.307583\n",
      "batch 2  d_loss: 0.388659  g_loss: 2.461649\n",
      "batch 3  d_loss: 0.306603  g_loss: 2.278938\n",
      "batch 4  d_loss: 0.430637  g_loss: 1.914245\n",
      "batch 5  d_loss: 0.307646  g_loss: 1.212451\n",
      "batch 6  d_loss: 0.330129  g_loss: 1.389872\n",
      "batch 7  d_loss: 0.612352  g_loss: 1.680653\n",
      "batch 8  d_loss: 0.462573  g_loss: 1.856948\n",
      "batch 9  d_loss: 0.365938  g_loss: 2.151919\n",
      "batch 10  d_loss: 0.386714  g_loss: 2.309420\n",
      "batch 11  d_loss: 0.494348  g_loss: 1.937400\n",
      "batch 12  d_loss: 0.451587  g_loss: 1.617651\n",
      "batch 13  d_loss: 0.576555  g_loss: 1.123105\n",
      "batch 14  d_loss: 0.416507  g_loss: 1.068572\n",
      "batch 15  d_loss: 0.494304  g_loss: 1.110851\n",
      "batch 16  d_loss: 0.339745  g_loss: 1.708442\n",
      "batch 17  d_loss: 0.389548  g_loss: 1.856653\n",
      "batch 18  d_loss: 0.328857  g_loss: 2.232242\n",
      "batch 19  d_loss: 0.384834  g_loss: 1.975778\n",
      "batch 20  d_loss: 0.412145  g_loss: 1.587853\n",
      "batch 21  d_loss: 0.406180  g_loss: 1.206093\n",
      "batch 22  d_loss: 0.349857  g_loss: 1.252146\n",
      "batch 23  d_loss: 0.398650  g_loss: 1.575430\n",
      "batch 24  d_loss: 0.329942  g_loss: 1.618555\n",
      "batch 25  d_loss: 0.304212  g_loss: 1.922844\n",
      "batch 26  d_loss: 0.263978  g_loss: 2.314934\n",
      "batch 27  d_loss: 0.255654  g_loss: 2.001876\n",
      "batch 28  d_loss: 0.435701  g_loss: 1.705248\n",
      "batch 29  d_loss: 0.422240  g_loss: 1.638543\n",
      "batch 30  d_loss: 0.258720  g_loss: 1.686866\n",
      "batch 31  d_loss: 0.412047  g_loss: 1.859133\n",
      "batch 32  d_loss: 0.260950  g_loss: 2.143306\n",
      "batch 33  d_loss: 0.268919  g_loss: 2.614050\n",
      "batch 34  d_loss: 0.498140  g_loss: 2.149544\n",
      "batch 35  d_loss: 0.390366  g_loss: 1.118561\n",
      "batch 36  d_loss: 0.414560  g_loss: 1.023893\n",
      "batch 37  d_loss: 0.557155  g_loss: 1.132940\n",
      "batch 38  d_loss: 0.490971  g_loss: 1.902826\n",
      "batch 39  d_loss: 0.364784  g_loss: 2.612534\n",
      "batch 40  d_loss: 0.285807  g_loss: 2.964386\n",
      "batch 41  d_loss: 0.503161  g_loss: 2.081901\n",
      "batch 42  d_loss: 0.379752  g_loss: 1.231336\n",
      "batch 43  d_loss: 0.415124  g_loss: 1.303681\n",
      "batch 44  d_loss: 0.441086  g_loss: 1.255668\n",
      "batch 45  d_loss: 0.427044  g_loss: 2.261122\n",
      "Epoch is 49\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.403767  g_loss: 2.663475\n",
      "batch 1  d_loss: 0.354937  g_loss: 2.624152\n",
      "batch 2  d_loss: 0.431746  g_loss: 1.879790\n",
      "batch 3  d_loss: 0.360018  g_loss: 1.463769\n",
      "batch 4  d_loss: 0.343079  g_loss: 1.027337\n",
      "batch 5  d_loss: 0.448211  g_loss: 1.019330\n",
      "batch 6  d_loss: 0.492836  g_loss: 1.387491\n",
      "batch 7  d_loss: 0.534440  g_loss: 2.359588\n",
      "batch 8  d_loss: 0.404742  g_loss: 2.537867\n",
      "batch 9  d_loss: 0.378541  g_loss: 2.788082\n",
      "batch 10  d_loss: 0.395088  g_loss: 2.516026\n",
      "batch 11  d_loss: 0.445385  g_loss: 2.105978\n",
      "batch 12  d_loss: 0.433745  g_loss: 1.385259\n",
      "batch 13  d_loss: 0.401702  g_loss: 1.093824\n",
      "batch 14  d_loss: 0.424536  g_loss: 1.294137\n",
      "batch 15  d_loss: 0.431595  g_loss: 1.418837\n",
      "batch 16  d_loss: 0.265614  g_loss: 2.064553\n",
      "batch 17  d_loss: 0.252834  g_loss: 2.458531\n",
      "batch 18  d_loss: 0.242277  g_loss: 2.616100\n",
      "batch 19  d_loss: 0.240947  g_loss: 2.700675\n",
      "batch 20  d_loss: 0.386303  g_loss: 2.305500\n",
      "batch 21  d_loss: 0.251356  g_loss: 1.799827\n",
      "batch 22  d_loss: 0.283137  g_loss: 1.841161\n",
      "batch 23  d_loss: 0.247778  g_loss: 2.059190\n",
      "batch 24  d_loss: 0.316331  g_loss: 2.163022\n",
      "batch 25  d_loss: 0.286057  g_loss: 2.052113\n",
      "batch 26  d_loss: 0.204038  g_loss: 2.333959\n",
      "batch 27  d_loss: 0.242354  g_loss: 2.331522\n",
      "batch 28  d_loss: 0.296738  g_loss: 2.335182\n",
      "batch 29  d_loss: 0.318053  g_loss: 2.078418\n",
      "batch 30  d_loss: 0.351653  g_loss: 1.773839\n",
      "batch 31  d_loss: 0.429104  g_loss: 1.754636\n",
      "batch 32  d_loss: 0.372181  g_loss: 1.904426\n",
      "batch 33  d_loss: 0.373077  g_loss: 1.639877\n",
      "batch 34  d_loss: 0.502052  g_loss: 1.897366\n",
      "batch 35  d_loss: 0.504622  g_loss: 1.593971\n",
      "batch 36  d_loss: 0.667835  g_loss: 1.654702\n",
      "batch 37  d_loss: 0.670767  g_loss: 1.643893\n",
      "batch 38  d_loss: 0.450662  g_loss: 1.788840\n",
      "batch 39  d_loss: 0.467576  g_loss: 1.833032\n",
      "batch 40  d_loss: 0.436754  g_loss: 1.775162\n",
      "batch 41  d_loss: 0.481548  g_loss: 2.181650\n",
      "batch 42  d_loss: 0.341456  g_loss: 2.292595\n",
      "batch 43  d_loss: 0.414084  g_loss: 1.623359\n",
      "batch 44  d_loss: 0.380532  g_loss: 1.484777\n",
      "batch 45  d_loss: 0.424270  g_loss: 1.271540\n",
      "CPU times: user 11min 38s, sys: 15.7 s, total: 11min 54s\n",
      "Wall time: 4min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176290,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "9077a4b0-a66a-4946-eb3c-f5f70f1d5452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.907354</td>\n",
       "      <td>0.345442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561648</td>\n",
       "      <td>0.317500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.579032</td>\n",
       "      <td>0.494862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.462686</td>\n",
       "      <td>0.945871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.349043</td>\n",
       "      <td>1.732489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch    d_loss    g_loss\n",
       "0      0      0  0.907354  0.345442\n",
       "1      0      1  0.561648  0.317500\n",
       "2      0      2  0.579032  0.494862\n",
       "3      0      3  0.462686  0.945871\n",
       "4      0      4  0.349043  1.732489"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.481548</td>\n",
       "      <td>2.181650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.341456</td>\n",
       "      <td>2.292595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>0.414084</td>\n",
       "      <td>1.623359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>0.380532</td>\n",
       "      <td>1.484777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>0.424270</td>\n",
       "      <td>1.271540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  batch    d_loss    g_loss\n",
       "2295     49     41  0.481548  2.181650\n",
       "2296     49     42  0.341456  2.292595\n",
       "2297     49     43  0.414084  1.623359\n",
       "2298     49     44  0.380532  1.484777\n",
       "2299     49     45  0.424270  1.271540"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176283,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "669f9caf-ccc0-46ef-ed8c-c46b1a28d5ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "generate(batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_with_keras-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
