{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1576148328509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "k3LWJrdjDSJy",
    "outputId": "748de6e4-fd9b-426e-d7db-b02b51ed8e51"
   },
   "source": [
    "### Sample program for DCGAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 22:21:50.331231: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-16 22:21:50.331283: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLeQXXYjCcVm"
   },
   "outputs": [],
   "source": [
    "used_digits = [4,8]\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images'\n",
    "model_g = 'model_dcgan-b{}_g.h5'.format(batch_size)\n",
    "model_d = 'model_dcgan-b{}_d.h5'.format(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove old img_dir and create new one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1576148329857,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "IOF5fZwICcVo",
    "outputId": "5c1cc125-a086-4060-de5a-21adba1d64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OK\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(img_dir):\n",
    "    shutil.rmtree(img_dir)\n",
    "\n",
    "cnt = 10\n",
    "while cnt > 0:\n",
    "    try:\n",
    "        os.makedirs(img_dir)\n",
    "        break\n",
    "    except:\n",
    "        sleep(1)\n",
    "    cnt -= 1\n",
    "    \n",
    "if cnt <= 0:\n",
    "    print('Cannot mkdir:', img_dir)\n",
    "else:\n",
    "    print('mkdir: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(n_noise, ), activation=\"tanh\"))\n",
    "    model.add(Dense(32 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Reshape((7, 7, 32), input_shape=(7 * 7 * 32,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     input_shape=(28, 28, 1),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"tanh\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjAEL8P8CcV0"
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    generator.load_weights(\"generator\")\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176294,
     "status": "ok",
     "timestamp": 1576148503868,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "00ea9935-7deb-4110-81bb-cd1c312a3a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anhvu/.local/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 22:21:53.402239: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-16 22:21:53.402269: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-16 22:21:53.402286: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anhvu): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "2022-01-16 22:21:53.663263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  d_loss: 0.714093  g_loss: 0.345825\n",
      "batch 1  d_loss: 0.511360  g_loss: 0.567378\n",
      "batch 2  d_loss: 0.437168  g_loss: 1.173110\n",
      "batch 3  d_loss: 0.296602  g_loss: 2.363376\n",
      "batch 4  d_loss: 0.186836  g_loss: 3.891134\n",
      "batch 5  d_loss: 0.087123  g_loss: 5.419366\n",
      "batch 6  d_loss: 0.066394  g_loss: 6.509733\n",
      "batch 7  d_loss: 0.242064  g_loss: 6.841009\n",
      "batch 8  d_loss: 0.099274  g_loss: 6.798533\n",
      "batch 9  d_loss: 0.095760  g_loss: 6.851528\n",
      "batch 10  d_loss: 0.304589  g_loss: 6.886571\n",
      "batch 11  d_loss: 0.420641  g_loss: 6.833150\n",
      "batch 12  d_loss: 0.287742  g_loss: 7.090028\n",
      "batch 13  d_loss: 0.331259  g_loss: 6.797531\n",
      "batch 14  d_loss: 0.205593  g_loss: 6.662777\n",
      "batch 15  d_loss: 0.280943  g_loss: 5.759856\n",
      "batch 16  d_loss: 0.406689  g_loss: 5.359427\n",
      "batch 17  d_loss: 0.362157  g_loss: 4.484129\n",
      "batch 18  d_loss: 0.323331  g_loss: 3.753250\n",
      "batch 19  d_loss: 0.449827  g_loss: 3.465730\n",
      "batch 20  d_loss: 0.531680  g_loss: 3.234364\n",
      "batch 21  d_loss: 0.494159  g_loss: 4.196012\n",
      "batch 22  d_loss: 0.598923  g_loss: 4.236837\n",
      "batch 23  d_loss: 0.360140  g_loss: 4.239524\n",
      "batch 24  d_loss: 0.181981  g_loss: 4.051287\n",
      "batch 25  d_loss: 0.221271  g_loss: 4.695389\n",
      "batch 26  d_loss: 0.165373  g_loss: 4.121893\n",
      "batch 27  d_loss: 0.332640  g_loss: 4.528026\n",
      "batch 28  d_loss: 0.209411  g_loss: 4.440034\n",
      "batch 29  d_loss: 0.319080  g_loss: 5.284183\n",
      "batch 30  d_loss: 0.340982  g_loss: 4.737565\n",
      "batch 31  d_loss: 0.186614  g_loss: 4.688731\n",
      "batch 32  d_loss: 0.173380  g_loss: 4.627693\n",
      "batch 33  d_loss: 0.175663  g_loss: 4.952133\n",
      "batch 34  d_loss: 0.048661  g_loss: 4.516750\n",
      "batch 35  d_loss: 0.198327  g_loss: 4.591857\n",
      "batch 36  d_loss: 0.127152  g_loss: 4.701559\n",
      "batch 37  d_loss: 0.100146  g_loss: 4.575191\n",
      "batch 38  d_loss: 0.073334  g_loss: 4.183502\n",
      "batch 39  d_loss: 0.081975  g_loss: 4.866554\n",
      "batch 40  d_loss: 0.064025  g_loss: 4.683855\n",
      "batch 41  d_loss: 0.090381  g_loss: 5.099862\n",
      "batch 42  d_loss: 0.075783  g_loss: 4.908935\n",
      "batch 43  d_loss: 0.076976  g_loss: 4.451698\n",
      "batch 44  d_loss: 0.078843  g_loss: 4.515109\n",
      "batch 45  d_loss: 0.036591  g_loss: 4.644804\n",
      "Epoch is 1\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.060939  g_loss: 5.362837\n",
      "batch 1  d_loss: 0.029441  g_loss: 5.021887\n",
      "batch 2  d_loss: 0.038195  g_loss: 4.878205\n",
      "batch 3  d_loss: 0.026458  g_loss: 4.738744\n",
      "batch 4  d_loss: 0.021564  g_loss: 4.545137\n",
      "batch 5  d_loss: 0.026499  g_loss: 5.033580\n",
      "batch 6  d_loss: 0.044702  g_loss: 4.585310\n",
      "batch 7  d_loss: 0.020894  g_loss: 5.084451\n",
      "batch 8  d_loss: 0.017097  g_loss: 4.907946\n",
      "batch 9  d_loss: 0.021581  g_loss: 5.218075\n",
      "batch 10  d_loss: 0.016119  g_loss: 5.107533\n",
      "batch 11  d_loss: 0.017994  g_loss: 5.254251\n",
      "batch 12  d_loss: 0.017703  g_loss: 5.223767\n",
      "batch 13  d_loss: 0.015663  g_loss: 5.244288\n",
      "batch 14  d_loss: 0.015626  g_loss: 5.472258\n",
      "batch 15  d_loss: 0.028137  g_loss: 5.539526\n",
      "batch 16  d_loss: 0.006358  g_loss: 5.531516\n",
      "batch 17  d_loss: 0.009552  g_loss: 5.656084\n",
      "batch 18  d_loss: 0.012287  g_loss: 5.226681\n",
      "batch 19  d_loss: 0.009131  g_loss: 5.485449\n",
      "batch 20  d_loss: 0.009263  g_loss: 5.328234\n",
      "batch 21  d_loss: 0.012346  g_loss: 5.610645\n",
      "batch 22  d_loss: 0.008169  g_loss: 5.900663\n",
      "batch 23  d_loss: 0.009746  g_loss: 5.599766\n",
      "batch 24  d_loss: 0.013208  g_loss: 5.787137\n",
      "batch 25  d_loss: 0.005141  g_loss: 6.047957\n",
      "batch 26  d_loss: 0.010255  g_loss: 5.628311\n",
      "batch 27  d_loss: 0.008654  g_loss: 5.858430\n",
      "batch 28  d_loss: 0.004986  g_loss: 6.007208\n",
      "batch 29  d_loss: 0.007652  g_loss: 5.946289\n",
      "batch 30  d_loss: 0.010602  g_loss: 5.898161\n",
      "batch 31  d_loss: 0.009068  g_loss: 5.796658\n",
      "batch 32  d_loss: 0.033051  g_loss: 5.784755\n",
      "batch 33  d_loss: 0.008281  g_loss: 6.094426\n",
      "batch 34  d_loss: 0.009715  g_loss: 5.450773\n",
      "batch 35  d_loss: 0.018501  g_loss: 5.324171\n",
      "batch 36  d_loss: 0.045622  g_loss: 4.769956\n",
      "batch 37  d_loss: 0.066009  g_loss: 5.501443\n",
      "batch 38  d_loss: 0.016904  g_loss: 5.103360\n",
      "batch 39  d_loss: 0.045488  g_loss: 6.002131\n",
      "batch 40  d_loss: 0.039800  g_loss: 5.689955\n",
      "batch 41  d_loss: 0.073301  g_loss: 5.995698\n",
      "batch 42  d_loss: 0.034944  g_loss: 6.124125\n",
      "batch 43  d_loss: 0.018594  g_loss: 6.407888\n",
      "batch 44  d_loss: 0.035292  g_loss: 6.234265\n",
      "batch 45  d_loss: 0.072894  g_loss: 6.789455\n",
      "Epoch is 2\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.050932  g_loss: 7.397198\n",
      "batch 1  d_loss: 0.063963  g_loss: 7.896886\n",
      "batch 2  d_loss: 0.067858  g_loss: 8.039886\n",
      "batch 3  d_loss: 0.108346  g_loss: 8.628402\n",
      "batch 4  d_loss: 0.135394  g_loss: 7.503052\n",
      "batch 5  d_loss: 0.048359  g_loss: 7.138465\n",
      "batch 6  d_loss: 0.128441  g_loss: 6.794506\n",
      "batch 7  d_loss: 0.215793  g_loss: 7.387945\n",
      "batch 8  d_loss: 0.160861  g_loss: 7.266293\n",
      "batch 9  d_loss: 0.101316  g_loss: 6.736065\n",
      "batch 10  d_loss: 0.058914  g_loss: 5.885036\n",
      "batch 11  d_loss: 0.101003  g_loss: 6.464966\n",
      "batch 12  d_loss: 0.122597  g_loss: 6.101959\n",
      "batch 13  d_loss: 0.161713  g_loss: 6.658350\n",
      "batch 14  d_loss: 0.203969  g_loss: 6.070719\n",
      "batch 15  d_loss: 0.204975  g_loss: 5.564687\n",
      "batch 16  d_loss: 0.305828  g_loss: 6.674958\n",
      "batch 17  d_loss: 0.061286  g_loss: 8.352478\n",
      "batch 18  d_loss: 0.268144  g_loss: 7.771514\n",
      "batch 19  d_loss: 0.220874  g_loss: 8.380941\n",
      "batch 20  d_loss: 0.167194  g_loss: 8.391457\n",
      "batch 21  d_loss: 0.132938  g_loss: 8.190507\n",
      "batch 22  d_loss: 0.200275  g_loss: 8.722182\n",
      "batch 23  d_loss: 0.135626  g_loss: 9.726893\n",
      "batch 24  d_loss: 0.259977  g_loss: 8.406597\n",
      "batch 25  d_loss: 0.110757  g_loss: 6.705469\n",
      "batch 26  d_loss: 0.242141  g_loss: 8.149266\n",
      "batch 27  d_loss: 0.161058  g_loss: 7.269805\n",
      "batch 28  d_loss: 0.111034  g_loss: 8.031225\n",
      "batch 29  d_loss: 0.099560  g_loss: 7.865140\n",
      "batch 30  d_loss: 0.196647  g_loss: 6.811511\n",
      "batch 31  d_loss: 0.247625  g_loss: 7.094492\n",
      "batch 32  d_loss: 0.262425  g_loss: 7.679354\n",
      "batch 33  d_loss: 0.106032  g_loss: 9.992356\n",
      "batch 34  d_loss: 0.079026  g_loss: 8.098875\n",
      "batch 35  d_loss: 0.094745  g_loss: 9.060434\n",
      "batch 36  d_loss: 0.084543  g_loss: 8.538399\n",
      "batch 37  d_loss: 0.105194  g_loss: 8.947096\n",
      "batch 38  d_loss: 0.117107  g_loss: 9.706940\n",
      "batch 39  d_loss: 0.049916  g_loss: 10.030617\n",
      "batch 40  d_loss: 0.097234  g_loss: 9.273401\n",
      "batch 41  d_loss: 0.085932  g_loss: 7.825770\n",
      "batch 42  d_loss: 0.164988  g_loss: 8.360609\n",
      "batch 43  d_loss: 0.034688  g_loss: 9.544195\n",
      "batch 44  d_loss: 0.066824  g_loss: 7.767758\n",
      "batch 45  d_loss: 0.029963  g_loss: 8.708381\n",
      "Epoch is 3\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.084647  g_loss: 9.073753\n",
      "batch 1  d_loss: 0.049961  g_loss: 8.768788\n",
      "batch 2  d_loss: 0.116424  g_loss: 7.198522\n",
      "batch 3  d_loss: 0.074122  g_loss: 6.593516\n",
      "batch 4  d_loss: 0.148981  g_loss: 9.213150\n",
      "batch 5  d_loss: 0.154873  g_loss: 8.891496\n",
      "batch 6  d_loss: 0.211428  g_loss: 8.153082\n",
      "batch 7  d_loss: 0.179938  g_loss: 6.977668\n",
      "batch 8  d_loss: 0.191652  g_loss: 8.003455\n",
      "batch 9  d_loss: 0.173256  g_loss: 7.608046\n",
      "batch 10  d_loss: 0.108439  g_loss: 7.855353\n",
      "batch 11  d_loss: 0.136709  g_loss: 6.920420\n",
      "batch 12  d_loss: 0.283230  g_loss: 7.558157\n",
      "batch 13  d_loss: 0.103286  g_loss: 7.185770\n",
      "batch 14  d_loss: 0.192502  g_loss: 6.926580\n",
      "batch 15  d_loss: 0.175514  g_loss: 6.822798\n",
      "batch 16  d_loss: 0.236653  g_loss: 8.869925\n",
      "batch 17  d_loss: 0.125231  g_loss: 8.327226\n",
      "batch 18  d_loss: 0.147920  g_loss: 7.982297\n",
      "batch 19  d_loss: 0.077491  g_loss: 8.464533\n",
      "batch 20  d_loss: 0.172197  g_loss: 7.531487\n",
      "batch 21  d_loss: 0.234391  g_loss: 7.437586\n",
      "batch 22  d_loss: 0.175965  g_loss: 6.961077\n",
      "batch 23  d_loss: 0.144403  g_loss: 8.379623\n",
      "batch 24  d_loss: 0.091144  g_loss: 8.485713\n",
      "batch 25  d_loss: 0.407295  g_loss: 6.748373\n",
      "batch 26  d_loss: 0.305378  g_loss: 5.017557\n",
      "batch 27  d_loss: 0.518973  g_loss: 6.745735\n",
      "batch 28  d_loss: 0.126818  g_loss: 7.844571\n",
      "batch 29  d_loss: 0.540131  g_loss: 6.328261\n",
      "batch 30  d_loss: 0.606563  g_loss: 5.095696\n",
      "batch 31  d_loss: 0.490900  g_loss: 4.626619\n",
      "batch 32  d_loss: 0.706577  g_loss: 5.222920\n",
      "batch 33  d_loss: 0.608140  g_loss: 6.604200\n",
      "batch 34  d_loss: 0.450493  g_loss: 7.506660\n",
      "batch 35  d_loss: 0.539652  g_loss: 6.135224\n",
      "batch 36  d_loss: 0.329774  g_loss: 5.599567\n",
      "batch 37  d_loss: 0.243289  g_loss: 5.272718\n",
      "batch 38  d_loss: 0.751852  g_loss: 5.629082\n",
      "batch 39  d_loss: 0.338873  g_loss: 6.804211\n",
      "batch 40  d_loss: 0.428725  g_loss: 7.770297\n",
      "batch 41  d_loss: 0.876382  g_loss: 6.530091\n",
      "batch 42  d_loss: 0.456014  g_loss: 4.294375\n",
      "batch 43  d_loss: 0.465748  g_loss: 4.373487\n",
      "batch 44  d_loss: 0.680921  g_loss: 3.786545\n",
      "batch 45  d_loss: 0.857167  g_loss: 3.890904\n",
      "Epoch is 4\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.340896  g_loss: 5.158820\n",
      "batch 1  d_loss: 0.412911  g_loss: 5.002483\n",
      "batch 2  d_loss: 0.631040  g_loss: 5.099628\n",
      "batch 3  d_loss: 0.561515  g_loss: 3.839551\n",
      "batch 4  d_loss: 0.417076  g_loss: 3.655088\n",
      "batch 5  d_loss: 0.602270  g_loss: 3.592429\n",
      "batch 6  d_loss: 0.477903  g_loss: 3.270880\n",
      "batch 7  d_loss: 0.588616  g_loss: 3.741802\n",
      "batch 8  d_loss: 0.572328  g_loss: 4.007120\n",
      "batch 9  d_loss: 0.350038  g_loss: 4.979972\n",
      "batch 10  d_loss: 0.177576  g_loss: 5.015271\n",
      "batch 11  d_loss: 0.461699  g_loss: 5.026949\n",
      "batch 12  d_loss: 0.503582  g_loss: 4.094880\n",
      "batch 13  d_loss: 0.309216  g_loss: 3.834494\n",
      "batch 14  d_loss: 0.249280  g_loss: 3.077040\n",
      "batch 15  d_loss: 0.347616  g_loss: 3.122332\n",
      "batch 16  d_loss: 0.420715  g_loss: 2.721100\n",
      "batch 17  d_loss: 0.329318  g_loss: 2.652636\n",
      "batch 18  d_loss: 0.391901  g_loss: 2.842611\n",
      "batch 19  d_loss: 0.385453  g_loss: 2.867256\n",
      "batch 20  d_loss: 0.278960  g_loss: 2.978015\n",
      "batch 21  d_loss: 0.290385  g_loss: 3.577684\n",
      "batch 22  d_loss: 0.321616  g_loss: 3.632392\n",
      "batch 23  d_loss: 0.434739  g_loss: 3.661260\n",
      "batch 24  d_loss: 0.364752  g_loss: 3.811460\n",
      "batch 25  d_loss: 0.340038  g_loss: 3.351581\n",
      "batch 26  d_loss: 0.224975  g_loss: 2.959545\n",
      "batch 27  d_loss: 0.352782  g_loss: 2.752693\n",
      "batch 28  d_loss: 0.380661  g_loss: 2.479581\n",
      "batch 29  d_loss: 0.527828  g_loss: 2.381960\n",
      "batch 30  d_loss: 0.591961  g_loss: 2.261840\n",
      "batch 31  d_loss: 0.532389  g_loss: 1.930676\n",
      "batch 32  d_loss: 0.589174  g_loss: 1.924147\n",
      "batch 33  d_loss: 0.545873  g_loss: 2.482843\n",
      "batch 34  d_loss: 0.508173  g_loss: 2.415637\n",
      "batch 35  d_loss: 0.471612  g_loss: 2.135275\n",
      "batch 36  d_loss: 0.632407  g_loss: 1.691697\n",
      "batch 37  d_loss: 0.572738  g_loss: 1.660502\n",
      "batch 38  d_loss: 0.622851  g_loss: 1.325088\n",
      "batch 39  d_loss: 0.403359  g_loss: 1.730629\n",
      "batch 40  d_loss: 0.471839  g_loss: 1.886888\n",
      "batch 41  d_loss: 0.451366  g_loss: 2.119253\n",
      "batch 42  d_loss: 0.408757  g_loss: 2.463167\n",
      "batch 43  d_loss: 0.377602  g_loss: 2.444406\n",
      "batch 44  d_loss: 0.427182  g_loss: 2.148084\n",
      "batch 45  d_loss: 0.374709  g_loss: 2.006645\n",
      "Epoch is 5\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.380504  g_loss: 1.921754\n",
      "batch 1  d_loss: 0.313940  g_loss: 1.830209\n",
      "batch 2  d_loss: 0.384139  g_loss: 1.717053\n",
      "batch 3  d_loss: 0.370883  g_loss: 1.709342\n",
      "batch 4  d_loss: 0.475765  g_loss: 1.751673\n",
      "batch 5  d_loss: 0.398037  g_loss: 1.892570\n",
      "batch 6  d_loss: 0.512220  g_loss: 2.020499\n",
      "batch 7  d_loss: 0.348504  g_loss: 1.769243\n",
      "batch 8  d_loss: 0.462666  g_loss: 2.000240\n",
      "batch 9  d_loss: 0.470480  g_loss: 1.890519\n",
      "batch 10  d_loss: 0.454380  g_loss: 2.100148\n",
      "batch 11  d_loss: 0.536433  g_loss: 1.884068\n",
      "batch 12  d_loss: 0.544977  g_loss: 2.063247\n",
      "batch 13  d_loss: 0.423905  g_loss: 1.954275\n",
      "batch 14  d_loss: 0.454866  g_loss: 1.729948\n",
      "batch 15  d_loss: 0.505485  g_loss: 1.540575\n",
      "batch 16  d_loss: 0.354661  g_loss: 1.222163\n",
      "batch 17  d_loss: 0.553965  g_loss: 1.183487\n",
      "batch 18  d_loss: 0.389126  g_loss: 1.787547\n",
      "batch 19  d_loss: 0.380124  g_loss: 2.718260\n",
      "batch 20  d_loss: 0.402884  g_loss: 2.913522\n",
      "batch 21  d_loss: 0.433967  g_loss: 2.670258\n",
      "batch 22  d_loss: 0.245480  g_loss: 2.653178\n",
      "batch 23  d_loss: 0.266185  g_loss: 2.224630\n",
      "batch 24  d_loss: 0.207273  g_loss: 2.047518\n",
      "batch 25  d_loss: 0.371245  g_loss: 2.316011\n",
      "batch 26  d_loss: 0.285967  g_loss: 2.347539\n",
      "batch 27  d_loss: 0.223544  g_loss: 2.407335\n",
      "batch 28  d_loss: 0.386890  g_loss: 2.771919\n",
      "batch 29  d_loss: 0.369539  g_loss: 2.983008\n",
      "batch 30  d_loss: 0.419335  g_loss: 2.807196\n",
      "batch 31  d_loss: 0.241603  g_loss: 2.483853\n",
      "batch 32  d_loss: 0.465040  g_loss: 2.040710\n",
      "batch 33  d_loss: 0.227144  g_loss: 1.396515\n",
      "batch 34  d_loss: 0.411125  g_loss: 1.683723\n",
      "batch 35  d_loss: 0.326446  g_loss: 2.790997\n",
      "batch 36  d_loss: 0.601429  g_loss: 2.856061\n",
      "batch 37  d_loss: 0.429681  g_loss: 2.563567\n",
      "batch 38  d_loss: 0.180503  g_loss: 2.375722\n",
      "batch 39  d_loss: 0.395471  g_loss: 2.257379\n",
      "batch 40  d_loss: 0.287906  g_loss: 2.425882\n",
      "batch 41  d_loss: 0.387264  g_loss: 2.676151\n",
      "batch 42  d_loss: 0.309861  g_loss: 2.233124\n",
      "batch 43  d_loss: 0.392558  g_loss: 2.217976\n",
      "batch 44  d_loss: 0.512702  g_loss: 2.217015\n",
      "batch 45  d_loss: 0.306418  g_loss: 2.424380\n",
      "Epoch is 6\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.417416  g_loss: 2.178460\n",
      "batch 1  d_loss: 0.399174  g_loss: 2.741720\n",
      "batch 2  d_loss: 0.699210  g_loss: 2.446486\n",
      "batch 3  d_loss: 0.464713  g_loss: 2.119392\n",
      "batch 4  d_loss: 0.630301  g_loss: 1.769637\n",
      "batch 5  d_loss: 0.395382  g_loss: 1.566658\n",
      "batch 6  d_loss: 0.512134  g_loss: 2.138710\n",
      "batch 7  d_loss: 0.686289  g_loss: 2.499005\n",
      "batch 8  d_loss: 0.544073  g_loss: 2.274965\n",
      "batch 9  d_loss: 0.363355  g_loss: 2.506731\n",
      "batch 10  d_loss: 0.197959  g_loss: 2.947086\n",
      "batch 11  d_loss: 0.509074  g_loss: 2.560970\n",
      "batch 12  d_loss: 0.394767  g_loss: 2.237168\n",
      "batch 13  d_loss: 0.232878  g_loss: 1.789056\n",
      "batch 14  d_loss: 0.303402  g_loss: 2.147637\n",
      "batch 15  d_loss: 0.255668  g_loss: 2.036306\n",
      "batch 16  d_loss: 0.284302  g_loss: 2.408789\n",
      "batch 17  d_loss: 0.267128  g_loss: 2.170782\n",
      "batch 18  d_loss: 0.297512  g_loss: 2.184071\n",
      "batch 19  d_loss: 0.216913  g_loss: 1.973932\n",
      "batch 20  d_loss: 0.258261  g_loss: 2.581317\n",
      "batch 21  d_loss: 0.277598  g_loss: 2.523913\n",
      "batch 22  d_loss: 0.258590  g_loss: 2.665437\n",
      "batch 23  d_loss: 0.316945  g_loss: 2.843914\n",
      "batch 24  d_loss: 0.251659  g_loss: 2.341256\n",
      "batch 25  d_loss: 0.329863  g_loss: 2.188929\n",
      "batch 26  d_loss: 0.403261  g_loss: 2.598117\n",
      "batch 27  d_loss: 0.324818  g_loss: 2.025231\n",
      "batch 28  d_loss: 0.418535  g_loss: 2.129817\n",
      "batch 29  d_loss: 0.643641  g_loss: 2.077065\n",
      "batch 30  d_loss: 0.496327  g_loss: 1.436528\n",
      "batch 31  d_loss: 0.396569  g_loss: 1.421287\n",
      "batch 32  d_loss: 0.850233  g_loss: 1.320485\n",
      "batch 33  d_loss: 0.771966  g_loss: 1.678790\n",
      "batch 34  d_loss: 0.583862  g_loss: 1.658680\n",
      "batch 35  d_loss: 0.543249  g_loss: 1.932786\n",
      "batch 36  d_loss: 0.580180  g_loss: 1.882517\n",
      "batch 37  d_loss: 0.721503  g_loss: 1.355912\n",
      "batch 38  d_loss: 0.458094  g_loss: 1.641441\n",
      "batch 39  d_loss: 0.405847  g_loss: 1.963199\n",
      "batch 40  d_loss: 0.347149  g_loss: 2.444469\n",
      "batch 41  d_loss: 0.483064  g_loss: 2.415097\n",
      "batch 42  d_loss: 0.430143  g_loss: 2.045756\n",
      "batch 43  d_loss: 0.295618  g_loss: 1.732194\n",
      "batch 44  d_loss: 0.273177  g_loss: 1.576674\n",
      "batch 45  d_loss: 0.223720  g_loss: 1.776461\n",
      "Epoch is 7\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.272905  g_loss: 2.308533\n",
      "batch 1  d_loss: 0.176197  g_loss: 2.817574\n",
      "batch 2  d_loss: 0.296623  g_loss: 3.213773\n",
      "batch 3  d_loss: 0.235656  g_loss: 2.808786\n",
      "batch 4  d_loss: 0.238236  g_loss: 2.291104\n",
      "batch 5  d_loss: 0.246970  g_loss: 1.938956\n",
      "batch 6  d_loss: 0.389354  g_loss: 2.097354\n",
      "batch 7  d_loss: 0.321816  g_loss: 2.731441\n",
      "batch 8  d_loss: 0.311949  g_loss: 2.962727\n",
      "batch 9  d_loss: 0.175360  g_loss: 2.957842\n",
      "batch 10  d_loss: 0.121357  g_loss: 3.355934\n",
      "batch 11  d_loss: 0.295165  g_loss: 3.418415\n",
      "batch 12  d_loss: 0.205524  g_loss: 3.338172\n",
      "batch 13  d_loss: 0.200205  g_loss: 2.973672\n",
      "batch 14  d_loss: 0.264677  g_loss: 2.514543\n",
      "batch 15  d_loss: 0.311870  g_loss: 2.574272\n",
      "batch 16  d_loss: 0.300106  g_loss: 2.342377\n",
      "batch 17  d_loss: 0.378284  g_loss: 2.424984\n",
      "batch 18  d_loss: 0.390365  g_loss: 2.383502\n",
      "batch 19  d_loss: 0.280483  g_loss: 2.434135\n",
      "batch 20  d_loss: 0.498046  g_loss: 2.282447\n",
      "batch 21  d_loss: 0.513400  g_loss: 1.786464\n",
      "batch 22  d_loss: 0.364022  g_loss: 2.237080\n",
      "batch 23  d_loss: 0.502394  g_loss: 2.025127\n",
      "batch 24  d_loss: 0.404579  g_loss: 2.003775\n",
      "batch 25  d_loss: 0.572031  g_loss: 2.023110\n",
      "batch 26  d_loss: 0.304733  g_loss: 1.867401\n",
      "batch 27  d_loss: 0.431512  g_loss: 2.202384\n",
      "batch 28  d_loss: 0.528744  g_loss: 1.391023\n",
      "batch 29  d_loss: 0.616967  g_loss: 1.050463\n",
      "batch 30  d_loss: 0.648820  g_loss: 1.860368\n",
      "batch 31  d_loss: 0.373360  g_loss: 2.635286\n",
      "batch 32  d_loss: 0.549901  g_loss: 2.117824\n",
      "batch 33  d_loss: 0.343336  g_loss: 1.889619\n",
      "batch 34  d_loss: 0.291708  g_loss: 1.423559\n",
      "batch 35  d_loss: 0.277454  g_loss: 1.194902\n",
      "batch 36  d_loss: 0.544851  g_loss: 1.934967\n",
      "batch 37  d_loss: 0.449382  g_loss: 2.698988\n",
      "batch 38  d_loss: 0.331765  g_loss: 3.153082\n",
      "batch 39  d_loss: 0.331789  g_loss: 3.150155\n",
      "batch 40  d_loss: 0.240007  g_loss: 3.107460\n",
      "batch 41  d_loss: 0.394782  g_loss: 2.409890\n",
      "batch 42  d_loss: 0.232380  g_loss: 1.982853\n",
      "batch 43  d_loss: 0.283314  g_loss: 1.828668\n",
      "batch 44  d_loss: 0.296196  g_loss: 2.135477\n",
      "batch 45  d_loss: 0.199261  g_loss: 2.837345\n",
      "Epoch is 8\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.190296  g_loss: 3.515774\n",
      "batch 1  d_loss: 0.115464  g_loss: 3.710798\n",
      "batch 2  d_loss: 0.324335  g_loss: 3.630573\n",
      "batch 3  d_loss: 0.254696  g_loss: 2.746846\n",
      "batch 4  d_loss: 0.253801  g_loss: 2.681718\n",
      "batch 5  d_loss: 0.298696  g_loss: 2.030612\n",
      "batch 6  d_loss: 0.243046  g_loss: 1.635047\n",
      "batch 7  d_loss: 0.390852  g_loss: 1.866642\n",
      "batch 8  d_loss: 0.252385  g_loss: 2.678617\n",
      "batch 9  d_loss: 0.253614  g_loss: 3.304186\n",
      "batch 10  d_loss: 0.143021  g_loss: 3.862517\n",
      "batch 11  d_loss: 0.381291  g_loss: 3.204907\n",
      "batch 12  d_loss: 0.385028  g_loss: 2.325614\n",
      "batch 13  d_loss: 0.275564  g_loss: 2.091332\n",
      "batch 14  d_loss: 0.474891  g_loss: 2.025084\n",
      "batch 15  d_loss: 0.338065  g_loss: 1.727116\n",
      "batch 16  d_loss: 0.393918  g_loss: 2.087995\n",
      "batch 17  d_loss: 0.523116  g_loss: 2.301320\n",
      "batch 18  d_loss: 0.413860  g_loss: 2.449614\n",
      "batch 19  d_loss: 0.285062  g_loss: 2.340514\n",
      "batch 20  d_loss: 0.485267  g_loss: 1.835234\n",
      "batch 21  d_loss: 0.296741  g_loss: 1.813258\n",
      "batch 22  d_loss: 0.449578  g_loss: 1.553363\n",
      "batch 23  d_loss: 0.384776  g_loss: 1.315534\n",
      "batch 24  d_loss: 0.295282  g_loss: 1.426033\n",
      "batch 25  d_loss: 0.566180  g_loss: 1.639780\n",
      "batch 26  d_loss: 0.343437  g_loss: 2.216829\n",
      "batch 27  d_loss: 0.309524  g_loss: 2.509933\n",
      "batch 28  d_loss: 0.468301  g_loss: 2.185179\n",
      "batch 29  d_loss: 0.691792  g_loss: 1.286330\n",
      "batch 30  d_loss: 0.583786  g_loss: 0.777184\n",
      "batch 31  d_loss: 0.330649  g_loss: 1.115949\n",
      "batch 32  d_loss: 0.515502  g_loss: 1.577273\n",
      "batch 33  d_loss: 0.456952  g_loss: 2.609780\n",
      "batch 34  d_loss: 0.367317  g_loss: 2.940453\n",
      "batch 35  d_loss: 0.390378  g_loss: 2.775383\n",
      "batch 36  d_loss: 0.415910  g_loss: 2.382843\n",
      "batch 37  d_loss: 0.301974  g_loss: 1.937963\n",
      "batch 38  d_loss: 0.229706  g_loss: 1.677140\n",
      "batch 39  d_loss: 0.296736  g_loss: 1.814685\n",
      "batch 40  d_loss: 0.297136  g_loss: 2.281564\n",
      "batch 41  d_loss: 0.274435  g_loss: 3.271332\n",
      "batch 42  d_loss: 0.199622  g_loss: 3.061523\n",
      "batch 43  d_loss: 0.247339  g_loss: 2.828939\n",
      "batch 44  d_loss: 0.218847  g_loss: 2.888494\n",
      "batch 45  d_loss: 0.209140  g_loss: 2.495742\n",
      "Epoch is 9\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.204521  g_loss: 2.405731\n",
      "batch 1  d_loss: 0.174890  g_loss: 2.390813\n",
      "batch 2  d_loss: 0.234755  g_loss: 2.144634\n",
      "batch 3  d_loss: 0.147466  g_loss: 2.417655\n",
      "batch 4  d_loss: 0.232070  g_loss: 2.292506\n",
      "batch 5  d_loss: 0.227856  g_loss: 2.426752\n",
      "batch 6  d_loss: 0.378664  g_loss: 2.411662\n",
      "batch 7  d_loss: 0.751213  g_loss: 2.180874\n",
      "batch 8  d_loss: 0.515459  g_loss: 1.554689\n",
      "batch 9  d_loss: 0.401830  g_loss: 2.100777\n",
      "batch 10  d_loss: 0.242491  g_loss: 2.619440\n",
      "batch 11  d_loss: 0.632563  g_loss: 2.605055\n",
      "batch 12  d_loss: 0.507956  g_loss: 1.618162\n",
      "batch 13  d_loss: 0.353975  g_loss: 1.148144\n",
      "batch 14  d_loss: 0.490143  g_loss: 1.308468\n",
      "batch 15  d_loss: 0.427109  g_loss: 1.905528\n",
      "batch 16  d_loss: 0.409204  g_loss: 2.162035\n",
      "batch 17  d_loss: 0.778708  g_loss: 1.890520\n",
      "batch 18  d_loss: 0.398476  g_loss: 1.417172\n",
      "batch 19  d_loss: 0.316111  g_loss: 1.537612\n",
      "batch 20  d_loss: 0.415498  g_loss: 1.809004\n",
      "batch 21  d_loss: 0.309414  g_loss: 2.373361\n",
      "batch 22  d_loss: 0.262866  g_loss: 2.448503\n",
      "batch 23  d_loss: 0.347618  g_loss: 2.176539\n",
      "batch 24  d_loss: 0.196781  g_loss: 2.328343\n",
      "batch 25  d_loss: 0.353207  g_loss: 2.160021\n",
      "batch 26  d_loss: 0.282221  g_loss: 2.385441\n",
      "batch 27  d_loss: 0.236782  g_loss: 3.105265\n",
      "batch 28  d_loss: 0.257001  g_loss: 2.820991\n",
      "batch 29  d_loss: 0.350360  g_loss: 2.378592\n",
      "batch 30  d_loss: 0.271965  g_loss: 2.179219\n",
      "batch 31  d_loss: 0.231712  g_loss: 2.209897\n",
      "batch 32  d_loss: 0.307079  g_loss: 1.972254\n",
      "batch 33  d_loss: 0.224661  g_loss: 2.522012\n",
      "batch 34  d_loss: 0.237376  g_loss: 2.603418\n",
      "batch 35  d_loss: 0.189576  g_loss: 2.741616\n",
      "batch 36  d_loss: 0.338140  g_loss: 2.261658\n",
      "batch 37  d_loss: 0.274847  g_loss: 1.895170\n",
      "batch 38  d_loss: 0.287662  g_loss: 2.410276\n",
      "batch 39  d_loss: 0.220232  g_loss: 3.105795\n",
      "batch 40  d_loss: 0.330568  g_loss: 2.700565\n",
      "batch 41  d_loss: 0.483263  g_loss: 2.097782\n",
      "batch 42  d_loss: 0.343992  g_loss: 1.870230\n",
      "batch 43  d_loss: 0.255421  g_loss: 1.817078\n",
      "batch 44  d_loss: 0.335779  g_loss: 2.352896\n",
      "batch 45  d_loss: 0.386753  g_loss: 2.529987\n",
      "Epoch is 10\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.295049  g_loss: 2.051194\n",
      "batch 1  d_loss: 0.392256  g_loss: 2.245995\n",
      "batch 2  d_loss: 0.434679  g_loss: 2.415553\n",
      "batch 3  d_loss: 0.409719  g_loss: 1.562918\n",
      "batch 4  d_loss: 0.396314  g_loss: 1.290361\n",
      "batch 5  d_loss: 0.612449  g_loss: 1.374228\n",
      "batch 6  d_loss: 0.336466  g_loss: 1.788590\n",
      "batch 7  d_loss: 0.827895  g_loss: 1.717805\n",
      "batch 8  d_loss: 0.555620  g_loss: 1.099238\n",
      "batch 9  d_loss: 0.399711  g_loss: 1.247886\n",
      "batch 10  d_loss: 0.411119  g_loss: 2.109625\n",
      "batch 11  d_loss: 0.475397  g_loss: 2.100048\n",
      "batch 12  d_loss: 0.449517  g_loss: 1.793900\n",
      "batch 13  d_loss: 0.307480  g_loss: 1.925172\n",
      "batch 14  d_loss: 0.320188  g_loss: 1.642203\n",
      "batch 15  d_loss: 0.345314  g_loss: 2.218183\n",
      "batch 16  d_loss: 0.275450  g_loss: 2.267695\n",
      "batch 17  d_loss: 0.426410  g_loss: 2.303333\n",
      "batch 18  d_loss: 0.257862  g_loss: 2.373289\n",
      "batch 19  d_loss: 0.213033  g_loss: 2.755535\n",
      "batch 20  d_loss: 0.213104  g_loss: 2.277390\n",
      "batch 21  d_loss: 0.201678  g_loss: 2.244713\n",
      "batch 22  d_loss: 0.202398  g_loss: 2.665061\n",
      "batch 23  d_loss: 0.286957  g_loss: 2.931035\n",
      "batch 24  d_loss: 0.242822  g_loss: 3.032801\n",
      "batch 25  d_loss: 0.334469  g_loss: 2.615301\n",
      "batch 26  d_loss: 0.331413  g_loss: 3.029018\n",
      "batch 27  d_loss: 0.232797  g_loss: 2.347370\n",
      "batch 28  d_loss: 0.317513  g_loss: 2.303858\n",
      "batch 29  d_loss: 0.532670  g_loss: 1.800936\n",
      "batch 30  d_loss: 0.470830  g_loss: 2.605576\n",
      "batch 31  d_loss: 0.449934  g_loss: 2.938560\n",
      "batch 32  d_loss: 0.488238  g_loss: 2.524361\n",
      "batch 33  d_loss: 0.437689  g_loss: 1.847616\n",
      "batch 34  d_loss: 0.368440  g_loss: 1.392403\n",
      "batch 35  d_loss: 0.379221  g_loss: 1.067075\n",
      "batch 36  d_loss: 0.547822  g_loss: 2.407889\n",
      "batch 37  d_loss: 0.572933  g_loss: 2.484164\n",
      "batch 38  d_loss: 0.404273  g_loss: 2.719511\n",
      "batch 39  d_loss: 0.513501  g_loss: 1.746508\n",
      "batch 40  d_loss: 0.421536  g_loss: 0.797583\n",
      "batch 41  d_loss: 0.494420  g_loss: 1.231951\n",
      "batch 42  d_loss: 0.407274  g_loss: 2.044094\n",
      "batch 43  d_loss: 0.400242  g_loss: 3.218985\n",
      "batch 44  d_loss: 0.735980  g_loss: 2.411742\n",
      "batch 45  d_loss: 0.218323  g_loss: 1.865510\n",
      "Epoch is 11\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.243815  g_loss: 1.873435\n",
      "batch 1  d_loss: 0.356296  g_loss: 2.336156\n",
      "batch 2  d_loss: 0.290469  g_loss: 3.221857\n",
      "batch 3  d_loss: 0.269316  g_loss: 2.957095\n",
      "batch 4  d_loss: 0.488945  g_loss: 2.608652\n",
      "batch 5  d_loss: 0.516107  g_loss: 2.072115\n",
      "batch 6  d_loss: 0.377227  g_loss: 2.099835\n",
      "batch 7  d_loss: 0.964976  g_loss: 1.765393\n",
      "batch 8  d_loss: 0.720150  g_loss: 2.671091\n",
      "batch 9  d_loss: 0.320763  g_loss: 2.900069\n",
      "batch 10  d_loss: 0.367754  g_loss: 2.488487\n",
      "batch 11  d_loss: 0.640562  g_loss: 1.604996\n",
      "batch 12  d_loss: 0.433868  g_loss: 0.982958\n",
      "batch 13  d_loss: 0.429105  g_loss: 0.771207\n",
      "batch 14  d_loss: 0.450489  g_loss: 1.390628\n",
      "batch 15  d_loss: 0.359201  g_loss: 2.230831\n",
      "batch 16  d_loss: 0.198658  g_loss: 2.963263\n",
      "batch 17  d_loss: 0.567583  g_loss: 2.595945\n",
      "batch 18  d_loss: 0.240841  g_loss: 1.788045\n",
      "batch 19  d_loss: 0.237093  g_loss: 1.690049\n",
      "batch 20  d_loss: 0.301259  g_loss: 1.399612\n",
      "batch 21  d_loss: 0.251033  g_loss: 1.858763\n",
      "batch 22  d_loss: 0.232571  g_loss: 2.324560\n",
      "batch 23  d_loss: 0.185725  g_loss: 2.635296\n",
      "batch 24  d_loss: 0.269383  g_loss: 3.091159\n",
      "batch 25  d_loss: 0.346223  g_loss: 2.938334\n",
      "batch 26  d_loss: 0.274953  g_loss: 1.796464\n",
      "batch 27  d_loss: 0.207879  g_loss: 1.419272\n",
      "batch 28  d_loss: 0.366884  g_loss: 1.509690\n",
      "batch 29  d_loss: 0.467565  g_loss: 1.783732\n",
      "batch 30  d_loss: 0.276796  g_loss: 2.203677\n",
      "batch 31  d_loss: 0.353045  g_loss: 2.601868\n",
      "batch 32  d_loss: 0.486118  g_loss: 1.892618\n",
      "batch 33  d_loss: 0.292108  g_loss: 1.923145\n",
      "batch 34  d_loss: 0.289483  g_loss: 1.410687\n",
      "batch 35  d_loss: 0.333088  g_loss: 1.741672\n",
      "batch 36  d_loss: 0.570797  g_loss: 2.617336\n",
      "batch 37  d_loss: 0.483824  g_loss: 2.772326\n",
      "batch 38  d_loss: 0.351443  g_loss: 2.594575\n",
      "batch 39  d_loss: 0.329071  g_loss: 2.127754\n",
      "batch 40  d_loss: 0.311106  g_loss: 1.606734\n",
      "batch 41  d_loss: 0.363722  g_loss: 1.538160\n",
      "batch 42  d_loss: 0.416527  g_loss: 1.946300\n",
      "batch 43  d_loss: 0.330147  g_loss: 1.829524\n",
      "batch 44  d_loss: 0.250636  g_loss: 1.962901\n",
      "batch 45  d_loss: 0.188393  g_loss: 2.448491\n",
      "Epoch is 12\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.310232  g_loss: 2.538486\n",
      "batch 1  d_loss: 0.334331  g_loss: 1.933790\n",
      "batch 2  d_loss: 0.244692  g_loss: 1.399714\n",
      "batch 3  d_loss: 0.371992  g_loss: 1.787588\n",
      "batch 4  d_loss: 0.373664  g_loss: 1.851624\n",
      "batch 5  d_loss: 0.464901  g_loss: 1.892949\n",
      "batch 6  d_loss: 0.316841  g_loss: 2.245257\n",
      "batch 7  d_loss: 1.135585  g_loss: 2.066269\n",
      "batch 8  d_loss: 0.604270  g_loss: 1.455621\n",
      "batch 9  d_loss: 0.337213  g_loss: 1.660384\n",
      "batch 10  d_loss: 0.370710  g_loss: 2.164664\n",
      "batch 11  d_loss: 0.375902  g_loss: 2.108243\n",
      "batch 12  d_loss: 0.415327  g_loss: 2.341546\n",
      "batch 13  d_loss: 0.306631  g_loss: 1.759150\n",
      "batch 14  d_loss: 0.255107  g_loss: 1.920472\n",
      "batch 15  d_loss: 0.252544  g_loss: 1.885942\n",
      "batch 16  d_loss: 0.216356  g_loss: 1.994541\n",
      "batch 17  d_loss: 0.343911  g_loss: 1.470944\n",
      "batch 18  d_loss: 0.259569  g_loss: 1.695110\n",
      "batch 19  d_loss: 0.281958  g_loss: 2.133942\n",
      "batch 20  d_loss: 0.212019  g_loss: 2.645732\n",
      "batch 21  d_loss: 0.139035  g_loss: 2.832844\n",
      "batch 22  d_loss: 0.194300  g_loss: 2.968171\n",
      "batch 23  d_loss: 0.254042  g_loss: 2.376813\n",
      "batch 24  d_loss: 0.172841  g_loss: 2.386904\n",
      "batch 25  d_loss: 0.247389  g_loss: 1.691413\n",
      "batch 26  d_loss: 0.270872  g_loss: 1.786964\n",
      "batch 27  d_loss: 0.293428  g_loss: 1.974701\n",
      "batch 28  d_loss: 0.340445  g_loss: 2.303059\n",
      "batch 29  d_loss: 0.303308  g_loss: 2.589738\n",
      "batch 30  d_loss: 0.415769  g_loss: 2.523436\n",
      "batch 31  d_loss: 0.299107  g_loss: 1.679395\n",
      "batch 32  d_loss: 0.374875  g_loss: 1.186652\n",
      "batch 33  d_loss: 0.370816  g_loss: 1.063784\n",
      "batch 34  d_loss: 0.409596  g_loss: 1.474463\n",
      "batch 35  d_loss: 0.349177  g_loss: 1.925581\n",
      "batch 36  d_loss: 0.518880  g_loss: 2.445701\n",
      "batch 37  d_loss: 0.589801  g_loss: 2.114383\n",
      "batch 38  d_loss: 0.328884  g_loss: 1.416590\n",
      "batch 39  d_loss: 0.375915  g_loss: 1.465460\n",
      "batch 40  d_loss: 0.314233  g_loss: 1.415160\n",
      "batch 41  d_loss: 0.398887  g_loss: 1.656173\n",
      "batch 42  d_loss: 0.271506  g_loss: 2.196021\n",
      "batch 43  d_loss: 0.274158  g_loss: 2.174318\n",
      "batch 44  d_loss: 0.271533  g_loss: 2.063270\n",
      "batch 45  d_loss: 0.190635  g_loss: 1.970263\n",
      "Epoch is 13\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.175536  g_loss: 1.827084\n",
      "batch 1  d_loss: 0.216377  g_loss: 2.122288\n",
      "batch 2  d_loss: 0.245731  g_loss: 2.227774\n",
      "batch 3  d_loss: 0.202561  g_loss: 2.658815\n",
      "batch 4  d_loss: 0.223513  g_loss: 2.015747\n",
      "batch 5  d_loss: 0.265300  g_loss: 1.898103\n",
      "batch 6  d_loss: 0.248402  g_loss: 1.892207\n",
      "batch 7  d_loss: 0.586511  g_loss: 1.848637\n",
      "batch 8  d_loss: 0.342480  g_loss: 2.222378\n",
      "batch 9  d_loss: 0.287397  g_loss: 2.268761\n",
      "batch 10  d_loss: 0.223372  g_loss: 2.753778\n",
      "batch 11  d_loss: 0.451267  g_loss: 2.151977\n",
      "batch 12  d_loss: 0.418645  g_loss: 1.273796\n",
      "batch 13  d_loss: 0.359792  g_loss: 1.345560\n",
      "batch 14  d_loss: 0.555907  g_loss: 1.993499\n",
      "batch 15  d_loss: 0.417784  g_loss: 2.146385\n",
      "batch 16  d_loss: 0.227444  g_loss: 2.212714\n",
      "batch 17  d_loss: 0.513798  g_loss: 1.734157\n",
      "batch 18  d_loss: 0.238392  g_loss: 1.632114\n",
      "batch 19  d_loss: 0.254651  g_loss: 2.059751\n",
      "batch 20  d_loss: 0.346101  g_loss: 2.478862\n",
      "batch 21  d_loss: 0.271491  g_loss: 2.792104\n",
      "batch 22  d_loss: 0.247890  g_loss: 2.840189\n",
      "batch 23  d_loss: 0.164127  g_loss: 2.213630\n",
      "batch 24  d_loss: 0.134628  g_loss: 2.151596\n",
      "batch 25  d_loss: 0.215072  g_loss: 1.954951\n",
      "batch 26  d_loss: 0.207904  g_loss: 2.822490\n",
      "batch 27  d_loss: 0.144147  g_loss: 3.354995\n",
      "batch 28  d_loss: 0.267714  g_loss: 3.247782\n",
      "batch 29  d_loss: 0.335325  g_loss: 2.511264\n",
      "batch 30  d_loss: 0.186251  g_loss: 1.775885\n",
      "batch 31  d_loss: 0.193505  g_loss: 1.964642\n",
      "batch 32  d_loss: 0.247766  g_loss: 2.294561\n",
      "batch 33  d_loss: 0.264339  g_loss: 2.910336\n",
      "batch 34  d_loss: 0.196004  g_loss: 3.910947\n",
      "batch 35  d_loss: 0.247460  g_loss: 3.655772\n",
      "batch 36  d_loss: 0.463593  g_loss: 2.700954\n",
      "batch 37  d_loss: 0.430730  g_loss: 1.638930\n",
      "batch 38  d_loss: 0.343376  g_loss: 1.556194\n",
      "batch 39  d_loss: 0.293117  g_loss: 2.016607\n",
      "batch 40  d_loss: 0.303075  g_loss: 2.683337\n",
      "batch 41  d_loss: 0.357129  g_loss: 2.990488\n",
      "batch 42  d_loss: 0.340029  g_loss: 2.326891\n",
      "batch 43  d_loss: 0.259433  g_loss: 1.782656\n",
      "batch 44  d_loss: 0.240519  g_loss: 1.878116\n",
      "batch 45  d_loss: 0.246363  g_loss: 2.474524\n",
      "Epoch is 14\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.198828  g_loss: 3.389708\n",
      "batch 1  d_loss: 0.231736  g_loss: 2.918943\n",
      "batch 2  d_loss: 0.225320  g_loss: 2.992226\n",
      "batch 3  d_loss: 0.152414  g_loss: 2.394059\n",
      "batch 4  d_loss: 0.435467  g_loss: 2.146644\n",
      "batch 5  d_loss: 0.392229  g_loss: 1.916227\n",
      "batch 6  d_loss: 0.375006  g_loss: 2.068257\n",
      "batch 7  d_loss: 1.048762  g_loss: 2.026085\n",
      "batch 8  d_loss: 0.641890  g_loss: 1.812038\n",
      "batch 9  d_loss: 0.395385  g_loss: 1.855120\n",
      "batch 10  d_loss: 0.261527  g_loss: 1.745089\n",
      "batch 11  d_loss: 0.602988  g_loss: 1.423059\n",
      "batch 12  d_loss: 0.525681  g_loss: 1.094387\n",
      "batch 13  d_loss: 0.457010  g_loss: 1.046984\n",
      "batch 14  d_loss: 0.395843  g_loss: 1.557196\n",
      "batch 15  d_loss: 0.396795  g_loss: 1.955229\n",
      "batch 16  d_loss: 0.313329  g_loss: 2.324940\n",
      "batch 17  d_loss: 0.676875  g_loss: 1.992341\n",
      "batch 18  d_loss: 0.312452  g_loss: 1.704656\n",
      "batch 19  d_loss: 0.268071  g_loss: 1.459643\n",
      "batch 20  d_loss: 0.261210  g_loss: 1.400075\n",
      "batch 21  d_loss: 0.306224  g_loss: 2.017827\n",
      "batch 22  d_loss: 0.185911  g_loss: 2.415640\n",
      "batch 23  d_loss: 0.230949  g_loss: 2.697849\n",
      "batch 24  d_loss: 0.200632  g_loss: 2.698921\n",
      "batch 25  d_loss: 0.271912  g_loss: 2.693291\n",
      "batch 26  d_loss: 0.191030  g_loss: 2.226113\n",
      "batch 27  d_loss: 0.185057  g_loss: 2.211623\n",
      "batch 28  d_loss: 0.270013  g_loss: 2.245666\n",
      "batch 29  d_loss: 0.336072  g_loss: 2.062376\n",
      "batch 30  d_loss: 0.288901  g_loss: 1.697915\n",
      "batch 31  d_loss: 0.263775  g_loss: 2.170621\n",
      "batch 32  d_loss: 0.226489  g_loss: 2.971616\n",
      "batch 33  d_loss: 0.298937  g_loss: 2.537066\n",
      "batch 34  d_loss: 0.277720  g_loss: 2.668875\n",
      "batch 35  d_loss: 0.277668  g_loss: 2.128613\n",
      "batch 36  d_loss: 0.472117  g_loss: 1.694589\n",
      "batch 37  d_loss: 0.603043  g_loss: 0.996697\n",
      "batch 38  d_loss: 0.522249  g_loss: 1.361626\n",
      "batch 39  d_loss: 0.481787  g_loss: 1.776164\n",
      "batch 40  d_loss: 0.328329  g_loss: 2.035752\n",
      "batch 41  d_loss: 0.413101  g_loss: 2.155408\n",
      "batch 42  d_loss: 0.493717  g_loss: 1.988577\n",
      "batch 43  d_loss: 0.442489  g_loss: 1.690487\n",
      "batch 44  d_loss: 0.385432  g_loss: 1.751487\n",
      "batch 45  d_loss: 0.257906  g_loss: 1.840558\n",
      "Epoch is 15\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.342997  g_loss: 1.894379\n",
      "batch 1  d_loss: 0.325260  g_loss: 1.908662\n",
      "batch 2  d_loss: 0.374118  g_loss: 1.651960\n",
      "batch 3  d_loss: 0.248991  g_loss: 1.737599\n",
      "batch 4  d_loss: 0.319745  g_loss: 1.364677\n",
      "batch 5  d_loss: 0.350656  g_loss: 1.295752\n",
      "batch 6  d_loss: 0.384982  g_loss: 1.961635\n",
      "batch 7  d_loss: 0.791527  g_loss: 2.240573\n",
      "batch 8  d_loss: 0.568737  g_loss: 2.719989\n",
      "batch 9  d_loss: 0.241830  g_loss: 2.622358\n",
      "batch 10  d_loss: 0.175637  g_loss: 2.684358\n",
      "batch 11  d_loss: 0.469801  g_loss: 2.228296\n",
      "batch 12  d_loss: 0.466797  g_loss: 2.243149\n",
      "batch 13  d_loss: 0.281307  g_loss: 1.735033\n",
      "batch 14  d_loss: 0.280970  g_loss: 1.396252\n",
      "batch 15  d_loss: 0.278888  g_loss: 1.770021\n",
      "batch 16  d_loss: 0.255309  g_loss: 2.178847\n",
      "batch 17  d_loss: 0.276233  g_loss: 1.721044\n",
      "batch 18  d_loss: 0.177237  g_loss: 2.204530\n",
      "batch 19  d_loss: 0.251686  g_loss: 2.306756\n",
      "batch 20  d_loss: 0.406906  g_loss: 2.277538\n",
      "batch 21  d_loss: 0.231339  g_loss: 1.965915\n",
      "batch 22  d_loss: 0.198940  g_loss: 1.834388\n",
      "batch 23  d_loss: 0.231510  g_loss: 1.848518\n",
      "batch 24  d_loss: 0.191067  g_loss: 2.228843\n",
      "batch 25  d_loss: 0.199362  g_loss: 2.753755\n",
      "batch 26  d_loss: 0.319406  g_loss: 2.468600\n",
      "batch 27  d_loss: 0.178651  g_loss: 2.573490\n",
      "batch 28  d_loss: 0.337290  g_loss: 2.045355\n",
      "batch 29  d_loss: 0.374816  g_loss: 1.766253\n",
      "batch 30  d_loss: 0.404485  g_loss: 1.869276\n",
      "batch 31  d_loss: 0.397495  g_loss: 2.495153\n",
      "batch 32  d_loss: 0.400113  g_loss: 2.388938\n",
      "batch 33  d_loss: 0.441036  g_loss: 1.882158\n",
      "batch 34  d_loss: 0.347749  g_loss: 1.605137\n",
      "batch 35  d_loss: 0.322555  g_loss: 1.925295\n",
      "batch 36  d_loss: 0.449872  g_loss: 2.182082\n",
      "batch 37  d_loss: 0.509912  g_loss: 2.058060\n",
      "batch 38  d_loss: 0.394955  g_loss: 1.630664\n",
      "batch 39  d_loss: 0.425245  g_loss: 1.962465\n",
      "batch 40  d_loss: 0.402651  g_loss: 1.960299\n",
      "batch 41  d_loss: 0.444337  g_loss: 2.027593\n",
      "batch 42  d_loss: 0.463926  g_loss: 1.825862\n",
      "batch 43  d_loss: 0.359882  g_loss: 1.906422\n",
      "batch 44  d_loss: 0.386074  g_loss: 2.133383\n",
      "batch 45  d_loss: 0.320119  g_loss: 2.115009\n",
      "Epoch is 16\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.259288  g_loss: 2.300436\n",
      "batch 1  d_loss: 0.314670  g_loss: 2.326596\n",
      "batch 2  d_loss: 0.220132  g_loss: 2.108838\n",
      "batch 3  d_loss: 0.236056  g_loss: 2.429282\n",
      "batch 4  d_loss: 0.249197  g_loss: 2.372359\n",
      "batch 5  d_loss: 0.223340  g_loss: 2.004059\n",
      "batch 6  d_loss: 0.227434  g_loss: 2.085922\n",
      "batch 7  d_loss: 0.371473  g_loss: 1.908516\n",
      "batch 8  d_loss: 0.313694  g_loss: 2.186199\n",
      "batch 9  d_loss: 0.204199  g_loss: 2.541995\n",
      "batch 10  d_loss: 0.206805  g_loss: 2.976366\n",
      "batch 11  d_loss: 0.352915  g_loss: 3.084160\n",
      "batch 12  d_loss: 0.364305  g_loss: 2.323905\n",
      "batch 13  d_loss: 0.174950  g_loss: 1.444400\n",
      "batch 14  d_loss: 0.153271  g_loss: 1.951116\n",
      "batch 15  d_loss: 0.307881  g_loss: 1.980823\n",
      "batch 16  d_loss: 0.285970  g_loss: 2.647538\n",
      "batch 17  d_loss: 0.240758  g_loss: 3.120951\n",
      "batch 18  d_loss: 0.195284  g_loss: 3.513676\n",
      "batch 19  d_loss: 0.118559  g_loss: 3.053903\n",
      "batch 20  d_loss: 0.258013  g_loss: 2.901979\n",
      "batch 21  d_loss: 0.169476  g_loss: 2.641927\n",
      "batch 22  d_loss: 0.201406  g_loss: 2.452518\n",
      "batch 23  d_loss: 0.194261  g_loss: 2.320867\n",
      "batch 24  d_loss: 0.252738  g_loss: 2.667870\n",
      "batch 25  d_loss: 0.288814  g_loss: 2.840084\n",
      "batch 26  d_loss: 0.157210  g_loss: 2.862143\n",
      "batch 27  d_loss: 0.141037  g_loss: 3.042361\n",
      "batch 28  d_loss: 0.289106  g_loss: 3.126471\n",
      "batch 29  d_loss: 0.443194  g_loss: 2.126726\n",
      "batch 30  d_loss: 0.259149  g_loss: 1.813600\n",
      "batch 31  d_loss: 0.333358  g_loss: 1.949437\n",
      "batch 32  d_loss: 0.266522  g_loss: 2.487387\n",
      "batch 33  d_loss: 0.364397  g_loss: 2.611845\n",
      "batch 34  d_loss: 0.251711  g_loss: 2.793576\n",
      "batch 35  d_loss: 0.300965  g_loss: 2.001793\n",
      "batch 36  d_loss: 0.504111  g_loss: 1.329731\n",
      "batch 37  d_loss: 0.433760  g_loss: 1.366674\n",
      "batch 38  d_loss: 0.330370  g_loss: 1.538566\n",
      "batch 39  d_loss: 0.370198  g_loss: 1.978516\n",
      "batch 40  d_loss: 0.330296  g_loss: 2.581288\n",
      "batch 41  d_loss: 0.385240  g_loss: 2.478163\n",
      "batch 42  d_loss: 0.236172  g_loss: 1.960005\n",
      "batch 43  d_loss: 0.215306  g_loss: 1.721185\n",
      "batch 44  d_loss: 0.337078  g_loss: 1.965018\n",
      "batch 45  d_loss: 0.229768  g_loss: 2.366872\n",
      "Epoch is 17\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.170401  g_loss: 3.471796\n",
      "batch 1  d_loss: 0.322101  g_loss: 2.652471\n",
      "batch 2  d_loss: 0.233654  g_loss: 2.545545\n",
      "batch 3  d_loss: 0.193812  g_loss: 2.439842\n",
      "batch 4  d_loss: 0.240339  g_loss: 1.915600\n",
      "batch 5  d_loss: 0.314803  g_loss: 2.158588\n",
      "batch 6  d_loss: 0.320205  g_loss: 2.374663\n",
      "batch 7  d_loss: 1.079744  g_loss: 2.428531\n",
      "batch 8  d_loss: 0.640698  g_loss: 3.048376\n",
      "batch 9  d_loss: 0.289367  g_loss: 2.637516\n",
      "batch 10  d_loss: 0.239394  g_loss: 2.515483\n",
      "batch 11  d_loss: 0.417808  g_loss: 1.846132\n",
      "batch 12  d_loss: 0.397407  g_loss: 1.323307\n",
      "batch 13  d_loss: 0.375644  g_loss: 1.305449\n",
      "batch 14  d_loss: 0.329877  g_loss: 1.953930\n",
      "batch 15  d_loss: 0.228009  g_loss: 2.689618\n",
      "batch 16  d_loss: 0.318872  g_loss: 2.759860\n",
      "batch 17  d_loss: 0.513208  g_loss: 2.418177\n",
      "batch 18  d_loss: 0.265475  g_loss: 2.209647\n",
      "batch 19  d_loss: 0.264886  g_loss: 1.830813\n",
      "batch 20  d_loss: 0.303759  g_loss: 1.749513\n",
      "batch 21  d_loss: 0.301347  g_loss: 1.964448\n",
      "batch 22  d_loss: 0.256026  g_loss: 2.181088\n",
      "batch 23  d_loss: 0.220341  g_loss: 2.616900\n",
      "batch 24  d_loss: 0.128307  g_loss: 2.735266\n",
      "batch 25  d_loss: 0.219164  g_loss: 2.439629\n",
      "batch 26  d_loss: 0.179620  g_loss: 1.952205\n",
      "batch 27  d_loss: 0.162780  g_loss: 2.043605\n",
      "batch 28  d_loss: 0.346478  g_loss: 2.267340\n",
      "batch 29  d_loss: 0.301390  g_loss: 1.857923\n",
      "batch 30  d_loss: 0.338914  g_loss: 2.411256\n",
      "batch 31  d_loss: 0.334677  g_loss: 2.473330\n",
      "batch 32  d_loss: 0.312300  g_loss: 3.087896\n",
      "batch 33  d_loss: 0.353043  g_loss: 2.509181\n",
      "batch 34  d_loss: 0.222331  g_loss: 1.757811\n",
      "batch 35  d_loss: 0.164579  g_loss: 1.420296\n",
      "batch 36  d_loss: 0.494414  g_loss: 1.624121\n",
      "batch 37  d_loss: 0.498511  g_loss: 1.688214\n",
      "batch 38  d_loss: 0.258709  g_loss: 2.536634\n",
      "batch 39  d_loss: 0.326258  g_loss: 3.117570\n",
      "batch 40  d_loss: 0.245576  g_loss: 3.661932\n",
      "batch 41  d_loss: 0.428676  g_loss: 3.109429\n",
      "batch 42  d_loss: 0.377601  g_loss: 2.128768\n",
      "batch 43  d_loss: 0.250684  g_loss: 2.225551\n",
      "batch 44  d_loss: 0.198258  g_loss: 2.064196\n",
      "batch 45  d_loss: 0.214267  g_loss: 2.651001\n",
      "Epoch is 18\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.262359  g_loss: 3.200883\n",
      "batch 1  d_loss: 0.264906  g_loss: 3.396178\n",
      "batch 2  d_loss: 0.255290  g_loss: 2.865476\n",
      "batch 3  d_loss: 0.186905  g_loss: 2.454281\n",
      "batch 4  d_loss: 0.291992  g_loss: 1.984187\n",
      "batch 5  d_loss: 0.424322  g_loss: 2.005037\n",
      "batch 6  d_loss: 0.308595  g_loss: 2.585927\n",
      "batch 7  d_loss: 0.785708  g_loss: 2.766830\n",
      "batch 8  d_loss: 0.575213  g_loss: 2.512480\n",
      "batch 9  d_loss: 0.153009  g_loss: 2.265277\n",
      "batch 10  d_loss: 0.180768  g_loss: 1.886504\n",
      "batch 11  d_loss: 0.498280  g_loss: 2.125114\n",
      "batch 12  d_loss: 0.519375  g_loss: 1.673835\n",
      "batch 13  d_loss: 0.300044  g_loss: 1.847518\n",
      "batch 14  d_loss: 0.369899  g_loss: 1.862871\n",
      "batch 15  d_loss: 0.272630  g_loss: 2.188341\n",
      "batch 16  d_loss: 0.288199  g_loss: 1.860166\n",
      "batch 17  d_loss: 0.304784  g_loss: 1.611806\n",
      "batch 18  d_loss: 0.247232  g_loss: 1.914286\n",
      "batch 19  d_loss: 0.236364  g_loss: 2.072749\n",
      "batch 20  d_loss: 0.326948  g_loss: 1.997846\n",
      "batch 21  d_loss: 0.193921  g_loss: 1.996038\n",
      "batch 22  d_loss: 0.266481  g_loss: 2.161969\n",
      "batch 23  d_loss: 0.286779  g_loss: 2.175401\n",
      "batch 24  d_loss: 0.145127  g_loss: 1.947391\n",
      "batch 25  d_loss: 0.219222  g_loss: 2.304170\n",
      "batch 26  d_loss: 0.152013  g_loss: 2.339492\n",
      "batch 27  d_loss: 0.181234  g_loss: 2.863425\n",
      "batch 28  d_loss: 0.199022  g_loss: 2.789580\n",
      "batch 29  d_loss: 0.282836  g_loss: 2.363415\n",
      "batch 30  d_loss: 0.237804  g_loss: 1.927922\n",
      "batch 31  d_loss: 0.331262  g_loss: 2.183936\n",
      "batch 32  d_loss: 0.211289  g_loss: 2.328869\n",
      "batch 33  d_loss: 0.283983  g_loss: 2.642921\n",
      "batch 34  d_loss: 0.237148  g_loss: 2.169663\n",
      "batch 35  d_loss: 0.305531  g_loss: 2.061444\n",
      "batch 36  d_loss: 0.431542  g_loss: 2.029707\n",
      "batch 37  d_loss: 0.446607  g_loss: 1.555444\n",
      "batch 38  d_loss: 0.317151  g_loss: 1.749834\n",
      "batch 39  d_loss: 0.280738  g_loss: 1.957543\n",
      "batch 40  d_loss: 0.265469  g_loss: 2.505827\n",
      "batch 41  d_loss: 0.347807  g_loss: 2.223336\n",
      "batch 42  d_loss: 0.404496  g_loss: 1.646179\n",
      "batch 43  d_loss: 0.379908  g_loss: 1.668648\n",
      "batch 44  d_loss: 0.354974  g_loss: 2.080430\n",
      "batch 45  d_loss: 0.232119  g_loss: 2.193020\n",
      "Epoch is 19\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.178903  g_loss: 2.420516\n",
      "batch 1  d_loss: 0.446702  g_loss: 1.607117\n",
      "batch 2  d_loss: 0.299668  g_loss: 1.428632\n",
      "batch 3  d_loss: 0.362736  g_loss: 2.101684\n",
      "batch 4  d_loss: 0.266985  g_loss: 2.904000\n",
      "batch 5  d_loss: 0.357604  g_loss: 2.892220\n",
      "batch 6  d_loss: 0.394912  g_loss: 2.184051\n",
      "batch 7  d_loss: 0.731799  g_loss: 1.465269\n",
      "batch 8  d_loss: 0.527066  g_loss: 1.140821\n",
      "batch 9  d_loss: 0.335343  g_loss: 1.485813\n",
      "batch 10  d_loss: 0.244234  g_loss: 2.228347\n",
      "batch 11  d_loss: 0.327800  g_loss: 2.543168\n",
      "batch 12  d_loss: 0.325520  g_loss: 2.710881\n",
      "batch 13  d_loss: 0.306736  g_loss: 2.050259\n",
      "batch 14  d_loss: 0.240960  g_loss: 1.632799\n",
      "batch 15  d_loss: 0.300139  g_loss: 1.681236\n",
      "batch 16  d_loss: 0.339440  g_loss: 1.948490\n",
      "batch 17  d_loss: 0.245302  g_loss: 2.222431\n",
      "batch 18  d_loss: 0.152243  g_loss: 3.092366\n",
      "batch 19  d_loss: 0.205615  g_loss: 3.169333\n",
      "batch 20  d_loss: 0.286851  g_loss: 2.915096\n",
      "batch 21  d_loss: 0.110845  g_loss: 2.459600\n",
      "batch 22  d_loss: 0.115700  g_loss: 2.393320\n",
      "batch 23  d_loss: 0.219873  g_loss: 2.196806\n",
      "batch 24  d_loss: 0.195062  g_loss: 2.136317\n",
      "batch 25  d_loss: 0.181023  g_loss: 2.589601\n",
      "batch 26  d_loss: 0.124249  g_loss: 3.085236\n",
      "batch 27  d_loss: 0.167898  g_loss: 3.585389\n",
      "batch 28  d_loss: 0.328506  g_loss: 2.951217\n",
      "batch 29  d_loss: 0.349341  g_loss: 2.330429\n",
      "batch 30  d_loss: 0.406615  g_loss: 1.802374\n",
      "batch 31  d_loss: 0.267603  g_loss: 2.157685\n",
      "batch 32  d_loss: 0.378333  g_loss: 2.840428\n",
      "batch 33  d_loss: 0.403097  g_loss: 3.036165\n",
      "batch 34  d_loss: 0.313589  g_loss: 2.594971\n",
      "batch 35  d_loss: 0.311783  g_loss: 2.057046\n",
      "batch 36  d_loss: 0.537771  g_loss: 1.526328\n",
      "batch 37  d_loss: 0.594506  g_loss: 1.468052\n",
      "batch 38  d_loss: 0.609334  g_loss: 1.688107\n",
      "batch 39  d_loss: 0.481209  g_loss: 2.484830\n",
      "batch 40  d_loss: 0.357767  g_loss: 2.642809\n",
      "batch 41  d_loss: 0.697682  g_loss: 1.799822\n",
      "batch 42  d_loss: 0.274897  g_loss: 1.494148\n",
      "batch 43  d_loss: 0.304461  g_loss: 1.580229\n",
      "batch 44  d_loss: 0.348571  g_loss: 1.804787\n",
      "batch 45  d_loss: 0.228609  g_loss: 2.452207\n",
      "Epoch is 20\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.210624  g_loss: 2.964334\n",
      "batch 1  d_loss: 0.536964  g_loss: 2.691389\n",
      "batch 2  d_loss: 0.414649  g_loss: 1.752324\n",
      "batch 3  d_loss: 0.221155  g_loss: 1.339574\n",
      "batch 4  d_loss: 0.350484  g_loss: 1.680506\n",
      "batch 5  d_loss: 0.256983  g_loss: 1.777161\n",
      "batch 6  d_loss: 0.256257  g_loss: 2.243007\n",
      "batch 7  d_loss: 0.646091  g_loss: 2.447675\n",
      "batch 8  d_loss: 0.457618  g_loss: 2.267992\n",
      "batch 9  d_loss: 0.192891  g_loss: 2.088699\n",
      "batch 10  d_loss: 0.241252  g_loss: 1.832294\n",
      "batch 11  d_loss: 0.365598  g_loss: 1.634721\n",
      "batch 12  d_loss: 0.411729  g_loss: 1.422601\n",
      "batch 13  d_loss: 0.270076  g_loss: 1.534256\n",
      "batch 14  d_loss: 0.293760  g_loss: 1.845650\n",
      "batch 15  d_loss: 0.344326  g_loss: 2.150094\n",
      "batch 16  d_loss: 0.238212  g_loss: 2.548249\n",
      "batch 17  d_loss: 0.419319  g_loss: 2.481247\n",
      "batch 18  d_loss: 0.183182  g_loss: 2.432439\n",
      "batch 19  d_loss: 0.217450  g_loss: 2.297715\n",
      "batch 20  d_loss: 0.280647  g_loss: 1.843203\n",
      "batch 21  d_loss: 0.275854  g_loss: 2.052824\n",
      "batch 22  d_loss: 0.199061  g_loss: 2.409043\n",
      "batch 23  d_loss: 0.236260  g_loss: 2.406541\n",
      "batch 24  d_loss: 0.265128  g_loss: 2.638269\n",
      "batch 25  d_loss: 0.401344  g_loss: 2.388701\n",
      "batch 26  d_loss: 0.206230  g_loss: 1.838320\n",
      "batch 27  d_loss: 0.314734  g_loss: 1.942867\n",
      "batch 28  d_loss: 0.265043  g_loss: 1.658858\n",
      "batch 29  d_loss: 0.386506  g_loss: 1.496728\n",
      "batch 30  d_loss: 0.310035  g_loss: 1.890115\n",
      "batch 31  d_loss: 0.230486  g_loss: 2.606536\n",
      "batch 32  d_loss: 0.260452  g_loss: 2.529102\n",
      "batch 33  d_loss: 0.388526  g_loss: 2.458019\n",
      "batch 34  d_loss: 0.330924  g_loss: 1.790939\n",
      "batch 35  d_loss: 0.320312  g_loss: 1.746322\n",
      "batch 36  d_loss: 0.442981  g_loss: 1.300447\n",
      "batch 37  d_loss: 0.460925  g_loss: 1.059973\n",
      "batch 38  d_loss: 0.603941  g_loss: 1.531479\n",
      "batch 39  d_loss: 0.465840  g_loss: 2.239042\n",
      "batch 40  d_loss: 0.333487  g_loss: 1.765868\n",
      "batch 41  d_loss: 0.496987  g_loss: 2.000805\n",
      "batch 42  d_loss: 0.408203  g_loss: 1.770846\n",
      "batch 43  d_loss: 0.280813  g_loss: 1.536170\n",
      "batch 44  d_loss: 0.283352  g_loss: 1.707778\n",
      "batch 45  d_loss: 0.251795  g_loss: 1.622734\n",
      "Epoch is 21\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.207244  g_loss: 2.162229\n",
      "batch 1  d_loss: 0.306774  g_loss: 2.160038\n",
      "batch 2  d_loss: 0.259520  g_loss: 2.111178\n",
      "batch 3  d_loss: 0.229585  g_loss: 2.072898\n",
      "batch 4  d_loss: 0.231764  g_loss: 2.181402\n",
      "batch 5  d_loss: 0.223509  g_loss: 2.090531\n",
      "batch 6  d_loss: 0.227384  g_loss: 2.441337\n",
      "batch 7  d_loss: 0.740019  g_loss: 2.626847\n",
      "batch 8  d_loss: 0.400659  g_loss: 2.402100\n",
      "batch 9  d_loss: 0.183620  g_loss: 2.587657\n",
      "batch 10  d_loss: 0.245719  g_loss: 2.071982\n",
      "batch 11  d_loss: 0.268929  g_loss: 2.154107\n",
      "batch 12  d_loss: 0.361023  g_loss: 1.685632\n",
      "batch 13  d_loss: 0.311523  g_loss: 1.378219\n",
      "batch 14  d_loss: 0.310333  g_loss: 1.773488\n",
      "batch 15  d_loss: 0.323203  g_loss: 2.271138\n",
      "batch 16  d_loss: 0.269393  g_loss: 2.467247\n",
      "batch 17  d_loss: 0.279197  g_loss: 2.465559\n",
      "batch 18  d_loss: 0.256483  g_loss: 2.633418\n",
      "batch 19  d_loss: 0.297763  g_loss: 2.106753\n",
      "batch 20  d_loss: 0.391935  g_loss: 1.798749\n",
      "batch 21  d_loss: 0.267305  g_loss: 1.761203\n",
      "batch 22  d_loss: 0.316199  g_loss: 1.645573\n",
      "batch 23  d_loss: 0.196135  g_loss: 2.100964\n",
      "batch 24  d_loss: 0.247984  g_loss: 2.838096\n",
      "batch 25  d_loss: 0.187626  g_loss: 2.596740\n",
      "batch 26  d_loss: 0.274287  g_loss: 2.285562\n",
      "batch 27  d_loss: 0.192443  g_loss: 2.368947\n",
      "batch 28  d_loss: 0.307191  g_loss: 1.936256\n",
      "batch 29  d_loss: 0.282134  g_loss: 1.418744\n",
      "batch 30  d_loss: 0.300137  g_loss: 2.200109\n",
      "batch 31  d_loss: 0.227143  g_loss: 2.370607\n",
      "batch 32  d_loss: 0.391985  g_loss: 2.555690\n",
      "batch 33  d_loss: 0.340474  g_loss: 2.619669\n",
      "batch 34  d_loss: 0.348104  g_loss: 2.102470\n",
      "batch 35  d_loss: 0.275384  g_loss: 2.192182\n",
      "batch 36  d_loss: 0.562005  g_loss: 2.073253\n",
      "batch 37  d_loss: 0.710764  g_loss: 1.820319\n",
      "batch 38  d_loss: 0.464520  g_loss: 1.895171\n",
      "batch 39  d_loss: 0.482101  g_loss: 2.798317\n",
      "batch 40  d_loss: 0.176790  g_loss: 3.534072\n",
      "batch 41  d_loss: 0.492379  g_loss: 3.219649\n",
      "batch 42  d_loss: 0.415680  g_loss: 2.499683\n",
      "batch 43  d_loss: 0.276361  g_loss: 1.817604\n",
      "batch 44  d_loss: 0.365377  g_loss: 1.892550\n",
      "batch 45  d_loss: 0.271232  g_loss: 2.711619\n",
      "Epoch is 22\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.192086  g_loss: 2.847211\n",
      "batch 1  d_loss: 0.252399  g_loss: 3.134360\n",
      "batch 2  d_loss: 0.232007  g_loss: 2.688130\n",
      "batch 3  d_loss: 0.149184  g_loss: 2.591737\n",
      "batch 4  d_loss: 0.241483  g_loss: 2.618317\n",
      "batch 5  d_loss: 0.237808  g_loss: 2.550017\n",
      "batch 6  d_loss: 0.312539  g_loss: 2.519263\n",
      "batch 7  d_loss: 0.559533  g_loss: 2.000910\n",
      "batch 8  d_loss: 0.358363  g_loss: 2.435130\n",
      "batch 9  d_loss: 0.223763  g_loss: 2.587428\n",
      "batch 10  d_loss: 0.156543  g_loss: 2.508689\n",
      "batch 11  d_loss: 0.362489  g_loss: 2.669795\n",
      "batch 12  d_loss: 0.352298  g_loss: 2.351797\n",
      "batch 13  d_loss: 0.245383  g_loss: 1.889139\n",
      "batch 14  d_loss: 0.196078  g_loss: 2.004124\n",
      "batch 15  d_loss: 0.259700  g_loss: 2.153668\n",
      "batch 16  d_loss: 0.282857  g_loss: 2.388698\n",
      "batch 17  d_loss: 0.338657  g_loss: 2.937616\n",
      "batch 18  d_loss: 0.166007  g_loss: 2.736342\n",
      "batch 19  d_loss: 0.161661  g_loss: 3.055578\n",
      "batch 20  d_loss: 0.225808  g_loss: 2.770527\n",
      "batch 21  d_loss: 0.211038  g_loss: 2.948750\n",
      "batch 22  d_loss: 0.255402  g_loss: 3.207345\n",
      "batch 23  d_loss: 0.273877  g_loss: 2.890400\n",
      "batch 24  d_loss: 0.219206  g_loss: 2.361991\n",
      "batch 25  d_loss: 0.278179  g_loss: 1.580264\n",
      "batch 26  d_loss: 0.225807  g_loss: 1.617200\n",
      "batch 27  d_loss: 0.240345  g_loss: 2.147048\n",
      "batch 28  d_loss: 0.307235  g_loss: 2.609337\n",
      "batch 29  d_loss: 0.338015  g_loss: 3.057196\n",
      "batch 30  d_loss: 0.243994  g_loss: 2.478252\n",
      "batch 31  d_loss: 0.332647  g_loss: 1.740235\n",
      "batch 32  d_loss: 0.285270  g_loss: 1.593791\n",
      "batch 33  d_loss: 0.316521  g_loss: 1.524022\n",
      "batch 34  d_loss: 0.402843  g_loss: 2.256887\n",
      "batch 35  d_loss: 0.371221  g_loss: 2.290687\n",
      "batch 36  d_loss: 0.447823  g_loss: 1.718304\n",
      "batch 37  d_loss: 0.384567  g_loss: 1.501895\n",
      "batch 38  d_loss: 0.391757  g_loss: 1.389807\n",
      "batch 39  d_loss: 0.388672  g_loss: 1.576915\n",
      "batch 40  d_loss: 0.232182  g_loss: 2.154239\n",
      "batch 41  d_loss: 0.440553  g_loss: 2.209822\n",
      "batch 42  d_loss: 0.303206  g_loss: 2.440806\n",
      "batch 43  d_loss: 0.239268  g_loss: 2.373918\n",
      "batch 44  d_loss: 0.284716  g_loss: 2.379287\n",
      "batch 45  d_loss: 0.238155  g_loss: 2.326899\n",
      "Epoch is 23\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.242332  g_loss: 2.260890\n",
      "batch 1  d_loss: 0.351044  g_loss: 2.716539\n",
      "batch 2  d_loss: 0.260299  g_loss: 2.026946\n",
      "batch 3  d_loss: 0.277654  g_loss: 2.246022\n",
      "batch 4  d_loss: 0.281757  g_loss: 2.567548\n",
      "batch 5  d_loss: 0.254217  g_loss: 2.530518\n",
      "batch 6  d_loss: 0.213088  g_loss: 2.517856\n",
      "batch 7  d_loss: 0.757756  g_loss: 2.355325\n",
      "batch 8  d_loss: 0.445592  g_loss: 2.003745\n",
      "batch 9  d_loss: 0.201184  g_loss: 1.998082\n",
      "batch 10  d_loss: 0.236492  g_loss: 1.991967\n",
      "batch 11  d_loss: 0.418782  g_loss: 2.031237\n",
      "batch 12  d_loss: 0.450900  g_loss: 1.430813\n",
      "batch 13  d_loss: 0.365181  g_loss: 1.476401\n",
      "batch 14  d_loss: 0.466401  g_loss: 1.394182\n",
      "batch 15  d_loss: 0.392525  g_loss: 2.001226\n",
      "batch 16  d_loss: 0.409937  g_loss: 1.905051\n",
      "batch 17  d_loss: 0.415335  g_loss: 2.147124\n",
      "batch 18  d_loss: 0.392228  g_loss: 2.264543\n",
      "batch 19  d_loss: 0.433954  g_loss: 2.248403\n",
      "batch 20  d_loss: 0.429764  g_loss: 1.768060\n",
      "batch 21  d_loss: 0.226439  g_loss: 1.810786\n",
      "batch 22  d_loss: 0.274724  g_loss: 1.963294\n",
      "batch 23  d_loss: 0.229431  g_loss: 2.289641\n",
      "batch 24  d_loss: 0.237672  g_loss: 2.668814\n",
      "batch 25  d_loss: 0.292522  g_loss: 2.722710\n",
      "batch 26  d_loss: 0.255583  g_loss: 2.280673\n",
      "batch 27  d_loss: 0.175526  g_loss: 2.116327\n",
      "batch 28  d_loss: 0.319021  g_loss: 2.531515\n",
      "batch 29  d_loss: 0.344031  g_loss: 1.603882\n",
      "batch 30  d_loss: 0.190447  g_loss: 1.962635\n",
      "batch 31  d_loss: 0.412393  g_loss: 2.075989\n",
      "batch 32  d_loss: 0.305157  g_loss: 2.700997\n",
      "batch 33  d_loss: 0.393837  g_loss: 3.007860\n",
      "batch 34  d_loss: 0.347120  g_loss: 2.296319\n",
      "batch 35  d_loss: 0.303325  g_loss: 1.741852\n",
      "batch 36  d_loss: 0.511950  g_loss: 1.447559\n",
      "batch 37  d_loss: 0.474044  g_loss: 1.677150\n",
      "batch 38  d_loss: 0.541631  g_loss: 1.700916\n",
      "batch 39  d_loss: 0.424001  g_loss: 2.470262\n",
      "batch 40  d_loss: 0.381866  g_loss: 2.607323\n",
      "batch 41  d_loss: 0.491499  g_loss: 2.391445\n",
      "batch 42  d_loss: 0.371613  g_loss: 1.877064\n",
      "batch 43  d_loss: 0.338786  g_loss: 1.547660\n",
      "batch 44  d_loss: 0.330734  g_loss: 1.687628\n",
      "batch 45  d_loss: 0.207331  g_loss: 2.419490\n",
      "Epoch is 24\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.187217  g_loss: 2.981177\n",
      "batch 1  d_loss: 0.596258  g_loss: 2.643563\n",
      "batch 2  d_loss: 0.243581  g_loss: 2.287000\n",
      "batch 3  d_loss: 0.265839  g_loss: 2.212103\n",
      "batch 4  d_loss: 0.265481  g_loss: 2.496352\n",
      "batch 5  d_loss: 0.319675  g_loss: 2.395895\n",
      "batch 6  d_loss: 0.240194  g_loss: 2.205670\n",
      "batch 7  d_loss: 0.626037  g_loss: 2.327843\n",
      "batch 8  d_loss: 0.511758  g_loss: 2.767087\n",
      "batch 9  d_loss: 0.175913  g_loss: 2.756128\n",
      "batch 10  d_loss: 0.236976  g_loss: 2.273286\n",
      "batch 11  d_loss: 0.410344  g_loss: 2.194066\n",
      "batch 12  d_loss: 0.426936  g_loss: 1.479207\n",
      "batch 13  d_loss: 0.312134  g_loss: 1.332739\n",
      "batch 14  d_loss: 0.437441  g_loss: 1.582898\n",
      "batch 15  d_loss: 0.331185  g_loss: 1.698510\n",
      "batch 16  d_loss: 0.223383  g_loss: 2.475149\n",
      "batch 17  d_loss: 0.327770  g_loss: 2.556837\n",
      "batch 18  d_loss: 0.183520  g_loss: 2.995850\n",
      "batch 19  d_loss: 0.220601  g_loss: 3.001826\n",
      "batch 20  d_loss: 0.255395  g_loss: 2.398686\n",
      "batch 21  d_loss: 0.206466  g_loss: 2.079380\n",
      "batch 22  d_loss: 0.229841  g_loss: 2.020279\n",
      "batch 23  d_loss: 0.271169  g_loss: 2.063268\n",
      "batch 24  d_loss: 0.292882  g_loss: 2.477214\n",
      "batch 25  d_loss: 0.246583  g_loss: 2.756141\n",
      "batch 26  d_loss: 0.236461  g_loss: 3.100137\n",
      "batch 27  d_loss: 0.274937  g_loss: 3.505995\n",
      "batch 28  d_loss: 0.252297  g_loss: 3.042910\n",
      "batch 29  d_loss: 0.317477  g_loss: 2.601626\n",
      "batch 30  d_loss: 0.297136  g_loss: 2.230374\n",
      "batch 31  d_loss: 0.437302  g_loss: 1.764665\n",
      "batch 32  d_loss: 0.291489  g_loss: 2.285217\n",
      "batch 33  d_loss: 0.401056  g_loss: 2.412156\n",
      "batch 34  d_loss: 0.328767  g_loss: 2.316330\n",
      "batch 35  d_loss: 0.335928  g_loss: 1.797642\n",
      "batch 36  d_loss: 0.440599  g_loss: 1.455610\n",
      "batch 37  d_loss: 0.447268  g_loss: 1.199551\n",
      "batch 38  d_loss: 0.300208  g_loss: 1.304940\n",
      "batch 39  d_loss: 0.421396  g_loss: 1.814356\n",
      "batch 40  d_loss: 0.422035  g_loss: 2.290493\n",
      "batch 41  d_loss: 0.562153  g_loss: 2.211173\n",
      "batch 42  d_loss: 0.325209  g_loss: 2.178302\n",
      "batch 43  d_loss: 0.209336  g_loss: 2.140296\n",
      "batch 44  d_loss: 0.404148  g_loss: 1.903289\n",
      "batch 45  d_loss: 0.253938  g_loss: 2.260251\n",
      "Epoch is 25\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.212196  g_loss: 1.815258\n",
      "batch 1  d_loss: 0.270056  g_loss: 2.196341\n",
      "batch 2  d_loss: 0.301433  g_loss: 3.100944\n",
      "batch 3  d_loss: 0.292998  g_loss: 2.765834\n",
      "batch 4  d_loss: 0.299917  g_loss: 2.571940\n",
      "batch 5  d_loss: 0.331141  g_loss: 1.813465\n",
      "batch 6  d_loss: 0.210699  g_loss: 1.706573\n",
      "batch 7  d_loss: 0.608210  g_loss: 1.624452\n",
      "batch 8  d_loss: 0.406959  g_loss: 1.310211\n",
      "batch 9  d_loss: 0.339954  g_loss: 1.368421\n",
      "batch 10  d_loss: 0.287804  g_loss: 2.028574\n",
      "batch 11  d_loss: 0.391531  g_loss: 2.486295\n",
      "batch 12  d_loss: 0.464870  g_loss: 2.355731\n",
      "batch 13  d_loss: 0.399247  g_loss: 2.164866\n",
      "batch 14  d_loss: 0.313214  g_loss: 1.681968\n",
      "batch 15  d_loss: 0.353135  g_loss: 1.267112\n",
      "batch 16  d_loss: 0.269198  g_loss: 1.005229\n",
      "batch 17  d_loss: 0.384108  g_loss: 1.385408\n",
      "batch 18  d_loss: 0.227562  g_loss: 1.734769\n",
      "batch 19  d_loss: 0.233857  g_loss: 2.333256\n",
      "batch 20  d_loss: 0.264438  g_loss: 2.496434\n",
      "batch 21  d_loss: 0.176564  g_loss: 2.868977\n",
      "batch 22  d_loss: 0.301076  g_loss: 2.539710\n",
      "batch 23  d_loss: 0.227028  g_loss: 2.165648\n",
      "batch 24  d_loss: 0.206754  g_loss: 2.235749\n",
      "batch 25  d_loss: 0.264358  g_loss: 1.790375\n",
      "batch 26  d_loss: 0.281991  g_loss: 1.917111\n",
      "batch 27  d_loss: 0.207845  g_loss: 1.680437\n",
      "batch 28  d_loss: 0.461202  g_loss: 2.016280\n",
      "batch 29  d_loss: 0.429560  g_loss: 2.342562\n",
      "batch 30  d_loss: 0.299240  g_loss: 2.491547\n",
      "batch 31  d_loss: 0.420209  g_loss: 2.316059\n",
      "batch 32  d_loss: 0.377622  g_loss: 2.418972\n",
      "batch 33  d_loss: 0.474466  g_loss: 1.838686\n",
      "batch 34  d_loss: 0.331272  g_loss: 1.563040\n",
      "batch 35  d_loss: 0.334396  g_loss: 1.328993\n",
      "batch 36  d_loss: 0.500872  g_loss: 1.564561\n",
      "batch 37  d_loss: 0.559639  g_loss: 1.891348\n",
      "batch 38  d_loss: 0.451611  g_loss: 1.794751\n",
      "batch 39  d_loss: 0.389403  g_loss: 2.252251\n",
      "batch 40  d_loss: 0.388703  g_loss: 2.318305\n",
      "batch 41  d_loss: 0.448544  g_loss: 2.239504\n",
      "batch 42  d_loss: 0.367846  g_loss: 2.266734\n",
      "batch 43  d_loss: 0.226813  g_loss: 1.996020\n",
      "batch 44  d_loss: 0.290484  g_loss: 1.843385\n",
      "batch 45  d_loss: 0.325958  g_loss: 2.222620\n",
      "Epoch is 26\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.242516  g_loss: 2.564008\n",
      "batch 1  d_loss: 0.379224  g_loss: 2.330022\n",
      "batch 2  d_loss: 0.318123  g_loss: 1.968826\n",
      "batch 3  d_loss: 0.242260  g_loss: 1.934230\n",
      "batch 4  d_loss: 0.360767  g_loss: 1.889226\n",
      "batch 5  d_loss: 0.328730  g_loss: 1.623650\n",
      "batch 6  d_loss: 0.228380  g_loss: 2.094906\n",
      "batch 7  d_loss: 0.517274  g_loss: 2.225947\n",
      "batch 8  d_loss: 0.366151  g_loss: 2.259871\n",
      "batch 9  d_loss: 0.128821  g_loss: 2.423875\n",
      "batch 10  d_loss: 0.267756  g_loss: 2.753307\n",
      "batch 11  d_loss: 0.387441  g_loss: 2.376297\n",
      "batch 12  d_loss: 0.361456  g_loss: 1.717617\n",
      "batch 13  d_loss: 0.240861  g_loss: 1.653213\n",
      "batch 14  d_loss: 0.334214  g_loss: 1.517271\n",
      "batch 15  d_loss: 0.308390  g_loss: 1.535937\n",
      "batch 16  d_loss: 0.251300  g_loss: 2.013229\n",
      "batch 17  d_loss: 0.330725  g_loss: 2.460920\n",
      "batch 18  d_loss: 0.159376  g_loss: 2.849554\n",
      "batch 19  d_loss: 0.285831  g_loss: 3.060529\n",
      "batch 20  d_loss: 0.312686  g_loss: 2.475711\n",
      "batch 21  d_loss: 0.216486  g_loss: 2.383307\n",
      "batch 22  d_loss: 0.316129  g_loss: 1.659404\n",
      "batch 23  d_loss: 0.302495  g_loss: 1.296426\n",
      "batch 24  d_loss: 0.361403  g_loss: 1.668807\n",
      "batch 25  d_loss: 0.312052  g_loss: 2.106386\n",
      "batch 26  d_loss: 0.227869  g_loss: 2.486524\n",
      "batch 27  d_loss: 0.361715  g_loss: 3.002487\n",
      "batch 28  d_loss: 0.357019  g_loss: 2.240326\n",
      "batch 29  d_loss: 0.553375  g_loss: 2.040735\n",
      "batch 30  d_loss: 0.355007  g_loss: 1.712024\n",
      "batch 31  d_loss: 0.340005  g_loss: 1.308291\n",
      "batch 32  d_loss: 0.364937  g_loss: 1.643515\n",
      "batch 33  d_loss: 0.572084  g_loss: 1.882726\n",
      "batch 34  d_loss: 0.483665  g_loss: 1.875762\n",
      "batch 35  d_loss: 0.502522  g_loss: 1.964887\n",
      "batch 36  d_loss: 0.724597  g_loss: 1.550874\n",
      "batch 37  d_loss: 0.726656  g_loss: 1.698159\n",
      "batch 38  d_loss: 0.600052  g_loss: 1.556721\n",
      "batch 39  d_loss: 0.448345  g_loss: 1.869176\n",
      "batch 40  d_loss: 0.343970  g_loss: 2.398176\n",
      "batch 41  d_loss: 0.394413  g_loss: 3.106676\n",
      "batch 42  d_loss: 0.378397  g_loss: 2.591094\n",
      "batch 43  d_loss: 0.221800  g_loss: 2.253433\n",
      "batch 44  d_loss: 0.254668  g_loss: 2.064612\n",
      "batch 45  d_loss: 0.240825  g_loss: 1.802856\n",
      "Epoch is 27\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.285480  g_loss: 2.031870\n",
      "batch 1  d_loss: 0.277870  g_loss: 1.985097\n",
      "batch 2  d_loss: 0.251062  g_loss: 2.265821\n",
      "batch 3  d_loss: 0.214649  g_loss: 2.513270\n",
      "batch 4  d_loss: 0.353067  g_loss: 2.285296\n",
      "batch 5  d_loss: 0.257792  g_loss: 2.012103\n",
      "batch 6  d_loss: 0.280883  g_loss: 1.613488\n",
      "batch 7  d_loss: 0.516480  g_loss: 1.703427\n",
      "batch 8  d_loss: 0.439568  g_loss: 1.908095\n",
      "batch 9  d_loss: 0.281956  g_loss: 2.209296\n",
      "batch 10  d_loss: 0.235382  g_loss: 1.768723\n",
      "batch 11  d_loss: 0.360552  g_loss: 2.121160\n",
      "batch 12  d_loss: 0.421033  g_loss: 2.034158\n",
      "batch 13  d_loss: 0.305304  g_loss: 1.823668\n",
      "batch 14  d_loss: 0.475232  g_loss: 1.762039\n",
      "batch 15  d_loss: 0.285720  g_loss: 1.641748\n",
      "batch 16  d_loss: 0.292105  g_loss: 1.825515\n",
      "batch 17  d_loss: 0.373485  g_loss: 1.730207\n",
      "batch 18  d_loss: 0.189324  g_loss: 1.892821\n",
      "batch 19  d_loss: 0.301900  g_loss: 2.017649\n",
      "batch 20  d_loss: 0.312951  g_loss: 2.467837\n",
      "batch 21  d_loss: 0.172949  g_loss: 2.649304\n",
      "batch 22  d_loss: 0.215394  g_loss: 2.371849\n",
      "batch 23  d_loss: 0.226609  g_loss: 2.315787\n",
      "batch 24  d_loss: 0.169094  g_loss: 2.292428\n",
      "batch 25  d_loss: 0.278641  g_loss: 2.239056\n",
      "batch 26  d_loss: 0.234248  g_loss: 2.245896\n",
      "batch 27  d_loss: 0.261063  g_loss: 2.814292\n",
      "batch 28  d_loss: 0.392068  g_loss: 3.265947\n",
      "batch 29  d_loss: 0.542085  g_loss: 2.274723\n",
      "batch 30  d_loss: 0.321732  g_loss: 2.579359\n",
      "batch 31  d_loss: 0.363666  g_loss: 2.200261\n",
      "batch 32  d_loss: 0.508407  g_loss: 2.217688\n",
      "batch 33  d_loss: 0.520649  g_loss: 2.596652\n",
      "batch 34  d_loss: 0.386415  g_loss: 2.187433\n",
      "batch 35  d_loss: 0.365102  g_loss: 1.639339\n",
      "batch 36  d_loss: 0.480142  g_loss: 1.788173\n",
      "batch 37  d_loss: 0.440838  g_loss: 1.818931\n",
      "batch 38  d_loss: 0.339737  g_loss: 2.220859\n",
      "batch 39  d_loss: 0.415006  g_loss: 2.296013\n",
      "batch 40  d_loss: 0.286005  g_loss: 2.614450\n",
      "batch 41  d_loss: 0.522498  g_loss: 1.750785\n",
      "batch 42  d_loss: 0.310715  g_loss: 1.616380\n",
      "batch 43  d_loss: 0.329836  g_loss: 1.427229\n",
      "batch 44  d_loss: 0.423459  g_loss: 1.455982\n",
      "batch 45  d_loss: 0.292016  g_loss: 2.130250\n",
      "Epoch is 28\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.192437  g_loss: 2.789082\n",
      "batch 1  d_loss: 0.474141  g_loss: 2.657564\n",
      "batch 2  d_loss: 0.316385  g_loss: 2.069640\n",
      "batch 3  d_loss: 0.346797  g_loss: 1.740201\n",
      "batch 4  d_loss: 0.421841  g_loss: 2.027688\n",
      "batch 5  d_loss: 0.449450  g_loss: 1.699401\n",
      "batch 6  d_loss: 0.309493  g_loss: 2.264218\n",
      "batch 7  d_loss: 0.657368  g_loss: 2.230779\n",
      "batch 8  d_loss: 0.512085  g_loss: 2.411466\n",
      "batch 9  d_loss: 0.289090  g_loss: 2.698068\n",
      "batch 10  d_loss: 0.327112  g_loss: 2.855232\n",
      "batch 11  d_loss: 0.521516  g_loss: 2.183261\n",
      "batch 12  d_loss: 0.496595  g_loss: 1.738892\n",
      "batch 13  d_loss: 0.420614  g_loss: 1.390819\n",
      "batch 14  d_loss: 0.361777  g_loss: 1.321563\n",
      "batch 15  d_loss: 0.428874  g_loss: 0.941154\n",
      "batch 16  d_loss: 0.375387  g_loss: 1.328676\n",
      "batch 17  d_loss: 0.453134  g_loss: 1.615359\n",
      "batch 18  d_loss: 0.260345  g_loss: 2.346029\n",
      "batch 19  d_loss: 0.288215  g_loss: 2.645089\n",
      "batch 20  d_loss: 0.439469  g_loss: 2.204724\n",
      "batch 21  d_loss: 0.288042  g_loss: 2.083496\n",
      "batch 22  d_loss: 0.260472  g_loss: 1.776568\n",
      "batch 23  d_loss: 0.241476  g_loss: 1.561773\n",
      "batch 24  d_loss: 0.289682  g_loss: 1.585265\n",
      "batch 25  d_loss: 0.316548  g_loss: 1.528549\n",
      "batch 26  d_loss: 0.253077  g_loss: 2.075739\n",
      "batch 27  d_loss: 0.352532  g_loss: 2.231087\n",
      "batch 28  d_loss: 0.294090  g_loss: 2.615098\n",
      "batch 29  d_loss: 0.307086  g_loss: 2.512049\n",
      "batch 30  d_loss: 0.308454  g_loss: 2.339953\n",
      "batch 31  d_loss: 0.311622  g_loss: 2.127320\n",
      "batch 32  d_loss: 0.253845  g_loss: 1.796080\n",
      "batch 33  d_loss: 0.324528  g_loss: 1.607705\n",
      "batch 34  d_loss: 0.350403  g_loss: 1.413719\n",
      "batch 35  d_loss: 0.403531  g_loss: 1.656484\n",
      "batch 36  d_loss: 0.419733  g_loss: 1.499202\n",
      "batch 37  d_loss: 0.550514  g_loss: 1.503975\n",
      "batch 38  d_loss: 0.479811  g_loss: 1.769785\n",
      "batch 39  d_loss: 0.406334  g_loss: 1.852577\n",
      "batch 40  d_loss: 0.339239  g_loss: 2.025256\n",
      "batch 41  d_loss: 0.453294  g_loss: 1.979050\n",
      "batch 42  d_loss: 0.349675  g_loss: 1.734694\n",
      "batch 43  d_loss: 0.289378  g_loss: 1.811418\n",
      "batch 44  d_loss: 0.347566  g_loss: 1.767804\n",
      "batch 45  d_loss: 0.279816  g_loss: 1.777329\n",
      "Epoch is 29\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.226861  g_loss: 2.019168\n",
      "batch 1  d_loss: 0.366378  g_loss: 2.052779\n",
      "batch 2  d_loss: 0.220239  g_loss: 2.063529\n",
      "batch 3  d_loss: 0.185828  g_loss: 1.946333\n",
      "batch 4  d_loss: 0.298399  g_loss: 2.043756\n",
      "batch 5  d_loss: 0.344680  g_loss: 1.871646\n",
      "batch 6  d_loss: 0.253549  g_loss: 2.190755\n",
      "batch 7  d_loss: 0.779163  g_loss: 2.227083\n",
      "batch 8  d_loss: 0.522857  g_loss: 1.895300\n",
      "batch 9  d_loss: 0.308074  g_loss: 1.811042\n",
      "batch 10  d_loss: 0.241928  g_loss: 2.663857\n",
      "batch 11  d_loss: 0.426077  g_loss: 2.360383\n",
      "batch 12  d_loss: 0.531649  g_loss: 1.986936\n",
      "batch 13  d_loss: 0.367302  g_loss: 1.575924\n",
      "batch 14  d_loss: 0.428310  g_loss: 1.320058\n",
      "batch 15  d_loss: 0.380360  g_loss: 1.785712\n",
      "batch 16  d_loss: 0.348852  g_loss: 2.031422\n",
      "batch 17  d_loss: 0.390632  g_loss: 1.947089\n",
      "batch 18  d_loss: 0.194353  g_loss: 2.142757\n",
      "batch 19  d_loss: 0.305777  g_loss: 2.139366\n",
      "batch 20  d_loss: 0.334082  g_loss: 2.046447\n",
      "batch 21  d_loss: 0.228613  g_loss: 1.731759\n",
      "batch 22  d_loss: 0.321729  g_loss: 1.700505\n",
      "batch 23  d_loss: 0.251530  g_loss: 2.003013\n",
      "batch 24  d_loss: 0.240239  g_loss: 1.906522\n",
      "batch 25  d_loss: 0.310727  g_loss: 2.336195\n",
      "batch 26  d_loss: 0.431774  g_loss: 2.043925\n",
      "batch 27  d_loss: 0.264411  g_loss: 1.459604\n",
      "batch 28  d_loss: 0.237845  g_loss: 1.520108\n",
      "batch 29  d_loss: 0.373146  g_loss: 1.653978\n",
      "batch 30  d_loss: 0.253186  g_loss: 1.937905\n",
      "batch 31  d_loss: 0.319083  g_loss: 1.996015\n",
      "batch 32  d_loss: 0.346229  g_loss: 2.256629\n",
      "batch 33  d_loss: 0.371159  g_loss: 2.261755\n",
      "batch 34  d_loss: 0.295570  g_loss: 1.836821\n",
      "batch 35  d_loss: 0.421581  g_loss: 1.886207\n",
      "batch 36  d_loss: 0.491344  g_loss: 1.514995\n",
      "batch 37  d_loss: 0.542089  g_loss: 1.741489\n",
      "batch 38  d_loss: 0.341158  g_loss: 1.975585\n",
      "batch 39  d_loss: 0.363745  g_loss: 2.284903\n",
      "batch 40  d_loss: 0.303825  g_loss: 2.297316\n",
      "batch 41  d_loss: 0.405314  g_loss: 2.452152\n",
      "batch 42  d_loss: 0.455070  g_loss: 1.504380\n",
      "batch 43  d_loss: 0.322515  g_loss: 1.682347\n",
      "batch 44  d_loss: 0.341300  g_loss: 1.703653\n",
      "batch 45  d_loss: 0.235137  g_loss: 2.270341\n",
      "Epoch is 30\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.271625  g_loss: 2.439798\n",
      "batch 1  d_loss: 0.336737  g_loss: 2.343489\n",
      "batch 2  d_loss: 0.288683  g_loss: 1.561138\n",
      "batch 3  d_loss: 0.311294  g_loss: 1.859007\n",
      "batch 4  d_loss: 0.301069  g_loss: 1.920751\n",
      "batch 5  d_loss: 0.408784  g_loss: 2.048631\n",
      "batch 6  d_loss: 0.227554  g_loss: 2.153796\n",
      "batch 7  d_loss: 0.674953  g_loss: 2.053974\n",
      "batch 8  d_loss: 0.482136  g_loss: 1.707492\n",
      "batch 9  d_loss: 0.324390  g_loss: 1.893937\n",
      "batch 10  d_loss: 0.277698  g_loss: 1.878415\n",
      "batch 11  d_loss: 0.409442  g_loss: 1.885335\n",
      "batch 12  d_loss: 0.456901  g_loss: 1.879296\n",
      "batch 13  d_loss: 0.371751  g_loss: 1.669778\n",
      "batch 14  d_loss: 0.410003  g_loss: 1.853412\n",
      "batch 15  d_loss: 0.363323  g_loss: 2.018301\n",
      "batch 16  d_loss: 0.340495  g_loss: 1.867430\n",
      "batch 17  d_loss: 0.317107  g_loss: 1.746123\n",
      "batch 18  d_loss: 0.207020  g_loss: 1.741235\n",
      "batch 19  d_loss: 0.221985  g_loss: 1.797813\n",
      "batch 20  d_loss: 0.303002  g_loss: 1.813003\n",
      "batch 21  d_loss: 0.276952  g_loss: 2.270411\n",
      "batch 22  d_loss: 0.251902  g_loss: 2.227439\n",
      "batch 23  d_loss: 0.197842  g_loss: 2.218184\n",
      "batch 24  d_loss: 0.268289  g_loss: 2.251882\n",
      "batch 25  d_loss: 0.231213  g_loss: 2.412367\n",
      "batch 26  d_loss: 0.339343  g_loss: 1.748597\n",
      "batch 27  d_loss: 0.213358  g_loss: 1.843231\n",
      "batch 28  d_loss: 0.275381  g_loss: 1.935754\n",
      "batch 29  d_loss: 0.393176  g_loss: 2.320824\n",
      "batch 30  d_loss: 0.303468  g_loss: 2.768312\n",
      "batch 31  d_loss: 0.317107  g_loss: 3.024965\n",
      "batch 32  d_loss: 0.266952  g_loss: 2.447462\n",
      "batch 33  d_loss: 0.365009  g_loss: 1.666344\n",
      "batch 34  d_loss: 0.380259  g_loss: 1.638812\n",
      "batch 35  d_loss: 0.370949  g_loss: 1.238268\n",
      "batch 36  d_loss: 0.464897  g_loss: 1.348973\n",
      "batch 37  d_loss: 0.488113  g_loss: 1.729898\n",
      "batch 38  d_loss: 0.502065  g_loss: 2.180571\n",
      "batch 39  d_loss: 0.372987  g_loss: 1.905974\n",
      "batch 40  d_loss: 0.336227  g_loss: 1.785768\n",
      "batch 41  d_loss: 0.356390  g_loss: 0.949106\n",
      "batch 42  d_loss: 0.449929  g_loss: 1.264530\n",
      "batch 43  d_loss: 0.482329  g_loss: 1.774982\n",
      "batch 44  d_loss: 0.365357  g_loss: 2.428488\n",
      "batch 45  d_loss: 0.295012  g_loss: 2.312441\n",
      "Epoch is 31\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.334491  g_loss: 2.563928\n",
      "batch 1  d_loss: 0.444934  g_loss: 1.995500\n",
      "batch 2  d_loss: 0.199246  g_loss: 1.551315\n",
      "batch 3  d_loss: 0.373303  g_loss: 1.815398\n",
      "batch 4  d_loss: 0.403442  g_loss: 2.089794\n",
      "batch 5  d_loss: 0.411030  g_loss: 1.873568\n",
      "batch 6  d_loss: 0.253968  g_loss: 2.371069\n",
      "batch 7  d_loss: 0.747052  g_loss: 2.298212\n",
      "batch 8  d_loss: 0.517477  g_loss: 2.014908\n",
      "batch 9  d_loss: 0.278920  g_loss: 1.656728\n",
      "batch 10  d_loss: 0.353480  g_loss: 1.837185\n",
      "batch 11  d_loss: 0.380269  g_loss: 1.449934\n",
      "batch 12  d_loss: 0.375542  g_loss: 1.618626\n",
      "batch 13  d_loss: 0.443118  g_loss: 1.770007\n",
      "batch 14  d_loss: 0.429515  g_loss: 2.157343\n",
      "batch 15  d_loss: 0.336104  g_loss: 2.019117\n",
      "batch 16  d_loss: 0.353016  g_loss: 1.912132\n",
      "batch 17  d_loss: 0.400159  g_loss: 1.795892\n",
      "batch 18  d_loss: 0.267986  g_loss: 1.551445\n",
      "batch 19  d_loss: 0.372212  g_loss: 1.786796\n",
      "batch 20  d_loss: 0.342607  g_loss: 1.702429\n",
      "batch 21  d_loss: 0.345797  g_loss: 2.234301\n",
      "batch 22  d_loss: 0.425585  g_loss: 2.350479\n",
      "batch 23  d_loss: 0.352991  g_loss: 2.022751\n",
      "batch 24  d_loss: 0.351735  g_loss: 1.977944\n",
      "batch 25  d_loss: 0.300919  g_loss: 1.648239\n",
      "batch 26  d_loss: 0.387784  g_loss: 1.372905\n",
      "batch 27  d_loss: 0.442733  g_loss: 1.564285\n",
      "batch 28  d_loss: 0.310960  g_loss: 1.514908\n",
      "batch 29  d_loss: 0.447746  g_loss: 2.096100\n",
      "batch 30  d_loss: 0.338514  g_loss: 1.932108\n",
      "batch 31  d_loss: 0.303092  g_loss: 1.672367\n",
      "batch 32  d_loss: 0.361276  g_loss: 2.024947\n",
      "batch 33  d_loss: 0.449280  g_loss: 2.099953\n",
      "batch 34  d_loss: 0.452458  g_loss: 1.556362\n",
      "batch 35  d_loss: 0.371347  g_loss: 1.262367\n",
      "batch 36  d_loss: 0.553760  g_loss: 1.056388\n",
      "batch 37  d_loss: 0.423564  g_loss: 1.192173\n",
      "batch 38  d_loss: 0.510799  g_loss: 1.835932\n",
      "batch 39  d_loss: 0.350174  g_loss: 2.282358\n",
      "batch 40  d_loss: 0.307585  g_loss: 3.061660\n",
      "batch 41  d_loss: 0.535359  g_loss: 2.424939\n",
      "batch 42  d_loss: 0.459519  g_loss: 2.156406\n",
      "batch 43  d_loss: 0.232897  g_loss: 1.880618\n",
      "batch 44  d_loss: 0.295983  g_loss: 1.825562\n",
      "batch 45  d_loss: 0.367807  g_loss: 2.021970\n",
      "Epoch is 32\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.209815  g_loss: 2.456388\n",
      "batch 1  d_loss: 0.340143  g_loss: 2.528749\n",
      "batch 2  d_loss: 0.270645  g_loss: 2.441832\n",
      "batch 3  d_loss: 0.278275  g_loss: 2.040226\n",
      "batch 4  d_loss: 0.447993  g_loss: 1.625299\n",
      "batch 5  d_loss: 0.438696  g_loss: 1.794396\n",
      "batch 6  d_loss: 0.383149  g_loss: 2.136250\n",
      "batch 7  d_loss: 0.477505  g_loss: 2.637356\n",
      "batch 8  d_loss: 0.452827  g_loss: 2.357115\n",
      "batch 9  d_loss: 0.303372  g_loss: 2.172201\n",
      "batch 10  d_loss: 0.280393  g_loss: 1.430519\n",
      "batch 11  d_loss: 0.333307  g_loss: 0.954312\n",
      "batch 12  d_loss: 0.474469  g_loss: 0.893841\n",
      "batch 13  d_loss: 0.468913  g_loss: 1.501356\n",
      "batch 14  d_loss: 0.410909  g_loss: 2.065062\n",
      "batch 15  d_loss: 0.423118  g_loss: 2.446684\n",
      "batch 16  d_loss: 0.437606  g_loss: 1.974175\n",
      "batch 17  d_loss: 0.469531  g_loss: 1.600020\n",
      "batch 18  d_loss: 0.242358  g_loss: 1.265256\n",
      "batch 19  d_loss: 0.275727  g_loss: 1.607520\n",
      "batch 20  d_loss: 0.443567  g_loss: 1.544023\n",
      "batch 21  d_loss: 0.255068  g_loss: 1.955221\n",
      "batch 22  d_loss: 0.274574  g_loss: 2.095006\n",
      "batch 23  d_loss: 0.267734  g_loss: 2.167181\n",
      "batch 24  d_loss: 0.294335  g_loss: 2.581883\n",
      "batch 25  d_loss: 0.320589  g_loss: 1.740980\n",
      "batch 26  d_loss: 0.284150  g_loss: 1.531371\n",
      "batch 27  d_loss: 0.245419  g_loss: 1.944198\n",
      "batch 28  d_loss: 0.332711  g_loss: 2.534525\n",
      "batch 29  d_loss: 0.343625  g_loss: 2.424074\n",
      "batch 30  d_loss: 0.273197  g_loss: 2.591088\n",
      "batch 31  d_loss: 0.266389  g_loss: 2.408968\n",
      "batch 32  d_loss: 0.229353  g_loss: 2.191869\n",
      "batch 33  d_loss: 0.408963  g_loss: 1.750752\n",
      "batch 34  d_loss: 0.357418  g_loss: 1.874630\n",
      "batch 35  d_loss: 0.418406  g_loss: 1.829137\n",
      "batch 36  d_loss: 0.516435  g_loss: 2.235097\n",
      "batch 37  d_loss: 0.607689  g_loss: 1.766475\n",
      "batch 38  d_loss: 0.468493  g_loss: 1.296710\n",
      "batch 39  d_loss: 0.405236  g_loss: 1.635872\n",
      "batch 40  d_loss: 0.327909  g_loss: 1.843818\n",
      "batch 41  d_loss: 0.450311  g_loss: 1.874245\n",
      "batch 42  d_loss: 0.403949  g_loss: 1.670157\n",
      "batch 43  d_loss: 0.289230  g_loss: 1.851225\n",
      "batch 44  d_loss: 0.298046  g_loss: 2.040370\n",
      "batch 45  d_loss: 0.354960  g_loss: 1.850295\n",
      "Epoch is 33\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.266688  g_loss: 1.613248\n",
      "batch 1  d_loss: 0.366529  g_loss: 1.631327\n",
      "batch 2  d_loss: 0.279144  g_loss: 1.482223\n",
      "batch 3  d_loss: 0.293607  g_loss: 2.183135\n",
      "batch 4  d_loss: 0.352359  g_loss: 2.265515\n",
      "batch 5  d_loss: 0.336555  g_loss: 2.122860\n",
      "batch 6  d_loss: 0.196188  g_loss: 2.049987\n",
      "batch 7  d_loss: 0.547963  g_loss: 1.990798\n",
      "batch 8  d_loss: 0.330884  g_loss: 2.054997\n",
      "batch 9  d_loss: 0.284736  g_loss: 1.786482\n",
      "batch 10  d_loss: 0.322361  g_loss: 1.374728\n",
      "batch 11  d_loss: 0.377633  g_loss: 1.543532\n",
      "batch 12  d_loss: 0.426186  g_loss: 1.719487\n",
      "batch 13  d_loss: 0.435554  g_loss: 2.042997\n",
      "batch 14  d_loss: 0.407794  g_loss: 1.550309\n",
      "batch 15  d_loss: 0.378866  g_loss: 1.505358\n",
      "batch 16  d_loss: 0.399218  g_loss: 1.395893\n",
      "batch 17  d_loss: 0.414726  g_loss: 1.567025\n",
      "batch 18  d_loss: 0.254060  g_loss: 1.890787\n",
      "batch 19  d_loss: 0.369669  g_loss: 2.231987\n",
      "batch 20  d_loss: 0.333318  g_loss: 1.703063\n",
      "batch 21  d_loss: 0.273571  g_loss: 1.587105\n",
      "batch 22  d_loss: 0.324422  g_loss: 1.899303\n",
      "batch 23  d_loss: 0.310727  g_loss: 2.336537\n",
      "batch 24  d_loss: 0.220810  g_loss: 2.428515\n",
      "batch 25  d_loss: 0.235451  g_loss: 2.104832\n",
      "batch 26  d_loss: 0.319416  g_loss: 1.859056\n",
      "batch 27  d_loss: 0.204250  g_loss: 1.579113\n",
      "batch 28  d_loss: 0.411526  g_loss: 2.076245\n",
      "batch 29  d_loss: 0.437835  g_loss: 2.458800\n",
      "batch 30  d_loss: 0.252849  g_loss: 2.876812\n",
      "batch 31  d_loss: 0.324991  g_loss: 2.855832\n",
      "batch 32  d_loss: 0.276704  g_loss: 2.786971\n",
      "batch 33  d_loss: 0.337066  g_loss: 2.051275\n",
      "batch 34  d_loss: 0.310923  g_loss: 1.513803\n",
      "batch 35  d_loss: 0.326779  g_loss: 1.679023\n",
      "batch 36  d_loss: 0.472212  g_loss: 1.378293\n",
      "batch 37  d_loss: 0.573219  g_loss: 2.025002\n",
      "batch 38  d_loss: 0.437362  g_loss: 2.459966\n",
      "batch 39  d_loss: 0.382307  g_loss: 2.416008\n",
      "batch 40  d_loss: 0.237765  g_loss: 2.596165\n",
      "batch 41  d_loss: 0.467590  g_loss: 2.067936\n",
      "batch 42  d_loss: 0.365628  g_loss: 1.878514\n",
      "batch 43  d_loss: 0.336127  g_loss: 1.976302\n",
      "batch 44  d_loss: 0.339024  g_loss: 2.269369\n",
      "batch 45  d_loss: 0.261520  g_loss: 2.447743\n",
      "Epoch is 34\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.318962  g_loss: 1.914618\n",
      "batch 1  d_loss: 0.419349  g_loss: 1.256595\n",
      "batch 2  d_loss: 0.346158  g_loss: 1.466936\n",
      "batch 3  d_loss: 0.538558  g_loss: 1.962812\n",
      "batch 4  d_loss: 0.377779  g_loss: 2.949453\n",
      "batch 5  d_loss: 0.503120  g_loss: 2.112331\n",
      "batch 6  d_loss: 0.244432  g_loss: 2.154851\n",
      "batch 7  d_loss: 0.667931  g_loss: 1.568687\n",
      "batch 8  d_loss: 0.373514  g_loss: 1.479703\n",
      "batch 9  d_loss: 0.396408  g_loss: 2.050634\n",
      "batch 10  d_loss: 0.282948  g_loss: 2.046495\n",
      "batch 11  d_loss: 0.440644  g_loss: 2.042899\n",
      "batch 12  d_loss: 0.409290  g_loss: 1.856402\n",
      "batch 13  d_loss: 0.314437  g_loss: 1.312679\n",
      "batch 14  d_loss: 0.502120  g_loss: 1.405659\n",
      "batch 15  d_loss: 0.278293  g_loss: 1.808759\n",
      "batch 16  d_loss: 0.273028  g_loss: 2.272960\n",
      "batch 17  d_loss: 0.306485  g_loss: 2.472199\n",
      "batch 18  d_loss: 0.261072  g_loss: 2.621587\n",
      "batch 19  d_loss: 0.256864  g_loss: 2.701288\n",
      "batch 20  d_loss: 0.329209  g_loss: 1.869936\n",
      "batch 21  d_loss: 0.219602  g_loss: 2.081926\n",
      "batch 22  d_loss: 0.314139  g_loss: 2.123898\n",
      "batch 23  d_loss: 0.273454  g_loss: 2.330047\n",
      "batch 24  d_loss: 0.254120  g_loss: 2.835917\n",
      "batch 25  d_loss: 0.259087  g_loss: 3.163865\n",
      "batch 26  d_loss: 0.399633  g_loss: 2.429164\n",
      "batch 27  d_loss: 0.238075  g_loss: 2.120005\n",
      "batch 28  d_loss: 0.362009  g_loss: 2.061558\n",
      "batch 29  d_loss: 0.362416  g_loss: 1.558542\n",
      "batch 30  d_loss: 0.335458  g_loss: 1.859476\n",
      "batch 31  d_loss: 0.308684  g_loss: 1.646631\n",
      "batch 32  d_loss: 0.344465  g_loss: 2.227736\n",
      "batch 33  d_loss: 0.409364  g_loss: 2.006817\n",
      "batch 34  d_loss: 0.401025  g_loss: 2.151901\n",
      "batch 35  d_loss: 0.469979  g_loss: 1.248245\n",
      "batch 36  d_loss: 0.515119  g_loss: 1.072588\n",
      "batch 37  d_loss: 0.453087  g_loss: 1.225348\n",
      "batch 38  d_loss: 0.578632  g_loss: 1.400711\n",
      "batch 39  d_loss: 0.472042  g_loss: 2.051337\n",
      "batch 40  d_loss: 0.417206  g_loss: 2.014869\n",
      "batch 41  d_loss: 0.555084  g_loss: 1.894778\n",
      "batch 42  d_loss: 0.433733  g_loss: 1.529372\n",
      "batch 43  d_loss: 0.289599  g_loss: 1.758474\n",
      "batch 44  d_loss: 0.246883  g_loss: 1.962584\n",
      "batch 45  d_loss: 0.210080  g_loss: 2.088532\n",
      "Epoch is 35\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.193960  g_loss: 2.145164\n",
      "batch 1  d_loss: 0.252418  g_loss: 2.389416\n",
      "batch 2  d_loss: 0.249181  g_loss: 2.577795\n",
      "batch 3  d_loss: 0.185934  g_loss: 2.738811\n",
      "batch 4  d_loss: 0.324638  g_loss: 2.288293\n",
      "batch 5  d_loss: 0.340958  g_loss: 2.076885\n",
      "batch 6  d_loss: 0.130996  g_loss: 2.117271\n",
      "batch 7  d_loss: 0.697883  g_loss: 1.952419\n",
      "batch 8  d_loss: 0.497442  g_loss: 1.713415\n",
      "batch 9  d_loss: 0.164256  g_loss: 1.899306\n",
      "batch 10  d_loss: 0.337914  g_loss: 2.106375\n",
      "batch 11  d_loss: 0.387043  g_loss: 2.291924\n",
      "batch 12  d_loss: 0.560637  g_loss: 1.974638\n",
      "batch 13  d_loss: 0.320549  g_loss: 1.636561\n",
      "batch 14  d_loss: 0.359275  g_loss: 1.459290\n",
      "batch 15  d_loss: 0.411589  g_loss: 1.718748\n",
      "batch 16  d_loss: 0.278564  g_loss: 2.223511\n",
      "batch 17  d_loss: 0.356785  g_loss: 2.991058\n",
      "batch 18  d_loss: 0.184699  g_loss: 2.721368\n",
      "batch 19  d_loss: 0.287474  g_loss: 2.614148\n",
      "batch 20  d_loss: 0.253783  g_loss: 2.238268\n",
      "batch 21  d_loss: 0.221378  g_loss: 1.635518\n",
      "batch 22  d_loss: 0.370512  g_loss: 1.420568\n",
      "batch 23  d_loss: 0.348417  g_loss: 1.869567\n",
      "batch 24  d_loss: 0.387644  g_loss: 2.525955\n",
      "batch 25  d_loss: 0.388099  g_loss: 2.348457\n",
      "batch 26  d_loss: 0.462592  g_loss: 1.577968\n",
      "batch 27  d_loss: 0.273505  g_loss: 1.248733\n",
      "batch 28  d_loss: 0.349819  g_loss: 1.358518\n",
      "batch 29  d_loss: 0.373942  g_loss: 1.346979\n",
      "batch 30  d_loss: 0.341473  g_loss: 1.790529\n",
      "batch 31  d_loss: 0.369269  g_loss: 2.280831\n",
      "batch 32  d_loss: 0.448487  g_loss: 2.327567\n",
      "batch 33  d_loss: 0.544280  g_loss: 2.299475\n",
      "batch 34  d_loss: 0.508062  g_loss: 1.644697\n",
      "batch 35  d_loss: 0.476801  g_loss: 1.292380\n",
      "batch 36  d_loss: 0.529551  g_loss: 1.253587\n",
      "batch 37  d_loss: 0.510194  g_loss: 1.606622\n",
      "batch 38  d_loss: 0.439704  g_loss: 1.941599\n",
      "batch 39  d_loss: 0.416105  g_loss: 2.129340\n",
      "batch 40  d_loss: 0.378044  g_loss: 2.078053\n",
      "batch 41  d_loss: 0.423251  g_loss: 1.781816\n",
      "batch 42  d_loss: 0.354912  g_loss: 1.335755\n",
      "batch 43  d_loss: 0.255835  g_loss: 1.503235\n",
      "batch 44  d_loss: 0.278685  g_loss: 1.940832\n",
      "batch 45  d_loss: 0.209886  g_loss: 2.473319\n",
      "Epoch is 36\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.266800  g_loss: 2.573769\n",
      "batch 1  d_loss: 0.369261  g_loss: 1.932450\n",
      "batch 2  d_loss: 0.266127  g_loss: 1.720551\n",
      "batch 3  d_loss: 0.230929  g_loss: 1.789325\n",
      "batch 4  d_loss: 0.286542  g_loss: 1.871079\n",
      "batch 5  d_loss: 0.370633  g_loss: 2.028275\n",
      "batch 6  d_loss: 0.267557  g_loss: 2.665713\n",
      "batch 7  d_loss: 0.647893  g_loss: 2.505093\n",
      "batch 8  d_loss: 0.607361  g_loss: 2.588010\n",
      "batch 9  d_loss: 0.315927  g_loss: 1.971458\n",
      "batch 10  d_loss: 0.250249  g_loss: 1.918639\n",
      "batch 11  d_loss: 0.469436  g_loss: 2.049640\n",
      "batch 12  d_loss: 0.483655  g_loss: 1.602533\n",
      "batch 13  d_loss: 0.300968  g_loss: 1.138150\n",
      "batch 14  d_loss: 0.486852  g_loss: 1.391601\n",
      "batch 15  d_loss: 0.459206  g_loss: 2.022896\n",
      "batch 16  d_loss: 0.322696  g_loss: 2.132594\n",
      "batch 17  d_loss: 0.469290  g_loss: 2.051180\n",
      "batch 18  d_loss: 0.288531  g_loss: 1.699709\n",
      "batch 19  d_loss: 0.279784  g_loss: 1.812171\n",
      "batch 20  d_loss: 0.453890  g_loss: 2.024769\n",
      "batch 21  d_loss: 0.420635  g_loss: 1.417720\n",
      "batch 22  d_loss: 0.234592  g_loss: 1.704862\n",
      "batch 23  d_loss: 0.245773  g_loss: 1.826118\n",
      "batch 24  d_loss: 0.337216  g_loss: 2.243141\n",
      "batch 25  d_loss: 0.366028  g_loss: 2.147438\n",
      "batch 26  d_loss: 0.481343  g_loss: 1.772247\n",
      "batch 27  d_loss: 0.281361  g_loss: 1.107274\n",
      "batch 28  d_loss: 0.357139  g_loss: 1.469234\n",
      "batch 29  d_loss: 0.348038  g_loss: 1.539833\n",
      "batch 30  d_loss: 0.218785  g_loss: 2.204860\n",
      "batch 31  d_loss: 0.270846  g_loss: 2.842169\n",
      "batch 32  d_loss: 0.262900  g_loss: 2.830252\n",
      "batch 33  d_loss: 0.375888  g_loss: 2.544280\n",
      "batch 34  d_loss: 0.360428  g_loss: 2.027222\n",
      "batch 35  d_loss: 0.398704  g_loss: 1.220954\n",
      "batch 36  d_loss: 0.451843  g_loss: 1.161919\n",
      "batch 37  d_loss: 0.731585  g_loss: 1.352881\n",
      "batch 38  d_loss: 0.664089  g_loss: 2.122374\n",
      "batch 39  d_loss: 0.424849  g_loss: 3.067066\n",
      "batch 40  d_loss: 0.307522  g_loss: 3.305629\n",
      "batch 41  d_loss: 0.535135  g_loss: 2.402710\n",
      "batch 42  d_loss: 0.498810  g_loss: 1.180934\n",
      "batch 43  d_loss: 0.409096  g_loss: 1.013470\n",
      "batch 44  d_loss: 0.495445  g_loss: 1.336712\n",
      "batch 45  d_loss: 0.364716  g_loss: 2.030386\n",
      "Epoch is 37\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.298068  g_loss: 2.503653\n",
      "batch 1  d_loss: 0.494678  g_loss: 2.564415\n",
      "batch 2  d_loss: 0.338896  g_loss: 1.853939\n",
      "batch 3  d_loss: 0.318273  g_loss: 1.384699\n",
      "batch 4  d_loss: 0.370370  g_loss: 1.304066\n",
      "batch 5  d_loss: 0.351607  g_loss: 1.625165\n",
      "batch 6  d_loss: 0.305322  g_loss: 2.000392\n",
      "batch 7  d_loss: 0.400082  g_loss: 2.429105\n",
      "batch 8  d_loss: 0.288919  g_loss: 2.899055\n",
      "batch 9  d_loss: 0.436384  g_loss: 2.297252\n",
      "batch 10  d_loss: 0.375470  g_loss: 1.843039\n",
      "batch 11  d_loss: 0.390310  g_loss: 1.533239\n",
      "batch 12  d_loss: 0.416221  g_loss: 1.015611\n",
      "batch 13  d_loss: 0.383122  g_loss: 1.149480\n",
      "batch 14  d_loss: 0.459153  g_loss: 1.342202\n",
      "batch 15  d_loss: 0.438164  g_loss: 1.674399\n",
      "batch 16  d_loss: 0.325468  g_loss: 2.237244\n",
      "batch 17  d_loss: 0.413388  g_loss: 1.991909\n",
      "batch 18  d_loss: 0.320636  g_loss: 2.120222\n",
      "batch 19  d_loss: 0.305941  g_loss: 1.829607\n",
      "batch 20  d_loss: 0.408816  g_loss: 1.465777\n",
      "batch 21  d_loss: 0.303161  g_loss: 1.276733\n",
      "batch 22  d_loss: 0.388353  g_loss: 1.855638\n",
      "batch 23  d_loss: 0.235027  g_loss: 1.534171\n",
      "batch 24  d_loss: 0.326204  g_loss: 1.801255\n",
      "batch 25  d_loss: 0.387580  g_loss: 1.635680\n",
      "batch 26  d_loss: 0.420286  g_loss: 1.325234\n",
      "batch 27  d_loss: 0.307246  g_loss: 1.297803\n",
      "batch 28  d_loss: 0.476129  g_loss: 1.601161\n",
      "batch 29  d_loss: 0.460538  g_loss: 1.669767\n",
      "batch 30  d_loss: 0.334128  g_loss: 2.412971\n",
      "batch 31  d_loss: 0.409396  g_loss: 2.156672\n",
      "batch 32  d_loss: 0.378936  g_loss: 1.896799\n",
      "batch 33  d_loss: 0.535539  g_loss: 1.630469\n",
      "batch 34  d_loss: 0.423893  g_loss: 1.468692\n",
      "batch 35  d_loss: 0.500992  g_loss: 0.833883\n",
      "batch 36  d_loss: 0.608080  g_loss: 1.264555\n",
      "batch 37  d_loss: 0.594161  g_loss: 1.596700\n",
      "batch 38  d_loss: 0.515289  g_loss: 1.866083\n",
      "batch 39  d_loss: 0.414635  g_loss: 2.114562\n",
      "batch 40  d_loss: 0.411397  g_loss: 1.936566\n",
      "batch 41  d_loss: 0.516187  g_loss: 1.504511\n",
      "batch 42  d_loss: 0.403345  g_loss: 1.457698\n",
      "batch 43  d_loss: 0.333793  g_loss: 1.278096\n",
      "batch 44  d_loss: 0.413264  g_loss: 1.797569\n",
      "batch 45  d_loss: 0.258164  g_loss: 2.045820\n",
      "Epoch is 38\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.308092  g_loss: 2.317501\n",
      "batch 1  d_loss: 0.352633  g_loss: 2.499381\n",
      "batch 2  d_loss: 0.282824  g_loss: 1.733660\n",
      "batch 3  d_loss: 0.227440  g_loss: 1.843846\n",
      "batch 4  d_loss: 0.458596  g_loss: 1.643177\n",
      "batch 5  d_loss: 0.406876  g_loss: 1.812072\n",
      "batch 6  d_loss: 0.255714  g_loss: 2.542571\n",
      "batch 7  d_loss: 0.958275  g_loss: 2.393281\n",
      "batch 8  d_loss: 0.593285  g_loss: 2.351362\n",
      "batch 9  d_loss: 0.311921  g_loss: 1.729364\n",
      "batch 10  d_loss: 0.463960  g_loss: 1.491550\n",
      "batch 11  d_loss: 0.508453  g_loss: 1.593368\n",
      "batch 12  d_loss: 0.624805  g_loss: 1.610287\n",
      "batch 13  d_loss: 0.438018  g_loss: 1.621562\n",
      "batch 14  d_loss: 0.436807  g_loss: 1.971358\n",
      "batch 15  d_loss: 0.402118  g_loss: 2.052505\n",
      "batch 16  d_loss: 0.318709  g_loss: 2.076975\n",
      "batch 17  d_loss: 0.343188  g_loss: 2.509661\n",
      "batch 18  d_loss: 0.292238  g_loss: 1.958103\n",
      "batch 19  d_loss: 0.247808  g_loss: 2.223349\n",
      "batch 20  d_loss: 0.401148  g_loss: 1.848101\n",
      "batch 21  d_loss: 0.349551  g_loss: 1.540855\n",
      "batch 22  d_loss: 0.314116  g_loss: 1.582695\n",
      "batch 23  d_loss: 0.308782  g_loss: 1.892390\n",
      "batch 24  d_loss: 0.334036  g_loss: 2.079131\n",
      "batch 25  d_loss: 0.270575  g_loss: 2.268426\n",
      "batch 26  d_loss: 0.365055  g_loss: 2.078497\n",
      "batch 27  d_loss: 0.243759  g_loss: 1.757290\n",
      "batch 28  d_loss: 0.405434  g_loss: 1.488643\n",
      "batch 29  d_loss: 0.437682  g_loss: 1.474696\n",
      "batch 30  d_loss: 0.367491  g_loss: 2.129968\n",
      "batch 31  d_loss: 0.373784  g_loss: 2.174599\n",
      "batch 32  d_loss: 0.303130  g_loss: 2.177042\n",
      "batch 33  d_loss: 0.433887  g_loss: 2.243902\n",
      "batch 34  d_loss: 0.402540  g_loss: 1.864333\n",
      "batch 35  d_loss: 0.442880  g_loss: 1.505445\n",
      "batch 36  d_loss: 0.529513  g_loss: 1.079742\n",
      "batch 37  d_loss: 0.621374  g_loss: 1.337930\n",
      "batch 38  d_loss: 0.451210  g_loss: 1.507168\n",
      "batch 39  d_loss: 0.341198  g_loss: 2.073878\n",
      "batch 40  d_loss: 0.394600  g_loss: 2.078249\n",
      "batch 41  d_loss: 0.464226  g_loss: 2.007510\n",
      "batch 42  d_loss: 0.357569  g_loss: 1.999162\n",
      "batch 43  d_loss: 0.208538  g_loss: 1.919888\n",
      "batch 44  d_loss: 0.356847  g_loss: 1.159999\n",
      "batch 45  d_loss: 0.315781  g_loss: 1.412435\n",
      "Epoch is 39\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.479258  g_loss: 1.728065\n",
      "batch 1  d_loss: 0.408763  g_loss: 1.871698\n",
      "batch 2  d_loss: 0.404569  g_loss: 2.103835\n",
      "batch 3  d_loss: 0.297008  g_loss: 2.033709\n",
      "batch 4  d_loss: 0.379016  g_loss: 2.298014\n",
      "batch 5  d_loss: 0.344928  g_loss: 1.861485\n",
      "batch 6  d_loss: 0.206204  g_loss: 1.985816\n",
      "batch 7  d_loss: 0.631824  g_loss: 1.624706\n",
      "batch 8  d_loss: 0.467658  g_loss: 1.905848\n",
      "batch 9  d_loss: 0.276789  g_loss: 2.089931\n",
      "batch 10  d_loss: 0.326274  g_loss: 2.516234\n",
      "batch 11  d_loss: 0.452402  g_loss: 2.485706\n",
      "batch 12  d_loss: 0.543669  g_loss: 2.480307\n",
      "batch 13  d_loss: 0.461837  g_loss: 1.727678\n",
      "batch 14  d_loss: 0.447831  g_loss: 1.780552\n",
      "batch 15  d_loss: 0.328598  g_loss: 2.293849\n",
      "batch 16  d_loss: 0.221564  g_loss: 2.160149\n",
      "batch 17  d_loss: 0.385714  g_loss: 2.178106\n",
      "batch 18  d_loss: 0.274975  g_loss: 2.253643\n",
      "batch 19  d_loss: 0.328391  g_loss: 2.104142\n",
      "batch 20  d_loss: 0.411050  g_loss: 1.546308\n",
      "batch 21  d_loss: 0.406474  g_loss: 1.471442\n",
      "batch 22  d_loss: 0.256979  g_loss: 1.484915\n",
      "batch 23  d_loss: 0.303474  g_loss: 1.542490\n",
      "batch 24  d_loss: 0.327952  g_loss: 2.475475\n",
      "batch 25  d_loss: 0.356910  g_loss: 2.706378\n",
      "batch 26  d_loss: 0.558096  g_loss: 1.836109\n",
      "batch 27  d_loss: 0.276336  g_loss: 1.202969\n",
      "batch 28  d_loss: 0.392338  g_loss: 0.907318\n",
      "batch 29  d_loss: 0.519710  g_loss: 1.086040\n",
      "batch 30  d_loss: 0.461969  g_loss: 2.528154\n",
      "batch 31  d_loss: 0.367750  g_loss: 2.947842\n",
      "batch 32  d_loss: 0.410211  g_loss: 3.190461\n",
      "batch 33  d_loss: 0.493064  g_loss: 2.110459\n",
      "batch 34  d_loss: 0.520949  g_loss: 1.151096\n",
      "batch 35  d_loss: 0.408126  g_loss: 0.866612\n",
      "batch 36  d_loss: 0.527433  g_loss: 0.942422\n",
      "batch 37  d_loss: 0.643505  g_loss: 1.128164\n",
      "batch 38  d_loss: 0.461258  g_loss: 2.014397\n",
      "batch 39  d_loss: 0.419267  g_loss: 2.440520\n",
      "batch 40  d_loss: 0.343131  g_loss: 2.310203\n",
      "batch 41  d_loss: 0.390182  g_loss: 1.731685\n",
      "batch 42  d_loss: 0.432801  g_loss: 1.435652\n",
      "batch 43  d_loss: 0.321181  g_loss: 1.450525\n",
      "batch 44  d_loss: 0.349420  g_loss: 1.124291\n",
      "batch 45  d_loss: 0.340069  g_loss: 1.611267\n",
      "Epoch is 40\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.337063  g_loss: 1.651226\n",
      "batch 1  d_loss: 0.448710  g_loss: 2.404438\n",
      "batch 2  d_loss: 0.332850  g_loss: 2.557680\n",
      "batch 3  d_loss: 0.285581  g_loss: 2.190528\n",
      "batch 4  d_loss: 0.425678  g_loss: 1.705541\n",
      "batch 5  d_loss: 0.332527  g_loss: 1.515823\n",
      "batch 6  d_loss: 0.357596  g_loss: 1.230676\n",
      "batch 7  d_loss: 0.632292  g_loss: 1.297674\n",
      "batch 8  d_loss: 0.399492  g_loss: 1.475805\n",
      "batch 9  d_loss: 0.321001  g_loss: 1.929078\n",
      "batch 10  d_loss: 0.302102  g_loss: 2.177061\n",
      "batch 11  d_loss: 0.421547  g_loss: 2.399393\n",
      "batch 12  d_loss: 0.529103  g_loss: 1.901109\n",
      "batch 13  d_loss: 0.361465  g_loss: 1.394292\n",
      "batch 14  d_loss: 0.340525  g_loss: 1.235043\n",
      "batch 15  d_loss: 0.383269  g_loss: 1.212240\n",
      "batch 16  d_loss: 0.468126  g_loss: 1.121002\n",
      "batch 17  d_loss: 0.348363  g_loss: 1.788449\n",
      "batch 18  d_loss: 0.316471  g_loss: 2.060869\n",
      "batch 19  d_loss: 0.325968  g_loss: 2.133203\n",
      "batch 20  d_loss: 0.468562  g_loss: 1.452116\n",
      "batch 21  d_loss: 0.297714  g_loss: 1.347893\n",
      "batch 22  d_loss: 0.413829  g_loss: 1.439854\n",
      "batch 23  d_loss: 0.344310  g_loss: 2.005605\n",
      "batch 24  d_loss: 0.416742  g_loss: 2.229471\n",
      "batch 25  d_loss: 0.327931  g_loss: 1.920111\n",
      "batch 26  d_loss: 0.452094  g_loss: 1.801033\n",
      "batch 27  d_loss: 0.376886  g_loss: 1.369361\n",
      "batch 28  d_loss: 0.569815  g_loss: 1.657748\n",
      "batch 29  d_loss: 0.482437  g_loss: 1.469008\n",
      "batch 30  d_loss: 0.374155  g_loss: 1.704359\n",
      "batch 31  d_loss: 0.329855  g_loss: 1.889050\n",
      "batch 32  d_loss: 0.331348  g_loss: 1.990163\n",
      "batch 33  d_loss: 0.405212  g_loss: 2.085382\n",
      "batch 34  d_loss: 0.578090  g_loss: 1.497396\n",
      "batch 35  d_loss: 0.569653  g_loss: 0.967372\n",
      "batch 36  d_loss: 0.501453  g_loss: 0.708054\n",
      "batch 37  d_loss: 0.563630  g_loss: 0.872478\n",
      "batch 38  d_loss: 0.421054  g_loss: 1.749704\n",
      "batch 39  d_loss: 0.462713  g_loss: 2.189134\n",
      "batch 40  d_loss: 0.419294  g_loss: 2.229379\n",
      "batch 41  d_loss: 0.472176  g_loss: 2.168532\n",
      "batch 42  d_loss: 0.407581  g_loss: 1.778058\n",
      "batch 43  d_loss: 0.345154  g_loss: 1.389421\n",
      "batch 44  d_loss: 0.302854  g_loss: 1.236800\n",
      "batch 45  d_loss: 0.321738  g_loss: 1.601476\n",
      "Epoch is 41\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.372129  g_loss: 2.193768\n",
      "batch 1  d_loss: 0.303352  g_loss: 2.231191\n",
      "batch 2  d_loss: 0.292395  g_loss: 2.344002\n",
      "batch 3  d_loss: 0.274501  g_loss: 2.050186\n",
      "batch 4  d_loss: 0.464329  g_loss: 1.833757\n",
      "batch 5  d_loss: 0.442399  g_loss: 1.688173\n",
      "batch 6  d_loss: 0.301792  g_loss: 1.772354\n",
      "batch 7  d_loss: 0.679129  g_loss: 2.134238\n",
      "batch 8  d_loss: 0.414423  g_loss: 2.266751\n",
      "batch 9  d_loss: 0.279203  g_loss: 2.850953\n",
      "batch 10  d_loss: 0.600296  g_loss: 2.362805\n",
      "batch 11  d_loss: 0.455290  g_loss: 1.872236\n",
      "batch 12  d_loss: 0.493048  g_loss: 1.370029\n",
      "batch 13  d_loss: 0.383636  g_loss: 1.298043\n",
      "batch 14  d_loss: 0.482178  g_loss: 1.426408\n",
      "batch 15  d_loss: 0.347553  g_loss: 1.478589\n",
      "batch 16  d_loss: 0.333781  g_loss: 1.687617\n",
      "batch 17  d_loss: 0.315234  g_loss: 2.049729\n",
      "batch 18  d_loss: 0.318445  g_loss: 2.468769\n",
      "batch 19  d_loss: 0.363118  g_loss: 2.290310\n",
      "batch 20  d_loss: 0.323705  g_loss: 1.606455\n",
      "batch 21  d_loss: 0.314338  g_loss: 1.269294\n",
      "batch 22  d_loss: 0.349796  g_loss: 1.237912\n",
      "batch 23  d_loss: 0.299773  g_loss: 1.344293\n",
      "batch 24  d_loss: 0.265167  g_loss: 2.234179\n",
      "batch 25  d_loss: 0.257692  g_loss: 2.013380\n",
      "batch 26  d_loss: 0.347960  g_loss: 2.363778\n",
      "batch 27  d_loss: 0.236540  g_loss: 2.922256\n",
      "batch 28  d_loss: 0.522674  g_loss: 2.275009\n",
      "batch 29  d_loss: 0.527139  g_loss: 1.480724\n",
      "batch 30  d_loss: 0.397264  g_loss: 1.267976\n",
      "batch 31  d_loss: 0.374437  g_loss: 1.387403\n",
      "batch 32  d_loss: 0.395891  g_loss: 1.640892\n",
      "batch 33  d_loss: 0.455861  g_loss: 2.433979\n",
      "batch 34  d_loss: 0.555407  g_loss: 2.600764\n",
      "batch 35  d_loss: 0.670866  g_loss: 2.343297\n",
      "batch 36  d_loss: 0.618472  g_loss: 2.008088\n",
      "batch 37  d_loss: 0.603508  g_loss: 1.249407\n",
      "batch 38  d_loss: 0.410447  g_loss: 0.860424\n",
      "batch 39  d_loss: 0.587591  g_loss: 1.248517\n",
      "batch 40  d_loss: 0.335824  g_loss: 1.796691\n",
      "batch 41  d_loss: 0.406176  g_loss: 2.428138\n",
      "batch 42  d_loss: 0.462616  g_loss: 2.437604\n",
      "batch 43  d_loss: 0.436591  g_loss: 2.342884\n",
      "batch 44  d_loss: 0.463138  g_loss: 1.853497\n",
      "batch 45  d_loss: 0.345217  g_loss: 1.415907\n",
      "Epoch is 42\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.435729  g_loss: 1.244520\n",
      "batch 1  d_loss: 0.395493  g_loss: 1.184770\n",
      "batch 2  d_loss: 0.375584  g_loss: 1.501058\n",
      "batch 3  d_loss: 0.268533  g_loss: 1.924330\n",
      "batch 4  d_loss: 0.360506  g_loss: 2.256827\n",
      "batch 5  d_loss: 0.375334  g_loss: 2.344093\n",
      "batch 6  d_loss: 0.331159  g_loss: 1.876458\n",
      "batch 7  d_loss: 0.519250  g_loss: 1.599599\n",
      "batch 8  d_loss: 0.428934  g_loss: 1.723306\n",
      "batch 9  d_loss: 0.328791  g_loss: 1.643776\n",
      "batch 10  d_loss: 0.243617  g_loss: 1.676381\n",
      "batch 11  d_loss: 0.395980  g_loss: 1.742494\n",
      "batch 12  d_loss: 0.379565  g_loss: 1.898578\n",
      "batch 13  d_loss: 0.324648  g_loss: 1.854549\n",
      "batch 14  d_loss: 0.369185  g_loss: 1.895839\n",
      "batch 15  d_loss: 0.394461  g_loss: 1.596200\n",
      "batch 16  d_loss: 0.265181  g_loss: 1.744080\n",
      "batch 17  d_loss: 0.449027  g_loss: 1.515608\n",
      "batch 18  d_loss: 0.291149  g_loss: 1.671771\n",
      "batch 19  d_loss: 0.320229  g_loss: 1.588365\n",
      "batch 20  d_loss: 0.384826  g_loss: 1.712857\n",
      "batch 21  d_loss: 0.298794  g_loss: 1.626042\n",
      "batch 22  d_loss: 0.327034  g_loss: 1.750680\n",
      "batch 23  d_loss: 0.278972  g_loss: 1.753801\n",
      "batch 24  d_loss: 0.299620  g_loss: 2.068271\n",
      "batch 25  d_loss: 0.229351  g_loss: 2.049068\n",
      "batch 26  d_loss: 0.354159  g_loss: 2.196437\n",
      "batch 27  d_loss: 0.247239  g_loss: 1.918781\n",
      "batch 28  d_loss: 0.391544  g_loss: 2.081579\n",
      "batch 29  d_loss: 0.415246  g_loss: 1.639969\n",
      "batch 30  d_loss: 0.341497  g_loss: 1.731462\n",
      "batch 31  d_loss: 0.343083  g_loss: 1.758329\n",
      "batch 32  d_loss: 0.302006  g_loss: 2.045727\n",
      "batch 33  d_loss: 0.403224  g_loss: 2.167160\n",
      "batch 34  d_loss: 0.543835  g_loss: 1.797070\n",
      "batch 35  d_loss: 0.434561  g_loss: 1.529490\n",
      "batch 36  d_loss: 0.653840  g_loss: 1.254812\n",
      "batch 37  d_loss: 0.736727  g_loss: 1.205117\n",
      "batch 38  d_loss: 0.574791  g_loss: 1.463428\n",
      "batch 39  d_loss: 0.452351  g_loss: 1.842766\n",
      "batch 40  d_loss: 0.263214  g_loss: 2.403925\n",
      "batch 41  d_loss: 0.358013  g_loss: 2.549139\n",
      "batch 42  d_loss: 0.360656  g_loss: 2.571849\n",
      "batch 43  d_loss: 0.282791  g_loss: 1.962514\n",
      "batch 44  d_loss: 0.349279  g_loss: 1.454009\n",
      "batch 45  d_loss: 0.330319  g_loss: 0.907517\n",
      "Epoch is 43\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.376193  g_loss: 1.143822\n",
      "batch 1  d_loss: 0.381984  g_loss: 1.295013\n",
      "batch 2  d_loss: 0.364989  g_loss: 1.892750\n",
      "batch 3  d_loss: 0.308915  g_loss: 2.222067\n",
      "batch 4  d_loss: 0.404396  g_loss: 2.109433\n",
      "batch 5  d_loss: 0.324395  g_loss: 1.970749\n",
      "batch 6  d_loss: 0.319328  g_loss: 1.739991\n",
      "batch 7  d_loss: 0.410649  g_loss: 1.531874\n",
      "batch 8  d_loss: 0.378919  g_loss: 1.527048\n",
      "batch 9  d_loss: 0.264097  g_loss: 1.362851\n",
      "batch 10  d_loss: 0.348409  g_loss: 1.380166\n",
      "batch 11  d_loss: 0.441115  g_loss: 1.971118\n",
      "batch 12  d_loss: 0.438525  g_loss: 2.145928\n",
      "batch 13  d_loss: 0.372585  g_loss: 1.916376\n",
      "batch 14  d_loss: 0.353321  g_loss: 1.916040\n",
      "batch 15  d_loss: 0.407541  g_loss: 1.792978\n",
      "batch 16  d_loss: 0.335114  g_loss: 1.771569\n",
      "batch 17  d_loss: 0.331799  g_loss: 1.930279\n",
      "batch 18  d_loss: 0.229539  g_loss: 2.172332\n",
      "batch 19  d_loss: 0.308265  g_loss: 2.434048\n",
      "batch 20  d_loss: 0.352018  g_loss: 2.274630\n",
      "batch 21  d_loss: 0.315367  g_loss: 2.316386\n",
      "batch 22  d_loss: 0.288808  g_loss: 2.011083\n",
      "batch 23  d_loss: 0.243678  g_loss: 2.038016\n",
      "batch 24  d_loss: 0.295017  g_loss: 1.702382\n",
      "batch 25  d_loss: 0.344552  g_loss: 1.669854\n",
      "batch 26  d_loss: 0.326916  g_loss: 1.451772\n",
      "batch 27  d_loss: 0.228229  g_loss: 1.643028\n",
      "batch 28  d_loss: 0.394375  g_loss: 1.692175\n",
      "batch 29  d_loss: 0.402609  g_loss: 1.967170\n",
      "batch 30  d_loss: 0.358287  g_loss: 1.846415\n",
      "batch 31  d_loss: 0.400637  g_loss: 1.813140\n",
      "batch 32  d_loss: 0.394375  g_loss: 1.792291\n",
      "batch 33  d_loss: 0.362634  g_loss: 1.835742\n",
      "batch 34  d_loss: 0.441157  g_loss: 1.440488\n",
      "batch 35  d_loss: 0.518844  g_loss: 1.108954\n",
      "batch 36  d_loss: 0.386875  g_loss: 1.077632\n",
      "batch 37  d_loss: 0.361987  g_loss: 0.920862\n",
      "batch 38  d_loss: 0.518776  g_loss: 1.324469\n",
      "batch 39  d_loss: 0.403935  g_loss: 2.037219\n",
      "batch 40  d_loss: 0.283250  g_loss: 2.331289\n",
      "batch 41  d_loss: 0.456757  g_loss: 2.278332\n",
      "batch 42  d_loss: 0.321892  g_loss: 2.006244\n",
      "batch 43  d_loss: 0.239050  g_loss: 1.859382\n",
      "batch 44  d_loss: 0.301762  g_loss: 1.266205\n",
      "batch 45  d_loss: 0.276756  g_loss: 1.719902\n",
      "Epoch is 44\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.354256  g_loss: 1.884461\n",
      "batch 1  d_loss: 0.201333  g_loss: 2.359064\n",
      "batch 2  d_loss: 0.244252  g_loss: 2.742499\n",
      "batch 3  d_loss: 0.263695  g_loss: 3.150767\n",
      "batch 4  d_loss: 0.383828  g_loss: 2.309615\n",
      "batch 5  d_loss: 0.306611  g_loss: 1.924458\n",
      "batch 6  d_loss: 0.259318  g_loss: 1.874861\n",
      "batch 7  d_loss: 0.657370  g_loss: 1.853894\n",
      "batch 8  d_loss: 0.470340  g_loss: 2.014234\n",
      "batch 9  d_loss: 0.258633  g_loss: 2.228213\n",
      "batch 10  d_loss: 0.355185  g_loss: 2.400827\n",
      "batch 11  d_loss: 0.498086  g_loss: 2.660717\n",
      "batch 12  d_loss: 0.738025  g_loss: 1.676404\n",
      "batch 13  d_loss: 0.319972  g_loss: 1.517572\n",
      "batch 14  d_loss: 0.363038  g_loss: 1.346259\n",
      "batch 15  d_loss: 0.381919  g_loss: 1.382551\n",
      "batch 16  d_loss: 0.276603  g_loss: 1.641674\n",
      "batch 17  d_loss: 0.297032  g_loss: 1.984370\n",
      "batch 18  d_loss: 0.259341  g_loss: 2.709691\n",
      "batch 19  d_loss: 0.272318  g_loss: 2.898221\n",
      "batch 20  d_loss: 0.419374  g_loss: 2.619518\n",
      "batch 21  d_loss: 0.251942  g_loss: 2.033018\n",
      "batch 22  d_loss: 0.267743  g_loss: 1.350649\n",
      "batch 23  d_loss: 0.280821  g_loss: 1.853183\n",
      "batch 24  d_loss: 0.268003  g_loss: 1.842439\n",
      "batch 25  d_loss: 0.251177  g_loss: 2.045870\n",
      "batch 26  d_loss: 0.263475  g_loss: 2.234401\n",
      "batch 27  d_loss: 0.322914  g_loss: 2.430067\n",
      "batch 28  d_loss: 0.381410  g_loss: 1.831779\n",
      "batch 29  d_loss: 0.443305  g_loss: 1.742868\n",
      "batch 30  d_loss: 0.321607  g_loss: 1.394503\n",
      "batch 31  d_loss: 0.338539  g_loss: 1.486505\n",
      "batch 32  d_loss: 0.490088  g_loss: 1.699607\n",
      "batch 33  d_loss: 0.352498  g_loss: 2.035391\n",
      "batch 34  d_loss: 0.527280  g_loss: 2.231674\n",
      "batch 35  d_loss: 0.533446  g_loss: 2.279408\n",
      "batch 36  d_loss: 0.493399  g_loss: 1.904380\n",
      "batch 37  d_loss: 0.425156  g_loss: 1.269273\n",
      "batch 38  d_loss: 0.594656  g_loss: 1.418428\n",
      "batch 39  d_loss: 0.527049  g_loss: 1.111482\n",
      "batch 40  d_loss: 0.532065  g_loss: 1.826839\n",
      "batch 41  d_loss: 0.417185  g_loss: 1.834544\n",
      "batch 42  d_loss: 0.373417  g_loss: 2.212868\n",
      "batch 43  d_loss: 0.330422  g_loss: 1.866808\n",
      "batch 44  d_loss: 0.476143  g_loss: 1.487993\n",
      "batch 45  d_loss: 0.390400  g_loss: 1.442344\n",
      "Epoch is 45\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.381089  g_loss: 1.460901\n",
      "batch 1  d_loss: 0.311409  g_loss: 1.857833\n",
      "batch 2  d_loss: 0.279107  g_loss: 1.584039\n",
      "batch 3  d_loss: 0.324341  g_loss: 2.334026\n",
      "batch 4  d_loss: 0.367533  g_loss: 2.311305\n",
      "batch 5  d_loss: 0.335474  g_loss: 2.416679\n",
      "batch 6  d_loss: 0.232150  g_loss: 1.964213\n",
      "batch 7  d_loss: 0.441213  g_loss: 2.000332\n",
      "batch 8  d_loss: 0.389696  g_loss: 1.612220\n",
      "batch 9  d_loss: 0.307075  g_loss: 1.868174\n",
      "batch 10  d_loss: 0.292688  g_loss: 1.879215\n",
      "batch 11  d_loss: 0.407689  g_loss: 2.286197\n",
      "batch 12  d_loss: 0.490913  g_loss: 1.994037\n",
      "batch 13  d_loss: 0.266974  g_loss: 1.771411\n",
      "batch 14  d_loss: 0.339752  g_loss: 1.482853\n",
      "batch 15  d_loss: 0.468104  g_loss: 1.832808\n",
      "batch 16  d_loss: 0.346221  g_loss: 1.842309\n",
      "batch 17  d_loss: 0.331473  g_loss: 2.120728\n",
      "batch 18  d_loss: 0.251849  g_loss: 2.401339\n",
      "batch 19  d_loss: 0.277642  g_loss: 2.491876\n",
      "batch 20  d_loss: 0.447833  g_loss: 1.825701\n",
      "batch 21  d_loss: 0.365351  g_loss: 1.568221\n",
      "batch 22  d_loss: 0.477093  g_loss: 1.246578\n",
      "batch 23  d_loss: 0.324705  g_loss: 1.822123\n",
      "batch 24  d_loss: 0.289586  g_loss: 2.224772\n",
      "batch 25  d_loss: 0.329704  g_loss: 2.339583\n",
      "batch 26  d_loss: 0.443687  g_loss: 2.287773\n",
      "batch 27  d_loss: 0.305950  g_loss: 1.912368\n",
      "batch 28  d_loss: 0.342585  g_loss: 1.520035\n",
      "batch 29  d_loss: 0.310782  g_loss: 1.402831\n",
      "batch 30  d_loss: 0.284005  g_loss: 1.334251\n",
      "batch 31  d_loss: 0.298408  g_loss: 1.781573\n",
      "batch 32  d_loss: 0.317160  g_loss: 2.091314\n",
      "batch 33  d_loss: 0.358694  g_loss: 2.713699\n",
      "batch 34  d_loss: 0.378154  g_loss: 2.306130\n",
      "batch 35  d_loss: 0.306600  g_loss: 2.049587\n",
      "batch 36  d_loss: 0.428238  g_loss: 1.726308\n",
      "batch 37  d_loss: 0.447341  g_loss: 1.254448\n",
      "batch 38  d_loss: 0.404156  g_loss: 1.046210\n",
      "batch 39  d_loss: 0.396752  g_loss: 1.286582\n",
      "batch 40  d_loss: 0.359744  g_loss: 1.793121\n",
      "batch 41  d_loss: 0.282992  g_loss: 2.514007\n",
      "batch 42  d_loss: 0.397370  g_loss: 2.604731\n",
      "batch 43  d_loss: 0.334693  g_loss: 2.567978\n",
      "batch 44  d_loss: 0.362549  g_loss: 2.116935\n",
      "batch 45  d_loss: 0.241795  g_loss: 1.716988\n",
      "Epoch is 46\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.297110  g_loss: 1.291958\n",
      "batch 1  d_loss: 0.306850  g_loss: 1.258217\n",
      "batch 2  d_loss: 0.322533  g_loss: 1.372902\n",
      "batch 3  d_loss: 0.313194  g_loss: 1.992326\n",
      "batch 4  d_loss: 0.385423  g_loss: 2.535971\n",
      "batch 5  d_loss: 0.418282  g_loss: 2.412758\n",
      "batch 6  d_loss: 0.301944  g_loss: 2.395090\n",
      "batch 7  d_loss: 0.457339  g_loss: 2.027904\n",
      "batch 8  d_loss: 0.384542  g_loss: 1.894180\n",
      "batch 9  d_loss: 0.276884  g_loss: 1.831645\n",
      "batch 10  d_loss: 0.324928  g_loss: 1.878370\n",
      "batch 11  d_loss: 0.408473  g_loss: 1.836332\n",
      "batch 12  d_loss: 0.455024  g_loss: 1.654866\n",
      "batch 13  d_loss: 0.314339  g_loss: 1.511252\n",
      "batch 14  d_loss: 0.401254  g_loss: 1.682055\n",
      "batch 15  d_loss: 0.341437  g_loss: 1.738047\n",
      "batch 16  d_loss: 0.314237  g_loss: 1.926681\n",
      "batch 17  d_loss: 0.368090  g_loss: 1.855829\n",
      "batch 18  d_loss: 0.272269  g_loss: 2.313539\n",
      "batch 19  d_loss: 0.329269  g_loss: 2.503617\n",
      "batch 20  d_loss: 0.439412  g_loss: 2.284933\n",
      "batch 21  d_loss: 0.374744  g_loss: 1.645323\n",
      "batch 22  d_loss: 0.303582  g_loss: 1.335749\n",
      "batch 23  d_loss: 0.296478  g_loss: 1.537715\n",
      "batch 24  d_loss: 0.316659  g_loss: 1.616658\n",
      "batch 25  d_loss: 0.305911  g_loss: 1.760350\n",
      "batch 26  d_loss: 0.342848  g_loss: 2.299982\n",
      "batch 27  d_loss: 0.339285  g_loss: 2.101343\n",
      "batch 28  d_loss: 0.312009  g_loss: 1.758675\n",
      "batch 29  d_loss: 0.346362  g_loss: 2.092081\n",
      "batch 30  d_loss: 0.235671  g_loss: 2.136009\n",
      "batch 31  d_loss: 0.341123  g_loss: 1.747700\n",
      "batch 32  d_loss: 0.310777  g_loss: 2.092456\n",
      "batch 33  d_loss: 0.360011  g_loss: 1.801107\n",
      "batch 34  d_loss: 0.478269  g_loss: 1.726004\n",
      "batch 35  d_loss: 0.411599  g_loss: 1.487664\n",
      "batch 36  d_loss: 0.511859  g_loss: 1.373291\n",
      "batch 37  d_loss: 0.434116  g_loss: 1.520702\n",
      "batch 38  d_loss: 0.425300  g_loss: 1.610801\n",
      "batch 39  d_loss: 0.385187  g_loss: 1.877425\n",
      "batch 40  d_loss: 0.286128  g_loss: 1.955700\n",
      "batch 41  d_loss: 0.392279  g_loss: 2.163821\n",
      "batch 42  d_loss: 0.352499  g_loss: 2.322587\n",
      "batch 43  d_loss: 0.306332  g_loss: 1.924647\n",
      "batch 44  d_loss: 0.429611  g_loss: 1.981411\n",
      "batch 45  d_loss: 0.308091  g_loss: 1.581452\n",
      "Epoch is 47\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.330369  g_loss: 1.600907\n",
      "batch 1  d_loss: 0.332761  g_loss: 1.290914\n",
      "batch 2  d_loss: 0.264752  g_loss: 1.369227\n",
      "batch 3  d_loss: 0.295478  g_loss: 2.000784\n",
      "batch 4  d_loss: 0.369125  g_loss: 1.929387\n",
      "batch 5  d_loss: 0.420528  g_loss: 2.264524\n",
      "batch 6  d_loss: 0.234612  g_loss: 2.822004\n",
      "batch 7  d_loss: 0.615740  g_loss: 2.184242\n",
      "batch 8  d_loss: 0.466097  g_loss: 1.989157\n",
      "batch 9  d_loss: 0.232028  g_loss: 1.737907\n",
      "batch 10  d_loss: 0.363579  g_loss: 1.734537\n",
      "batch 11  d_loss: 0.536971  g_loss: 1.927620\n",
      "batch 12  d_loss: 0.503802  g_loss: 1.596960\n",
      "batch 13  d_loss: 0.315039  g_loss: 1.566481\n",
      "batch 14  d_loss: 0.334034  g_loss: 1.808693\n",
      "batch 15  d_loss: 0.387537  g_loss: 1.620383\n",
      "batch 16  d_loss: 0.320869  g_loss: 1.890214\n",
      "batch 17  d_loss: 0.386290  g_loss: 1.883593\n",
      "batch 18  d_loss: 0.233761  g_loss: 2.640987\n",
      "batch 19  d_loss: 0.276192  g_loss: 2.532309\n",
      "batch 20  d_loss: 0.355083  g_loss: 2.434148\n",
      "batch 21  d_loss: 0.292190  g_loss: 1.876327\n",
      "batch 22  d_loss: 0.271523  g_loss: 1.721875\n",
      "batch 23  d_loss: 0.258024  g_loss: 2.416359\n",
      "batch 24  d_loss: 0.225479  g_loss: 2.175922\n",
      "batch 25  d_loss: 0.231537  g_loss: 2.025936\n",
      "batch 26  d_loss: 0.305984  g_loss: 2.437467\n",
      "batch 27  d_loss: 0.188703  g_loss: 3.024636\n",
      "batch 28  d_loss: 0.471862  g_loss: 2.598697\n",
      "batch 29  d_loss: 0.591851  g_loss: 1.882678\n",
      "batch 30  d_loss: 0.271017  g_loss: 1.390139\n",
      "batch 31  d_loss: 0.322050  g_loss: 1.460262\n",
      "batch 32  d_loss: 0.468507  g_loss: 1.779326\n",
      "batch 33  d_loss: 0.483794  g_loss: 2.717025\n",
      "batch 34  d_loss: 0.540327  g_loss: 2.635445\n",
      "batch 35  d_loss: 0.519629  g_loss: 1.834902\n",
      "batch 36  d_loss: 0.616118  g_loss: 1.544342\n",
      "batch 37  d_loss: 0.534412  g_loss: 0.920656\n",
      "batch 38  d_loss: 0.630950  g_loss: 0.829442\n",
      "batch 39  d_loss: 0.354938  g_loss: 1.672677\n",
      "batch 40  d_loss: 0.424886  g_loss: 2.304255\n",
      "batch 41  d_loss: 0.377499  g_loss: 2.584439\n",
      "batch 42  d_loss: 0.431223  g_loss: 2.157605\n",
      "batch 43  d_loss: 0.403643  g_loss: 1.719912\n",
      "batch 44  d_loss: 0.398355  g_loss: 1.479977\n",
      "batch 45  d_loss: 0.352366  g_loss: 1.543278\n",
      "Epoch is 48\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.349159  g_loss: 1.729136\n",
      "batch 1  d_loss: 0.322493  g_loss: 1.681486\n",
      "batch 2  d_loss: 0.296244  g_loss: 2.231985\n",
      "batch 3  d_loss: 0.293122  g_loss: 2.184210\n",
      "batch 4  d_loss: 0.449984  g_loss: 2.155806\n",
      "batch 5  d_loss: 0.341410  g_loss: 2.103851\n",
      "batch 6  d_loss: 0.232651  g_loss: 1.893996\n",
      "batch 7  d_loss: 0.432600  g_loss: 2.002974\n",
      "batch 8  d_loss: 0.395662  g_loss: 2.128581\n",
      "batch 9  d_loss: 0.320615  g_loss: 2.559687\n",
      "batch 10  d_loss: 0.347328  g_loss: 2.537220\n",
      "batch 11  d_loss: 0.435723  g_loss: 2.373284\n",
      "batch 12  d_loss: 0.452924  g_loss: 1.709908\n",
      "batch 13  d_loss: 0.339464  g_loss: 1.266893\n",
      "batch 14  d_loss: 0.518255  g_loss: 1.145737\n",
      "batch 15  d_loss: 0.395606  g_loss: 1.087271\n",
      "batch 16  d_loss: 0.323790  g_loss: 1.397152\n",
      "batch 17  d_loss: 0.609398  g_loss: 2.089937\n",
      "batch 18  d_loss: 0.319425  g_loss: 2.962411\n",
      "batch 19  d_loss: 0.423497  g_loss: 2.549269\n",
      "batch 20  d_loss: 0.422183  g_loss: 2.124193\n",
      "batch 21  d_loss: 0.304470  g_loss: 1.710125\n",
      "batch 22  d_loss: 0.333405  g_loss: 1.565729\n",
      "batch 23  d_loss: 0.281422  g_loss: 1.224074\n",
      "batch 24  d_loss: 0.323057  g_loss: 1.474694\n",
      "batch 25  d_loss: 0.325886  g_loss: 1.483669\n",
      "batch 26  d_loss: 0.392171  g_loss: 2.104572\n",
      "batch 27  d_loss: 0.260557  g_loss: 2.297441\n",
      "batch 28  d_loss: 0.402417  g_loss: 2.255054\n",
      "batch 29  d_loss: 0.527660  g_loss: 1.929451\n",
      "batch 30  d_loss: 0.403036  g_loss: 1.774910\n",
      "batch 31  d_loss: 0.399851  g_loss: 1.290354\n",
      "batch 32  d_loss: 0.414624  g_loss: 1.424037\n",
      "batch 33  d_loss: 0.393555  g_loss: 1.387264\n",
      "batch 34  d_loss: 0.412016  g_loss: 1.507301\n",
      "batch 35  d_loss: 0.428008  g_loss: 1.665796\n",
      "batch 36  d_loss: 0.431029  g_loss: 2.066098\n",
      "batch 37  d_loss: 0.454047  g_loss: 2.080405\n",
      "batch 38  d_loss: 0.406964  g_loss: 1.794149\n",
      "batch 39  d_loss: 0.289227  g_loss: 1.689845\n",
      "batch 40  d_loss: 0.259992  g_loss: 1.589499\n",
      "batch 41  d_loss: 0.244444  g_loss: 1.274960\n",
      "batch 42  d_loss: 0.367931  g_loss: 1.849940\n",
      "batch 43  d_loss: 0.276941  g_loss: 1.858458\n",
      "batch 44  d_loss: 0.260158  g_loss: 2.240226\n",
      "batch 45  d_loss: 0.296761  g_loss: 2.214321\n",
      "Epoch is 49\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.403292  g_loss: 2.750850\n",
      "batch 1  d_loss: 0.370597  g_loss: 2.355764\n",
      "batch 2  d_loss: 0.262999  g_loss: 1.937058\n",
      "batch 3  d_loss: 0.253968  g_loss: 1.628261\n",
      "batch 4  d_loss: 0.348247  g_loss: 2.068711\n",
      "batch 5  d_loss: 0.258338  g_loss: 1.956247\n",
      "batch 6  d_loss: 0.193699  g_loss: 2.074408\n",
      "batch 7  d_loss: 0.616205  g_loss: 2.212878\n",
      "batch 8  d_loss: 0.434067  g_loss: 1.945850\n",
      "batch 9  d_loss: 0.221702  g_loss: 1.950686\n",
      "batch 10  d_loss: 0.239110  g_loss: 2.288216\n",
      "batch 11  d_loss: 0.469059  g_loss: 1.999768\n",
      "batch 12  d_loss: 0.479423  g_loss: 2.439430\n",
      "batch 13  d_loss: 0.337320  g_loss: 1.940912\n",
      "batch 14  d_loss: 0.327928  g_loss: 2.180358\n",
      "batch 15  d_loss: 0.421436  g_loss: 2.151059\n",
      "batch 16  d_loss: 0.307587  g_loss: 2.024393\n",
      "batch 17  d_loss: 0.294179  g_loss: 2.027768\n",
      "batch 18  d_loss: 0.309911  g_loss: 2.214399\n",
      "batch 19  d_loss: 0.314265  g_loss: 2.503838\n",
      "batch 20  d_loss: 0.251907  g_loss: 2.212018\n",
      "batch 21  d_loss: 0.298261  g_loss: 2.269381\n",
      "batch 22  d_loss: 0.233676  g_loss: 2.062134\n",
      "batch 23  d_loss: 0.230675  g_loss: 1.568368\n",
      "batch 24  d_loss: 0.246024  g_loss: 1.447385\n",
      "batch 25  d_loss: 0.284540  g_loss: 1.711394\n",
      "batch 26  d_loss: 0.245652  g_loss: 2.164488\n",
      "batch 27  d_loss: 0.231482  g_loss: 2.460435\n",
      "batch 28  d_loss: 0.454100  g_loss: 2.730221\n",
      "batch 29  d_loss: 0.334669  g_loss: 2.424412\n",
      "batch 30  d_loss: 0.253616  g_loss: 2.063582\n",
      "batch 31  d_loss: 0.327246  g_loss: 1.808130\n",
      "batch 32  d_loss: 0.341084  g_loss: 1.723677\n",
      "batch 33  d_loss: 0.402836  g_loss: 1.523405\n",
      "batch 34  d_loss: 0.433741  g_loss: 2.091890\n",
      "batch 35  d_loss: 0.418617  g_loss: 2.016822\n",
      "batch 36  d_loss: 0.551235  g_loss: 2.125612\n",
      "batch 37  d_loss: 0.479005  g_loss: 1.964994\n",
      "batch 38  d_loss: 0.340929  g_loss: 1.422549\n",
      "batch 39  d_loss: 0.385602  g_loss: 1.588917\n",
      "batch 40  d_loss: 0.499163  g_loss: 1.452828\n",
      "batch 41  d_loss: 0.414335  g_loss: 1.825084\n",
      "batch 42  d_loss: 0.406678  g_loss: 2.076692\n",
      "batch 43  d_loss: 0.371924  g_loss: 1.696614\n",
      "batch 44  d_loss: 0.384660  g_loss: 1.531089\n",
      "batch 45  d_loss: 0.298988  g_loss: 1.725255\n",
      "CPU times: user 10min 12s, sys: 12.4 s, total: 10min 25s\n",
      "Wall time: 3min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176290,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "9077a4b0-a66a-4946-eb3c-f5f70f1d5452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.714093</td>\n",
       "      <td>0.345825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.511360</td>\n",
       "      <td>0.567378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.437168</td>\n",
       "      <td>1.173110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.296602</td>\n",
       "      <td>2.363376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.186836</td>\n",
       "      <td>3.891134</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch    d_loss    g_loss\n",
       "0      0      0  0.714093  0.345825\n",
       "1      0      1  0.511360  0.567378\n",
       "2      0      2  0.437168  1.173110\n",
       "3      0      3  0.296602  2.363376\n",
       "4      0      4  0.186836  3.891134"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.414335</td>\n",
       "      <td>1.825084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.406678</td>\n",
       "      <td>2.076692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>0.371924</td>\n",
       "      <td>1.696614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>0.384660</td>\n",
       "      <td>1.531089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>0.298988</td>\n",
       "      <td>1.725255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  batch    d_loss    g_loss\n",
       "2295     49     41  0.414335  1.825084\n",
       "2296     49     42  0.406678  2.076692\n",
       "2297     49     43  0.371924  1.696614\n",
       "2298     49     44  0.384660  1.531089\n",
       "2299     49     45  0.298988  1.725255"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176283,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "669f9caf-ccc0-46ef-ed8c-c46b1a28d5ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.core.Dense object at 0x7f0bf849eb50> and <keras.layers.core.Activation object at 0x7f0bfa9bcbb0>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.core.Dense object at 0x7f0bfaa26490> and <keras.layers.core.Reshape object at 0x7f0bfb371a60>).\n",
      "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
      "\n",
      "Two checkpoint references resolved to different objects (<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x7f0bfa2a3460> and <keras.layers.convolutional.UpSampling2D object at 0x7f0bfb3719d0>).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Matrix size-incompatible: In[0]: [32,100], In[1]: [102,256]\n\t [[{{node dense_4/BiasAdd}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_171694/22114704.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_171694/2472900370.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(BATCH_SIZE)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnoise\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_noise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m127.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m     return func.predict(\n\u001b[0m\u001b[1;32m    971\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m     x, _, _ = model._standardize_user_data(\n\u001b[1;32m    698\u001b[0m         x, check_steps=True, steps_name='steps', steps=steps)\n\u001b[0;32m--> 699\u001b[0;31m     return predict_loop(\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4029\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4031\u001b[0;31m     fetched = self._callable_fn(*array_vals,\n\u001b[0m\u001b[1;32m   4032\u001b[0m                                 run_metadata=self.run_metadata)\n\u001b[1;32m   4033\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1476\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[0mrun_metadata_ptr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_NewBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0m\u001b[1;32m   1479\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m                                                run_metadata_ptr)\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Matrix size-incompatible: In[0]: [32,100], In[1]: [102,256]\n\t [[{{node dense_4/BiasAdd}}]]"
     ]
    }
   ],
   "source": [
    "generate(batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_with_keras-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
