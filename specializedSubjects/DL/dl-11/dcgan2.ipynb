{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1008,
     "status": "ok",
     "timestamp": 1576148328509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "k3LWJrdjDSJy",
    "outputId": "748de6e4-fd9b-426e-d7db-b02b51ed8e51"
   },
   "source": [
    "### Sample program for DCGAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(11)\n",
    "tf.random.set_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xLeQXXYjCcVm"
   },
   "outputs": [],
   "source": [
    "used_digits = [1,7]\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images'\n",
    "model_g = 'model_dcgan-b{}_g.h5'.format(batch_size)\n",
    "model_d = 'model_dcgan-b{}_d.h5'.format(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove old img_dir and create new one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2331,
     "status": "ok",
     "timestamp": 1576148329857,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "IOF5fZwICcVo",
    "outputId": "5c1cc125-a086-4060-de5a-21adba1d64ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OK\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(img_dir):\n",
    "    shutil.rmtree(img_dir)\n",
    "\n",
    "cnt = 10\n",
    "while cnt > 0:\n",
    "    try:\n",
    "        os.makedirs(img_dir)\n",
    "        break\n",
    "    except:\n",
    "        sleep(1)\n",
    "    cnt -= 1\n",
    "    \n",
    "if cnt <= 0:\n",
    "    print('Cannot mkdir:', img_dir)\n",
    "else:\n",
    "    print('mkdir: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_shape=(n_noise, ), activation=\"tanh\"))\n",
    "    model.add(Dense(32 * 7 * 7))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"tanh\"))\n",
    "    model.add(Reshape((7, 7, 32), input_shape=(7 * 7 * 32,)))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(UpSampling2D(size=(2, 2)))\n",
    "    model.add(Conv2D(1, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (5, 5),\n",
    "                     padding=\"same\",\n",
    "                     input_shape=(28, 28, 1),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (5, 5),\n",
    "                     activation=\"tanh\",\n",
    "                     data_format=\"channels_last\"))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(256, activation=\"tanh\"))\n",
    "    model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    discriminator.trainable = False\n",
    "    model.add(discriminator)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            generated_images = generator.predict(noise, verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X = np.concatenate((image_batch, generated_images))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch(X, y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                noise, [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cjAEL8P8CcV0"
   },
   "outputs": [],
   "source": [
    "def generate(BATCH_SIZE):\n",
    "    generator = generator_model()\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    generator.load_weights(\"generator\")\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    for i in range(BATCH_SIZE):\n",
    "        noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "    generated_images = generator.predict(noise, verbose=1)\n",
    "    image = combine_images(generated_images)\n",
    "    image = image*127.5+127.5\n",
    "    Image.fromarray(image.astype(np.uint8)).save(\"generated_image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176294,
     "status": "ok",
     "timestamp": 1576148503868,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "00ea9935-7deb-4110-81bb-cd1c312a3a05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.669027  g_loss: 0.386611\n",
      "batch 1  d_loss: 0.504099  g_loss: 0.526209\n",
      "batch 2  d_loss: 0.440529  g_loss: 1.068747\n",
      "batch 3  d_loss: 0.326694  g_loss: 2.138679\n",
      "batch 4  d_loss: 0.190049  g_loss: 3.491627\n",
      "batch 5  d_loss: 0.116961  g_loss: 4.801705\n",
      "batch 6  d_loss: 0.104315  g_loss: 6.068556\n",
      "batch 7  d_loss: 0.104287  g_loss: 6.916336\n",
      "batch 8  d_loss: 0.057619  g_loss: 7.185473\n",
      "batch 9  d_loss: 0.131019  g_loss: 7.876730\n",
      "batch 10  d_loss: 0.207099  g_loss: 8.396229\n",
      "batch 11  d_loss: 0.239186  g_loss: 8.969109\n",
      "batch 12  d_loss: 0.450091  g_loss: 8.847228\n",
      "batch 13  d_loss: 0.460974  g_loss: 8.272520\n",
      "batch 14  d_loss: 0.475278  g_loss: 7.212518\n",
      "batch 15  d_loss: 0.589513  g_loss: 6.634154\n",
      "batch 16  d_loss: 0.479813  g_loss: 5.876115\n",
      "batch 17  d_loss: 0.364892  g_loss: 5.349485\n",
      "batch 18  d_loss: 0.169798  g_loss: 5.150387\n",
      "batch 19  d_loss: 0.180033  g_loss: 4.751775\n",
      "batch 20  d_loss: 0.349986  g_loss: 3.399637\n",
      "batch 21  d_loss: 0.291796  g_loss: 3.897694\n",
      "batch 22  d_loss: 0.597154  g_loss: 3.370263\n",
      "batch 23  d_loss: 0.706130  g_loss: 4.463867\n",
      "batch 24  d_loss: 0.171286  g_loss: 4.076783\n",
      "batch 25  d_loss: 0.395731  g_loss: 4.088828\n",
      "batch 26  d_loss: 0.241286  g_loss: 4.662448\n",
      "batch 27  d_loss: 0.087335  g_loss: 5.245333\n",
      "batch 28  d_loss: 0.105500  g_loss: 5.513505\n",
      "batch 29  d_loss: 0.359311  g_loss: 4.956552\n",
      "batch 30  d_loss: 0.219647  g_loss: 5.187474\n",
      "batch 31  d_loss: 0.084099  g_loss: 4.955795\n",
      "batch 32  d_loss: 0.255489  g_loss: 4.877730\n",
      "batch 33  d_loss: 0.355453  g_loss: 5.197565\n",
      "batch 34  d_loss: 0.192202  g_loss: 5.752322\n",
      "batch 35  d_loss: 0.140882  g_loss: 5.930357\n",
      "batch 36  d_loss: 0.134144  g_loss: 5.276108\n",
      "batch 37  d_loss: 0.101166  g_loss: 5.749651\n",
      "batch 38  d_loss: 0.125967  g_loss: 5.142920\n",
      "batch 39  d_loss: 0.079992  g_loss: 5.134089\n",
      "batch 40  d_loss: 0.102910  g_loss: 5.328743\n",
      "batch 41  d_loss: 0.105131  g_loss: 5.087025\n",
      "batch 42  d_loss: 0.053577  g_loss: 5.130512\n",
      "batch 43  d_loss: 0.038893  g_loss: 4.943448\n",
      "batch 44  d_loss: 0.033435  g_loss: 4.616081\n",
      "batch 45  d_loss: 0.032760  g_loss: 4.830853\n",
      "Epoch is 1\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.034086  g_loss: 5.180708\n",
      "batch 1  d_loss: 0.070396  g_loss: 4.568545\n",
      "batch 2  d_loss: 0.064159  g_loss: 4.738366\n",
      "batch 3  d_loss: 0.072026  g_loss: 4.514775\n",
      "batch 4  d_loss: 0.036658  g_loss: 4.822303\n",
      "batch 5  d_loss: 0.017485  g_loss: 4.518804\n",
      "batch 6  d_loss: 0.040248  g_loss: 3.938166\n",
      "batch 7  d_loss: 0.074731  g_loss: 4.302807\n",
      "batch 8  d_loss: 0.028474  g_loss: 4.379360\n",
      "batch 9  d_loss: 0.045634  g_loss: 4.599448\n",
      "batch 10  d_loss: 0.094224  g_loss: 4.463962\n",
      "batch 11  d_loss: 0.138888  g_loss: 4.175521\n",
      "batch 12  d_loss: 0.035868  g_loss: 3.957924\n",
      "batch 13  d_loss: 0.054967  g_loss: 5.014059\n",
      "batch 14  d_loss: 0.072501  g_loss: 4.325620\n",
      "batch 15  d_loss: 0.095182  g_loss: 5.015330\n",
      "batch 16  d_loss: 0.060776  g_loss: 5.084700\n",
      "batch 17  d_loss: 0.052128  g_loss: 4.730556\n",
      "batch 18  d_loss: 0.070972  g_loss: 4.397412\n",
      "batch 19  d_loss: 0.048906  g_loss: 4.742372\n",
      "batch 20  d_loss: 0.031769  g_loss: 5.526090\n",
      "batch 21  d_loss: 0.061528  g_loss: 4.654168\n",
      "batch 22  d_loss: 0.067949  g_loss: 6.216464\n",
      "batch 23  d_loss: 0.051452  g_loss: 6.175718\n",
      "batch 24  d_loss: 0.087020  g_loss: 6.091074\n",
      "batch 25  d_loss: 0.098341  g_loss: 5.310714\n",
      "batch 26  d_loss: 0.033269  g_loss: 5.386883\n",
      "batch 27  d_loss: 0.111335  g_loss: 5.555949\n",
      "batch 28  d_loss: 0.056365  g_loss: 5.614154\n",
      "batch 29  d_loss: 0.104763  g_loss: 6.082160\n",
      "batch 30  d_loss: 0.074822  g_loss: 5.669168\n",
      "batch 31  d_loss: 0.061861  g_loss: 5.816996\n",
      "batch 32  d_loss: 0.119728  g_loss: 4.760949\n",
      "batch 33  d_loss: 0.056471  g_loss: 5.137367\n",
      "batch 34  d_loss: 0.063649  g_loss: 5.066380\n",
      "batch 35  d_loss: 0.155202  g_loss: 6.165091\n",
      "batch 36  d_loss: 0.158650  g_loss: 5.644786\n",
      "batch 37  d_loss: 0.132671  g_loss: 4.545396\n",
      "batch 38  d_loss: 0.099527  g_loss: 5.207456\n",
      "batch 39  d_loss: 0.088609  g_loss: 4.826222\n",
      "batch 40  d_loss: 0.053348  g_loss: 5.179147\n",
      "batch 41  d_loss: 0.120873  g_loss: 5.196341\n",
      "batch 42  d_loss: 0.038203  g_loss: 5.607482\n",
      "batch 43  d_loss: 0.073856  g_loss: 5.058794\n",
      "batch 44  d_loss: 0.128188  g_loss: 5.284977\n",
      "batch 45  d_loss: 0.040766  g_loss: 5.778895\n",
      "Epoch is 2\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.065620  g_loss: 6.329677\n",
      "batch 1  d_loss: 0.211491  g_loss: 6.527112\n",
      "batch 2  d_loss: 0.082654  g_loss: 5.965335\n",
      "batch 3  d_loss: 0.137418  g_loss: 5.990375\n",
      "batch 4  d_loss: 0.215090  g_loss: 6.621324\n",
      "batch 5  d_loss: 0.061486  g_loss: 7.362743\n",
      "batch 6  d_loss: 0.142135  g_loss: 7.359467\n",
      "batch 7  d_loss: 0.337155  g_loss: 6.875141\n",
      "batch 8  d_loss: 0.090453  g_loss: 6.192591\n",
      "batch 9  d_loss: 0.215182  g_loss: 5.769402\n",
      "batch 10  d_loss: 0.264965  g_loss: 6.133526\n",
      "batch 11  d_loss: 0.300982  g_loss: 5.968830\n",
      "batch 12  d_loss: 0.076976  g_loss: 6.297723\n",
      "batch 13  d_loss: 0.140509  g_loss: 5.739964\n",
      "batch 14  d_loss: 0.182248  g_loss: 5.946061\n",
      "batch 15  d_loss: 0.093559  g_loss: 5.245340\n",
      "batch 16  d_loss: 0.095313  g_loss: 6.478714\n",
      "batch 17  d_loss: 0.152794  g_loss: 7.113154\n",
      "batch 18  d_loss: 0.153237  g_loss: 6.318368\n",
      "batch 19  d_loss: 0.218743  g_loss: 5.489340\n",
      "batch 20  d_loss: 0.256919  g_loss: 6.575157\n",
      "batch 21  d_loss: 0.121921  g_loss: 5.861489\n",
      "batch 22  d_loss: 0.051699  g_loss: 7.413294\n",
      "batch 23  d_loss: 0.069371  g_loss: 6.417032\n",
      "batch 24  d_loss: 0.132934  g_loss: 6.790539\n",
      "batch 25  d_loss: 0.174540  g_loss: 6.921904\n",
      "batch 26  d_loss: 0.097107  g_loss: 7.001668\n",
      "batch 27  d_loss: 0.091610  g_loss: 7.987156\n",
      "batch 28  d_loss: 0.145002  g_loss: 6.692256\n",
      "batch 29  d_loss: 0.169888  g_loss: 7.658153\n",
      "batch 30  d_loss: 0.190146  g_loss: 7.498216\n",
      "batch 31  d_loss: 0.240560  g_loss: 7.860526\n",
      "batch 32  d_loss: 0.114792  g_loss: 7.871714\n",
      "batch 33  d_loss: 0.156740  g_loss: 7.874266\n",
      "batch 34  d_loss: 0.093670  g_loss: 8.723518\n",
      "batch 35  d_loss: 0.207897  g_loss: 8.130816\n",
      "batch 36  d_loss: 0.171671  g_loss: 8.685143\n",
      "batch 37  d_loss: 0.249531  g_loss: 8.703094\n",
      "batch 38  d_loss: 0.122674  g_loss: 7.884640\n",
      "batch 39  d_loss: 0.163927  g_loss: 8.559883\n",
      "batch 40  d_loss: 0.146120  g_loss: 8.916883\n",
      "batch 41  d_loss: 0.216579  g_loss: 8.136862\n",
      "batch 42  d_loss: 0.201140  g_loss: 8.785732\n",
      "batch 43  d_loss: 0.121256  g_loss: 8.616121\n",
      "batch 44  d_loss: 0.050632  g_loss: 8.808117\n",
      "batch 45  d_loss: 0.108466  g_loss: 10.172476\n",
      "Epoch is 3\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.143685  g_loss: 8.786413\n",
      "batch 1  d_loss: 0.199325  g_loss: 8.116447\n",
      "batch 2  d_loss: 0.210183  g_loss: 9.000364\n",
      "batch 3  d_loss: 0.171152  g_loss: 9.398056\n",
      "batch 4  d_loss: 0.059563  g_loss: 9.078020\n",
      "batch 5  d_loss: 0.126903  g_loss: 9.334574\n",
      "batch 6  d_loss: 0.204122  g_loss: 9.741798\n",
      "batch 7  d_loss: 0.210207  g_loss: 9.807553\n",
      "batch 8  d_loss: 0.201398  g_loss: 8.998663\n",
      "batch 9  d_loss: 0.103565  g_loss: 9.171888\n",
      "batch 10  d_loss: 0.189759  g_loss: 10.008165\n",
      "batch 11  d_loss: 0.147468  g_loss: 9.507560\n",
      "batch 12  d_loss: 0.060867  g_loss: 10.923430\n",
      "batch 13  d_loss: 0.067582  g_loss: 9.684706\n",
      "batch 14  d_loss: 0.077846  g_loss: 9.599537\n",
      "batch 15  d_loss: 0.214841  g_loss: 10.483273\n",
      "batch 16  d_loss: 0.215440  g_loss: 10.013653\n",
      "batch 17  d_loss: 0.083000  g_loss: 9.378704\n",
      "batch 18  d_loss: 0.222956  g_loss: 9.774551\n",
      "batch 19  d_loss: 0.190539  g_loss: 10.843752\n",
      "batch 20  d_loss: 0.219963  g_loss: 9.431978\n",
      "batch 21  d_loss: 0.128791  g_loss: 7.811309\n",
      "batch 22  d_loss: 0.071639  g_loss: 7.547858\n",
      "batch 23  d_loss: 0.227682  g_loss: 9.429122\n",
      "batch 24  d_loss: 0.145523  g_loss: 9.820622\n",
      "batch 25  d_loss: 0.102324  g_loss: 8.774872\n",
      "batch 26  d_loss: 0.099429  g_loss: 7.252967\n",
      "batch 27  d_loss: 0.126884  g_loss: 8.323397\n",
      "batch 28  d_loss: 0.112195  g_loss: 7.996249\n",
      "batch 29  d_loss: 0.116797  g_loss: 7.694875\n",
      "batch 30  d_loss: 0.119622  g_loss: 9.620680\n",
      "batch 31  d_loss: 0.103619  g_loss: 8.956054\n",
      "batch 32  d_loss: 0.245569  g_loss: 9.314534\n",
      "batch 33  d_loss: 0.155867  g_loss: 8.311419\n",
      "batch 34  d_loss: 0.171508  g_loss: 7.625735\n",
      "batch 35  d_loss: 0.324132  g_loss: 8.895513\n",
      "batch 36  d_loss: 0.152682  g_loss: 8.715704\n",
      "batch 37  d_loss: 0.093896  g_loss: 9.576071\n",
      "batch 38  d_loss: 0.209216  g_loss: 9.245579\n",
      "batch 39  d_loss: 0.088120  g_loss: 9.370691\n",
      "batch 40  d_loss: 0.040159  g_loss: 7.523835\n",
      "batch 41  d_loss: 0.240381  g_loss: 7.882427\n",
      "batch 42  d_loss: 0.173238  g_loss: 9.511144\n",
      "batch 43  d_loss: 0.072028  g_loss: 8.870852\n",
      "batch 44  d_loss: 0.144854  g_loss: 8.447987\n",
      "batch 45  d_loss: 0.154016  g_loss: 7.600199\n",
      "Epoch is 4\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.152642  g_loss: 7.809926\n",
      "batch 1  d_loss: 0.225684  g_loss: 8.157012\n",
      "batch 2  d_loss: 0.174761  g_loss: 8.161239\n",
      "batch 3  d_loss: 0.295687  g_loss: 8.143538\n",
      "batch 4  d_loss: 0.186480  g_loss: 7.611237\n",
      "batch 5  d_loss: 0.153986  g_loss: 8.644653\n",
      "batch 6  d_loss: 0.205055  g_loss: 9.163702\n",
      "batch 7  d_loss: 0.362417  g_loss: 6.845513\n",
      "batch 8  d_loss: 0.278443  g_loss: 7.095753\n",
      "batch 9  d_loss: 0.289334  g_loss: 6.920944\n",
      "batch 10  d_loss: 0.269720  g_loss: 6.951405\n",
      "batch 11  d_loss: 0.283292  g_loss: 6.624041\n",
      "batch 12  d_loss: 0.224645  g_loss: 5.772274\n",
      "batch 13  d_loss: 0.306839  g_loss: 6.158597\n",
      "batch 14  d_loss: 0.336007  g_loss: 6.203061\n",
      "batch 15  d_loss: 0.320107  g_loss: 5.798811\n",
      "batch 16  d_loss: 0.239207  g_loss: 5.529132\n",
      "batch 17  d_loss: 0.306190  g_loss: 6.487654\n",
      "batch 18  d_loss: 0.274314  g_loss: 5.717925\n",
      "batch 19  d_loss: 0.342971  g_loss: 3.951145\n",
      "batch 20  d_loss: 0.423124  g_loss: 4.187690\n",
      "batch 21  d_loss: 0.271302  g_loss: 6.340007\n",
      "batch 22  d_loss: 0.247212  g_loss: 5.644741\n",
      "batch 23  d_loss: 0.381587  g_loss: 3.820940\n",
      "batch 24  d_loss: 0.315642  g_loss: 3.551798\n",
      "batch 25  d_loss: 0.571981  g_loss: 3.790336\n",
      "batch 26  d_loss: 0.125324  g_loss: 4.950736\n",
      "batch 27  d_loss: 0.307383  g_loss: 5.761972\n",
      "batch 28  d_loss: 0.185698  g_loss: 4.687574\n",
      "batch 29  d_loss: 0.210475  g_loss: 4.711601\n",
      "batch 30  d_loss: 0.218391  g_loss: 3.870335\n",
      "batch 31  d_loss: 0.328265  g_loss: 4.689563\n",
      "batch 32  d_loss: 0.274943  g_loss: 5.267207\n",
      "batch 33  d_loss: 0.251911  g_loss: 5.756666\n",
      "batch 34  d_loss: 0.130488  g_loss: 4.745338\n",
      "batch 35  d_loss: 0.238633  g_loss: 4.645557\n",
      "batch 36  d_loss: 0.196467  g_loss: 4.727700\n",
      "batch 37  d_loss: 0.285847  g_loss: 3.958531\n",
      "batch 38  d_loss: 0.162867  g_loss: 4.146144\n",
      "batch 39  d_loss: 0.196488  g_loss: 4.115729\n",
      "batch 40  d_loss: 0.276360  g_loss: 5.340023\n",
      "batch 41  d_loss: 0.459954  g_loss: 4.410277\n",
      "batch 42  d_loss: 0.220206  g_loss: 3.807867\n",
      "batch 43  d_loss: 0.328696  g_loss: 3.246706\n",
      "batch 44  d_loss: 0.401562  g_loss: 4.078927\n",
      "batch 45  d_loss: 0.182572  g_loss: 4.438813\n",
      "Epoch is 5\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.314031  g_loss: 3.791580\n",
      "batch 1  d_loss: 0.452184  g_loss: 3.171766\n",
      "batch 2  d_loss: 0.175677  g_loss: 2.066190\n",
      "batch 3  d_loss: 0.221568  g_loss: 2.056159\n",
      "batch 4  d_loss: 0.209862  g_loss: 2.822584\n",
      "batch 5  d_loss: 0.168529  g_loss: 4.383020\n",
      "batch 6  d_loss: 0.239904  g_loss: 5.200902\n",
      "batch 7  d_loss: 0.399172  g_loss: 4.553468\n",
      "batch 8  d_loss: 0.245918  g_loss: 2.605507\n",
      "batch 9  d_loss: 0.373895  g_loss: 1.277515\n",
      "batch 10  d_loss: 0.567769  g_loss: 1.102298\n",
      "batch 11  d_loss: 0.861539  g_loss: 2.833404\n",
      "batch 12  d_loss: 0.164685  g_loss: 4.834669\n",
      "batch 13  d_loss: 1.137548  g_loss: 3.598650\n",
      "batch 14  d_loss: 0.845733  g_loss: 1.496127\n",
      "batch 15  d_loss: 0.499404  g_loss: 0.755267\n",
      "batch 16  d_loss: 0.717861  g_loss: 1.202395\n",
      "batch 17  d_loss: 0.763740  g_loss: 2.360688\n",
      "batch 18  d_loss: 0.519143  g_loss: 3.492079\n",
      "batch 19  d_loss: 0.602786  g_loss: 3.046390\n",
      "batch 20  d_loss: 0.562933  g_loss: 3.066840\n",
      "batch 21  d_loss: 0.373277  g_loss: 1.973374\n",
      "batch 22  d_loss: 0.339004  g_loss: 1.486539\n",
      "batch 23  d_loss: 0.484211  g_loss: 2.059425\n",
      "batch 24  d_loss: 0.440746  g_loss: 2.523702\n",
      "batch 25  d_loss: 0.512075  g_loss: 3.141566\n",
      "batch 26  d_loss: 0.281043  g_loss: 3.175594\n",
      "batch 27  d_loss: 0.457529  g_loss: 2.914739\n",
      "batch 28  d_loss: 0.328959  g_loss: 2.193167\n",
      "batch 29  d_loss: 0.421522  g_loss: 2.029248\n",
      "batch 30  d_loss: 0.474113  g_loss: 1.799291\n",
      "batch 31  d_loss: 0.412054  g_loss: 1.485971\n",
      "batch 32  d_loss: 0.433107  g_loss: 1.705898\n",
      "batch 33  d_loss: 0.459074  g_loss: 1.856084\n",
      "batch 34  d_loss: 0.455833  g_loss: 1.949815\n",
      "batch 35  d_loss: 0.485776  g_loss: 1.848430\n",
      "batch 36  d_loss: 0.396196  g_loss: 1.884810\n",
      "batch 37  d_loss: 0.438639  g_loss: 1.644366\n",
      "batch 38  d_loss: 0.341185  g_loss: 1.739557\n",
      "batch 39  d_loss: 0.315046  g_loss: 1.869419\n",
      "batch 40  d_loss: 0.519333  g_loss: 2.042682\n",
      "batch 41  d_loss: 0.605209  g_loss: 1.727771\n",
      "batch 42  d_loss: 0.521037  g_loss: 1.464902\n",
      "batch 43  d_loss: 0.572173  g_loss: 1.490124\n",
      "batch 44  d_loss: 0.438615  g_loss: 1.565375\n",
      "batch 45  d_loss: 0.345774  g_loss: 2.036388\n",
      "Epoch is 6\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.301489  g_loss: 1.904431\n",
      "batch 1  d_loss: 0.598161  g_loss: 2.063815\n",
      "batch 2  d_loss: 0.451908  g_loss: 1.831178\n",
      "batch 3  d_loss: 0.494099  g_loss: 1.374035\n",
      "batch 4  d_loss: 0.379738  g_loss: 1.207953\n",
      "batch 5  d_loss: 0.418557  g_loss: 1.368179\n",
      "batch 6  d_loss: 0.405875  g_loss: 1.533314\n",
      "batch 7  d_loss: 0.375814  g_loss: 1.733854\n",
      "batch 8  d_loss: 0.416806  g_loss: 1.873722\n",
      "batch 9  d_loss: 0.434609  g_loss: 1.666100\n",
      "batch 10  d_loss: 0.369618  g_loss: 1.399701\n",
      "batch 11  d_loss: 0.425971  g_loss: 1.210228\n",
      "batch 12  d_loss: 0.355384  g_loss: 1.751366\n",
      "batch 13  d_loss: 0.341498  g_loss: 2.416765\n",
      "batch 14  d_loss: 0.434505  g_loss: 2.250938\n",
      "batch 15  d_loss: 0.397458  g_loss: 1.954028\n",
      "batch 16  d_loss: 0.416609  g_loss: 1.590557\n",
      "batch 17  d_loss: 0.386769  g_loss: 1.389797\n",
      "batch 18  d_loss: 0.441701  g_loss: 1.703523\n",
      "batch 19  d_loss: 0.562967  g_loss: 2.083257\n",
      "batch 20  d_loss: 0.585423  g_loss: 2.532115\n",
      "batch 21  d_loss: 0.545206  g_loss: 2.232251\n",
      "batch 22  d_loss: 0.374403  g_loss: 1.684384\n",
      "batch 23  d_loss: 0.514245  g_loss: 1.364816\n",
      "batch 24  d_loss: 0.623684  g_loss: 1.299373\n",
      "batch 25  d_loss: 0.628276  g_loss: 1.229028\n",
      "batch 26  d_loss: 0.576704  g_loss: 1.821215\n",
      "batch 27  d_loss: 0.701029  g_loss: 2.096523\n",
      "batch 28  d_loss: 0.467587  g_loss: 1.424645\n",
      "batch 29  d_loss: 0.576406  g_loss: 1.183187\n",
      "batch 30  d_loss: 0.590409  g_loss: 1.126487\n",
      "batch 31  d_loss: 0.723285  g_loss: 1.513084\n",
      "batch 32  d_loss: 0.563200  g_loss: 1.742650\n",
      "batch 33  d_loss: 0.550940  g_loss: 2.074563\n",
      "batch 34  d_loss: 0.422329  g_loss: 2.135776\n",
      "batch 35  d_loss: 0.484395  g_loss: 1.929057\n",
      "batch 36  d_loss: 0.314624  g_loss: 1.641146\n",
      "batch 37  d_loss: 0.292791  g_loss: 1.270051\n",
      "batch 38  d_loss: 0.485366  g_loss: 1.810942\n",
      "batch 39  d_loss: 0.250791  g_loss: 2.217543\n",
      "batch 40  d_loss: 0.334301  g_loss: 2.622374\n",
      "batch 41  d_loss: 0.390294  g_loss: 3.106525\n",
      "batch 42  d_loss: 0.350607  g_loss: 2.718750\n",
      "batch 43  d_loss: 0.280884  g_loss: 2.274204\n",
      "batch 44  d_loss: 0.262233  g_loss: 1.971553\n",
      "batch 45  d_loss: 0.223542  g_loss: 2.046917\n",
      "Epoch is 7\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.345432  g_loss: 1.997597\n",
      "batch 1  d_loss: 0.448199  g_loss: 2.183675\n",
      "batch 2  d_loss: 0.286882  g_loss: 2.784265\n",
      "batch 3  d_loss: 0.396629  g_loss: 2.381915\n",
      "batch 4  d_loss: 0.435206  g_loss: 1.767796\n",
      "batch 5  d_loss: 0.438068  g_loss: 1.757680\n",
      "batch 6  d_loss: 0.412508  g_loss: 1.482172\n",
      "batch 7  d_loss: 0.511726  g_loss: 1.653213\n",
      "batch 8  d_loss: 0.549372  g_loss: 1.724683\n",
      "batch 9  d_loss: 0.847489  g_loss: 1.869242\n",
      "batch 10  d_loss: 0.596308  g_loss: 1.554836\n",
      "batch 11  d_loss: 0.549963  g_loss: 1.558753\n",
      "batch 12  d_loss: 0.371443  g_loss: 1.243046\n",
      "batch 13  d_loss: 0.480471  g_loss: 1.275931\n",
      "batch 14  d_loss: 0.621747  g_loss: 1.288917\n",
      "batch 15  d_loss: 0.405051  g_loss: 1.748362\n",
      "batch 16  d_loss: 0.360724  g_loss: 1.890956\n",
      "batch 17  d_loss: 0.242422  g_loss: 2.092183\n",
      "batch 18  d_loss: 0.290005  g_loss: 2.510051\n",
      "batch 19  d_loss: 0.310814  g_loss: 2.255354\n",
      "batch 20  d_loss: 0.232708  g_loss: 2.426866\n",
      "batch 21  d_loss: 0.204594  g_loss: 2.454734\n",
      "batch 22  d_loss: 0.249827  g_loss: 3.110206\n",
      "batch 23  d_loss: 0.155277  g_loss: 3.370513\n",
      "batch 24  d_loss: 0.317972  g_loss: 2.698743\n",
      "batch 25  d_loss: 0.289444  g_loss: 2.805299\n",
      "batch 26  d_loss: 0.242552  g_loss: 2.393792\n",
      "batch 27  d_loss: 0.386365  g_loss: 2.070427\n",
      "batch 28  d_loss: 0.278572  g_loss: 2.564007\n",
      "batch 29  d_loss: 0.240421  g_loss: 2.247017\n",
      "batch 30  d_loss: 0.379324  g_loss: 1.922861\n",
      "batch 31  d_loss: 0.507256  g_loss: 2.033911\n",
      "batch 32  d_loss: 0.562980  g_loss: 1.840614\n",
      "batch 33  d_loss: 0.538345  g_loss: 1.214581\n",
      "batch 34  d_loss: 0.412333  g_loss: 1.363361\n",
      "batch 35  d_loss: 0.480035  g_loss: 1.471725\n",
      "batch 36  d_loss: 0.465949  g_loss: 1.470302\n",
      "batch 37  d_loss: 0.615778  g_loss: 1.434070\n",
      "batch 38  d_loss: 0.514516  g_loss: 1.648761\n",
      "batch 39  d_loss: 0.524632  g_loss: 1.481108\n",
      "batch 40  d_loss: 0.527989  g_loss: 1.704845\n",
      "batch 41  d_loss: 0.553028  g_loss: 1.918454\n",
      "batch 42  d_loss: 0.618733  g_loss: 1.751572\n",
      "batch 43  d_loss: 0.800231  g_loss: 1.343219\n",
      "batch 44  d_loss: 0.344323  g_loss: 1.417579\n",
      "batch 45  d_loss: 0.407842  g_loss: 1.819176\n",
      "Epoch is 8\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.293449  g_loss: 1.981391\n",
      "batch 1  d_loss: 0.375741  g_loss: 2.201412\n",
      "batch 2  d_loss: 0.269715  g_loss: 2.327814\n",
      "batch 3  d_loss: 0.343318  g_loss: 2.378090\n",
      "batch 4  d_loss: 0.307368  g_loss: 2.314155\n",
      "batch 5  d_loss: 0.245033  g_loss: 1.671639\n",
      "batch 6  d_loss: 0.368179  g_loss: 1.962020\n",
      "batch 7  d_loss: 0.486813  g_loss: 2.512527\n",
      "batch 8  d_loss: 0.394447  g_loss: 2.228490\n",
      "batch 9  d_loss: 0.331683  g_loss: 2.554775\n",
      "batch 10  d_loss: 0.345152  g_loss: 2.453435\n",
      "batch 11  d_loss: 0.298399  g_loss: 2.627752\n",
      "batch 12  d_loss: 0.218466  g_loss: 2.748930\n",
      "batch 13  d_loss: 0.347057  g_loss: 2.565556\n",
      "batch 14  d_loss: 0.420080  g_loss: 2.351475\n",
      "batch 15  d_loss: 0.334257  g_loss: 2.316190\n",
      "batch 16  d_loss: 0.225068  g_loss: 2.329648\n",
      "batch 17  d_loss: 0.373006  g_loss: 2.218123\n",
      "batch 18  d_loss: 0.361478  g_loss: 1.958990\n",
      "batch 19  d_loss: 0.331471  g_loss: 2.181628\n",
      "batch 20  d_loss: 0.385162  g_loss: 2.422391\n",
      "batch 21  d_loss: 0.400799  g_loss: 2.411008\n",
      "batch 22  d_loss: 0.292393  g_loss: 2.193726\n",
      "batch 23  d_loss: 0.268897  g_loss: 2.005877\n",
      "batch 24  d_loss: 0.590173  g_loss: 1.696245\n",
      "batch 25  d_loss: 0.600311  g_loss: 2.127080\n",
      "batch 26  d_loss: 0.510881  g_loss: 1.945681\n",
      "batch 27  d_loss: 0.530635  g_loss: 2.058120\n",
      "batch 28  d_loss: 0.564895  g_loss: 1.858084\n",
      "batch 29  d_loss: 0.475258  g_loss: 1.507775\n",
      "batch 30  d_loss: 0.406659  g_loss: 1.531479\n",
      "batch 31  d_loss: 0.734894  g_loss: 1.501175\n",
      "batch 32  d_loss: 0.514498  g_loss: 1.600243\n",
      "batch 33  d_loss: 0.516192  g_loss: 1.423183\n",
      "batch 34  d_loss: 0.577033  g_loss: 1.191896\n",
      "batch 35  d_loss: 0.482092  g_loss: 1.200729\n",
      "batch 36  d_loss: 0.430976  g_loss: 1.505500\n",
      "batch 37  d_loss: 0.579050  g_loss: 1.705027\n",
      "batch 38  d_loss: 0.364318  g_loss: 1.818666\n",
      "batch 39  d_loss: 0.314527  g_loss: 2.173470\n",
      "batch 40  d_loss: 0.339852  g_loss: 2.207125\n",
      "batch 41  d_loss: 0.518691  g_loss: 2.023471\n",
      "batch 42  d_loss: 0.541180  g_loss: 1.868447\n",
      "batch 43  d_loss: 0.511645  g_loss: 1.523952\n",
      "batch 44  d_loss: 0.333249  g_loss: 1.556173\n",
      "batch 45  d_loss: 0.282606  g_loss: 2.007999\n",
      "Epoch is 9\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.258412  g_loss: 2.094158\n",
      "batch 1  d_loss: 0.378896  g_loss: 1.839641\n",
      "batch 2  d_loss: 0.243834  g_loss: 1.773202\n",
      "batch 3  d_loss: 0.344762  g_loss: 1.870976\n",
      "batch 4  d_loss: 0.314489  g_loss: 1.553450\n",
      "batch 5  d_loss: 0.304905  g_loss: 1.905697\n",
      "batch 6  d_loss: 0.310115  g_loss: 1.769279\n",
      "batch 7  d_loss: 0.376552  g_loss: 1.806360\n",
      "batch 8  d_loss: 0.424517  g_loss: 1.381120\n",
      "batch 9  d_loss: 0.452151  g_loss: 1.551857\n",
      "batch 10  d_loss: 0.344749  g_loss: 1.302645\n",
      "batch 11  d_loss: 0.505862  g_loss: 1.641295\n",
      "batch 12  d_loss: 0.410427  g_loss: 1.655252\n",
      "batch 13  d_loss: 0.450311  g_loss: 1.677069\n",
      "batch 14  d_loss: 0.499313  g_loss: 1.556612\n",
      "batch 15  d_loss: 0.355830  g_loss: 1.376758\n",
      "batch 16  d_loss: 0.426076  g_loss: 1.385353\n",
      "batch 17  d_loss: 0.386934  g_loss: 1.624909\n",
      "batch 18  d_loss: 0.457611  g_loss: 2.262980\n",
      "batch 19  d_loss: 0.434253  g_loss: 2.057372\n",
      "batch 20  d_loss: 0.404750  g_loss: 1.642998\n",
      "batch 21  d_loss: 0.333252  g_loss: 1.310593\n",
      "batch 22  d_loss: 0.305056  g_loss: 1.497774\n",
      "batch 23  d_loss: 0.378928  g_loss: 1.564673\n",
      "batch 24  d_loss: 0.481031  g_loss: 2.212966\n",
      "batch 25  d_loss: 0.499472  g_loss: 1.889266\n",
      "batch 26  d_loss: 0.493270  g_loss: 1.558714\n",
      "batch 27  d_loss: 0.585853  g_loss: 1.575058\n",
      "batch 28  d_loss: 0.480360  g_loss: 1.144721\n",
      "batch 29  d_loss: 0.415829  g_loss: 1.214515\n",
      "batch 30  d_loss: 0.438996  g_loss: 1.767797\n",
      "batch 31  d_loss: 0.468482  g_loss: 1.586102\n",
      "batch 32  d_loss: 0.466625  g_loss: 1.627727\n",
      "batch 33  d_loss: 0.546485  g_loss: 2.138503\n",
      "batch 34  d_loss: 0.400392  g_loss: 1.918218\n",
      "batch 35  d_loss: 0.442914  g_loss: 1.559121\n",
      "batch 36  d_loss: 0.429626  g_loss: 1.510638\n",
      "batch 37  d_loss: 0.339256  g_loss: 1.436615\n",
      "batch 38  d_loss: 0.385944  g_loss: 1.967543\n",
      "batch 39  d_loss: 0.426292  g_loss: 1.953205\n",
      "batch 40  d_loss: 0.539595  g_loss: 1.907475\n",
      "batch 41  d_loss: 0.321638  g_loss: 2.006158\n",
      "batch 42  d_loss: 0.392175  g_loss: 1.542209\n",
      "batch 43  d_loss: 0.452314  g_loss: 1.450240\n",
      "batch 44  d_loss: 0.328379  g_loss: 1.230761\n",
      "batch 45  d_loss: 0.443830  g_loss: 1.259842\n",
      "Epoch is 10\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.327567  g_loss: 2.105604\n",
      "batch 1  d_loss: 0.372395  g_loss: 2.155869\n",
      "batch 2  d_loss: 0.253562  g_loss: 2.731584\n",
      "batch 3  d_loss: 0.375810  g_loss: 2.342101\n",
      "batch 4  d_loss: 0.258974  g_loss: 1.670798\n",
      "batch 5  d_loss: 0.245750  g_loss: 1.825445\n",
      "batch 6  d_loss: 0.344743  g_loss: 1.778043\n",
      "batch 7  d_loss: 0.317540  g_loss: 2.032366\n",
      "batch 8  d_loss: 0.357867  g_loss: 2.045255\n",
      "batch 9  d_loss: 0.523123  g_loss: 2.377219\n",
      "batch 10  d_loss: 0.369749  g_loss: 2.108165\n",
      "batch 11  d_loss: 0.376667  g_loss: 2.059656\n",
      "batch 12  d_loss: 0.299240  g_loss: 2.652854\n",
      "batch 13  d_loss: 0.527954  g_loss: 1.991152\n",
      "batch 14  d_loss: 0.629906  g_loss: 1.457629\n",
      "batch 15  d_loss: 0.424010  g_loss: 1.048229\n",
      "batch 16  d_loss: 0.527289  g_loss: 1.355991\n",
      "batch 17  d_loss: 0.546448  g_loss: 2.014858\n",
      "batch 18  d_loss: 0.536365  g_loss: 2.662585\n",
      "batch 19  d_loss: 0.922921  g_loss: 2.046048\n",
      "batch 20  d_loss: 0.520699  g_loss: 1.063261\n",
      "batch 21  d_loss: 0.569490  g_loss: 1.051567\n",
      "batch 22  d_loss: 0.507898  g_loss: 1.186358\n",
      "batch 23  d_loss: 0.483977  g_loss: 1.531318\n",
      "batch 24  d_loss: 0.621596  g_loss: 2.263017\n",
      "batch 25  d_loss: 0.621400  g_loss: 2.398431\n",
      "batch 26  d_loss: 0.580868  g_loss: 1.915065\n",
      "batch 27  d_loss: 0.628909  g_loss: 1.353582\n",
      "batch 28  d_loss: 0.691120  g_loss: 1.271769\n",
      "batch 29  d_loss: 0.535266  g_loss: 1.208881\n",
      "batch 30  d_loss: 0.402150  g_loss: 1.518582\n",
      "batch 31  d_loss: 0.665554  g_loss: 1.466014\n",
      "batch 32  d_loss: 0.440137  g_loss: 1.467327\n",
      "batch 33  d_loss: 0.500414  g_loss: 1.491165\n",
      "batch 34  d_loss: 0.411907  g_loss: 1.559675\n",
      "batch 35  d_loss: 0.454910  g_loss: 1.292122\n",
      "batch 36  d_loss: 0.401930  g_loss: 1.249532\n",
      "batch 37  d_loss: 0.417789  g_loss: 1.103442\n",
      "batch 38  d_loss: 0.407935  g_loss: 1.061739\n",
      "batch 39  d_loss: 0.368491  g_loss: 1.261036\n",
      "batch 40  d_loss: 0.407110  g_loss: 1.672187\n",
      "batch 41  d_loss: 0.461058  g_loss: 1.851769\n",
      "batch 42  d_loss: 0.467580  g_loss: 1.657396\n",
      "batch 43  d_loss: 0.546629  g_loss: 1.497017\n",
      "batch 44  d_loss: 0.362010  g_loss: 1.542913\n",
      "batch 45  d_loss: 0.305354  g_loss: 1.734332\n",
      "Epoch is 11\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.300747  g_loss: 1.542135\n",
      "batch 1  d_loss: 0.399196  g_loss: 1.529566\n",
      "batch 2  d_loss: 0.313120  g_loss: 1.704041\n",
      "batch 3  d_loss: 0.399882  g_loss: 1.879864\n",
      "batch 4  d_loss: 0.385311  g_loss: 1.701300\n",
      "batch 5  d_loss: 0.286189  g_loss: 1.637162\n",
      "batch 6  d_loss: 0.405260  g_loss: 1.725132\n",
      "batch 7  d_loss: 0.461661  g_loss: 1.324171\n",
      "batch 8  d_loss: 0.520707  g_loss: 1.308720\n",
      "batch 9  d_loss: 0.519415  g_loss: 0.980953\n",
      "batch 10  d_loss: 0.449143  g_loss: 1.396201\n",
      "batch 11  d_loss: 0.462485  g_loss: 1.095493\n",
      "batch 12  d_loss: 0.324905  g_loss: 1.545916\n",
      "batch 13  d_loss: 0.455675  g_loss: 1.418454\n",
      "batch 14  d_loss: 0.559190  g_loss: 1.867373\n",
      "batch 15  d_loss: 0.480398  g_loss: 2.021785\n",
      "batch 16  d_loss: 0.424300  g_loss: 1.405272\n",
      "batch 17  d_loss: 0.400769  g_loss: 1.319097\n",
      "batch 18  d_loss: 0.386144  g_loss: 1.442865\n",
      "batch 19  d_loss: 0.490694  g_loss: 1.000646\n",
      "batch 20  d_loss: 0.454959  g_loss: 1.039658\n",
      "batch 21  d_loss: 0.357170  g_loss: 1.364749\n",
      "batch 22  d_loss: 0.441928  g_loss: 1.491848\n",
      "batch 23  d_loss: 0.410420  g_loss: 1.625809\n",
      "batch 24  d_loss: 0.467422  g_loss: 1.546602\n",
      "batch 25  d_loss: 0.546558  g_loss: 1.534446\n",
      "batch 26  d_loss: 0.484117  g_loss: 1.724799\n",
      "batch 27  d_loss: 0.515051  g_loss: 1.359136\n",
      "batch 28  d_loss: 0.543685  g_loss: 0.986317\n",
      "batch 29  d_loss: 0.458596  g_loss: 0.988584\n",
      "batch 30  d_loss: 0.486966  g_loss: 1.499428\n",
      "batch 31  d_loss: 0.606030  g_loss: 1.372601\n",
      "batch 32  d_loss: 0.476998  g_loss: 1.870352\n",
      "batch 33  d_loss: 0.491898  g_loss: 1.470891\n",
      "batch 34  d_loss: 0.383396  g_loss: 1.900181\n",
      "batch 35  d_loss: 0.512435  g_loss: 1.476661\n",
      "batch 36  d_loss: 0.477726  g_loss: 1.016626\n",
      "batch 37  d_loss: 0.673937  g_loss: 0.760112\n",
      "batch 38  d_loss: 0.571129  g_loss: 1.092810\n",
      "batch 39  d_loss: 0.459027  g_loss: 1.828025\n",
      "batch 40  d_loss: 0.447014  g_loss: 2.299519\n",
      "batch 41  d_loss: 0.614571  g_loss: 2.494803\n",
      "batch 42  d_loss: 0.493674  g_loss: 1.807704\n",
      "batch 43  d_loss: 0.544295  g_loss: 1.359151\n",
      "batch 44  d_loss: 0.342261  g_loss: 1.369486\n",
      "batch 45  d_loss: 0.487612  g_loss: 1.278254\n",
      "Epoch is 12\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.430810  g_loss: 1.942473\n",
      "batch 1  d_loss: 0.510028  g_loss: 2.391862\n",
      "batch 2  d_loss: 0.277360  g_loss: 2.666223\n",
      "batch 3  d_loss: 0.494649  g_loss: 2.676363\n",
      "batch 4  d_loss: 0.644514  g_loss: 2.101110\n",
      "batch 5  d_loss: 0.397817  g_loss: 1.225577\n",
      "batch 6  d_loss: 0.395756  g_loss: 0.883709\n",
      "batch 7  d_loss: 0.549505  g_loss: 0.621835\n",
      "batch 8  d_loss: 0.577271  g_loss: 0.898568\n",
      "batch 9  d_loss: 0.475326  g_loss: 1.053455\n",
      "batch 10  d_loss: 0.503482  g_loss: 1.525381\n",
      "batch 11  d_loss: 0.484829  g_loss: 1.963096\n",
      "batch 12  d_loss: 0.556147  g_loss: 1.900970\n",
      "batch 13  d_loss: 0.601985  g_loss: 1.730808\n",
      "batch 14  d_loss: 0.590324  g_loss: 1.375221\n",
      "batch 15  d_loss: 0.435836  g_loss: 1.272657\n",
      "batch 16  d_loss: 0.417967  g_loss: 1.229486\n",
      "batch 17  d_loss: 0.477804  g_loss: 1.289233\n",
      "batch 18  d_loss: 0.390264  g_loss: 1.256172\n",
      "batch 19  d_loss: 0.445841  g_loss: 1.594382\n",
      "batch 20  d_loss: 0.382274  g_loss: 1.536922\n",
      "batch 21  d_loss: 0.394112  g_loss: 1.709818\n",
      "batch 22  d_loss: 0.298477  g_loss: 1.799162\n",
      "batch 23  d_loss: 0.287132  g_loss: 1.863987\n",
      "batch 24  d_loss: 0.397590  g_loss: 1.516759\n",
      "batch 25  d_loss: 0.391552  g_loss: 1.573580\n",
      "batch 26  d_loss: 0.398547  g_loss: 1.435625\n",
      "batch 27  d_loss: 0.389140  g_loss: 1.589552\n",
      "batch 28  d_loss: 0.392554  g_loss: 1.573154\n",
      "batch 29  d_loss: 0.369547  g_loss: 1.772661\n",
      "batch 30  d_loss: 0.377381  g_loss: 1.966099\n",
      "batch 31  d_loss: 0.578997  g_loss: 1.937158\n",
      "batch 32  d_loss: 0.412818  g_loss: 1.702371\n",
      "batch 33  d_loss: 0.476769  g_loss: 1.615335\n",
      "batch 34  d_loss: 0.457265  g_loss: 1.642360\n",
      "batch 35  d_loss: 0.529875  g_loss: 1.839454\n",
      "batch 36  d_loss: 0.431467  g_loss: 2.192959\n",
      "batch 37  d_loss: 0.458296  g_loss: 1.702662\n",
      "batch 38  d_loss: 0.348011  g_loss: 2.057782\n",
      "batch 39  d_loss: 0.322241  g_loss: 1.557855\n",
      "batch 40  d_loss: 0.358590  g_loss: 1.246811\n",
      "batch 41  d_loss: 0.534524  g_loss: 1.070463\n",
      "batch 42  d_loss: 0.525015  g_loss: 1.448595\n",
      "batch 43  d_loss: 0.622726  g_loss: 1.542442\n",
      "batch 44  d_loss: 0.350059  g_loss: 1.958237\n",
      "batch 45  d_loss: 0.441322  g_loss: 2.361664\n",
      "Epoch is 13\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.374482  g_loss: 2.472215\n",
      "batch 1  d_loss: 0.661267  g_loss: 2.235902\n",
      "batch 2  d_loss: 0.379512  g_loss: 2.006000\n",
      "batch 3  d_loss: 0.472143  g_loss: 1.706309\n",
      "batch 4  d_loss: 0.492971  g_loss: 1.439914\n",
      "batch 5  d_loss: 0.413068  g_loss: 1.277262\n",
      "batch 6  d_loss: 0.400428  g_loss: 1.330446\n",
      "batch 7  d_loss: 0.446076  g_loss: 1.251839\n",
      "batch 8  d_loss: 0.490150  g_loss: 1.330149\n",
      "batch 9  d_loss: 0.504973  g_loss: 1.302448\n",
      "batch 10  d_loss: 0.510301  g_loss: 1.235162\n",
      "batch 11  d_loss: 0.435806  g_loss: 1.502387\n",
      "batch 12  d_loss: 0.394961  g_loss: 1.312639\n",
      "batch 13  d_loss: 0.469695  g_loss: 1.475408\n",
      "batch 14  d_loss: 0.475779  g_loss: 1.460697\n",
      "batch 15  d_loss: 0.415965  g_loss: 1.783585\n",
      "batch 16  d_loss: 0.315851  g_loss: 1.898248\n",
      "batch 17  d_loss: 0.313372  g_loss: 1.750646\n",
      "batch 18  d_loss: 0.360200  g_loss: 1.930723\n",
      "batch 19  d_loss: 0.444359  g_loss: 1.969257\n",
      "batch 20  d_loss: 0.353912  g_loss: 1.698186\n",
      "batch 21  d_loss: 0.280471  g_loss: 1.478082\n",
      "batch 22  d_loss: 0.425108  g_loss: 1.465964\n",
      "batch 23  d_loss: 0.300165  g_loss: 1.647433\n",
      "batch 24  d_loss: 0.322283  g_loss: 1.780105\n",
      "batch 25  d_loss: 0.453290  g_loss: 2.231069\n",
      "batch 26  d_loss: 0.306715  g_loss: 2.289449\n",
      "batch 27  d_loss: 0.427983  g_loss: 2.018660\n",
      "batch 28  d_loss: 0.417263  g_loss: 1.747165\n",
      "batch 29  d_loss: 0.403063  g_loss: 1.554715\n",
      "batch 30  d_loss: 0.393343  g_loss: 1.401816\n",
      "batch 31  d_loss: 0.471259  g_loss: 1.302633\n",
      "batch 32  d_loss: 0.420713  g_loss: 1.505761\n",
      "batch 33  d_loss: 0.475765  g_loss: 1.803914\n",
      "batch 34  d_loss: 0.362360  g_loss: 1.915094\n",
      "batch 35  d_loss: 0.350261  g_loss: 2.108154\n",
      "batch 36  d_loss: 0.447914  g_loss: 2.245079\n",
      "batch 37  d_loss: 0.730530  g_loss: 1.790664\n",
      "batch 38  d_loss: 0.398748  g_loss: 0.974519\n",
      "batch 39  d_loss: 0.410228  g_loss: 1.354643\n",
      "batch 40  d_loss: 0.640579  g_loss: 0.974870\n",
      "batch 41  d_loss: 0.690390  g_loss: 1.152554\n",
      "batch 42  d_loss: 0.587152  g_loss: 1.511425\n",
      "batch 43  d_loss: 0.598149  g_loss: 1.553780\n",
      "batch 44  d_loss: 0.573082  g_loss: 1.580584\n",
      "batch 45  d_loss: 0.425949  g_loss: 1.852315\n",
      "Epoch is 14\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.355914  g_loss: 1.811568\n",
      "batch 1  d_loss: 0.497726  g_loss: 1.758849\n",
      "batch 2  d_loss: 0.346801  g_loss: 1.564325\n",
      "batch 3  d_loss: 0.310247  g_loss: 1.329876\n",
      "batch 4  d_loss: 0.313485  g_loss: 1.685970\n",
      "batch 5  d_loss: 0.396328  g_loss: 2.122779\n",
      "batch 6  d_loss: 0.376050  g_loss: 1.802360\n",
      "batch 7  d_loss: 0.433839  g_loss: 1.870707\n",
      "batch 8  d_loss: 0.568093  g_loss: 1.546607\n",
      "batch 9  d_loss: 0.366702  g_loss: 1.721344\n",
      "batch 10  d_loss: 0.399892  g_loss: 1.412313\n",
      "batch 11  d_loss: 0.380823  g_loss: 1.107130\n",
      "batch 12  d_loss: 0.404927  g_loss: 1.281252\n",
      "batch 13  d_loss: 0.401105  g_loss: 1.705773\n",
      "batch 14  d_loss: 0.411587  g_loss: 1.845778\n",
      "batch 15  d_loss: 0.369813  g_loss: 2.116009\n",
      "batch 16  d_loss: 0.355313  g_loss: 1.949318\n",
      "batch 17  d_loss: 0.503485  g_loss: 1.832075\n",
      "batch 18  d_loss: 0.449457  g_loss: 1.830759\n",
      "batch 19  d_loss: 0.540831  g_loss: 1.454446\n",
      "batch 20  d_loss: 0.521640  g_loss: 1.059636\n",
      "batch 21  d_loss: 0.610450  g_loss: 1.346301\n",
      "batch 22  d_loss: 0.564689  g_loss: 1.537917\n",
      "batch 23  d_loss: 0.534782  g_loss: 1.502015\n",
      "batch 24  d_loss: 0.552622  g_loss: 1.347168\n",
      "batch 25  d_loss: 0.567521  g_loss: 1.151313\n",
      "batch 26  d_loss: 0.542474  g_loss: 1.272447\n",
      "batch 27  d_loss: 0.509572  g_loss: 1.339165\n",
      "batch 28  d_loss: 0.580919  g_loss: 1.262370\n",
      "batch 29  d_loss: 0.616323  g_loss: 1.371605\n",
      "batch 30  d_loss: 0.534034  g_loss: 1.316712\n",
      "batch 31  d_loss: 0.676715  g_loss: 1.455599\n",
      "batch 32  d_loss: 0.465412  g_loss: 1.208126\n",
      "batch 33  d_loss: 0.506898  g_loss: 1.448199\n",
      "batch 34  d_loss: 0.502276  g_loss: 1.477344\n",
      "batch 35  d_loss: 0.407326  g_loss: 1.417379\n",
      "batch 36  d_loss: 0.412089  g_loss: 1.520695\n",
      "batch 37  d_loss: 0.540627  g_loss: 1.475290\n",
      "batch 38  d_loss: 0.357840  g_loss: 1.496164\n",
      "batch 39  d_loss: 0.421332  g_loss: 1.283527\n",
      "batch 40  d_loss: 0.417290  g_loss: 1.454974\n",
      "batch 41  d_loss: 0.523832  g_loss: 1.326776\n",
      "batch 42  d_loss: 0.510496  g_loss: 1.591447\n",
      "batch 43  d_loss: 0.466032  g_loss: 1.548871\n",
      "batch 44  d_loss: 0.398882  g_loss: 1.759752\n",
      "batch 45  d_loss: 0.455130  g_loss: 1.589940\n",
      "Epoch is 15\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.371226  g_loss: 1.992460\n",
      "batch 1  d_loss: 0.423042  g_loss: 2.233484\n",
      "batch 2  d_loss: 0.285052  g_loss: 2.451274\n",
      "batch 3  d_loss: 0.303793  g_loss: 2.139669\n",
      "batch 4  d_loss: 0.314086  g_loss: 2.174160\n",
      "batch 5  d_loss: 0.274997  g_loss: 1.868379\n",
      "batch 6  d_loss: 0.270531  g_loss: 1.791836\n",
      "batch 7  d_loss: 0.244417  g_loss: 1.735093\n",
      "batch 8  d_loss: 0.395354  g_loss: 1.766650\n",
      "batch 9  d_loss: 0.483842  g_loss: 1.813198\n",
      "batch 10  d_loss: 0.397563  g_loss: 1.740034\n",
      "batch 11  d_loss: 0.351359  g_loss: 1.858294\n",
      "batch 12  d_loss: 0.248264  g_loss: 1.857069\n",
      "batch 13  d_loss: 0.402676  g_loss: 2.031831\n",
      "batch 14  d_loss: 0.393864  g_loss: 1.817440\n",
      "batch 15  d_loss: 0.357927  g_loss: 1.601301\n",
      "batch 16  d_loss: 0.283148  g_loss: 1.358401\n",
      "batch 17  d_loss: 0.276629  g_loss: 1.650140\n",
      "batch 18  d_loss: 0.271690  g_loss: 1.956076\n",
      "batch 19  d_loss: 0.372990  g_loss: 2.193294\n",
      "batch 20  d_loss: 0.412430  g_loss: 1.958697\n",
      "batch 21  d_loss: 0.342382  g_loss: 1.944406\n",
      "batch 22  d_loss: 0.431733  g_loss: 1.604662\n",
      "batch 23  d_loss: 0.386596  g_loss: 1.386272\n",
      "batch 24  d_loss: 0.513647  g_loss: 1.231982\n",
      "batch 25  d_loss: 0.427507  g_loss: 1.335651\n",
      "batch 26  d_loss: 0.481287  g_loss: 1.592237\n",
      "batch 27  d_loss: 0.599952  g_loss: 1.935925\n",
      "batch 28  d_loss: 0.569822  g_loss: 2.169382\n",
      "batch 29  d_loss: 0.464071  g_loss: 2.087251\n",
      "batch 30  d_loss: 0.632350  g_loss: 1.606087\n",
      "batch 31  d_loss: 0.679996  g_loss: 1.252145\n",
      "batch 32  d_loss: 0.600401  g_loss: 0.976798\n",
      "batch 33  d_loss: 0.515930  g_loss: 1.228010\n",
      "batch 34  d_loss: 0.486644  g_loss: 1.732808\n",
      "batch 35  d_loss: 0.465122  g_loss: 1.885596\n",
      "batch 36  d_loss: 0.469918  g_loss: 2.050891\n",
      "batch 37  d_loss: 0.497686  g_loss: 1.555435\n",
      "batch 38  d_loss: 0.369104  g_loss: 1.641750\n",
      "batch 39  d_loss: 0.445143  g_loss: 1.379167\n",
      "batch 40  d_loss: 0.409276  g_loss: 1.284130\n",
      "batch 41  d_loss: 0.364701  g_loss: 1.435780\n",
      "batch 42  d_loss: 0.407853  g_loss: 1.518659\n",
      "batch 43  d_loss: 0.435483  g_loss: 1.906062\n",
      "batch 44  d_loss: 0.347752  g_loss: 1.982298\n",
      "batch 45  d_loss: 0.425500  g_loss: 2.286303\n",
      "Epoch is 16\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.290408  g_loss: 2.689420\n",
      "batch 1  d_loss: 0.457004  g_loss: 2.470041\n",
      "batch 2  d_loss: 0.305430  g_loss: 2.173048\n",
      "batch 3  d_loss: 0.257180  g_loss: 2.498296\n",
      "batch 4  d_loss: 0.299775  g_loss: 2.243028\n",
      "batch 5  d_loss: 0.389963  g_loss: 1.952592\n",
      "batch 6  d_loss: 0.399515  g_loss: 1.709439\n",
      "batch 7  d_loss: 0.381352  g_loss: 1.682535\n",
      "batch 8  d_loss: 0.375533  g_loss: 1.936942\n",
      "batch 9  d_loss: 0.701398  g_loss: 1.942305\n",
      "batch 10  d_loss: 0.435334  g_loss: 1.573390\n",
      "batch 11  d_loss: 0.366688  g_loss: 1.825900\n",
      "batch 12  d_loss: 0.427228  g_loss: 2.234963\n",
      "batch 13  d_loss: 0.643419  g_loss: 1.906171\n",
      "batch 14  d_loss: 0.560992  g_loss: 1.343655\n",
      "batch 15  d_loss: 0.427880  g_loss: 1.352263\n",
      "batch 16  d_loss: 0.505495  g_loss: 1.467797\n",
      "batch 17  d_loss: 0.492669  g_loss: 1.913866\n",
      "batch 18  d_loss: 0.486377  g_loss: 1.634124\n",
      "batch 19  d_loss: 0.588359  g_loss: 2.066355\n",
      "batch 20  d_loss: 0.607265  g_loss: 1.892306\n",
      "batch 21  d_loss: 0.543199  g_loss: 1.319411\n",
      "batch 22  d_loss: 0.597020  g_loss: 1.330374\n",
      "batch 23  d_loss: 0.516395  g_loss: 1.266136\n",
      "batch 24  d_loss: 0.449809  g_loss: 1.230462\n",
      "batch 25  d_loss: 0.501598  g_loss: 1.423509\n",
      "batch 26  d_loss: 0.449570  g_loss: 1.581879\n",
      "batch 27  d_loss: 0.373313  g_loss: 1.589002\n",
      "batch 28  d_loss: 0.428522  g_loss: 1.473294\n",
      "batch 29  d_loss: 0.328590  g_loss: 1.680035\n",
      "batch 30  d_loss: 0.296137  g_loss: 1.822029\n",
      "batch 31  d_loss: 0.410172  g_loss: 1.610585\n",
      "batch 32  d_loss: 0.421744  g_loss: 1.779010\n",
      "batch 33  d_loss: 0.460027  g_loss: 2.273187\n",
      "batch 34  d_loss: 0.324842  g_loss: 2.234490\n",
      "batch 35  d_loss: 0.485678  g_loss: 2.319752\n",
      "batch 36  d_loss: 0.394350  g_loss: 2.116649\n",
      "batch 37  d_loss: 0.467404  g_loss: 1.764649\n",
      "batch 38  d_loss: 0.396890  g_loss: 1.735791\n",
      "batch 39  d_loss: 0.468220  g_loss: 1.188821\n",
      "batch 40  d_loss: 0.427506  g_loss: 1.528485\n",
      "batch 41  d_loss: 0.479607  g_loss: 1.528337\n",
      "batch 42  d_loss: 0.517698  g_loss: 1.770403\n",
      "batch 43  d_loss: 0.511010  g_loss: 1.684142\n",
      "batch 44  d_loss: 0.470058  g_loss: 1.458796\n",
      "batch 45  d_loss: 0.361130  g_loss: 1.483632\n",
      "Epoch is 17\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.440797  g_loss: 1.661272\n",
      "batch 1  d_loss: 0.476846  g_loss: 1.563802\n",
      "batch 2  d_loss: 0.374817  g_loss: 1.468612\n",
      "batch 3  d_loss: 0.433084  g_loss: 1.867839\n",
      "batch 4  d_loss: 0.338567  g_loss: 1.824919\n",
      "batch 5  d_loss: 0.389041  g_loss: 1.835992\n",
      "batch 6  d_loss: 0.379073  g_loss: 1.875369\n",
      "batch 7  d_loss: 0.395987  g_loss: 1.547588\n",
      "batch 8  d_loss: 0.484635  g_loss: 1.379713\n",
      "batch 9  d_loss: 0.484341  g_loss: 1.249534\n",
      "batch 10  d_loss: 0.427134  g_loss: 1.101052\n",
      "batch 11  d_loss: 0.368990  g_loss: 1.445807\n",
      "batch 12  d_loss: 0.407782  g_loss: 1.304743\n",
      "batch 13  d_loss: 0.464684  g_loss: 1.758951\n",
      "batch 14  d_loss: 0.438512  g_loss: 2.011358\n",
      "batch 15  d_loss: 0.325849  g_loss: 2.013531\n",
      "batch 16  d_loss: 0.420948  g_loss: 1.712357\n",
      "batch 17  d_loss: 0.389533  g_loss: 1.680021\n",
      "batch 18  d_loss: 0.341126  g_loss: 1.807857\n",
      "batch 19  d_loss: 0.444764  g_loss: 1.695296\n",
      "batch 20  d_loss: 0.490349  g_loss: 1.454417\n",
      "batch 21  d_loss: 0.292756  g_loss: 1.494274\n",
      "batch 22  d_loss: 0.368858  g_loss: 1.555804\n",
      "batch 23  d_loss: 0.302255  g_loss: 1.766492\n",
      "batch 24  d_loss: 0.346475  g_loss: 1.912425\n",
      "batch 25  d_loss: 0.338283  g_loss: 2.284847\n",
      "batch 26  d_loss: 0.279703  g_loss: 2.352612\n",
      "batch 27  d_loss: 0.386545  g_loss: 2.108675\n",
      "batch 28  d_loss: 0.327963  g_loss: 1.734218\n",
      "batch 29  d_loss: 0.331217  g_loss: 1.552036\n",
      "batch 30  d_loss: 0.393350  g_loss: 1.538442\n",
      "batch 31  d_loss: 0.679725  g_loss: 1.765743\n",
      "batch 32  d_loss: 0.487656  g_loss: 1.648770\n",
      "batch 33  d_loss: 0.472843  g_loss: 1.997131\n",
      "batch 34  d_loss: 0.300657  g_loss: 2.392500\n",
      "batch 35  d_loss: 0.399187  g_loss: 2.644344\n",
      "batch 36  d_loss: 0.537675  g_loss: 1.374448\n",
      "batch 37  d_loss: 0.793271  g_loss: 0.983899\n",
      "batch 38  d_loss: 0.556098  g_loss: 0.741522\n",
      "batch 39  d_loss: 0.649490  g_loss: 1.385298\n",
      "batch 40  d_loss: 0.587682  g_loss: 2.106630\n",
      "batch 41  d_loss: 0.648307  g_loss: 2.162727\n",
      "batch 42  d_loss: 0.600163  g_loss: 1.799395\n",
      "batch 43  d_loss: 0.499082  g_loss: 1.218057\n",
      "batch 44  d_loss: 0.459379  g_loss: 1.175463\n",
      "batch 45  d_loss: 0.476612  g_loss: 0.938345\n",
      "Epoch is 18\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.526634  g_loss: 1.799900\n",
      "batch 1  d_loss: 0.504259  g_loss: 1.792594\n",
      "batch 2  d_loss: 0.441404  g_loss: 2.114683\n",
      "batch 3  d_loss: 0.497664  g_loss: 2.034017\n",
      "batch 4  d_loss: 0.613804  g_loss: 2.035258\n",
      "batch 5  d_loss: 0.416975  g_loss: 1.502027\n",
      "batch 6  d_loss: 0.403942  g_loss: 1.516893\n",
      "batch 7  d_loss: 0.542276  g_loss: 1.485156\n",
      "batch 8  d_loss: 0.538211  g_loss: 1.378519\n",
      "batch 9  d_loss: 0.428002  g_loss: 1.290692\n",
      "batch 10  d_loss: 0.432696  g_loss: 1.778569\n",
      "batch 11  d_loss: 0.346542  g_loss: 1.764928\n",
      "batch 12  d_loss: 0.399254  g_loss: 1.800991\n",
      "batch 13  d_loss: 0.399324  g_loss: 1.768739\n",
      "batch 14  d_loss: 0.453205  g_loss: 1.527548\n",
      "batch 15  d_loss: 0.327032  g_loss: 1.625792\n",
      "batch 16  d_loss: 0.333558  g_loss: 1.669463\n",
      "batch 17  d_loss: 0.344681  g_loss: 1.331081\n",
      "batch 18  d_loss: 0.386829  g_loss: 1.660948\n",
      "batch 19  d_loss: 0.346898  g_loss: 1.903086\n",
      "batch 20  d_loss: 0.310339  g_loss: 2.126890\n",
      "batch 21  d_loss: 0.278577  g_loss: 2.231650\n",
      "batch 22  d_loss: 0.333217  g_loss: 2.052565\n",
      "batch 23  d_loss: 0.286163  g_loss: 2.054694\n",
      "batch 24  d_loss: 0.278797  g_loss: 1.985090\n",
      "batch 25  d_loss: 0.331885  g_loss: 1.865253\n",
      "batch 26  d_loss: 0.312238  g_loss: 1.574615\n",
      "batch 27  d_loss: 0.306518  g_loss: 1.580543\n",
      "batch 28  d_loss: 0.465794  g_loss: 1.748649\n",
      "batch 29  d_loss: 0.344299  g_loss: 1.798426\n",
      "batch 30  d_loss: 0.355607  g_loss: 2.416541\n",
      "batch 31  d_loss: 0.414155  g_loss: 2.116600\n",
      "batch 32  d_loss: 0.313403  g_loss: 2.036370\n",
      "batch 33  d_loss: 0.479248  g_loss: 1.653540\n",
      "batch 34  d_loss: 0.381992  g_loss: 1.516025\n",
      "batch 35  d_loss: 0.313066  g_loss: 1.497376\n",
      "batch 36  d_loss: 0.444179  g_loss: 1.858994\n",
      "batch 37  d_loss: 0.538239  g_loss: 1.668072\n",
      "batch 38  d_loss: 0.479745  g_loss: 1.803268\n",
      "batch 39  d_loss: 0.483375  g_loss: 1.392245\n",
      "batch 40  d_loss: 0.511913  g_loss: 1.373665\n",
      "batch 41  d_loss: 0.507625  g_loss: 1.412910\n",
      "batch 42  d_loss: 0.521911  g_loss: 1.423456\n",
      "batch 43  d_loss: 0.783425  g_loss: 1.698343\n",
      "batch 44  d_loss: 0.579951  g_loss: 1.729817\n",
      "batch 45  d_loss: 0.589498  g_loss: 1.567588\n",
      "Epoch is 19\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.421897  g_loss: 1.543805\n",
      "batch 1  d_loss: 0.496507  g_loss: 1.536120\n",
      "batch 2  d_loss: 0.397492  g_loss: 1.541025\n",
      "batch 3  d_loss: 0.370774  g_loss: 1.694116\n",
      "batch 4  d_loss: 0.331683  g_loss: 2.101278\n",
      "batch 5  d_loss: 0.373383  g_loss: 1.920233\n",
      "batch 6  d_loss: 0.427699  g_loss: 1.564241\n",
      "batch 7  d_loss: 0.340055  g_loss: 1.467248\n",
      "batch 8  d_loss: 0.422287  g_loss: 1.690584\n",
      "batch 9  d_loss: 0.444590  g_loss: 1.675333\n",
      "batch 10  d_loss: 0.425257  g_loss: 1.523513\n",
      "batch 11  d_loss: 0.364415  g_loss: 1.833434\n",
      "batch 12  d_loss: 0.319581  g_loss: 1.815473\n",
      "batch 13  d_loss: 0.403715  g_loss: 1.674213\n",
      "batch 14  d_loss: 0.457323  g_loss: 1.538494\n",
      "batch 15  d_loss: 0.406177  g_loss: 1.747942\n",
      "batch 16  d_loss: 0.411262  g_loss: 1.857156\n",
      "batch 17  d_loss: 0.383278  g_loss: 1.829436\n",
      "batch 18  d_loss: 0.336304  g_loss: 1.900144\n",
      "batch 19  d_loss: 0.469294  g_loss: 1.579379\n",
      "batch 20  d_loss: 0.377041  g_loss: 1.562131\n",
      "batch 21  d_loss: 0.470281  g_loss: 1.680364\n",
      "batch 22  d_loss: 0.460507  g_loss: 1.801580\n",
      "batch 23  d_loss: 0.433843  g_loss: 1.960322\n",
      "batch 24  d_loss: 0.408792  g_loss: 1.925784\n",
      "batch 25  d_loss: 0.380206  g_loss: 1.906343\n",
      "batch 26  d_loss: 0.360911  g_loss: 1.438515\n",
      "batch 27  d_loss: 0.333995  g_loss: 1.450068\n",
      "batch 28  d_loss: 0.434512  g_loss: 1.233356\n",
      "batch 29  d_loss: 0.379713  g_loss: 1.574700\n",
      "batch 30  d_loss: 0.354027  g_loss: 1.700448\n",
      "batch 31  d_loss: 0.536851  g_loss: 1.988319\n",
      "batch 32  d_loss: 0.339609  g_loss: 2.085004\n",
      "batch 33  d_loss: 0.356717  g_loss: 2.142046\n",
      "batch 34  d_loss: 0.419810  g_loss: 2.293115\n",
      "batch 35  d_loss: 0.446773  g_loss: 1.504430\n",
      "batch 36  d_loss: 0.386301  g_loss: 1.450486\n",
      "batch 37  d_loss: 0.696399  g_loss: 1.261528\n",
      "batch 38  d_loss: 0.460887  g_loss: 1.269654\n",
      "batch 39  d_loss: 0.456704  g_loss: 1.545357\n",
      "batch 40  d_loss: 0.410280  g_loss: 1.700632\n",
      "batch 41  d_loss: 0.506314  g_loss: 2.075484\n",
      "batch 42  d_loss: 0.502413  g_loss: 1.587638\n",
      "batch 43  d_loss: 0.516533  g_loss: 1.292570\n",
      "batch 44  d_loss: 0.458711  g_loss: 1.181837\n",
      "batch 45  d_loss: 0.461050  g_loss: 1.120560\n",
      "Epoch is 20\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.352235  g_loss: 1.321006\n",
      "batch 1  d_loss: 0.312714  g_loss: 1.425277\n",
      "batch 2  d_loss: 0.312945  g_loss: 1.926640\n",
      "batch 3  d_loss: 0.335607  g_loss: 2.062263\n",
      "batch 4  d_loss: 0.418645  g_loss: 2.112148\n",
      "batch 5  d_loss: 0.383518  g_loss: 2.150596\n",
      "batch 6  d_loss: 0.358477  g_loss: 2.126750\n",
      "batch 7  d_loss: 0.461464  g_loss: 2.131313\n",
      "batch 8  d_loss: 0.472803  g_loss: 1.372212\n",
      "batch 9  d_loss: 0.458019  g_loss: 1.547268\n",
      "batch 10  d_loss: 0.450239  g_loss: 1.214360\n",
      "batch 11  d_loss: 0.470968  g_loss: 1.154604\n",
      "batch 12  d_loss: 0.455137  g_loss: 1.689336\n",
      "batch 13  d_loss: 0.364124  g_loss: 2.001606\n",
      "batch 14  d_loss: 0.433356  g_loss: 2.162894\n",
      "batch 15  d_loss: 0.366729  g_loss: 2.347226\n",
      "batch 16  d_loss: 0.275087  g_loss: 2.445801\n",
      "batch 17  d_loss: 0.425446  g_loss: 2.374638\n",
      "batch 18  d_loss: 0.458864  g_loss: 2.108693\n",
      "batch 19  d_loss: 0.492736  g_loss: 1.674435\n",
      "batch 20  d_loss: 0.604437  g_loss: 1.567813\n",
      "batch 21  d_loss: 0.410172  g_loss: 1.664009\n",
      "batch 22  d_loss: 0.435677  g_loss: 1.719994\n",
      "batch 23  d_loss: 0.518007  g_loss: 1.837429\n",
      "batch 24  d_loss: 0.494796  g_loss: 2.031791\n",
      "batch 25  d_loss: 0.584950  g_loss: 1.999512\n",
      "batch 26  d_loss: 0.416590  g_loss: 1.377608\n",
      "batch 27  d_loss: 0.438886  g_loss: 1.502353\n",
      "batch 28  d_loss: 0.531571  g_loss: 1.235507\n",
      "batch 29  d_loss: 0.540762  g_loss: 1.282896\n",
      "batch 30  d_loss: 0.393876  g_loss: 1.542035\n",
      "batch 31  d_loss: 0.643664  g_loss: 1.437761\n",
      "batch 32  d_loss: 0.467957  g_loss: 1.829957\n",
      "batch 33  d_loss: 0.413669  g_loss: 1.749094\n",
      "batch 34  d_loss: 0.367506  g_loss: 1.872184\n",
      "batch 35  d_loss: 0.465506  g_loss: 1.660678\n",
      "batch 36  d_loss: 0.485803  g_loss: 1.360771\n",
      "batch 37  d_loss: 0.586698  g_loss: 1.046092\n",
      "batch 38  d_loss: 0.466574  g_loss: 1.397848\n",
      "batch 39  d_loss: 0.473751  g_loss: 1.641181\n",
      "batch 40  d_loss: 0.463566  g_loss: 2.212660\n",
      "batch 41  d_loss: 0.658555  g_loss: 2.084724\n",
      "batch 42  d_loss: 0.500634  g_loss: 1.511179\n",
      "batch 43  d_loss: 0.468949  g_loss: 1.390701\n",
      "batch 44  d_loss: 0.327389  g_loss: 1.149519\n",
      "batch 45  d_loss: 0.448034  g_loss: 1.485451\n",
      "Epoch is 21\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.321389  g_loss: 1.698533\n",
      "batch 1  d_loss: 0.390310  g_loss: 1.633383\n",
      "batch 2  d_loss: 0.286374  g_loss: 2.458427\n",
      "batch 3  d_loss: 0.349583  g_loss: 2.779918\n",
      "batch 4  d_loss: 0.309964  g_loss: 2.083913\n",
      "batch 5  d_loss: 0.350531  g_loss: 1.949634\n",
      "batch 6  d_loss: 0.353835  g_loss: 1.643351\n",
      "batch 7  d_loss: 0.292571  g_loss: 1.638605\n",
      "batch 8  d_loss: 0.335092  g_loss: 1.702396\n",
      "batch 9  d_loss: 0.390580  g_loss: 1.681151\n",
      "batch 10  d_loss: 0.380579  g_loss: 2.440338\n",
      "batch 11  d_loss: 0.304950  g_loss: 2.378943\n",
      "batch 12  d_loss: 0.390557  g_loss: 2.277457\n",
      "batch 13  d_loss: 0.468952  g_loss: 1.941849\n",
      "batch 14  d_loss: 0.492165  g_loss: 1.649870\n",
      "batch 15  d_loss: 0.303518  g_loss: 1.233735\n",
      "batch 16  d_loss: 0.574024  g_loss: 1.198972\n",
      "batch 17  d_loss: 0.513998  g_loss: 1.514842\n",
      "batch 18  d_loss: 0.439214  g_loss: 1.831526\n",
      "batch 19  d_loss: 0.687582  g_loss: 2.000215\n",
      "batch 20  d_loss: 0.482213  g_loss: 1.506190\n",
      "batch 21  d_loss: 0.535955  g_loss: 0.888825\n",
      "batch 22  d_loss: 0.473727  g_loss: 1.156986\n",
      "batch 23  d_loss: 0.474531  g_loss: 1.323066\n",
      "batch 24  d_loss: 0.507806  g_loss: 1.573147\n",
      "batch 25  d_loss: 0.555495  g_loss: 1.487989\n",
      "batch 26  d_loss: 0.455276  g_loss: 1.584917\n",
      "batch 27  d_loss: 0.530024  g_loss: 1.366434\n",
      "batch 28  d_loss: 0.591684  g_loss: 0.994710\n",
      "batch 29  d_loss: 0.407961  g_loss: 1.025909\n",
      "batch 30  d_loss: 0.416728  g_loss: 0.992401\n",
      "batch 31  d_loss: 0.597085  g_loss: 1.061051\n",
      "batch 32  d_loss: 0.457688  g_loss: 1.397102\n",
      "batch 33  d_loss: 0.453052  g_loss: 2.110901\n",
      "batch 34  d_loss: 0.400612  g_loss: 2.592931\n",
      "batch 35  d_loss: 0.550371  g_loss: 2.243659\n",
      "batch 36  d_loss: 0.533237  g_loss: 2.066652\n",
      "batch 37  d_loss: 0.609239  g_loss: 1.463518\n",
      "batch 38  d_loss: 0.319120  g_loss: 1.106594\n",
      "batch 39  d_loss: 0.448303  g_loss: 1.047734\n",
      "batch 40  d_loss: 0.453061  g_loss: 1.342838\n",
      "batch 41  d_loss: 0.513330  g_loss: 1.580162\n",
      "batch 42  d_loss: 0.318075  g_loss: 1.821651\n",
      "batch 43  d_loss: 0.472266  g_loss: 2.266923\n",
      "batch 44  d_loss: 0.272353  g_loss: 1.933006\n",
      "batch 45  d_loss: 0.247370  g_loss: 2.321439\n",
      "Epoch is 22\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.277372  g_loss: 2.613942\n",
      "batch 1  d_loss: 0.297634  g_loss: 2.796965\n",
      "batch 2  d_loss: 0.159331  g_loss: 2.733400\n",
      "batch 3  d_loss: 0.254923  g_loss: 2.710297\n",
      "batch 4  d_loss: 0.223390  g_loss: 2.353608\n",
      "batch 5  d_loss: 0.227519  g_loss: 2.626969\n",
      "batch 6  d_loss: 0.343290  g_loss: 2.680027\n",
      "batch 7  d_loss: 0.309180  g_loss: 2.202240\n",
      "batch 8  d_loss: 0.425217  g_loss: 2.060410\n",
      "batch 9  d_loss: 0.661431  g_loss: 1.789400\n",
      "batch 10  d_loss: 0.656510  g_loss: 1.344517\n",
      "batch 11  d_loss: 0.454077  g_loss: 1.364731\n",
      "batch 12  d_loss: 0.441793  g_loss: 1.822377\n",
      "batch 13  d_loss: 0.683986  g_loss: 1.560548\n",
      "batch 14  d_loss: 0.767927  g_loss: 1.755610\n",
      "batch 15  d_loss: 0.471941  g_loss: 1.510749\n",
      "batch 16  d_loss: 0.502917  g_loss: 1.566242\n",
      "batch 17  d_loss: 0.546821  g_loss: 1.307642\n",
      "batch 18  d_loss: 0.576660  g_loss: 1.319725\n",
      "batch 19  d_loss: 0.655197  g_loss: 1.242225\n",
      "batch 20  d_loss: 0.598953  g_loss: 1.179970\n",
      "batch 21  d_loss: 0.476168  g_loss: 1.344218\n",
      "batch 22  d_loss: 0.542478  g_loss: 1.088143\n",
      "batch 23  d_loss: 0.533964  g_loss: 1.012072\n",
      "batch 24  d_loss: 0.371371  g_loss: 1.248115\n",
      "batch 25  d_loss: 0.441280  g_loss: 1.526924\n",
      "batch 26  d_loss: 0.356914  g_loss: 1.599988\n",
      "batch 27  d_loss: 0.420647  g_loss: 1.775349\n",
      "batch 28  d_loss: 0.393671  g_loss: 1.816874\n",
      "batch 29  d_loss: 0.338501  g_loss: 1.948478\n",
      "batch 30  d_loss: 0.382825  g_loss: 1.681942\n",
      "batch 31  d_loss: 0.432298  g_loss: 1.725953\n",
      "batch 32  d_loss: 0.334588  g_loss: 1.715379\n",
      "batch 33  d_loss: 0.247711  g_loss: 1.669039\n",
      "batch 34  d_loss: 0.313772  g_loss: 1.759186\n",
      "batch 35  d_loss: 0.327310  g_loss: 1.804767\n",
      "batch 36  d_loss: 0.394947  g_loss: 2.252509\n",
      "batch 37  d_loss: 0.541645  g_loss: 2.048280\n",
      "batch 38  d_loss: 0.321345  g_loss: 1.812657\n",
      "batch 39  d_loss: 0.370134  g_loss: 1.506191\n",
      "batch 40  d_loss: 0.341319  g_loss: 1.627207\n",
      "batch 41  d_loss: 0.413509  g_loss: 1.582578\n",
      "batch 42  d_loss: 0.397497  g_loss: 1.607205\n",
      "batch 43  d_loss: 0.350422  g_loss: 1.417352\n",
      "batch 44  d_loss: 0.394480  g_loss: 1.773530\n",
      "batch 45  d_loss: 0.311803  g_loss: 1.817373\n",
      "Epoch is 23\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.359114  g_loss: 1.826143\n",
      "batch 1  d_loss: 0.374701  g_loss: 1.955174\n",
      "batch 2  d_loss: 0.377511  g_loss: 1.808471\n",
      "batch 3  d_loss: 0.292490  g_loss: 1.877448\n",
      "batch 4  d_loss: 0.288098  g_loss: 1.676896\n",
      "batch 5  d_loss: 0.389082  g_loss: 1.554330\n",
      "batch 6  d_loss: 0.366010  g_loss: 1.202793\n",
      "batch 7  d_loss: 0.440861  g_loss: 1.633394\n",
      "batch 8  d_loss: 0.418228  g_loss: 1.855998\n",
      "batch 9  d_loss: 0.599417  g_loss: 1.466705\n",
      "batch 10  d_loss: 0.377565  g_loss: 1.165965\n",
      "batch 11  d_loss: 0.384520  g_loss: 1.027318\n",
      "batch 12  d_loss: 0.420235  g_loss: 1.097642\n",
      "batch 13  d_loss: 0.602124  g_loss: 1.493761\n",
      "batch 14  d_loss: 0.587987  g_loss: 1.391859\n",
      "batch 15  d_loss: 0.486479  g_loss: 1.281595\n",
      "batch 16  d_loss: 0.503808  g_loss: 1.093167\n",
      "batch 17  d_loss: 0.501597  g_loss: 1.257327\n",
      "batch 18  d_loss: 0.417425  g_loss: 1.330737\n",
      "batch 19  d_loss: 0.597249  g_loss: 1.374261\n",
      "batch 20  d_loss: 0.356249  g_loss: 1.322459\n",
      "batch 21  d_loss: 0.431851  g_loss: 1.503926\n",
      "batch 22  d_loss: 0.376558  g_loss: 1.422699\n",
      "batch 23  d_loss: 0.376985  g_loss: 1.653966\n",
      "batch 24  d_loss: 0.282596  g_loss: 1.708238\n",
      "batch 25  d_loss: 0.431501  g_loss: 1.820148\n",
      "batch 26  d_loss: 0.307353  g_loss: 2.165656\n",
      "batch 27  d_loss: 0.421695  g_loss: 2.084205\n",
      "batch 28  d_loss: 0.484486  g_loss: 1.450553\n",
      "batch 29  d_loss: 0.449741  g_loss: 1.194697\n",
      "batch 30  d_loss: 0.439574  g_loss: 1.640626\n",
      "batch 31  d_loss: 0.551597  g_loss: 1.852427\n",
      "batch 32  d_loss: 0.288330  g_loss: 2.089754\n",
      "batch 33  d_loss: 0.370708  g_loss: 2.272869\n",
      "batch 34  d_loss: 0.383241  g_loss: 2.802208\n",
      "batch 35  d_loss: 0.475892  g_loss: 2.023480\n",
      "batch 36  d_loss: 0.421781  g_loss: 1.687694\n",
      "batch 37  d_loss: 0.518457  g_loss: 1.602418\n",
      "batch 38  d_loss: 0.350312  g_loss: 1.436789\n",
      "batch 39  d_loss: 0.537812  g_loss: 1.399335\n",
      "batch 40  d_loss: 0.528587  g_loss: 1.334757\n",
      "batch 41  d_loss: 0.483598  g_loss: 1.605424\n",
      "batch 42  d_loss: 0.524515  g_loss: 1.600247\n",
      "batch 43  d_loss: 0.622840  g_loss: 1.597635\n",
      "batch 44  d_loss: 0.495341  g_loss: 1.174527\n",
      "batch 45  d_loss: 0.440473  g_loss: 1.662472\n",
      "Epoch is 24\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.428273  g_loss: 1.827856\n",
      "batch 1  d_loss: 0.561409  g_loss: 1.821615\n",
      "batch 2  d_loss: 0.355642  g_loss: 1.843345\n",
      "batch 3  d_loss: 0.410588  g_loss: 1.712047\n",
      "batch 4  d_loss: 0.356958  g_loss: 1.465551\n",
      "batch 5  d_loss: 0.405125  g_loss: 1.689100\n",
      "batch 6  d_loss: 0.431051  g_loss: 1.455883\n",
      "batch 7  d_loss: 0.353568  g_loss: 1.927963\n",
      "batch 8  d_loss: 0.457646  g_loss: 1.647502\n",
      "batch 9  d_loss: 0.736232  g_loss: 1.329670\n",
      "batch 10  d_loss: 0.497333  g_loss: 1.451149\n",
      "batch 11  d_loss: 0.369230  g_loss: 1.509392\n",
      "batch 12  d_loss: 0.320541  g_loss: 1.655783\n",
      "batch 13  d_loss: 0.411586  g_loss: 2.065161\n",
      "batch 14  d_loss: 0.409863  g_loss: 1.881597\n",
      "batch 15  d_loss: 0.281222  g_loss: 1.640764\n",
      "batch 16  d_loss: 0.237540  g_loss: 2.081055\n",
      "batch 17  d_loss: 0.227777  g_loss: 2.001079\n",
      "batch 18  d_loss: 0.244887  g_loss: 1.873274\n",
      "batch 19  d_loss: 0.419115  g_loss: 1.947206\n",
      "batch 20  d_loss: 0.323817  g_loss: 1.625591\n",
      "batch 21  d_loss: 0.392299  g_loss: 1.627733\n",
      "batch 22  d_loss: 0.399254  g_loss: 1.297480\n",
      "batch 23  d_loss: 0.351844  g_loss: 1.541261\n",
      "batch 24  d_loss: 0.297598  g_loss: 1.739513\n",
      "batch 25  d_loss: 0.453493  g_loss: 2.130290\n",
      "batch 26  d_loss: 0.331080  g_loss: 2.136561\n",
      "batch 27  d_loss: 0.373863  g_loss: 1.719499\n",
      "batch 28  d_loss: 0.375683  g_loss: 1.325556\n",
      "batch 29  d_loss: 0.397009  g_loss: 1.313817\n",
      "batch 30  d_loss: 0.369342  g_loss: 1.955490\n",
      "batch 31  d_loss: 0.428251  g_loss: 2.088901\n",
      "batch 32  d_loss: 0.433437  g_loss: 2.560572\n",
      "batch 33  d_loss: 0.441567  g_loss: 2.485618\n",
      "batch 34  d_loss: 0.511408  g_loss: 2.151120\n",
      "batch 35  d_loss: 0.432052  g_loss: 1.689586\n",
      "batch 36  d_loss: 0.399195  g_loss: 1.547643\n",
      "batch 37  d_loss: 0.621769  g_loss: 1.335764\n",
      "batch 38  d_loss: 0.324967  g_loss: 1.279417\n",
      "batch 39  d_loss: 0.436056  g_loss: 1.442560\n",
      "batch 40  d_loss: 0.405608  g_loss: 2.032289\n",
      "batch 41  d_loss: 0.499569  g_loss: 2.265077\n",
      "batch 42  d_loss: 0.470411  g_loss: 2.347464\n",
      "batch 43  d_loss: 0.453692  g_loss: 1.657582\n",
      "batch 44  d_loss: 0.377136  g_loss: 1.794968\n",
      "batch 45  d_loss: 0.310341  g_loss: 1.145479\n",
      "Epoch is 25\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.353845  g_loss: 1.131526\n",
      "batch 1  d_loss: 0.457623  g_loss: 1.405974\n",
      "batch 2  d_loss: 0.340545  g_loss: 1.753181\n",
      "batch 3  d_loss: 0.243604  g_loss: 2.206975\n",
      "batch 4  d_loss: 0.346943  g_loss: 2.291745\n",
      "batch 5  d_loss: 0.535842  g_loss: 2.166121\n",
      "batch 6  d_loss: 0.446536  g_loss: 1.799527\n",
      "batch 7  d_loss: 0.268381  g_loss: 1.506197\n",
      "batch 8  d_loss: 0.516717  g_loss: 1.228366\n",
      "batch 9  d_loss: 0.846251  g_loss: 1.297655\n",
      "batch 10  d_loss: 0.534563  g_loss: 1.295684\n",
      "batch 11  d_loss: 0.363469  g_loss: 1.287016\n",
      "batch 12  d_loss: 0.425387  g_loss: 1.635916\n",
      "batch 13  d_loss: 0.647739  g_loss: 1.631523\n",
      "batch 14  d_loss: 0.562577  g_loss: 1.416209\n",
      "batch 15  d_loss: 0.456026  g_loss: 1.423501\n",
      "batch 16  d_loss: 0.342536  g_loss: 1.647679\n",
      "batch 17  d_loss: 0.379072  g_loss: 1.440731\n",
      "batch 18  d_loss: 0.365137  g_loss: 1.732743\n",
      "batch 19  d_loss: 0.512543  g_loss: 1.584990\n",
      "batch 20  d_loss: 0.439412  g_loss: 1.560382\n",
      "batch 21  d_loss: 0.385804  g_loss: 1.513958\n",
      "batch 22  d_loss: 0.390346  g_loss: 1.386049\n",
      "batch 23  d_loss: 0.405956  g_loss: 1.440924\n",
      "batch 24  d_loss: 0.406814  g_loss: 1.670624\n",
      "batch 25  d_loss: 0.492685  g_loss: 1.799254\n",
      "batch 26  d_loss: 0.384180  g_loss: 1.757527\n",
      "batch 27  d_loss: 0.459427  g_loss: 1.934029\n",
      "batch 28  d_loss: 0.644072  g_loss: 1.772944\n",
      "batch 29  d_loss: 0.356690  g_loss: 1.698931\n",
      "batch 30  d_loss: 0.470852  g_loss: 1.757160\n",
      "batch 31  d_loss: 0.446418  g_loss: 1.667790\n",
      "batch 32  d_loss: 0.350852  g_loss: 1.372345\n",
      "batch 33  d_loss: 0.398378  g_loss: 1.445588\n",
      "batch 34  d_loss: 0.327764  g_loss: 2.026625\n",
      "batch 35  d_loss: 0.387761  g_loss: 2.069450\n",
      "batch 36  d_loss: 0.451177  g_loss: 2.158883\n",
      "batch 37  d_loss: 0.557269  g_loss: 1.639624\n",
      "batch 38  d_loss: 0.409019  g_loss: 1.642032\n",
      "batch 39  d_loss: 0.503644  g_loss: 1.539122\n",
      "batch 40  d_loss: 0.422569  g_loss: 1.190763\n",
      "batch 41  d_loss: 0.506567  g_loss: 1.148494\n",
      "batch 42  d_loss: 0.418076  g_loss: 1.426747\n",
      "batch 43  d_loss: 0.499382  g_loss: 1.758217\n",
      "batch 44  d_loss: 0.413547  g_loss: 1.758948\n",
      "batch 45  d_loss: 0.450239  g_loss: 2.272170\n",
      "Epoch is 26\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.376898  g_loss: 1.915085\n",
      "batch 1  d_loss: 0.347985  g_loss: 1.692198\n",
      "batch 2  d_loss: 0.356842  g_loss: 1.878445\n",
      "batch 3  d_loss: 0.311560  g_loss: 1.694116\n",
      "batch 4  d_loss: 0.279021  g_loss: 1.806317\n",
      "batch 5  d_loss: 0.459359  g_loss: 1.637645\n",
      "batch 6  d_loss: 0.376820  g_loss: 1.865978\n",
      "batch 7  d_loss: 0.285101  g_loss: 1.447545\n",
      "batch 8  d_loss: 0.440631  g_loss: 1.899634\n",
      "batch 9  d_loss: 0.667614  g_loss: 1.514278\n",
      "batch 10  d_loss: 0.629426  g_loss: 1.257444\n",
      "batch 11  d_loss: 0.376264  g_loss: 1.459123\n",
      "batch 12  d_loss: 0.327168  g_loss: 1.459597\n",
      "batch 13  d_loss: 0.472332  g_loss: 1.618372\n",
      "batch 14  d_loss: 0.561773  g_loss: 1.493957\n",
      "batch 15  d_loss: 0.366991  g_loss: 1.604049\n",
      "batch 16  d_loss: 0.499574  g_loss: 1.615151\n",
      "batch 17  d_loss: 0.549738  g_loss: 1.514972\n",
      "batch 18  d_loss: 0.571251  g_loss: 1.612671\n",
      "batch 19  d_loss: 0.760300  g_loss: 1.409684\n",
      "batch 20  d_loss: 0.652475  g_loss: 1.466517\n",
      "batch 21  d_loss: 0.573729  g_loss: 1.337270\n",
      "batch 22  d_loss: 0.471225  g_loss: 1.496423\n",
      "batch 23  d_loss: 0.526078  g_loss: 1.278420\n",
      "batch 24  d_loss: 0.558218  g_loss: 1.001407\n",
      "batch 25  d_loss: 0.566152  g_loss: 1.258099\n",
      "batch 26  d_loss: 0.474908  g_loss: 1.751507\n",
      "batch 27  d_loss: 0.483296  g_loss: 1.646314\n",
      "batch 28  d_loss: 0.525436  g_loss: 1.677388\n",
      "batch 29  d_loss: 0.402163  g_loss: 1.585804\n",
      "batch 30  d_loss: 0.399827  g_loss: 1.468691\n",
      "batch 31  d_loss: 0.555356  g_loss: 1.075782\n",
      "batch 32  d_loss: 0.421861  g_loss: 1.307068\n",
      "batch 33  d_loss: 0.439412  g_loss: 1.731758\n",
      "batch 34  d_loss: 0.411896  g_loss: 2.170444\n",
      "batch 35  d_loss: 0.456964  g_loss: 2.032032\n",
      "batch 36  d_loss: 0.454954  g_loss: 2.015018\n",
      "batch 37  d_loss: 0.635579  g_loss: 1.785519\n",
      "batch 38  d_loss: 0.343510  g_loss: 0.988166\n",
      "batch 39  d_loss: 0.464084  g_loss: 1.272264\n",
      "batch 40  d_loss: 0.460687  g_loss: 1.070710\n",
      "batch 41  d_loss: 0.542058  g_loss: 1.490026\n",
      "batch 42  d_loss: 0.508205  g_loss: 1.709942\n",
      "batch 43  d_loss: 0.526258  g_loss: 1.883079\n",
      "batch 44  d_loss: 0.492330  g_loss: 2.053453\n",
      "batch 45  d_loss: 0.319135  g_loss: 1.890741\n",
      "Epoch is 27\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.410818  g_loss: 1.384983\n",
      "batch 1  d_loss: 0.415748  g_loss: 1.354191\n",
      "batch 2  d_loss: 0.397329  g_loss: 1.352605\n",
      "batch 3  d_loss: 0.450332  g_loss: 1.098833\n",
      "batch 4  d_loss: 0.436548  g_loss: 1.452890\n",
      "batch 5  d_loss: 0.562442  g_loss: 1.112779\n",
      "batch 6  d_loss: 0.546824  g_loss: 1.231229\n",
      "batch 7  d_loss: 0.514525  g_loss: 1.517674\n",
      "batch 8  d_loss: 0.593104  g_loss: 1.500645\n",
      "batch 9  d_loss: 0.559003  g_loss: 1.464252\n",
      "batch 10  d_loss: 0.569271  g_loss: 1.091171\n",
      "batch 11  d_loss: 0.502215  g_loss: 0.967447\n",
      "batch 12  d_loss: 0.554588  g_loss: 0.997064\n",
      "batch 13  d_loss: 0.658810  g_loss: 1.145892\n",
      "batch 14  d_loss: 0.527696  g_loss: 1.167931\n",
      "batch 15  d_loss: 0.478393  g_loss: 1.120590\n",
      "batch 16  d_loss: 0.516121  g_loss: 1.355658\n",
      "batch 17  d_loss: 0.430705  g_loss: 1.673809\n",
      "batch 18  d_loss: 0.420867  g_loss: 1.763010\n",
      "batch 19  d_loss: 0.548281  g_loss: 1.843168\n",
      "batch 20  d_loss: 0.492221  g_loss: 1.746821\n",
      "batch 21  d_loss: 0.419758  g_loss: 1.369735\n",
      "batch 22  d_loss: 0.406040  g_loss: 1.487888\n",
      "batch 23  d_loss: 0.392913  g_loss: 1.081660\n",
      "batch 24  d_loss: 0.382616  g_loss: 1.043659\n",
      "batch 25  d_loss: 0.414880  g_loss: 1.042361\n",
      "batch 26  d_loss: 0.403373  g_loss: 0.973327\n",
      "batch 27  d_loss: 0.309458  g_loss: 1.279688\n",
      "batch 28  d_loss: 0.382395  g_loss: 1.768610\n",
      "batch 29  d_loss: 0.377432  g_loss: 1.828467\n",
      "batch 30  d_loss: 0.345821  g_loss: 1.747631\n",
      "batch 31  d_loss: 0.574786  g_loss: 1.823132\n",
      "batch 32  d_loss: 0.361221  g_loss: 1.642020\n",
      "batch 33  d_loss: 0.275671  g_loss: 1.430691\n",
      "batch 34  d_loss: 0.331617  g_loss: 1.590561\n",
      "batch 35  d_loss: 0.333472  g_loss: 1.785024\n",
      "batch 36  d_loss: 0.435245  g_loss: 1.874310\n",
      "batch 37  d_loss: 0.667206  g_loss: 1.688134\n",
      "batch 38  d_loss: 0.278414  g_loss: 1.630842\n",
      "batch 39  d_loss: 0.328414  g_loss: 1.400360\n",
      "batch 40  d_loss: 0.294150  g_loss: 1.577439\n",
      "batch 41  d_loss: 0.560394  g_loss: 1.519865\n",
      "batch 42  d_loss: 0.626711  g_loss: 1.394993\n",
      "batch 43  d_loss: 0.512880  g_loss: 1.490720\n",
      "batch 44  d_loss: 0.608761  g_loss: 1.403486\n",
      "batch 45  d_loss: 0.452072  g_loss: 1.354635\n",
      "Epoch is 28\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.396046  g_loss: 1.361297\n",
      "batch 1  d_loss: 0.460118  g_loss: 1.683437\n",
      "batch 2  d_loss: 0.415317  g_loss: 1.877357\n",
      "batch 3  d_loss: 0.385842  g_loss: 2.028006\n",
      "batch 4  d_loss: 0.342876  g_loss: 2.682908\n",
      "batch 5  d_loss: 0.628222  g_loss: 2.216498\n",
      "batch 6  d_loss: 0.538182  g_loss: 1.686539\n",
      "batch 7  d_loss: 0.324419  g_loss: 1.628628\n",
      "batch 8  d_loss: 0.520746  g_loss: 1.503379\n",
      "batch 9  d_loss: 0.858248  g_loss: 1.308557\n",
      "batch 10  d_loss: 0.701560  g_loss: 1.302710\n",
      "batch 11  d_loss: 0.523028  g_loss: 1.584596\n",
      "batch 12  d_loss: 0.467757  g_loss: 2.263728\n",
      "batch 13  d_loss: 0.699978  g_loss: 2.272957\n",
      "batch 14  d_loss: 0.591000  g_loss: 2.173596\n",
      "batch 15  d_loss: 0.377841  g_loss: 2.342269\n",
      "batch 16  d_loss: 0.419680  g_loss: 1.787545\n",
      "batch 17  d_loss: 0.449945  g_loss: 1.418540\n",
      "batch 18  d_loss: 0.409272  g_loss: 1.198374\n",
      "batch 19  d_loss: 0.548006  g_loss: 1.635777\n",
      "batch 20  d_loss: 0.479797  g_loss: 1.800809\n",
      "batch 21  d_loss: 0.460894  g_loss: 1.631892\n",
      "batch 22  d_loss: 0.345537  g_loss: 1.741674\n",
      "batch 23  d_loss: 0.526860  g_loss: 1.751505\n",
      "batch 24  d_loss: 0.449273  g_loss: 1.454520\n",
      "batch 25  d_loss: 0.439072  g_loss: 1.079511\n",
      "batch 26  d_loss: 0.478744  g_loss: 1.374709\n",
      "batch 27  d_loss: 0.498233  g_loss: 1.366472\n",
      "batch 28  d_loss: 0.614707  g_loss: 1.368169\n",
      "batch 29  d_loss: 0.472594  g_loss: 1.482914\n",
      "batch 30  d_loss: 0.459819  g_loss: 1.587189\n",
      "batch 31  d_loss: 0.606126  g_loss: 1.606787\n",
      "batch 32  d_loss: 0.401727  g_loss: 1.378867\n",
      "batch 33  d_loss: 0.303507  g_loss: 1.508348\n",
      "batch 34  d_loss: 0.396734  g_loss: 1.490995\n",
      "batch 35  d_loss: 0.401668  g_loss: 1.319893\n",
      "batch 36  d_loss: 0.454219  g_loss: 1.283175\n",
      "batch 37  d_loss: 0.667557  g_loss: 1.131162\n",
      "batch 38  d_loss: 0.498121  g_loss: 1.035479\n",
      "batch 39  d_loss: 0.524504  g_loss: 1.134876\n",
      "batch 40  d_loss: 0.455874  g_loss: 1.540115\n",
      "batch 41  d_loss: 0.668034  g_loss: 1.456293\n",
      "batch 42  d_loss: 0.624240  g_loss: 1.345285\n",
      "batch 43  d_loss: 0.599739  g_loss: 1.217239\n",
      "batch 44  d_loss: 0.602600  g_loss: 1.214279\n",
      "batch 45  d_loss: 0.435991  g_loss: 1.131551\n",
      "Epoch is 29\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.433502  g_loss: 1.060155\n",
      "batch 1  d_loss: 0.453698  g_loss: 1.294024\n",
      "batch 2  d_loss: 0.430499  g_loss: 1.332858\n",
      "batch 3  d_loss: 0.438144  g_loss: 1.488381\n",
      "batch 4  d_loss: 0.412454  g_loss: 1.412737\n",
      "batch 5  d_loss: 0.485253  g_loss: 1.499445\n",
      "batch 6  d_loss: 0.506337  g_loss: 1.224628\n",
      "batch 7  d_loss: 0.438329  g_loss: 1.161861\n",
      "batch 8  d_loss: 0.491289  g_loss: 1.292899\n",
      "batch 9  d_loss: 0.612412  g_loss: 1.050866\n",
      "batch 10  d_loss: 0.601359  g_loss: 1.187207\n",
      "batch 11  d_loss: 0.453112  g_loss: 1.280730\n",
      "batch 12  d_loss: 0.404274  g_loss: 1.417849\n",
      "batch 13  d_loss: 0.534707  g_loss: 1.344424\n",
      "batch 14  d_loss: 0.550659  g_loss: 1.414553\n",
      "batch 15  d_loss: 0.431001  g_loss: 1.346679\n",
      "batch 16  d_loss: 0.387601  g_loss: 1.490294\n",
      "batch 17  d_loss: 0.370504  g_loss: 1.429532\n",
      "batch 18  d_loss: 0.409616  g_loss: 1.469693\n",
      "batch 19  d_loss: 0.488134  g_loss: 1.406928\n",
      "batch 20  d_loss: 0.498459  g_loss: 1.387275\n",
      "batch 21  d_loss: 0.442835  g_loss: 1.294853\n",
      "batch 22  d_loss: 0.551971  g_loss: 1.069365\n",
      "batch 23  d_loss: 0.454517  g_loss: 1.721826\n",
      "batch 24  d_loss: 0.316127  g_loss: 1.462317\n",
      "batch 25  d_loss: 0.425050  g_loss: 1.497373\n",
      "batch 26  d_loss: 0.407353  g_loss: 1.378163\n",
      "batch 27  d_loss: 0.482925  g_loss: 1.559802\n",
      "batch 28  d_loss: 0.530627  g_loss: 1.524402\n",
      "batch 29  d_loss: 0.497793  g_loss: 1.124752\n",
      "batch 30  d_loss: 0.412627  g_loss: 1.207667\n",
      "batch 31  d_loss: 0.661937  g_loss: 1.203679\n",
      "batch 32  d_loss: 0.487846  g_loss: 1.252921\n",
      "batch 33  d_loss: 0.369976  g_loss: 1.559063\n",
      "batch 34  d_loss: 0.403843  g_loss: 1.765948\n",
      "batch 35  d_loss: 0.422052  g_loss: 1.608857\n",
      "batch 36  d_loss: 0.400476  g_loss: 1.391479\n",
      "batch 37  d_loss: 0.567562  g_loss: 1.108306\n",
      "batch 38  d_loss: 0.347745  g_loss: 1.025111\n",
      "batch 39  d_loss: 0.502262  g_loss: 1.134319\n",
      "batch 40  d_loss: 0.404952  g_loss: 1.162957\n",
      "batch 41  d_loss: 0.486219  g_loss: 1.606317\n",
      "batch 42  d_loss: 0.400102  g_loss: 1.592352\n",
      "batch 43  d_loss: 0.500653  g_loss: 1.913910\n",
      "batch 44  d_loss: 0.419227  g_loss: 1.711166\n",
      "batch 45  d_loss: 0.366660  g_loss: 1.516067\n",
      "Epoch is 30\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.401673  g_loss: 1.537443\n",
      "batch 1  d_loss: 0.465106  g_loss: 1.336680\n",
      "batch 2  d_loss: 0.323080  g_loss: 1.989213\n",
      "batch 3  d_loss: 0.375242  g_loss: 2.005127\n",
      "batch 4  d_loss: 0.335847  g_loss: 1.785942\n",
      "batch 5  d_loss: 0.522210  g_loss: 1.671183\n",
      "batch 6  d_loss: 0.452574  g_loss: 1.660425\n",
      "batch 7  d_loss: 0.372522  g_loss: 1.339450\n",
      "batch 8  d_loss: 0.427085  g_loss: 1.752914\n",
      "batch 9  d_loss: 0.431000  g_loss: 1.906728\n",
      "batch 10  d_loss: 0.470478  g_loss: 1.953249\n",
      "batch 11  d_loss: 0.424153  g_loss: 1.619154\n",
      "batch 12  d_loss: 0.532663  g_loss: 1.442289\n",
      "batch 13  d_loss: 0.504648  g_loss: 1.256793\n",
      "batch 14  d_loss: 0.659307  g_loss: 1.105350\n",
      "batch 15  d_loss: 0.488542  g_loss: 1.094282\n",
      "batch 16  d_loss: 0.567757  g_loss: 1.489344\n",
      "batch 17  d_loss: 0.464323  g_loss: 1.550385\n",
      "batch 18  d_loss: 0.487014  g_loss: 1.680905\n",
      "batch 19  d_loss: 0.449919  g_loss: 1.571486\n",
      "batch 20  d_loss: 0.594271  g_loss: 1.422224\n",
      "batch 21  d_loss: 0.458129  g_loss: 1.427752\n",
      "batch 22  d_loss: 0.536136  g_loss: 1.286433\n",
      "batch 23  d_loss: 0.444794  g_loss: 1.253902\n",
      "batch 24  d_loss: 0.304554  g_loss: 1.513183\n",
      "batch 25  d_loss: 0.368547  g_loss: 1.915002\n",
      "batch 26  d_loss: 0.329955  g_loss: 2.069010\n",
      "batch 27  d_loss: 0.411149  g_loss: 1.950952\n",
      "batch 28  d_loss: 0.404610  g_loss: 1.554633\n",
      "batch 29  d_loss: 0.385921  g_loss: 1.532940\n",
      "batch 30  d_loss: 0.314065  g_loss: 1.342844\n",
      "batch 31  d_loss: 0.411230  g_loss: 1.866961\n",
      "batch 32  d_loss: 0.298835  g_loss: 1.839087\n",
      "batch 33  d_loss: 0.191145  g_loss: 1.757724\n",
      "batch 34  d_loss: 0.222694  g_loss: 2.309482\n",
      "batch 35  d_loss: 0.213629  g_loss: 2.219194\n",
      "batch 36  d_loss: 0.313667  g_loss: 2.228521\n",
      "batch 37  d_loss: 0.418256  g_loss: 1.953654\n",
      "batch 38  d_loss: 0.240907  g_loss: 1.740386\n",
      "batch 39  d_loss: 0.278922  g_loss: 2.372759\n",
      "batch 40  d_loss: 0.184897  g_loss: 3.064674\n",
      "batch 41  d_loss: 0.335419  g_loss: 3.621460\n",
      "batch 42  d_loss: 0.236298  g_loss: 3.862652\n",
      "batch 43  d_loss: 0.197872  g_loss: 3.822044\n",
      "batch 44  d_loss: 0.165718  g_loss: 4.329007\n",
      "batch 45  d_loss: 0.234828  g_loss: 4.143766\n",
      "Epoch is 31\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.162752  g_loss: 4.455916\n",
      "batch 1  d_loss: 0.137280  g_loss: 4.636684\n",
      "batch 2  d_loss: 0.205007  g_loss: 3.774264\n",
      "batch 3  d_loss: 0.223552  g_loss: 3.243970\n",
      "batch 4  d_loss: 0.193821  g_loss: 3.110513\n",
      "batch 5  d_loss: 0.200921  g_loss: 3.147940\n",
      "batch 6  d_loss: 0.384261  g_loss: 2.132281\n",
      "batch 7  d_loss: 0.384510  g_loss: 2.659241\n",
      "batch 8  d_loss: 0.562114  g_loss: 2.613460\n",
      "batch 9  d_loss: 1.047990  g_loss: 2.170473\n",
      "batch 10  d_loss: 0.777410  g_loss: 2.014657\n",
      "batch 11  d_loss: 0.422753  g_loss: 1.954394\n",
      "batch 12  d_loss: 0.179133  g_loss: 1.897736\n",
      "batch 13  d_loss: 0.493657  g_loss: 1.832894\n",
      "batch 14  d_loss: 0.336159  g_loss: 2.000078\n",
      "batch 15  d_loss: 0.223677  g_loss: 1.804682\n",
      "batch 16  d_loss: 0.453106  g_loss: 1.925387\n",
      "batch 17  d_loss: 0.365293  g_loss: 1.997315\n",
      "batch 18  d_loss: 0.282026  g_loss: 2.372425\n",
      "batch 19  d_loss: 0.683756  g_loss: 2.298671\n",
      "batch 20  d_loss: 0.567360  g_loss: 1.675462\n",
      "batch 21  d_loss: 0.424760  g_loss: 1.417850\n",
      "batch 22  d_loss: 0.339210  g_loss: 1.831156\n",
      "batch 23  d_loss: 0.527883  g_loss: 1.170868\n",
      "batch 24  d_loss: 0.357930  g_loss: 1.637459\n",
      "batch 25  d_loss: 0.365332  g_loss: 1.886627\n",
      "batch 26  d_loss: 0.300479  g_loss: 1.503721\n",
      "batch 27  d_loss: 0.273550  g_loss: 1.999568\n",
      "batch 28  d_loss: 0.295788  g_loss: 1.712086\n",
      "batch 29  d_loss: 0.252192  g_loss: 1.912435\n",
      "batch 30  d_loss: 0.245717  g_loss: 2.050335\n",
      "batch 31  d_loss: 0.280982  g_loss: 2.102217\n",
      "batch 32  d_loss: 0.256224  g_loss: 2.364617\n",
      "batch 33  d_loss: 0.221126  g_loss: 2.483739\n",
      "batch 34  d_loss: 0.171286  g_loss: 2.398640\n",
      "batch 35  d_loss: 0.214876  g_loss: 2.489174\n",
      "batch 36  d_loss: 0.376640  g_loss: 2.311202\n",
      "batch 37  d_loss: 0.803434  g_loss: 1.329879\n",
      "batch 38  d_loss: 0.450796  g_loss: 1.257074\n",
      "batch 39  d_loss: 0.377636  g_loss: 1.640097\n",
      "batch 40  d_loss: 0.470482  g_loss: 2.259251\n",
      "batch 41  d_loss: 0.989379  g_loss: 2.251970\n",
      "batch 42  d_loss: 0.896942  g_loss: 2.522232\n",
      "batch 43  d_loss: 0.819707  g_loss: 1.864142\n",
      "batch 44  d_loss: 0.541863  g_loss: 1.361873\n",
      "batch 45  d_loss: 0.404347  g_loss: 1.097898\n",
      "Epoch is 32\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.486222  g_loss: 1.391119\n",
      "batch 1  d_loss: 0.505867  g_loss: 1.432616\n",
      "batch 2  d_loss: 0.339875  g_loss: 1.909951\n",
      "batch 3  d_loss: 0.334359  g_loss: 2.161656\n",
      "batch 4  d_loss: 0.387394  g_loss: 2.273490\n",
      "batch 5  d_loss: 0.440484  g_loss: 2.406456\n",
      "batch 6  d_loss: 0.396737  g_loss: 1.901711\n",
      "batch 7  d_loss: 0.359123  g_loss: 1.712075\n",
      "batch 8  d_loss: 0.305895  g_loss: 1.494441\n",
      "batch 9  d_loss: 0.502831  g_loss: 1.718215\n",
      "batch 10  d_loss: 0.405606  g_loss: 1.287230\n",
      "batch 11  d_loss: 0.397126  g_loss: 1.352075\n",
      "batch 12  d_loss: 0.374342  g_loss: 1.371626\n",
      "batch 13  d_loss: 0.346801  g_loss: 1.576033\n",
      "batch 14  d_loss: 0.444663  g_loss: 1.566691\n",
      "batch 15  d_loss: 0.460967  g_loss: 1.636412\n",
      "batch 16  d_loss: 0.340065  g_loss: 1.805324\n",
      "batch 17  d_loss: 0.316174  g_loss: 1.676152\n",
      "batch 18  d_loss: 0.320947  g_loss: 1.846428\n",
      "batch 19  d_loss: 0.429050  g_loss: 1.469754\n",
      "batch 20  d_loss: 0.484856  g_loss: 1.623063\n",
      "batch 21  d_loss: 0.385969  g_loss: 1.437417\n",
      "batch 22  d_loss: 0.412048  g_loss: 1.435366\n",
      "batch 23  d_loss: 0.358142  g_loss: 1.073190\n",
      "batch 24  d_loss: 0.503881  g_loss: 1.050717\n",
      "batch 25  d_loss: 0.494793  g_loss: 1.599198\n",
      "batch 26  d_loss: 0.401741  g_loss: 1.890182\n",
      "batch 27  d_loss: 0.446647  g_loss: 2.036801\n",
      "batch 28  d_loss: 0.403201  g_loss: 2.030180\n",
      "batch 29  d_loss: 0.506875  g_loss: 1.694487\n",
      "batch 30  d_loss: 0.313873  g_loss: 1.588001\n",
      "batch 31  d_loss: 0.599784  g_loss: 1.091236\n",
      "batch 32  d_loss: 0.474519  g_loss: 1.514884\n",
      "batch 33  d_loss: 0.400102  g_loss: 1.223204\n",
      "batch 34  d_loss: 0.333162  g_loss: 1.880382\n",
      "batch 35  d_loss: 0.305259  g_loss: 2.353954\n",
      "batch 36  d_loss: 0.364185  g_loss: 2.257292\n",
      "batch 37  d_loss: 0.661813  g_loss: 2.206696\n",
      "batch 38  d_loss: 0.293424  g_loss: 1.765896\n",
      "batch 39  d_loss: 0.320661  g_loss: 1.545441\n",
      "batch 40  d_loss: 0.236390  g_loss: 1.332036\n",
      "batch 41  d_loss: 0.514973  g_loss: 1.464300\n",
      "batch 42  d_loss: 0.398799  g_loss: 1.687186\n",
      "batch 43  d_loss: 0.396243  g_loss: 1.724477\n",
      "batch 44  d_loss: 0.391424  g_loss: 1.744619\n",
      "batch 45  d_loss: 0.392176  g_loss: 1.879171\n",
      "Epoch is 33\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.267349  g_loss: 2.050151\n",
      "batch 1  d_loss: 0.318820  g_loss: 2.374762\n",
      "batch 2  d_loss: 0.286262  g_loss: 2.223505\n",
      "batch 3  d_loss: 0.339730  g_loss: 2.401527\n",
      "batch 4  d_loss: 0.337577  g_loss: 2.191608\n",
      "batch 5  d_loss: 0.494263  g_loss: 1.793903\n",
      "batch 6  d_loss: 0.412368  g_loss: 1.974462\n",
      "batch 7  d_loss: 0.254979  g_loss: 2.411381\n",
      "batch 8  d_loss: 0.473310  g_loss: 2.018280\n",
      "batch 9  d_loss: 0.432159  g_loss: 1.778971\n",
      "batch 10  d_loss: 0.521775  g_loss: 1.862679\n",
      "batch 11  d_loss: 0.401036  g_loss: 1.938136\n",
      "batch 12  d_loss: 0.318725  g_loss: 1.704771\n",
      "batch 13  d_loss: 0.531464  g_loss: 2.127427\n",
      "batch 14  d_loss: 0.498429  g_loss: 2.528275\n",
      "batch 15  d_loss: 0.476037  g_loss: 2.228866\n",
      "batch 16  d_loss: 0.528922  g_loss: 1.982324\n",
      "batch 17  d_loss: 0.609905  g_loss: 1.850986\n",
      "batch 18  d_loss: 0.365815  g_loss: 1.340623\n",
      "batch 19  d_loss: 0.496706  g_loss: 1.194551\n",
      "batch 20  d_loss: 0.452613  g_loss: 0.987837\n",
      "batch 21  d_loss: 0.470470  g_loss: 1.170724\n",
      "batch 22  d_loss: 0.402462  g_loss: 2.011497\n",
      "batch 23  d_loss: 0.438165  g_loss: 2.022474\n",
      "batch 24  d_loss: 0.284497  g_loss: 2.133223\n",
      "batch 25  d_loss: 0.385419  g_loss: 2.120965\n",
      "batch 26  d_loss: 0.284520  g_loss: 1.930864\n",
      "batch 27  d_loss: 0.289965  g_loss: 1.614939\n",
      "batch 28  d_loss: 0.332729  g_loss: 1.855188\n",
      "batch 29  d_loss: 0.265539  g_loss: 1.650793\n",
      "batch 30  d_loss: 0.338919  g_loss: 1.738845\n",
      "batch 31  d_loss: 0.482492  g_loss: 1.979463\n",
      "batch 32  d_loss: 0.308609  g_loss: 1.888063\n",
      "batch 33  d_loss: 0.274285  g_loss: 2.117421\n",
      "batch 34  d_loss: 0.250826  g_loss: 2.140994\n",
      "batch 35  d_loss: 0.306207  g_loss: 1.955780\n",
      "batch 36  d_loss: 0.403616  g_loss: 1.804070\n",
      "batch 37  d_loss: 0.696885  g_loss: 1.268295\n",
      "batch 38  d_loss: 0.347917  g_loss: 0.932060\n",
      "batch 39  d_loss: 0.470508  g_loss: 1.033995\n",
      "batch 40  d_loss: 0.524906  g_loss: 1.490523\n",
      "batch 41  d_loss: 0.700835  g_loss: 2.032702\n",
      "batch 42  d_loss: 0.741504  g_loss: 2.187585\n",
      "batch 43  d_loss: 0.806482  g_loss: 1.516344\n",
      "batch 44  d_loss: 0.752495  g_loss: 1.062935\n",
      "batch 45  d_loss: 0.625570  g_loss: 1.047430\n",
      "Epoch is 34\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.731994  g_loss: 1.105324\n",
      "batch 1  d_loss: 0.594092  g_loss: 1.385530\n",
      "batch 2  d_loss: 0.519677  g_loss: 1.999135\n",
      "batch 3  d_loss: 0.415472  g_loss: 1.599516\n",
      "batch 4  d_loss: 0.442046  g_loss: 1.799346\n",
      "batch 5  d_loss: 0.608990  g_loss: 1.501896\n",
      "batch 6  d_loss: 0.415449  g_loss: 1.177082\n",
      "batch 7  d_loss: 0.459322  g_loss: 1.093650\n",
      "batch 8  d_loss: 0.540055  g_loss: 1.412800\n",
      "batch 9  d_loss: 0.484465  g_loss: 1.344556\n",
      "batch 10  d_loss: 0.415432  g_loss: 1.578318\n",
      "batch 11  d_loss: 0.503756  g_loss: 1.242439\n",
      "batch 12  d_loss: 0.472212  g_loss: 1.185753\n",
      "batch 13  d_loss: 0.507216  g_loss: 1.180021\n",
      "batch 14  d_loss: 0.441918  g_loss: 1.203508\n",
      "batch 15  d_loss: 0.449522  g_loss: 1.289798\n",
      "batch 16  d_loss: 0.415583  g_loss: 1.478945\n",
      "batch 17  d_loss: 0.406577  g_loss: 1.460489\n",
      "batch 18  d_loss: 0.396814  g_loss: 1.800816\n",
      "batch 19  d_loss: 0.407418  g_loss: 1.723710\n",
      "batch 20  d_loss: 0.369046  g_loss: 1.642197\n",
      "batch 21  d_loss: 0.277696  g_loss: 1.611049\n",
      "batch 22  d_loss: 0.413328  g_loss: 1.462051\n",
      "batch 23  d_loss: 0.416809  g_loss: 1.477843\n",
      "batch 24  d_loss: 0.360717  g_loss: 2.258408\n",
      "batch 25  d_loss: 0.445645  g_loss: 2.187117\n",
      "batch 26  d_loss: 0.314246  g_loss: 2.011275\n",
      "batch 27  d_loss: 0.431749  g_loss: 1.696653\n",
      "batch 28  d_loss: 0.601127  g_loss: 1.090917\n",
      "batch 29  d_loss: 0.390904  g_loss: 1.161506\n",
      "batch 30  d_loss: 0.387425  g_loss: 1.447720\n",
      "batch 31  d_loss: 0.450736  g_loss: 1.641492\n",
      "batch 32  d_loss: 0.421942  g_loss: 1.911413\n",
      "batch 33  d_loss: 0.405829  g_loss: 1.984933\n",
      "batch 34  d_loss: 0.306627  g_loss: 2.026650\n",
      "batch 35  d_loss: 0.410132  g_loss: 1.571945\n",
      "batch 36  d_loss: 0.607981  g_loss: 1.342670\n",
      "batch 37  d_loss: 0.838225  g_loss: 0.824951\n",
      "batch 38  d_loss: 0.713773  g_loss: 1.090145\n",
      "batch 39  d_loss: 0.670415  g_loss: 1.340406\n",
      "batch 40  d_loss: 0.738729  g_loss: 1.305230\n",
      "batch 41  d_loss: 1.075496  g_loss: 1.868354\n",
      "batch 42  d_loss: 0.860723  g_loss: 1.790085\n",
      "batch 43  d_loss: 0.906999  g_loss: 1.337825\n",
      "batch 44  d_loss: 0.661768  g_loss: 1.209576\n",
      "batch 45  d_loss: 0.564734  g_loss: 1.096987\n",
      "Epoch is 35\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.489958  g_loss: 1.202645\n",
      "batch 1  d_loss: 0.488204  g_loss: 1.265717\n",
      "batch 2  d_loss: 0.448828  g_loss: 1.294752\n",
      "batch 3  d_loss: 0.393615  g_loss: 1.798043\n",
      "batch 4  d_loss: 0.432938  g_loss: 2.491656\n",
      "batch 5  d_loss: 0.524567  g_loss: 2.359942\n",
      "batch 6  d_loss: 0.467552  g_loss: 2.260085\n",
      "batch 7  d_loss: 0.527333  g_loss: 1.801794\n",
      "batch 8  d_loss: 0.562676  g_loss: 1.625791\n",
      "batch 9  d_loss: 0.635704  g_loss: 1.180272\n",
      "batch 10  d_loss: 0.553898  g_loss: 0.743803\n",
      "batch 11  d_loss: 0.609152  g_loss: 0.845861\n",
      "batch 12  d_loss: 0.637921  g_loss: 1.046838\n",
      "batch 13  d_loss: 0.450680  g_loss: 0.964086\n",
      "batch 14  d_loss: 0.537498  g_loss: 1.473580\n",
      "batch 15  d_loss: 0.452823  g_loss: 1.603058\n",
      "batch 16  d_loss: 0.314339  g_loss: 1.586566\n",
      "batch 17  d_loss: 0.388323  g_loss: 1.933531\n",
      "batch 18  d_loss: 0.429135  g_loss: 1.692510\n",
      "batch 19  d_loss: 0.557940  g_loss: 1.592660\n",
      "batch 20  d_loss: 0.445632  g_loss: 1.182142\n",
      "batch 21  d_loss: 0.392339  g_loss: 1.149042\n",
      "batch 22  d_loss: 0.471475  g_loss: 1.099437\n",
      "batch 23  d_loss: 0.486016  g_loss: 1.156654\n",
      "batch 24  d_loss: 0.367459  g_loss: 1.458338\n",
      "batch 25  d_loss: 0.329684  g_loss: 1.654459\n",
      "batch 26  d_loss: 0.381634  g_loss: 1.745306\n",
      "batch 27  d_loss: 0.412415  g_loss: 2.157652\n",
      "batch 28  d_loss: 0.337826  g_loss: 2.192322\n",
      "batch 29  d_loss: 0.393698  g_loss: 2.104785\n",
      "batch 30  d_loss: 0.303582  g_loss: 1.708870\n",
      "batch 31  d_loss: 0.651932  g_loss: 1.513203\n",
      "batch 32  d_loss: 0.398264  g_loss: 1.157603\n",
      "batch 33  d_loss: 0.564625  g_loss: 1.165983\n",
      "batch 34  d_loss: 0.493570  g_loss: 1.353296\n",
      "batch 35  d_loss: 0.428393  g_loss: 1.726632\n",
      "batch 36  d_loss: 0.551957  g_loss: 1.881739\n",
      "batch 37  d_loss: 1.044928  g_loss: 1.673936\n",
      "batch 38  d_loss: 0.501280  g_loss: 1.393662\n",
      "batch 39  d_loss: 0.541111  g_loss: 1.065936\n",
      "batch 40  d_loss: 0.475877  g_loss: 1.118706\n",
      "batch 41  d_loss: 0.946507  g_loss: 1.292247\n",
      "batch 42  d_loss: 0.786396  g_loss: 1.434527\n",
      "batch 43  d_loss: 0.675143  g_loss: 1.610260\n",
      "batch 44  d_loss: 0.613890  g_loss: 1.383389\n",
      "batch 45  d_loss: 0.619204  g_loss: 1.190549\n",
      "Epoch is 36\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.429357  g_loss: 1.301970\n",
      "batch 1  d_loss: 0.532559  g_loss: 1.232652\n",
      "batch 2  d_loss: 0.413058  g_loss: 1.381032\n",
      "batch 3  d_loss: 0.404299  g_loss: 1.541806\n",
      "batch 4  d_loss: 0.406904  g_loss: 1.754404\n",
      "batch 5  d_loss: 0.352092  g_loss: 1.804443\n",
      "batch 6  d_loss: 0.393364  g_loss: 1.770514\n",
      "batch 7  d_loss: 0.414168  g_loss: 1.869456\n",
      "batch 8  d_loss: 0.422737  g_loss: 1.399952\n",
      "batch 9  d_loss: 0.406158  g_loss: 1.347926\n",
      "batch 10  d_loss: 0.395426  g_loss: 1.682934\n",
      "batch 11  d_loss: 0.375712  g_loss: 1.650337\n",
      "batch 12  d_loss: 0.372602  g_loss: 1.977982\n",
      "batch 13  d_loss: 0.450537  g_loss: 1.639055\n",
      "batch 14  d_loss: 0.399443  g_loss: 1.851895\n",
      "batch 15  d_loss: 0.363557  g_loss: 1.542339\n",
      "batch 16  d_loss: 0.287457  g_loss: 1.831014\n",
      "batch 17  d_loss: 0.385712  g_loss: 1.838639\n",
      "batch 18  d_loss: 0.443976  g_loss: 1.558677\n",
      "batch 19  d_loss: 0.409668  g_loss: 1.719176\n",
      "batch 20  d_loss: 0.436111  g_loss: 1.890145\n",
      "batch 21  d_loss: 0.395887  g_loss: 1.453458\n",
      "batch 22  d_loss: 0.502639  g_loss: 1.711066\n",
      "batch 23  d_loss: 0.499114  g_loss: 1.300634\n",
      "batch 24  d_loss: 0.532475  g_loss: 1.305114\n",
      "batch 25  d_loss: 0.606024  g_loss: 1.452578\n",
      "batch 26  d_loss: 0.443243  g_loss: 1.290163\n",
      "batch 27  d_loss: 0.561357  g_loss: 1.501032\n",
      "batch 28  d_loss: 0.726457  g_loss: 1.247583\n",
      "batch 29  d_loss: 0.536554  g_loss: 1.061086\n",
      "batch 30  d_loss: 0.547932  g_loss: 0.937960\n",
      "batch 31  d_loss: 0.594112  g_loss: 1.022113\n",
      "batch 32  d_loss: 0.662774  g_loss: 1.406381\n",
      "batch 33  d_loss: 0.373968  g_loss: 1.556553\n",
      "batch 34  d_loss: 0.470244  g_loss: 1.785344\n",
      "batch 35  d_loss: 0.650892  g_loss: 1.809284\n",
      "batch 36  d_loss: 0.621052  g_loss: 1.669976\n",
      "batch 37  d_loss: 0.633446  g_loss: 1.219207\n",
      "batch 38  d_loss: 0.563055  g_loss: 1.138330\n",
      "batch 39  d_loss: 0.604059  g_loss: 0.874960\n",
      "batch 40  d_loss: 0.470670  g_loss: 0.983338\n",
      "batch 41  d_loss: 0.497341  g_loss: 0.868831\n",
      "batch 42  d_loss: 0.487667  g_loss: 1.269321\n",
      "batch 43  d_loss: 0.530088  g_loss: 1.408363\n",
      "batch 44  d_loss: 0.474802  g_loss: 1.560964\n",
      "batch 45  d_loss: 0.387158  g_loss: 1.621243\n",
      "Epoch is 37\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.314322  g_loss: 1.852232\n",
      "batch 1  d_loss: 0.407331  g_loss: 1.759321\n",
      "batch 2  d_loss: 0.345529  g_loss: 1.601097\n",
      "batch 3  d_loss: 0.362379  g_loss: 1.722068\n",
      "batch 4  d_loss: 0.306162  g_loss: 1.696977\n",
      "batch 5  d_loss: 0.384387  g_loss: 1.570769\n",
      "batch 6  d_loss: 0.331795  g_loss: 1.532412\n",
      "batch 7  d_loss: 0.284254  g_loss: 1.343048\n",
      "batch 8  d_loss: 0.393515  g_loss: 1.442437\n",
      "batch 9  d_loss: 0.510490  g_loss: 1.312267\n",
      "batch 10  d_loss: 0.392290  g_loss: 1.203565\n",
      "batch 11  d_loss: 0.394178  g_loss: 1.121536\n",
      "batch 12  d_loss: 0.380026  g_loss: 1.299283\n",
      "batch 13  d_loss: 0.553128  g_loss: 1.578539\n",
      "batch 14  d_loss: 0.662856  g_loss: 1.442868\n",
      "batch 15  d_loss: 0.331707  g_loss: 1.855364\n",
      "batch 16  d_loss: 0.527703  g_loss: 1.996564\n",
      "batch 17  d_loss: 0.468726  g_loss: 1.834199\n",
      "batch 18  d_loss: 0.544459  g_loss: 1.523298\n",
      "batch 19  d_loss: 0.559709  g_loss: 1.582384\n",
      "batch 20  d_loss: 0.492524  g_loss: 1.306185\n",
      "batch 21  d_loss: 0.453464  g_loss: 1.284752\n",
      "batch 22  d_loss: 0.392458  g_loss: 1.431831\n",
      "batch 23  d_loss: 0.399148  g_loss: 1.466461\n",
      "batch 24  d_loss: 0.351139  g_loss: 1.448870\n",
      "batch 25  d_loss: 0.362027  g_loss: 1.929858\n",
      "batch 26  d_loss: 0.434091  g_loss: 1.887702\n",
      "batch 27  d_loss: 0.385982  g_loss: 1.839618\n",
      "batch 28  d_loss: 0.463712  g_loss: 1.641517\n",
      "batch 29  d_loss: 0.594790  g_loss: 1.237677\n",
      "batch 30  d_loss: 0.495373  g_loss: 1.131893\n",
      "batch 31  d_loss: 0.645044  g_loss: 1.061660\n",
      "batch 32  d_loss: 0.601440  g_loss: 1.183157\n",
      "batch 33  d_loss: 0.480622  g_loss: 1.468877\n",
      "batch 34  d_loss: 0.470250  g_loss: 2.038448\n",
      "batch 35  d_loss: 0.545102  g_loss: 2.071651\n",
      "batch 36  d_loss: 0.515494  g_loss: 1.731856\n",
      "batch 37  d_loss: 0.698933  g_loss: 1.333374\n",
      "batch 38  d_loss: 0.529784  g_loss: 1.273807\n",
      "batch 39  d_loss: 0.567254  g_loss: 0.884255\n",
      "batch 40  d_loss: 0.550350  g_loss: 1.310394\n",
      "batch 41  d_loss: 0.635720  g_loss: 1.568383\n",
      "batch 42  d_loss: 0.707419  g_loss: 1.328816\n",
      "batch 43  d_loss: 0.713662  g_loss: 1.177582\n",
      "batch 44  d_loss: 0.577610  g_loss: 1.083532\n",
      "batch 45  d_loss: 0.574881  g_loss: 1.002467\n",
      "Epoch is 38\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.481559  g_loss: 1.340412\n",
      "batch 1  d_loss: 0.516561  g_loss: 1.316652\n",
      "batch 2  d_loss: 0.442932  g_loss: 1.419892\n",
      "batch 3  d_loss: 0.524064  g_loss: 1.458131\n",
      "batch 4  d_loss: 0.531440  g_loss: 1.528187\n",
      "batch 5  d_loss: 0.437407  g_loss: 1.252334\n",
      "batch 6  d_loss: 0.530220  g_loss: 1.062136\n",
      "batch 7  d_loss: 0.499427  g_loss: 1.198814\n",
      "batch 8  d_loss: 0.548942  g_loss: 1.527853\n",
      "batch 9  d_loss: 0.695625  g_loss: 1.228435\n",
      "batch 10  d_loss: 0.548795  g_loss: 1.212516\n",
      "batch 11  d_loss: 0.447730  g_loss: 1.289790\n",
      "batch 12  d_loss: 0.385652  g_loss: 1.295805\n",
      "batch 13  d_loss: 0.712661  g_loss: 1.561010\n",
      "batch 14  d_loss: 0.569593  g_loss: 1.645118\n",
      "batch 15  d_loss: 0.345116  g_loss: 1.457067\n",
      "batch 16  d_loss: 0.354571  g_loss: 1.536099\n",
      "batch 17  d_loss: 0.310917  g_loss: 1.490898\n",
      "batch 18  d_loss: 0.399934  g_loss: 1.508023\n",
      "batch 19  d_loss: 0.538073  g_loss: 1.419985\n",
      "batch 20  d_loss: 0.468349  g_loss: 1.328683\n",
      "batch 21  d_loss: 0.365698  g_loss: 1.328352\n",
      "batch 22  d_loss: 0.514153  g_loss: 1.394613\n",
      "batch 23  d_loss: 0.349143  g_loss: 1.589376\n",
      "batch 24  d_loss: 0.377921  g_loss: 1.806093\n",
      "batch 25  d_loss: 0.440966  g_loss: 1.708387\n",
      "batch 26  d_loss: 0.383622  g_loss: 2.028966\n",
      "batch 27  d_loss: 0.517976  g_loss: 1.943591\n",
      "batch 28  d_loss: 0.684600  g_loss: 1.570620\n",
      "batch 29  d_loss: 0.441586  g_loss: 1.114370\n",
      "batch 30  d_loss: 0.518845  g_loss: 1.207422\n",
      "batch 31  d_loss: 0.752008  g_loss: 1.314544\n",
      "batch 32  d_loss: 0.531313  g_loss: 1.326137\n",
      "batch 33  d_loss: 0.541277  g_loss: 1.609053\n",
      "batch 34  d_loss: 0.539940  g_loss: 2.169431\n",
      "batch 35  d_loss: 0.557436  g_loss: 2.049705\n",
      "batch 36  d_loss: 0.524072  g_loss: 1.267817\n",
      "batch 37  d_loss: 0.609436  g_loss: 0.884593\n",
      "batch 38  d_loss: 0.495538  g_loss: 1.466653\n",
      "batch 39  d_loss: 0.555308  g_loss: 1.045862\n",
      "batch 40  d_loss: 0.541648  g_loss: 1.460843\n",
      "batch 41  d_loss: 0.562825  g_loss: 1.784854\n",
      "batch 42  d_loss: 0.687574  g_loss: 1.751809\n",
      "batch 43  d_loss: 0.542992  g_loss: 1.458406\n",
      "batch 44  d_loss: 0.561850  g_loss: 1.237131\n",
      "batch 45  d_loss: 0.519081  g_loss: 0.874325\n",
      "Epoch is 39\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.438891  g_loss: 0.777861\n",
      "batch 1  d_loss: 0.496377  g_loss: 1.059195\n",
      "batch 2  d_loss: 0.572657  g_loss: 1.192833\n",
      "batch 3  d_loss: 0.466140  g_loss: 1.513356\n",
      "batch 4  d_loss: 0.527569  g_loss: 1.308810\n",
      "batch 5  d_loss: 0.478393  g_loss: 1.346713\n",
      "batch 6  d_loss: 0.615498  g_loss: 1.511143\n",
      "batch 7  d_loss: 0.611963  g_loss: 1.280552\n",
      "batch 8  d_loss: 0.612230  g_loss: 1.110347\n",
      "batch 9  d_loss: 0.562857  g_loss: 1.045076\n",
      "batch 10  d_loss: 0.470127  g_loss: 1.167911\n",
      "batch 11  d_loss: 0.475971  g_loss: 1.196594\n",
      "batch 12  d_loss: 0.423546  g_loss: 1.167596\n",
      "batch 13  d_loss: 0.554162  g_loss: 1.224489\n",
      "batch 14  d_loss: 0.580014  g_loss: 1.123760\n",
      "batch 15  d_loss: 0.450965  g_loss: 1.221219\n",
      "batch 16  d_loss: 0.406696  g_loss: 1.572633\n",
      "batch 17  d_loss: 0.415565  g_loss: 1.568076\n",
      "batch 18  d_loss: 0.344670  g_loss: 1.681532\n",
      "batch 19  d_loss: 0.645020  g_loss: 1.539683\n",
      "batch 20  d_loss: 0.376641  g_loss: 1.363268\n",
      "batch 21  d_loss: 0.385964  g_loss: 1.285419\n",
      "batch 22  d_loss: 0.454446  g_loss: 1.240329\n",
      "batch 23  d_loss: 0.401540  g_loss: 1.017205\n",
      "batch 24  d_loss: 0.479836  g_loss: 1.351600\n",
      "batch 25  d_loss: 0.463416  g_loss: 1.431451\n",
      "batch 26  d_loss: 0.448900  g_loss: 1.611942\n",
      "batch 27  d_loss: 0.488502  g_loss: 1.620456\n",
      "batch 28  d_loss: 0.594822  g_loss: 1.472086\n",
      "batch 29  d_loss: 0.446533  g_loss: 1.589908\n",
      "batch 30  d_loss: 0.495250  g_loss: 1.378245\n",
      "batch 31  d_loss: 0.596693  g_loss: 1.411453\n",
      "batch 32  d_loss: 0.410315  g_loss: 1.836656\n",
      "batch 33  d_loss: 0.324482  g_loss: 1.986474\n",
      "batch 34  d_loss: 0.278118  g_loss: 1.942161\n",
      "batch 35  d_loss: 0.391804  g_loss: 1.904065\n",
      "batch 36  d_loss: 0.400143  g_loss: 1.977744\n",
      "batch 37  d_loss: 0.608832  g_loss: 1.683751\n",
      "batch 38  d_loss: 0.430377  g_loss: 1.351825\n",
      "batch 39  d_loss: 0.485088  g_loss: 1.128147\n",
      "batch 40  d_loss: 0.499893  g_loss: 1.054581\n",
      "batch 41  d_loss: 0.579618  g_loss: 1.132265\n",
      "batch 42  d_loss: 0.756550  g_loss: 1.059070\n",
      "batch 43  d_loss: 0.524512  g_loss: 1.104746\n",
      "batch 44  d_loss: 0.457713  g_loss: 1.150312\n",
      "batch 45  d_loss: 0.387008  g_loss: 1.210516\n",
      "Epoch is 40\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.450428  g_loss: 1.335391\n",
      "batch 1  d_loss: 0.420932  g_loss: 1.364769\n",
      "batch 2  d_loss: 0.401162  g_loss: 1.445082\n",
      "batch 3  d_loss: 0.430455  g_loss: 1.698933\n",
      "batch 4  d_loss: 0.430632  g_loss: 1.455592\n",
      "batch 5  d_loss: 0.579068  g_loss: 1.346363\n",
      "batch 6  d_loss: 0.565214  g_loss: 1.232987\n",
      "batch 7  d_loss: 0.390898  g_loss: 1.070019\n",
      "batch 8  d_loss: 0.445504  g_loss: 0.900582\n",
      "batch 9  d_loss: 0.708539  g_loss: 0.987867\n",
      "batch 10  d_loss: 0.497398  g_loss: 1.019804\n",
      "batch 11  d_loss: 0.440560  g_loss: 1.188164\n",
      "batch 12  d_loss: 0.366608  g_loss: 1.309901\n",
      "batch 13  d_loss: 0.544187  g_loss: 1.402230\n",
      "batch 14  d_loss: 0.520311  g_loss: 1.547171\n",
      "batch 15  d_loss: 0.458580  g_loss: 1.397080\n",
      "batch 16  d_loss: 0.366002  g_loss: 1.353283\n",
      "batch 17  d_loss: 0.362591  g_loss: 1.408094\n",
      "batch 18  d_loss: 0.448169  g_loss: 1.358173\n",
      "batch 19  d_loss: 0.598958  g_loss: 1.213053\n",
      "batch 20  d_loss: 0.477878  g_loss: 1.354409\n",
      "batch 21  d_loss: 0.452311  g_loss: 1.334260\n",
      "batch 22  d_loss: 0.436822  g_loss: 1.337336\n",
      "batch 23  d_loss: 0.468084  g_loss: 1.203163\n",
      "batch 24  d_loss: 0.438490  g_loss: 1.279217\n",
      "batch 25  d_loss: 0.528972  g_loss: 1.513409\n",
      "batch 26  d_loss: 0.450021  g_loss: 1.769023\n",
      "batch 27  d_loss: 0.509783  g_loss: 1.461414\n",
      "batch 28  d_loss: 0.576629  g_loss: 1.503061\n",
      "batch 29  d_loss: 0.572711  g_loss: 1.301588\n",
      "batch 30  d_loss: 0.379254  g_loss: 1.201301\n",
      "batch 31  d_loss: 0.604683  g_loss: 1.208267\n",
      "batch 32  d_loss: 0.472642  g_loss: 1.135612\n",
      "batch 33  d_loss: 0.347813  g_loss: 1.524070\n",
      "batch 34  d_loss: 0.351097  g_loss: 1.989577\n",
      "batch 35  d_loss: 0.436085  g_loss: 2.267636\n",
      "batch 36  d_loss: 0.478423  g_loss: 2.102100\n",
      "batch 37  d_loss: 0.534413  g_loss: 1.608957\n",
      "batch 38  d_loss: 0.458398  g_loss: 1.318110\n",
      "batch 39  d_loss: 0.590848  g_loss: 0.995111\n",
      "batch 40  d_loss: 0.440127  g_loss: 1.325926\n",
      "batch 41  d_loss: 0.473148  g_loss: 1.800398\n",
      "batch 42  d_loss: 0.521526  g_loss: 2.049263\n",
      "batch 43  d_loss: 0.587908  g_loss: 1.555828\n",
      "batch 44  d_loss: 0.507823  g_loss: 1.465600\n",
      "batch 45  d_loss: 0.601499  g_loss: 1.235084\n",
      "Epoch is 41\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.450194  g_loss: 1.124267\n",
      "batch 1  d_loss: 0.602843  g_loss: 1.308553\n",
      "batch 2  d_loss: 0.485241  g_loss: 1.447643\n",
      "batch 3  d_loss: 0.454334  g_loss: 1.433993\n",
      "batch 4  d_loss: 0.510041  g_loss: 1.466048\n",
      "batch 5  d_loss: 0.527862  g_loss: 1.470136\n",
      "batch 6  d_loss: 0.478274  g_loss: 1.120120\n",
      "batch 7  d_loss: 0.573246  g_loss: 1.283566\n",
      "batch 8  d_loss: 0.501815  g_loss: 1.107281\n",
      "batch 9  d_loss: 0.517783  g_loss: 0.991735\n",
      "batch 10  d_loss: 0.452973  g_loss: 1.346359\n",
      "batch 11  d_loss: 0.485149  g_loss: 1.483152\n",
      "batch 12  d_loss: 0.392275  g_loss: 1.542013\n",
      "batch 13  d_loss: 0.470121  g_loss: 1.485503\n",
      "batch 14  d_loss: 0.419451  g_loss: 1.607778\n",
      "batch 15  d_loss: 0.361217  g_loss: 1.317724\n",
      "batch 16  d_loss: 0.344671  g_loss: 1.573899\n",
      "batch 17  d_loss: 0.352490  g_loss: 1.536474\n",
      "batch 18  d_loss: 0.458410  g_loss: 1.790271\n",
      "batch 19  d_loss: 0.467429  g_loss: 1.449539\n",
      "batch 20  d_loss: 0.439276  g_loss: 1.633637\n",
      "batch 21  d_loss: 0.446817  g_loss: 1.758949\n",
      "batch 22  d_loss: 0.442646  g_loss: 1.568033\n",
      "batch 23  d_loss: 0.507413  g_loss: 1.752400\n",
      "batch 24  d_loss: 0.342963  g_loss: 2.124429\n",
      "batch 25  d_loss: 0.433710  g_loss: 1.872816\n",
      "batch 26  d_loss: 0.372041  g_loss: 1.778817\n",
      "batch 27  d_loss: 0.430483  g_loss: 1.409553\n",
      "batch 28  d_loss: 0.548646  g_loss: 1.125875\n",
      "batch 29  d_loss: 0.435234  g_loss: 1.214981\n",
      "batch 30  d_loss: 0.448249  g_loss: 1.146825\n",
      "batch 31  d_loss: 0.437141  g_loss: 1.497966\n",
      "batch 32  d_loss: 0.506510  g_loss: 1.498626\n",
      "batch 33  d_loss: 0.373067  g_loss: 1.944018\n",
      "batch 34  d_loss: 0.386820  g_loss: 2.158954\n",
      "batch 35  d_loss: 0.445823  g_loss: 2.208517\n",
      "batch 36  d_loss: 0.413662  g_loss: 1.966888\n",
      "batch 37  d_loss: 0.539750  g_loss: 1.500949\n",
      "batch 38  d_loss: 0.406147  g_loss: 1.192850\n",
      "batch 39  d_loss: 0.492271  g_loss: 1.074671\n",
      "batch 40  d_loss: 0.491654  g_loss: 1.102785\n",
      "batch 41  d_loss: 0.587165  g_loss: 1.445773\n",
      "batch 42  d_loss: 0.518386  g_loss: 1.463311\n",
      "batch 43  d_loss: 0.772176  g_loss: 1.651648\n",
      "batch 44  d_loss: 0.478294  g_loss: 1.391560\n",
      "batch 45  d_loss: 0.467422  g_loss: 1.430302\n",
      "Epoch is 42\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.448823  g_loss: 1.674514\n",
      "batch 1  d_loss: 0.420478  g_loss: 1.517575\n",
      "batch 2  d_loss: 0.439262  g_loss: 1.882069\n",
      "batch 3  d_loss: 0.357756  g_loss: 2.049711\n",
      "batch 4  d_loss: 0.426257  g_loss: 1.940076\n",
      "batch 5  d_loss: 0.543706  g_loss: 1.734327\n",
      "batch 6  d_loss: 0.498559  g_loss: 1.433676\n",
      "batch 7  d_loss: 0.280777  g_loss: 1.375116\n",
      "batch 8  d_loss: 0.432277  g_loss: 1.210480\n",
      "batch 9  d_loss: 0.616897  g_loss: 1.135873\n",
      "batch 10  d_loss: 0.479470  g_loss: 1.334101\n",
      "batch 11  d_loss: 0.511819  g_loss: 1.577378\n",
      "batch 12  d_loss: 0.413280  g_loss: 1.777901\n",
      "batch 13  d_loss: 0.587096  g_loss: 1.763476\n",
      "batch 14  d_loss: 0.641238  g_loss: 1.689822\n",
      "batch 15  d_loss: 0.601531  g_loss: 1.409021\n",
      "batch 16  d_loss: 0.437611  g_loss: 1.024338\n",
      "batch 17  d_loss: 0.382207  g_loss: 1.074208\n",
      "batch 18  d_loss: 0.476972  g_loss: 1.128713\n",
      "batch 19  d_loss: 0.698538  g_loss: 1.076479\n",
      "batch 20  d_loss: 0.633584  g_loss: 1.289505\n",
      "batch 21  d_loss: 0.738313  g_loss: 1.579809\n",
      "batch 22  d_loss: 0.641272  g_loss: 1.620365\n",
      "batch 23  d_loss: 0.657087  g_loss: 1.380189\n",
      "batch 24  d_loss: 0.498684  g_loss: 1.287293\n",
      "batch 25  d_loss: 0.541438  g_loss: 1.186178\n",
      "batch 26  d_loss: 0.468527  g_loss: 1.325980\n",
      "batch 27  d_loss: 0.571958  g_loss: 1.388596\n",
      "batch 28  d_loss: 0.502881  g_loss: 1.595001\n",
      "batch 29  d_loss: 0.453428  g_loss: 1.710718\n",
      "batch 30  d_loss: 0.433903  g_loss: 1.704158\n",
      "batch 31  d_loss: 0.566282  g_loss: 1.688334\n",
      "batch 32  d_loss: 0.423296  g_loss: 1.599528\n",
      "batch 33  d_loss: 0.434142  g_loss: 1.495209\n",
      "batch 34  d_loss: 0.343996  g_loss: 1.590614\n",
      "batch 35  d_loss: 0.418488  g_loss: 1.532457\n",
      "batch 36  d_loss: 0.409203  g_loss: 1.453075\n",
      "batch 37  d_loss: 0.504747  g_loss: 1.289918\n",
      "batch 38  d_loss: 0.401710  g_loss: 1.340062\n",
      "batch 39  d_loss: 0.505019  g_loss: 1.477586\n",
      "batch 40  d_loss: 0.340396  g_loss: 1.418306\n",
      "batch 41  d_loss: 0.444150  g_loss: 1.430303\n",
      "batch 42  d_loss: 0.510134  g_loss: 1.341869\n",
      "batch 43  d_loss: 0.563428  g_loss: 1.505185\n",
      "batch 44  d_loss: 0.535409  g_loss: 1.528203\n",
      "batch 45  d_loss: 0.500333  g_loss: 1.692487\n",
      "Epoch is 43\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.362734  g_loss: 1.641389\n",
      "batch 1  d_loss: 0.459934  g_loss: 1.821172\n",
      "batch 2  d_loss: 0.449190  g_loss: 1.986766\n",
      "batch 3  d_loss: 0.409095  g_loss: 2.235449\n",
      "batch 4  d_loss: 0.415587  g_loss: 1.714860\n",
      "batch 5  d_loss: 0.437523  g_loss: 1.572533\n",
      "batch 6  d_loss: 0.436943  g_loss: 1.215463\n",
      "batch 7  d_loss: 0.385991  g_loss: 1.168808\n",
      "batch 8  d_loss: 0.487094  g_loss: 0.976370\n",
      "batch 9  d_loss: 0.495521  g_loss: 1.349183\n",
      "batch 10  d_loss: 0.493249  g_loss: 1.557671\n",
      "batch 11  d_loss: 0.556456  g_loss: 1.420856\n",
      "batch 12  d_loss: 0.502680  g_loss: 1.460595\n",
      "batch 13  d_loss: 0.698336  g_loss: 1.288165\n",
      "batch 14  d_loss: 0.523540  g_loss: 1.087016\n",
      "batch 15  d_loss: 0.526295  g_loss: 1.001389\n",
      "batch 16  d_loss: 0.496828  g_loss: 1.575096\n",
      "batch 17  d_loss: 0.399221  g_loss: 1.748127\n",
      "batch 18  d_loss: 0.416525  g_loss: 2.239505\n",
      "batch 19  d_loss: 0.611296  g_loss: 1.812801\n",
      "batch 20  d_loss: 0.436720  g_loss: 1.759530\n",
      "batch 21  d_loss: 0.511466  g_loss: 1.419093\n",
      "batch 22  d_loss: 0.453406  g_loss: 1.331336\n",
      "batch 23  d_loss: 0.379626  g_loss: 1.467780\n",
      "batch 24  d_loss: 0.348891  g_loss: 1.522909\n",
      "batch 25  d_loss: 0.420358  g_loss: 1.531938\n",
      "batch 26  d_loss: 0.339402  g_loss: 1.930157\n",
      "batch 27  d_loss: 0.395853  g_loss: 1.852555\n",
      "batch 28  d_loss: 0.435067  g_loss: 1.456660\n",
      "batch 29  d_loss: 0.470089  g_loss: 1.455426\n",
      "batch 30  d_loss: 0.328431  g_loss: 1.785031\n",
      "batch 31  d_loss: 0.431661  g_loss: 1.676675\n",
      "batch 32  d_loss: 0.403019  g_loss: 1.884787\n",
      "batch 33  d_loss: 0.291103  g_loss: 2.141971\n",
      "batch 34  d_loss: 0.403931  g_loss: 1.889257\n",
      "batch 35  d_loss: 0.372233  g_loss: 2.070458\n",
      "batch 36  d_loss: 0.365361  g_loss: 1.711744\n",
      "batch 37  d_loss: 0.455682  g_loss: 1.347224\n",
      "batch 38  d_loss: 0.373222  g_loss: 1.311350\n",
      "batch 39  d_loss: 0.483496  g_loss: 1.250292\n",
      "batch 40  d_loss: 0.599523  g_loss: 1.104839\n",
      "batch 41  d_loss: 0.519846  g_loss: 1.617704\n",
      "batch 42  d_loss: 0.840941  g_loss: 1.489101\n",
      "batch 43  d_loss: 0.595705  g_loss: 1.499392\n",
      "batch 44  d_loss: 0.468018  g_loss: 1.309905\n",
      "batch 45  d_loss: 0.483731  g_loss: 0.998684\n",
      "Epoch is 44\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.432137  g_loss: 1.404032\n",
      "batch 1  d_loss: 0.419854  g_loss: 1.309149\n",
      "batch 2  d_loss: 0.497215  g_loss: 1.503152\n",
      "batch 3  d_loss: 0.386045  g_loss: 1.706824\n",
      "batch 4  d_loss: 0.364473  g_loss: 1.541643\n",
      "batch 5  d_loss: 0.529835  g_loss: 1.458549\n",
      "batch 6  d_loss: 0.426438  g_loss: 1.435325\n",
      "batch 7  d_loss: 0.404191  g_loss: 1.444795\n",
      "batch 8  d_loss: 0.530602  g_loss: 1.530484\n",
      "batch 9  d_loss: 0.700843  g_loss: 1.354806\n",
      "batch 10  d_loss: 0.503701  g_loss: 1.221058\n",
      "batch 11  d_loss: 0.456032  g_loss: 1.303538\n",
      "batch 12  d_loss: 0.461601  g_loss: 1.257387\n",
      "batch 13  d_loss: 0.676342  g_loss: 1.266983\n",
      "batch 14  d_loss: 0.629691  g_loss: 1.393447\n",
      "batch 15  d_loss: 0.483148  g_loss: 1.415609\n",
      "batch 16  d_loss: 0.566729  g_loss: 1.439752\n",
      "batch 17  d_loss: 0.488128  g_loss: 1.284450\n",
      "batch 18  d_loss: 0.434023  g_loss: 1.576324\n",
      "batch 19  d_loss: 0.560509  g_loss: 1.515277\n",
      "batch 20  d_loss: 0.415685  g_loss: 1.431717\n",
      "batch 21  d_loss: 0.336179  g_loss: 1.809333\n",
      "batch 22  d_loss: 0.374504  g_loss: 1.536906\n",
      "batch 23  d_loss: 0.399782  g_loss: 1.629052\n",
      "batch 24  d_loss: 0.314366  g_loss: 1.781925\n",
      "batch 25  d_loss: 0.369370  g_loss: 1.835399\n",
      "batch 26  d_loss: 0.368989  g_loss: 1.651232\n",
      "batch 27  d_loss: 0.433724  g_loss: 1.591037\n",
      "batch 28  d_loss: 0.511550  g_loss: 1.580174\n",
      "batch 29  d_loss: 0.408195  g_loss: 1.334321\n",
      "batch 30  d_loss: 0.481043  g_loss: 1.208781\n",
      "batch 31  d_loss: 0.509923  g_loss: 1.227981\n",
      "batch 32  d_loss: 0.413769  g_loss: 1.230811\n",
      "batch 33  d_loss: 0.370339  g_loss: 1.744477\n",
      "batch 34  d_loss: 0.379853  g_loss: 1.806945\n",
      "batch 35  d_loss: 0.499789  g_loss: 1.919173\n",
      "batch 36  d_loss: 0.598449  g_loss: 1.593176\n",
      "batch 37  d_loss: 0.891450  g_loss: 1.348422\n",
      "batch 38  d_loss: 0.396112  g_loss: 1.505568\n",
      "batch 39  d_loss: 0.479807  g_loss: 1.083514\n",
      "batch 40  d_loss: 0.447036  g_loss: 1.185580\n",
      "batch 41  d_loss: 0.540439  g_loss: 1.535418\n",
      "batch 42  d_loss: 0.621680  g_loss: 1.537395\n",
      "batch 43  d_loss: 0.477679  g_loss: 1.822376\n",
      "batch 44  d_loss: 0.493616  g_loss: 1.747834\n",
      "batch 45  d_loss: 0.521198  g_loss: 1.591719\n",
      "Epoch is 45\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.357435  g_loss: 1.872125\n",
      "batch 1  d_loss: 0.457830  g_loss: 1.524717\n",
      "batch 2  d_loss: 0.403020  g_loss: 1.445458\n",
      "batch 3  d_loss: 0.416180  g_loss: 1.352007\n",
      "batch 4  d_loss: 0.391947  g_loss: 1.508737\n",
      "batch 5  d_loss: 0.629397  g_loss: 1.537700\n",
      "batch 6  d_loss: 0.575838  g_loss: 1.316604\n",
      "batch 7  d_loss: 0.410095  g_loss: 1.631887\n",
      "batch 8  d_loss: 0.601897  g_loss: 1.272734\n",
      "batch 9  d_loss: 0.857503  g_loss: 1.254951\n",
      "batch 10  d_loss: 0.622809  g_loss: 1.154463\n",
      "batch 11  d_loss: 0.590257  g_loss: 1.499284\n",
      "batch 12  d_loss: 0.383440  g_loss: 1.451416\n",
      "batch 13  d_loss: 0.471038  g_loss: 1.608097\n",
      "batch 14  d_loss: 0.479312  g_loss: 1.563845\n",
      "batch 15  d_loss: 0.315784  g_loss: 1.387113\n",
      "batch 16  d_loss: 0.428243  g_loss: 1.408762\n",
      "batch 17  d_loss: 0.437396  g_loss: 1.316227\n",
      "batch 18  d_loss: 0.448008  g_loss: 1.738440\n",
      "batch 19  d_loss: 0.596372  g_loss: 1.446401\n",
      "batch 20  d_loss: 0.624279  g_loss: 1.335537\n",
      "batch 21  d_loss: 0.483815  g_loss: 1.038658\n",
      "batch 22  d_loss: 0.605302  g_loss: 0.942077\n",
      "batch 23  d_loss: 0.506932  g_loss: 0.929205\n",
      "batch 24  d_loss: 0.522856  g_loss: 0.804618\n",
      "batch 25  d_loss: 0.495656  g_loss: 0.988395\n",
      "batch 26  d_loss: 0.378061  g_loss: 1.170597\n",
      "batch 27  d_loss: 0.464662  g_loss: 1.415509\n",
      "batch 28  d_loss: 0.510022  g_loss: 1.640815\n",
      "batch 29  d_loss: 0.420797  g_loss: 1.382225\n",
      "batch 30  d_loss: 0.433244  g_loss: 1.424287\n",
      "batch 31  d_loss: 0.505403  g_loss: 1.118548\n",
      "batch 32  d_loss: 0.381010  g_loss: 1.043218\n",
      "batch 33  d_loss: 0.361147  g_loss: 1.224488\n",
      "batch 34  d_loss: 0.329858  g_loss: 1.622116\n",
      "batch 35  d_loss: 0.364288  g_loss: 1.707370\n",
      "batch 36  d_loss: 0.450121  g_loss: 1.752359\n",
      "batch 37  d_loss: 0.713305  g_loss: 1.547076\n",
      "batch 38  d_loss: 0.416606  g_loss: 1.210742\n",
      "batch 39  d_loss: 0.436303  g_loss: 1.093506\n",
      "batch 40  d_loss: 0.379171  g_loss: 1.049735\n",
      "batch 41  d_loss: 0.595209  g_loss: 1.278486\n",
      "batch 42  d_loss: 0.738430  g_loss: 1.480322\n",
      "batch 43  d_loss: 0.612249  g_loss: 1.427215\n",
      "batch 44  d_loss: 0.714222  g_loss: 1.449435\n",
      "batch 45  d_loss: 0.526596  g_loss: 1.166131\n",
      "Epoch is 46\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.569872  g_loss: 1.276423\n",
      "batch 1  d_loss: 0.526724  g_loss: 1.167074\n",
      "batch 2  d_loss: 0.512883  g_loss: 1.203557\n",
      "batch 3  d_loss: 0.503148  g_loss: 1.239810\n",
      "batch 4  d_loss: 0.512840  g_loss: 1.582415\n",
      "batch 5  d_loss: 0.565361  g_loss: 1.598322\n",
      "batch 6  d_loss: 0.546592  g_loss: 1.671964\n",
      "batch 7  d_loss: 0.456223  g_loss: 1.364912\n",
      "batch 8  d_loss: 0.625304  g_loss: 1.317827\n",
      "batch 9  d_loss: 0.530946  g_loss: 1.137177\n",
      "batch 10  d_loss: 0.460138  g_loss: 1.211807\n",
      "batch 11  d_loss: 0.505564  g_loss: 1.054261\n",
      "batch 12  d_loss: 0.569569  g_loss: 0.914412\n",
      "batch 13  d_loss: 0.603785  g_loss: 1.167729\n",
      "batch 14  d_loss: 0.517912  g_loss: 1.215986\n",
      "batch 15  d_loss: 0.571900  g_loss: 1.119427\n",
      "batch 16  d_loss: 0.445725  g_loss: 1.327391\n",
      "batch 17  d_loss: 0.410637  g_loss: 1.432559\n",
      "batch 18  d_loss: 0.534461  g_loss: 1.547234\n",
      "batch 19  d_loss: 0.483787  g_loss: 1.570711\n",
      "batch 20  d_loss: 0.547610  g_loss: 1.231582\n",
      "batch 21  d_loss: 0.436879  g_loss: 1.109505\n",
      "batch 22  d_loss: 0.578309  g_loss: 0.826890\n",
      "batch 23  d_loss: 0.594038  g_loss: 0.947736\n",
      "batch 24  d_loss: 0.418912  g_loss: 1.076770\n",
      "batch 25  d_loss: 0.528128  g_loss: 1.081080\n",
      "batch 26  d_loss: 0.405402  g_loss: 1.194452\n",
      "batch 27  d_loss: 0.440541  g_loss: 1.249895\n",
      "batch 28  d_loss: 0.468116  g_loss: 1.481314\n",
      "batch 29  d_loss: 0.566606  g_loss: 1.362819\n",
      "batch 30  d_loss: 0.467767  g_loss: 1.276078\n",
      "batch 31  d_loss: 0.564711  g_loss: 1.322969\n",
      "batch 32  d_loss: 0.462327  g_loss: 1.116008\n",
      "batch 33  d_loss: 0.390199  g_loss: 1.325852\n",
      "batch 34  d_loss: 0.424807  g_loss: 1.262597\n",
      "batch 35  d_loss: 0.443514  g_loss: 1.426143\n",
      "batch 36  d_loss: 0.523515  g_loss: 1.567320\n",
      "batch 37  d_loss: 0.750744  g_loss: 1.291035\n",
      "batch 38  d_loss: 0.503009  g_loss: 1.277219\n",
      "batch 39  d_loss: 0.541553  g_loss: 1.079671\n",
      "batch 40  d_loss: 0.494390  g_loss: 1.013111\n",
      "batch 41  d_loss: 0.676045  g_loss: 0.920136\n",
      "batch 42  d_loss: 0.679323  g_loss: 1.071582\n",
      "batch 43  d_loss: 0.512766  g_loss: 1.025401\n",
      "batch 44  d_loss: 0.678336  g_loss: 0.984593\n",
      "batch 45  d_loss: 0.548927  g_loss: 1.068610\n",
      "Epoch is 47\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.474953  g_loss: 1.030735\n",
      "batch 1  d_loss: 0.549500  g_loss: 1.248924\n",
      "batch 2  d_loss: 0.507377  g_loss: 1.300896\n",
      "batch 3  d_loss: 0.504240  g_loss: 1.314993\n",
      "batch 4  d_loss: 0.426641  g_loss: 1.497345\n",
      "batch 5  d_loss: 0.560627  g_loss: 1.595705\n",
      "batch 6  d_loss: 0.474823  g_loss: 1.475446\n",
      "batch 7  d_loss: 0.352868  g_loss: 1.416480\n",
      "batch 8  d_loss: 0.523730  g_loss: 1.337091\n",
      "batch 9  d_loss: 0.443490  g_loss: 1.452533\n",
      "batch 10  d_loss: 0.412983  g_loss: 1.348936\n",
      "batch 11  d_loss: 0.456817  g_loss: 1.407427\n",
      "batch 12  d_loss: 0.450984  g_loss: 1.406914\n",
      "batch 13  d_loss: 0.461219  g_loss: 1.276729\n",
      "batch 14  d_loss: 0.513351  g_loss: 1.205322\n",
      "batch 15  d_loss: 0.472812  g_loss: 1.091090\n",
      "batch 16  d_loss: 0.360968  g_loss: 1.219022\n",
      "batch 17  d_loss: 0.420057  g_loss: 1.218001\n",
      "batch 18  d_loss: 0.432155  g_loss: 1.501233\n",
      "batch 19  d_loss: 0.481484  g_loss: 1.351518\n",
      "batch 20  d_loss: 0.449315  g_loss: 1.362661\n",
      "batch 21  d_loss: 0.479586  g_loss: 1.220691\n",
      "batch 22  d_loss: 0.501125  g_loss: 1.276920\n",
      "batch 23  d_loss: 0.461963  g_loss: 1.027638\n",
      "batch 24  d_loss: 0.455507  g_loss: 1.129757\n",
      "batch 25  d_loss: 0.471287  g_loss: 1.238136\n",
      "batch 26  d_loss: 0.418656  g_loss: 1.730235\n",
      "batch 27  d_loss: 0.398722  g_loss: 1.860973\n",
      "batch 28  d_loss: 0.575042  g_loss: 1.569129\n",
      "batch 29  d_loss: 0.445714  g_loss: 1.587386\n",
      "batch 30  d_loss: 0.336644  g_loss: 1.308624\n",
      "batch 31  d_loss: 0.410824  g_loss: 0.985400\n",
      "batch 32  d_loss: 0.387725  g_loss: 1.206071\n",
      "batch 33  d_loss: 0.379166  g_loss: 1.253803\n",
      "batch 34  d_loss: 0.395425  g_loss: 1.569258\n",
      "batch 35  d_loss: 0.325911  g_loss: 1.904700\n",
      "batch 36  d_loss: 0.373399  g_loss: 2.040983\n",
      "batch 37  d_loss: 0.659010  g_loss: 1.982749\n",
      "batch 38  d_loss: 0.377666  g_loss: 1.591053\n",
      "batch 39  d_loss: 0.400316  g_loss: 1.257578\n",
      "batch 40  d_loss: 0.408820  g_loss: 1.089915\n",
      "batch 41  d_loss: 0.799935  g_loss: 1.249905\n",
      "batch 42  d_loss: 0.615052  g_loss: 1.347053\n",
      "batch 43  d_loss: 0.690863  g_loss: 1.402329\n",
      "batch 44  d_loss: 0.717679  g_loss: 1.268048\n",
      "batch 45  d_loss: 0.586052  g_loss: 1.216500\n",
      "Epoch is 48\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.428625  g_loss: 1.190468\n",
      "batch 1  d_loss: 0.461981  g_loss: 1.317803\n",
      "batch 2  d_loss: 0.561900  g_loss: 1.585069\n",
      "batch 3  d_loss: 0.418229  g_loss: 1.681370\n",
      "batch 4  d_loss: 0.447895  g_loss: 1.111959\n",
      "batch 5  d_loss: 0.458193  g_loss: 1.368883\n",
      "batch 6  d_loss: 0.412795  g_loss: 1.030670\n",
      "batch 7  d_loss: 0.535750  g_loss: 0.897091\n",
      "batch 8  d_loss: 0.594776  g_loss: 0.980902\n",
      "batch 9  d_loss: 0.492006  g_loss: 1.069485\n",
      "batch 10  d_loss: 0.425304  g_loss: 1.510031\n",
      "batch 11  d_loss: 0.594677  g_loss: 1.384496\n",
      "batch 12  d_loss: 0.764226  g_loss: 1.051729\n",
      "batch 13  d_loss: 0.636369  g_loss: 0.781173\n",
      "batch 14  d_loss: 0.611362  g_loss: 0.905019\n",
      "batch 15  d_loss: 0.590626  g_loss: 0.968494\n",
      "batch 16  d_loss: 0.509711  g_loss: 1.090714\n",
      "batch 17  d_loss: 0.526835  g_loss: 1.382775\n",
      "batch 18  d_loss: 0.496487  g_loss: 1.595212\n",
      "batch 19  d_loss: 0.488859  g_loss: 1.636399\n",
      "batch 20  d_loss: 0.488775  g_loss: 1.451687\n",
      "batch 21  d_loss: 0.490949  g_loss: 1.172684\n",
      "batch 22  d_loss: 0.445878  g_loss: 1.046380\n",
      "batch 23  d_loss: 0.428940  g_loss: 1.323270\n",
      "batch 24  d_loss: 0.388534  g_loss: 1.020470\n",
      "batch 25  d_loss: 0.423605  g_loss: 1.431305\n",
      "batch 26  d_loss: 0.351059  g_loss: 1.620823\n",
      "batch 27  d_loss: 0.345220  g_loss: 1.970294\n",
      "batch 28  d_loss: 0.454528  g_loss: 2.002412\n",
      "batch 29  d_loss: 0.481368  g_loss: 1.735295\n",
      "batch 30  d_loss: 0.308068  g_loss: 1.642344\n",
      "batch 31  d_loss: 0.412470  g_loss: 1.167981\n",
      "batch 32  d_loss: 0.341904  g_loss: 1.361993\n",
      "batch 33  d_loss: 0.351428  g_loss: 1.062826\n",
      "batch 34  d_loss: 0.332040  g_loss: 1.345024\n",
      "batch 35  d_loss: 0.331412  g_loss: 1.508673\n",
      "batch 36  d_loss: 0.401900  g_loss: 1.884192\n",
      "batch 37  d_loss: 0.635751  g_loss: 1.716317\n",
      "batch 38  d_loss: 0.452977  g_loss: 1.811054\n",
      "batch 39  d_loss: 0.470092  g_loss: 1.248305\n",
      "batch 40  d_loss: 0.500625  g_loss: 1.151391\n",
      "batch 41  d_loss: 0.603580  g_loss: 0.952679\n",
      "batch 42  d_loss: 0.821513  g_loss: 0.960501\n",
      "batch 43  d_loss: 0.684034  g_loss: 1.174485\n",
      "batch 44  d_loss: 0.748050  g_loss: 1.487265\n",
      "batch 45  d_loss: 0.636774  g_loss: 1.090172\n",
      "Epoch is 49\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.549808  g_loss: 1.154411\n",
      "batch 1  d_loss: 0.523099  g_loss: 1.168568\n",
      "batch 2  d_loss: 0.508228  g_loss: 1.225902\n",
      "batch 3  d_loss: 0.466562  g_loss: 1.377604\n",
      "batch 4  d_loss: 0.452675  g_loss: 1.491317\n",
      "batch 5  d_loss: 0.504361  g_loss: 1.396416\n",
      "batch 6  d_loss: 0.390230  g_loss: 1.713600\n",
      "batch 7  d_loss: 0.469088  g_loss: 1.606572\n",
      "batch 8  d_loss: 0.568375  g_loss: 1.247998\n",
      "batch 9  d_loss: 0.475793  g_loss: 1.350159\n",
      "batch 10  d_loss: 0.575505  g_loss: 1.604921\n",
      "batch 11  d_loss: 0.575133  g_loss: 1.569864\n",
      "batch 12  d_loss: 0.571470  g_loss: 1.198989\n",
      "batch 13  d_loss: 0.598935  g_loss: 1.184939\n",
      "batch 14  d_loss: 0.593403  g_loss: 1.004856\n",
      "batch 15  d_loss: 0.553040  g_loss: 1.312355\n",
      "batch 16  d_loss: 0.399976  g_loss: 1.327952\n",
      "batch 17  d_loss: 0.455407  g_loss: 1.578159\n",
      "batch 18  d_loss: 0.455416  g_loss: 1.795607\n",
      "batch 19  d_loss: 0.621404  g_loss: 1.579678\n",
      "batch 20  d_loss: 0.443027  g_loss: 1.076706\n",
      "batch 21  d_loss: 0.417363  g_loss: 1.097094\n",
      "batch 22  d_loss: 0.533902  g_loss: 0.968708\n",
      "batch 23  d_loss: 0.595856  g_loss: 1.456674\n",
      "batch 24  d_loss: 0.426039  g_loss: 1.729765\n",
      "batch 25  d_loss: 0.433242  g_loss: 1.776554\n",
      "batch 26  d_loss: 0.461372  g_loss: 2.011797\n",
      "batch 27  d_loss: 0.558377  g_loss: 2.172450\n",
      "batch 28  d_loss: 0.660252  g_loss: 1.748150\n",
      "batch 29  d_loss: 0.468081  g_loss: 1.331877\n",
      "batch 30  d_loss: 0.410242  g_loss: 1.260841\n",
      "batch 31  d_loss: 0.620839  g_loss: 1.168173\n",
      "batch 32  d_loss: 0.475425  g_loss: 1.399717\n",
      "batch 33  d_loss: 0.362549  g_loss: 1.854892\n",
      "batch 34  d_loss: 0.349708  g_loss: 2.295043\n",
      "batch 35  d_loss: 0.515147  g_loss: 1.755881\n",
      "batch 36  d_loss: 0.582660  g_loss: 2.170728\n",
      "batch 37  d_loss: 0.706860  g_loss: 1.328044\n",
      "batch 38  d_loss: 0.361698  g_loss: 1.078705\n",
      "batch 39  d_loss: 0.510192  g_loss: 0.955554\n",
      "batch 40  d_loss: 0.466523  g_loss: 1.180555\n",
      "batch 41  d_loss: 0.568660  g_loss: 1.288999\n",
      "batch 42  d_loss: 0.745649  g_loss: 1.598038\n",
      "batch 43  d_loss: 0.593830  g_loss: 1.188664\n",
      "batch 44  d_loss: 0.535952  g_loss: 1.170298\n",
      "batch 45  d_loss: 0.629982  g_loss: 1.087632\n",
      "CPU times: user 11min 19s, sys: 13.6 s, total: 11min 33s\n",
      "Wall time: 3min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176290,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "9077a4b0-a66a-4946-eb3c-f5f70f1d5452"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.669027</td>\n",
       "      <td>0.386611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.504099</td>\n",
       "      <td>0.526209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.440529</td>\n",
       "      <td>1.068747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.326694</td>\n",
       "      <td>2.138679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.190049</td>\n",
       "      <td>3.491627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch    d_loss    g_loss\n",
       "0      0      0  0.669027  0.386611\n",
       "1      0      1  0.504099  0.526209\n",
       "2      0      2  0.440529  1.068747\n",
       "3      0      3  0.326694  2.138679\n",
       "4      0      4  0.190049  3.491627"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.568660</td>\n",
       "      <td>1.288999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.745649</td>\n",
       "      <td>1.598038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>0.593830</td>\n",
       "      <td>1.188664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>0.535952</td>\n",
       "      <td>1.170298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>0.629982</td>\n",
       "      <td>1.087632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  batch    d_loss    g_loss\n",
       "2295     49     41  0.568660  1.288999\n",
       "2296     49     42  0.745649  1.598038\n",
       "2297     49     43  0.593830  1.188664\n",
       "2298     49     44  0.535952  1.170298\n",
       "2299     49     45  0.629982  1.087632"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 176283,
     "status": "ok",
     "timestamp": 1576148503873,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "669f9caf-ccc0-46ef-ed8c-c46b1a28d5ad"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "generate(batch_size)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan_with_keras-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
