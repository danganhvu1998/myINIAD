{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "source": [
    "### Sample program for c-DCGAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:30.738920: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-20 23:33:30.738958: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(17)\n",
    "tf.random.set_seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1264,
     "status": "ok",
     "timestamp": 1577108391508,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "xLeQXXYjCcVm",
    "outputId": "c592030f-9708-4c4c-cc40-1767a4d8a59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 0, 8: 1}\n"
     ]
    }
   ],
   "source": [
    "used_digits = [4, 8]\n",
    "n_digits = len(used_digits)\n",
    "digit2idx = { x:i for i,x in enumerate(used_digits) }\n",
    "print(digit2idx)\n",
    "digits_str = ''.join([str(x) for x in used_digits])\n",
    "\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images_cdcgan'\n",
    "model_g = 'model_cdcgan-b{}_g-d{}.h5'.format(batch_size, digits_str)\n",
    "model_d = 'model_cdcgan-b{}_d-d{}.h5'.format(batch_size, digits_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove old img_dir and create new one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1577108391509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "IOF5fZwICcVo",
    "outputId": "53708760-2253-4bf5-9c88-ce1bdedd32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OK\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(img_dir):\n",
    "    shutil.rmtree(img_dir)\n",
    "\n",
    "cnt = 10\n",
    "while cnt > 0:\n",
    "    try:\n",
    "        os.makedirs(img_dir)\n",
    "        break\n",
    "    except:\n",
    "        sleep(1)\n",
    "    cnt -= 1\n",
    "    \n",
    "if cnt <= 0:\n",
    "    print('Cannot mkdir:', img_dir)\n",
    "else:\n",
    "    print('mkdir: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    in1 = Input(shape=(n_noise,))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    in12 = concatenate([in1, in2])\n",
    "    x = Dense(256, activation='tanh')(in12)\n",
    "    x = Dense(64 * 7 * 7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Reshape((7, 7, 64), input_shape=(7 * 7 * 64,))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(32, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(1, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    in1 = Input(shape=(28, 28, 1))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    in2_up = Reshape((1, 1, n_digits))(in2)\n",
    "    in2_up = UpSampling2D((28, 28))(in2_up)\n",
    "    in12 = concatenate([in1, in2_up])\n",
    "    x = Conv2D(32, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(in12)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='tanh')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    in1 = Input(shape=(n_noise,))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    x = generator([in1, in2])\n",
    "    discriminator.trainable = False\n",
    "    x = discriminator([x, in2])\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples with labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPL73pZG8mny"
   },
   "outputs": [],
   "source": [
    "def combine_images_digits(generated_images, n_digits, height=None):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    if height is not None:\n",
    "        generated_images = generated_images[:height*n_digits]\n",
    "    else:\n",
    "        height = generated_images.shape[0]\n",
    "    width = n_digits\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = shuffle(mnist.load_data())\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    y_train = np.array([digit2idx[x] for x in y_train])\n",
    "    y_train = to_categorical(y_train, n_digits)\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            labels = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict([noise, labels], verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X_img = np.concatenate((image_batch, generated_images))\n",
    "            X_lbl = np.concatenate((labels, labels))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch([X_img, X_lbl], y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                [noise, labels], [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161609,
     "status": "ok",
     "timestamp": 1577108551916,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "ceedb4fd-8000-4006-b0ab-1ef90fd7a83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anhvu/.local/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:38.395835: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-20 23:33:38.395940: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-20 23:33:38.395977: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anhvu): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:39.109224: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-01-20 23:33:41.278319: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 32614400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  d_loss: 0.748881  g_loss: 1.145698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:41.668286: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 32614400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1  d_loss: 0.177903  g_loss: 5.427390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:42.006191: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 32614400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2  d_loss: 0.006019  g_loss: 8.828770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:42.316667: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 32614400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3  d_loss: 0.043294  g_loss: 11.825085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-20 23:33:42.619896: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 32614400 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4  d_loss: 0.008178  g_loss: 12.381811\n",
      "batch 5  d_loss: 0.002399  g_loss: 12.446604\n",
      "batch 6  d_loss: 0.243566  g_loss: 13.121792\n",
      "batch 7  d_loss: 1.153916  g_loss: 11.764465\n",
      "batch 8  d_loss: 0.384261  g_loss: 12.854314\n",
      "batch 9  d_loss: 0.151743  g_loss: 11.617856\n",
      "batch 10  d_loss: 0.019597  g_loss: 12.372681\n",
      "batch 11  d_loss: 0.001314  g_loss: 11.467209\n",
      "batch 12  d_loss: 0.001084  g_loss: 10.938767\n",
      "batch 13  d_loss: 0.368134  g_loss: 11.724192\n",
      "batch 14  d_loss: 0.015735  g_loss: 11.766214\n",
      "batch 15  d_loss: 0.120713  g_loss: 10.046049\n",
      "batch 16  d_loss: 0.740187  g_loss: 9.569216\n",
      "batch 17  d_loss: 0.712215  g_loss: 10.993944\n",
      "batch 18  d_loss: 0.230840  g_loss: 11.409792\n",
      "batch 19  d_loss: 0.123556  g_loss: 12.100167\n",
      "batch 20  d_loss: 0.780475  g_loss: 13.004476\n",
      "batch 21  d_loss: 0.187651  g_loss: 13.408035\n",
      "batch 22  d_loss: 0.352767  g_loss: 12.289024\n",
      "batch 23  d_loss: 0.606079  g_loss: 11.614554\n",
      "batch 24  d_loss: 0.160139  g_loss: 12.697385\n",
      "batch 25  d_loss: 0.435349  g_loss: 11.147728\n",
      "batch 26  d_loss: 0.193550  g_loss: 8.922274\n",
      "batch 27  d_loss: 0.468302  g_loss: 10.435842\n",
      "batch 28  d_loss: 0.986708  g_loss: 12.204395\n",
      "batch 29  d_loss: 0.779698  g_loss: 11.324141\n",
      "batch 30  d_loss: 0.569003  g_loss: 10.752115\n",
      "batch 31  d_loss: 0.118828  g_loss: 10.437303\n",
      "batch 32  d_loss: 0.165174  g_loss: 8.672188\n",
      "batch 33  d_loss: 0.564890  g_loss: 9.032113\n",
      "batch 34  d_loss: 0.475412  g_loss: 9.027976\n",
      "batch 35  d_loss: 0.512355  g_loss: 9.528649\n",
      "batch 36  d_loss: 0.241544  g_loss: 9.667492\n",
      "batch 37  d_loss: 0.154199  g_loss: 9.828798\n",
      "batch 38  d_loss: 0.190307  g_loss: 9.653856\n",
      "batch 39  d_loss: 0.202544  g_loss: 9.941969\n",
      "batch 40  d_loss: 0.186058  g_loss: 8.753938\n",
      "batch 41  d_loss: 0.236017  g_loss: 7.863711\n",
      "batch 42  d_loss: 0.273402  g_loss: 7.404457\n",
      "batch 43  d_loss: 0.204879  g_loss: 7.684356\n",
      "batch 44  d_loss: 0.334653  g_loss: 9.074665\n",
      "batch 45  d_loss: 0.145317  g_loss: 8.371260\n",
      "Epoch is 1\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.139156  g_loss: 8.845014\n",
      "batch 1  d_loss: 0.074605  g_loss: 8.300600\n",
      "batch 2  d_loss: 0.134237  g_loss: 8.714743\n",
      "batch 3  d_loss: 0.145034  g_loss: 7.856215\n",
      "batch 4  d_loss: 0.145228  g_loss: 8.890984\n",
      "batch 5  d_loss: 0.107726  g_loss: 7.907373\n",
      "batch 6  d_loss: 0.160703  g_loss: 8.527884\n",
      "batch 7  d_loss: 0.112969  g_loss: 6.994576\n",
      "batch 8  d_loss: 0.060354  g_loss: 8.103942\n",
      "batch 9  d_loss: 0.067118  g_loss: 6.115269\n",
      "batch 10  d_loss: 0.194966  g_loss: 6.636945\n",
      "batch 11  d_loss: 0.128427  g_loss: 7.031261\n",
      "batch 12  d_loss: 0.136310  g_loss: 7.326098\n",
      "batch 13  d_loss: 0.086615  g_loss: 8.340933\n",
      "batch 14  d_loss: 0.129026  g_loss: 9.585687\n",
      "batch 15  d_loss: 0.192100  g_loss: 9.264102\n",
      "batch 16  d_loss: 0.116177  g_loss: 9.869282\n",
      "batch 17  d_loss: 0.067255  g_loss: 8.889172\n",
      "batch 18  d_loss: 0.039182  g_loss: 9.532929\n",
      "batch 19  d_loss: 0.055953  g_loss: 8.881128\n",
      "batch 20  d_loss: 0.065151  g_loss: 8.502703\n",
      "batch 21  d_loss: 0.107252  g_loss: 8.400245\n",
      "batch 22  d_loss: 0.146892  g_loss: 7.511922\n",
      "batch 23  d_loss: 0.146829  g_loss: 7.794581\n",
      "batch 24  d_loss: 0.253448  g_loss: 8.791154\n",
      "batch 25  d_loss: 0.046372  g_loss: 8.759460\n",
      "batch 26  d_loss: 0.145617  g_loss: 9.463837\n",
      "batch 27  d_loss: 0.161475  g_loss: 10.233223\n",
      "batch 28  d_loss: 0.235914  g_loss: 9.764252\n",
      "batch 29  d_loss: 0.335790  g_loss: 8.736547\n",
      "batch 30  d_loss: 0.174583  g_loss: 8.319274\n",
      "batch 31  d_loss: 0.291067  g_loss: 8.425736\n",
      "batch 32  d_loss: 0.242189  g_loss: 8.391035\n",
      "batch 33  d_loss: 0.250633  g_loss: 8.179307\n",
      "batch 34  d_loss: 0.116263  g_loss: 8.116113\n",
      "batch 35  d_loss: 0.346345  g_loss: 8.676320\n",
      "batch 36  d_loss: 0.453421  g_loss: 7.916178\n",
      "batch 37  d_loss: 0.289822  g_loss: 7.953673\n",
      "batch 38  d_loss: 0.208293  g_loss: 7.574359\n",
      "batch 39  d_loss: 0.165315  g_loss: 7.102381\n",
      "batch 40  d_loss: 0.225486  g_loss: 7.777745\n",
      "batch 41  d_loss: 0.201031  g_loss: 7.848609\n",
      "batch 42  d_loss: 0.258243  g_loss: 7.913427\n",
      "batch 43  d_loss: 0.278847  g_loss: 8.287544\n",
      "batch 44  d_loss: 0.370664  g_loss: 7.751723\n",
      "batch 45  d_loss: 0.144316  g_loss: 8.324759\n",
      "Epoch is 2\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.272016  g_loss: 8.268894\n",
      "batch 1  d_loss: 0.212853  g_loss: 8.223763\n",
      "batch 2  d_loss: 0.377659  g_loss: 8.017743\n",
      "batch 3  d_loss: 0.259385  g_loss: 7.686338\n",
      "batch 4  d_loss: 0.314478  g_loss: 7.920118\n",
      "batch 5  d_loss: 0.289233  g_loss: 8.193146\n",
      "batch 6  d_loss: 0.238903  g_loss: 8.279875\n",
      "batch 7  d_loss: 0.480600  g_loss: 8.137049\n",
      "batch 8  d_loss: 0.328869  g_loss: 7.521226\n",
      "batch 9  d_loss: 0.400800  g_loss: 7.522600\n",
      "batch 10  d_loss: 0.395270  g_loss: 7.518556\n",
      "batch 11  d_loss: 0.302195  g_loss: 8.296596\n",
      "batch 12  d_loss: 0.358223  g_loss: 7.737604\n",
      "batch 13  d_loss: 0.243715  g_loss: 7.832184\n",
      "batch 14  d_loss: 0.189583  g_loss: 7.464191\n",
      "batch 15  d_loss: 0.293841  g_loss: 7.535603\n",
      "batch 16  d_loss: 0.275330  g_loss: 6.345644\n",
      "batch 17  d_loss: 0.270007  g_loss: 6.830247\n",
      "batch 18  d_loss: 0.351906  g_loss: 7.113439\n",
      "batch 19  d_loss: 0.251910  g_loss: 8.019935\n",
      "batch 20  d_loss: 0.505426  g_loss: 7.629587\n",
      "batch 21  d_loss: 0.365507  g_loss: 6.530165\n",
      "batch 22  d_loss: 0.265636  g_loss: 6.780992\n",
      "batch 23  d_loss: 0.288440  g_loss: 7.043227\n",
      "batch 24  d_loss: 0.349362  g_loss: 6.900106\n",
      "batch 25  d_loss: 0.310038  g_loss: 6.908253\n",
      "batch 26  d_loss: 0.342915  g_loss: 7.351852\n",
      "batch 27  d_loss: 0.336376  g_loss: 7.876987\n",
      "batch 28  d_loss: 0.285956  g_loss: 7.357324\n",
      "batch 29  d_loss: 0.239848  g_loss: 7.038691\n",
      "batch 30  d_loss: 0.272636  g_loss: 6.900703\n",
      "batch 31  d_loss: 0.279831  g_loss: 6.594828\n",
      "batch 32  d_loss: 0.297376  g_loss: 5.824530\n",
      "batch 33  d_loss: 0.375590  g_loss: 7.046716\n",
      "batch 34  d_loss: 0.239327  g_loss: 6.511890\n",
      "batch 35  d_loss: 0.210832  g_loss: 7.697762\n",
      "batch 36  d_loss: 0.277681  g_loss: 6.641214\n",
      "batch 37  d_loss: 0.250956  g_loss: 6.248837\n",
      "batch 38  d_loss: 0.246539  g_loss: 7.163463\n",
      "batch 39  d_loss: 0.350383  g_loss: 7.330882\n",
      "batch 40  d_loss: 0.449402  g_loss: 7.023703\n",
      "batch 41  d_loss: 0.341105  g_loss: 6.289858\n",
      "batch 42  d_loss: 0.261420  g_loss: 6.996060\n",
      "batch 43  d_loss: 0.305818  g_loss: 5.942326\n",
      "batch 44  d_loss: 0.370606  g_loss: 6.908154\n",
      "batch 45  d_loss: 0.335193  g_loss: 5.826478\n",
      "Epoch is 3\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.417833  g_loss: 6.596247\n",
      "batch 1  d_loss: 0.326018  g_loss: 6.024913\n",
      "batch 2  d_loss: 0.234217  g_loss: 6.589293\n",
      "batch 3  d_loss: 0.349300  g_loss: 6.132785\n",
      "batch 4  d_loss: 0.402989  g_loss: 5.977544\n",
      "batch 5  d_loss: 0.237069  g_loss: 5.465777\n",
      "batch 6  d_loss: 0.386705  g_loss: 5.603475\n",
      "batch 7  d_loss: 0.406357  g_loss: 5.793500\n",
      "batch 8  d_loss: 0.261003  g_loss: 5.399755\n",
      "batch 9  d_loss: 0.264284  g_loss: 6.470823\n",
      "batch 10  d_loss: 0.223086  g_loss: 5.659119\n",
      "batch 11  d_loss: 0.279050  g_loss: 5.586883\n",
      "batch 12  d_loss: 0.360849  g_loss: 4.959851\n",
      "batch 13  d_loss: 0.236158  g_loss: 4.814085\n",
      "batch 14  d_loss: 0.155341  g_loss: 4.894112\n",
      "batch 15  d_loss: 0.260599  g_loss: 4.914813\n",
      "batch 16  d_loss: 0.254214  g_loss: 5.118354\n",
      "batch 17  d_loss: 0.497424  g_loss: 5.261536\n",
      "batch 18  d_loss: 0.264662  g_loss: 4.915133\n",
      "batch 19  d_loss: 0.197753  g_loss: 5.723336\n",
      "batch 20  d_loss: 0.174555  g_loss: 6.365734\n",
      "batch 21  d_loss: 0.115148  g_loss: 5.272987\n",
      "batch 22  d_loss: 0.179668  g_loss: 5.721474\n",
      "batch 23  d_loss: 0.241948  g_loss: 6.025047\n",
      "batch 24  d_loss: 0.090395  g_loss: 5.436265\n",
      "batch 25  d_loss: 0.097395  g_loss: 5.776584\n",
      "batch 26  d_loss: 0.162520  g_loss: 6.194028\n",
      "batch 27  d_loss: 0.084191  g_loss: 5.716988\n",
      "batch 28  d_loss: 0.177547  g_loss: 6.533433\n",
      "batch 29  d_loss: 0.108384  g_loss: 6.145789\n",
      "batch 30  d_loss: 0.170172  g_loss: 5.894362\n",
      "batch 31  d_loss: 0.100883  g_loss: 5.534099\n",
      "batch 32  d_loss: 0.252073  g_loss: 5.282873\n",
      "batch 33  d_loss: 0.329703  g_loss: 5.739394\n",
      "batch 34  d_loss: 0.170328  g_loss: 6.154231\n",
      "batch 35  d_loss: 0.082438  g_loss: 6.716823\n",
      "batch 36  d_loss: 0.190938  g_loss: 8.239406\n",
      "batch 37  d_loss: 0.100651  g_loss: 7.450440\n",
      "batch 38  d_loss: 0.120399  g_loss: 6.743742\n",
      "batch 39  d_loss: 0.143387  g_loss: 6.804245\n",
      "batch 40  d_loss: 0.140129  g_loss: 6.742514\n",
      "batch 41  d_loss: 0.264902  g_loss: 6.936424\n",
      "batch 42  d_loss: 0.101444  g_loss: 6.392416\n",
      "batch 43  d_loss: 0.227392  g_loss: 6.767175\n",
      "batch 44  d_loss: 0.223921  g_loss: 7.129731\n",
      "batch 45  d_loss: 0.050480  g_loss: 7.415423\n",
      "Epoch is 4\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.179463  g_loss: 6.440628\n",
      "batch 1  d_loss: 0.139800  g_loss: 7.538387\n",
      "batch 2  d_loss: 0.375750  g_loss: 7.847020\n",
      "batch 3  d_loss: 0.314281  g_loss: 6.519320\n",
      "batch 4  d_loss: 0.110916  g_loss: 6.404800\n",
      "batch 5  d_loss: 0.414288  g_loss: 5.945767\n",
      "batch 6  d_loss: 0.229034  g_loss: 7.382581\n",
      "batch 7  d_loss: 0.109021  g_loss: 7.448734\n",
      "batch 8  d_loss: 0.169603  g_loss: 7.975798\n",
      "batch 9  d_loss: 0.119459  g_loss: 7.609687\n",
      "batch 10  d_loss: 0.136549  g_loss: 7.532984\n",
      "batch 11  d_loss: 0.212262  g_loss: 6.698622\n",
      "batch 12  d_loss: 0.159929  g_loss: 7.181629\n",
      "batch 13  d_loss: 0.209780  g_loss: 6.764770\n",
      "batch 14  d_loss: 0.170849  g_loss: 6.553221\n",
      "batch 15  d_loss: 0.147776  g_loss: 6.906879\n",
      "batch 16  d_loss: 0.172281  g_loss: 6.129823\n",
      "batch 17  d_loss: 0.228501  g_loss: 7.386306\n",
      "batch 18  d_loss: 0.141064  g_loss: 8.168427\n",
      "batch 19  d_loss: 0.120428  g_loss: 7.176360\n",
      "batch 20  d_loss: 0.350368  g_loss: 7.342021\n",
      "batch 21  d_loss: 0.200922  g_loss: 6.015265\n",
      "batch 22  d_loss: 0.129717  g_loss: 5.263673\n",
      "batch 23  d_loss: 0.146573  g_loss: 6.699780\n",
      "batch 24  d_loss: 0.212323  g_loss: 6.861713\n",
      "batch 25  d_loss: 0.159952  g_loss: 7.761384\n",
      "batch 26  d_loss: 0.171127  g_loss: 7.535263\n",
      "batch 27  d_loss: 0.101652  g_loss: 7.381868\n",
      "batch 28  d_loss: 0.164414  g_loss: 6.683506\n",
      "batch 29  d_loss: 0.241154  g_loss: 6.696154\n",
      "batch 30  d_loss: 0.207013  g_loss: 6.988431\n",
      "batch 31  d_loss: 0.195671  g_loss: 6.538006\n",
      "batch 32  d_loss: 0.301124  g_loss: 6.996441\n",
      "batch 33  d_loss: 0.118676  g_loss: 6.221969\n",
      "batch 34  d_loss: 0.182671  g_loss: 6.060344\n",
      "batch 35  d_loss: 0.227598  g_loss: 5.834889\n",
      "batch 36  d_loss: 0.334026  g_loss: 6.340512\n",
      "batch 37  d_loss: 0.156952  g_loss: 6.568113\n",
      "batch 38  d_loss: 0.198058  g_loss: 6.784748\n",
      "batch 39  d_loss: 0.206111  g_loss: 6.936172\n",
      "batch 40  d_loss: 0.176301  g_loss: 6.751444\n",
      "batch 41  d_loss: 0.267903  g_loss: 7.247769\n",
      "batch 42  d_loss: 0.235759  g_loss: 5.601254\n",
      "batch 43  d_loss: 0.111400  g_loss: 6.040195\n",
      "batch 44  d_loss: 0.131701  g_loss: 5.866881\n",
      "batch 45  d_loss: 0.046027  g_loss: 6.080573\n",
      "Epoch is 5\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.282130  g_loss: 6.839221\n",
      "batch 1  d_loss: 0.308011  g_loss: 6.568729\n",
      "batch 2  d_loss: 0.143850  g_loss: 7.909439\n",
      "batch 3  d_loss: 0.111420  g_loss: 7.919993\n",
      "batch 4  d_loss: 0.157018  g_loss: 8.158623\n",
      "batch 5  d_loss: 0.135464  g_loss: 8.489319\n",
      "batch 6  d_loss: 0.191667  g_loss: 7.670673\n",
      "batch 7  d_loss: 0.278017  g_loss: 7.643087\n",
      "batch 8  d_loss: 0.280927  g_loss: 7.395784\n",
      "batch 9  d_loss: 0.123964  g_loss: 5.945493\n",
      "batch 10  d_loss: 0.142234  g_loss: 6.711456\n",
      "batch 11  d_loss: 0.282389  g_loss: 5.967194\n",
      "batch 12  d_loss: 0.240294  g_loss: 7.437402\n",
      "batch 13  d_loss: 0.434785  g_loss: 7.103966\n",
      "batch 14  d_loss: 0.192400  g_loss: 7.015779\n",
      "batch 15  d_loss: 0.334422  g_loss: 7.061699\n",
      "batch 16  d_loss: 0.227158  g_loss: 6.561412\n",
      "batch 17  d_loss: 0.318717  g_loss: 6.433480\n",
      "batch 18  d_loss: 0.202344  g_loss: 5.440854\n",
      "batch 19  d_loss: 0.218935  g_loss: 6.378899\n",
      "batch 20  d_loss: 0.313561  g_loss: 5.310874\n",
      "batch 21  d_loss: 0.261365  g_loss: 4.913116\n",
      "batch 22  d_loss: 0.251869  g_loss: 5.638943\n",
      "batch 23  d_loss: 0.305902  g_loss: 6.041498\n",
      "batch 24  d_loss: 0.245458  g_loss: 5.925309\n",
      "batch 25  d_loss: 0.338844  g_loss: 6.186202\n",
      "batch 26  d_loss: 0.224331  g_loss: 5.941911\n",
      "batch 27  d_loss: 0.149931  g_loss: 5.481433\n",
      "batch 28  d_loss: 0.294337  g_loss: 5.236036\n",
      "batch 29  d_loss: 0.221274  g_loss: 5.819487\n",
      "batch 30  d_loss: 0.212997  g_loss: 5.858447\n",
      "batch 31  d_loss: 0.309923  g_loss: 6.510149\n",
      "batch 32  d_loss: 0.265324  g_loss: 5.744254\n",
      "batch 33  d_loss: 0.203521  g_loss: 5.702823\n",
      "batch 34  d_loss: 0.201751  g_loss: 5.562280\n",
      "batch 35  d_loss: 0.263529  g_loss: 4.845301\n",
      "batch 36  d_loss: 0.246915  g_loss: 4.833359\n",
      "batch 37  d_loss: 0.123438  g_loss: 4.573404\n",
      "batch 38  d_loss: 0.292949  g_loss: 4.086784\n",
      "batch 39  d_loss: 0.226986  g_loss: 4.559981\n",
      "batch 40  d_loss: 0.150796  g_loss: 4.791594\n",
      "batch 41  d_loss: 0.191380  g_loss: 5.174048\n",
      "batch 42  d_loss: 0.170642  g_loss: 5.231623\n",
      "batch 43  d_loss: 0.158060  g_loss: 4.863961\n",
      "batch 44  d_loss: 0.237256  g_loss: 4.126591\n",
      "batch 45  d_loss: 0.141398  g_loss: 3.883373\n",
      "Epoch is 6\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.315259  g_loss: 3.757400\n",
      "batch 1  d_loss: 0.249920  g_loss: 4.229493\n",
      "batch 2  d_loss: 0.258049  g_loss: 4.794380\n",
      "batch 3  d_loss: 0.247612  g_loss: 4.674614\n",
      "batch 4  d_loss: 0.270809  g_loss: 4.739165\n",
      "batch 5  d_loss: 0.257947  g_loss: 3.925720\n",
      "batch 6  d_loss: 0.236267  g_loss: 4.249337\n",
      "batch 7  d_loss: 0.483964  g_loss: 4.206079\n",
      "batch 8  d_loss: 0.416731  g_loss: 4.198591\n",
      "batch 9  d_loss: 0.455267  g_loss: 3.831767\n",
      "batch 10  d_loss: 0.200988  g_loss: 4.810163\n",
      "batch 11  d_loss: 0.340400  g_loss: 4.532497\n",
      "batch 12  d_loss: 0.304073  g_loss: 4.383255\n",
      "batch 13  d_loss: 0.305106  g_loss: 4.397410\n",
      "batch 14  d_loss: 0.284131  g_loss: 3.839076\n",
      "batch 15  d_loss: 0.297559  g_loss: 3.894059\n",
      "batch 16  d_loss: 0.237213  g_loss: 4.293887\n",
      "batch 17  d_loss: 0.285412  g_loss: 4.195253\n",
      "batch 18  d_loss: 0.211169  g_loss: 4.211419\n",
      "batch 19  d_loss: 0.213439  g_loss: 3.986208\n",
      "batch 20  d_loss: 0.230552  g_loss: 4.332719\n",
      "batch 21  d_loss: 0.161463  g_loss: 4.602117\n",
      "batch 22  d_loss: 0.177933  g_loss: 4.271920\n",
      "batch 23  d_loss: 0.161879  g_loss: 4.753069\n",
      "batch 24  d_loss: 0.145685  g_loss: 4.442506\n",
      "batch 25  d_loss: 0.100912  g_loss: 4.484375\n",
      "batch 26  d_loss: 0.101990  g_loss: 3.866991\n",
      "batch 27  d_loss: 0.183853  g_loss: 4.630265\n",
      "batch 28  d_loss: 0.135907  g_loss: 4.841512\n",
      "batch 29  d_loss: 0.170389  g_loss: 4.948293\n",
      "batch 30  d_loss: 0.178120  g_loss: 4.511363\n",
      "batch 31  d_loss: 0.178883  g_loss: 4.287505\n",
      "batch 32  d_loss: 0.129122  g_loss: 4.142007\n",
      "batch 33  d_loss: 0.217104  g_loss: 4.044329\n",
      "batch 34  d_loss: 0.304176  g_loss: 4.231252\n",
      "batch 35  d_loss: 0.143614  g_loss: 4.283898\n",
      "batch 36  d_loss: 0.295197  g_loss: 4.537985\n",
      "batch 37  d_loss: 0.233253  g_loss: 3.715976\n",
      "batch 38  d_loss: 0.189204  g_loss: 4.235025\n",
      "batch 39  d_loss: 0.184874  g_loss: 3.851473\n",
      "batch 40  d_loss: 0.182526  g_loss: 4.334727\n",
      "batch 41  d_loss: 0.277739  g_loss: 4.216990\n",
      "batch 42  d_loss: 0.186557  g_loss: 3.885443\n",
      "batch 43  d_loss: 0.195424  g_loss: 3.773226\n",
      "batch 44  d_loss: 0.201208  g_loss: 4.115861\n",
      "batch 45  d_loss: 0.162604  g_loss: 3.983714\n",
      "Epoch is 7\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.153807  g_loss: 4.188195\n",
      "batch 1  d_loss: 0.061723  g_loss: 4.660564\n",
      "batch 2  d_loss: 0.226833  g_loss: 4.050577\n",
      "batch 3  d_loss: 0.161190  g_loss: 3.877399\n",
      "batch 4  d_loss: 0.166634  g_loss: 3.659077\n",
      "batch 5  d_loss: 0.223579  g_loss: 3.499526\n",
      "batch 6  d_loss: 0.159055  g_loss: 3.483147\n",
      "batch 7  d_loss: 0.229439  g_loss: 4.443707\n",
      "batch 8  d_loss: 0.140192  g_loss: 4.156006\n",
      "batch 9  d_loss: 0.128109  g_loss: 4.406796\n",
      "batch 10  d_loss: 0.188075  g_loss: 4.407948\n",
      "batch 11  d_loss: 0.129454  g_loss: 4.081747\n",
      "batch 12  d_loss: 0.093298  g_loss: 3.579566\n",
      "batch 13  d_loss: 0.171163  g_loss: 3.868272\n",
      "batch 14  d_loss: 0.154540  g_loss: 3.648933\n",
      "batch 15  d_loss: 0.147263  g_loss: 3.684855\n",
      "batch 16  d_loss: 0.155747  g_loss: 4.055500\n",
      "batch 17  d_loss: 0.160407  g_loss: 4.574853\n",
      "batch 18  d_loss: 0.091424  g_loss: 4.361046\n",
      "batch 19  d_loss: 0.138783  g_loss: 3.872693\n",
      "batch 20  d_loss: 0.092617  g_loss: 4.308429\n",
      "batch 21  d_loss: 0.110123  g_loss: 4.375156\n",
      "batch 22  d_loss: 0.118540  g_loss: 3.694267\n",
      "batch 23  d_loss: 0.097835  g_loss: 3.668938\n",
      "batch 24  d_loss: 0.158032  g_loss: 4.051409\n",
      "batch 25  d_loss: 0.081489  g_loss: 4.490846\n",
      "batch 26  d_loss: 0.100406  g_loss: 4.419322\n",
      "batch 27  d_loss: 0.077521  g_loss: 4.913964\n",
      "batch 28  d_loss: 0.110298  g_loss: 4.746173\n",
      "batch 29  d_loss: 0.131185  g_loss: 4.340104\n",
      "batch 30  d_loss: 0.081585  g_loss: 3.985283\n",
      "batch 31  d_loss: 0.140706  g_loss: 4.251157\n",
      "batch 32  d_loss: 0.216671  g_loss: 3.184616\n",
      "batch 33  d_loss: 0.275507  g_loss: 3.391074\n",
      "batch 34  d_loss: 0.160961  g_loss: 3.423601\n",
      "batch 35  d_loss: 0.229507  g_loss: 4.038669\n",
      "batch 36  d_loss: 0.312027  g_loss: 3.932697\n",
      "batch 37  d_loss: 0.151990  g_loss: 3.228553\n",
      "batch 38  d_loss: 0.179626  g_loss: 3.445977\n",
      "batch 39  d_loss: 0.176124  g_loss: 3.584887\n",
      "batch 40  d_loss: 0.192570  g_loss: 3.966381\n",
      "batch 41  d_loss: 0.192603  g_loss: 4.419842\n",
      "batch 42  d_loss: 0.213152  g_loss: 3.841131\n",
      "batch 43  d_loss: 0.137371  g_loss: 4.135378\n",
      "batch 44  d_loss: 0.222704  g_loss: 3.971144\n",
      "batch 45  d_loss: 0.163190  g_loss: 3.626886\n",
      "Epoch is 8\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.162440  g_loss: 4.176176\n",
      "batch 1  d_loss: 0.149491  g_loss: 3.899724\n",
      "batch 2  d_loss: 0.183481  g_loss: 4.082015\n",
      "batch 3  d_loss: 0.112267  g_loss: 4.083549\n",
      "batch 4  d_loss: 0.192754  g_loss: 3.805266\n",
      "batch 5  d_loss: 0.233920  g_loss: 3.685841\n",
      "batch 6  d_loss: 0.151514  g_loss: 3.960266\n",
      "batch 7  d_loss: 0.666376  g_loss: 2.862494\n",
      "batch 8  d_loss: 0.261940  g_loss: 1.849334\n",
      "batch 9  d_loss: 0.323252  g_loss: 2.612060\n",
      "batch 10  d_loss: 0.292968  g_loss: 2.852344\n",
      "batch 11  d_loss: 0.185621  g_loss: 3.721562\n",
      "batch 12  d_loss: 0.228283  g_loss: 3.532792\n",
      "batch 13  d_loss: 0.236169  g_loss: 2.883813\n",
      "batch 14  d_loss: 0.177636  g_loss: 2.731738\n",
      "batch 15  d_loss: 0.227156  g_loss: 1.918215\n",
      "batch 16  d_loss: 0.243638  g_loss: 2.069764\n",
      "batch 17  d_loss: 0.211651  g_loss: 2.876832\n",
      "batch 18  d_loss: 0.149097  g_loss: 3.171374\n",
      "batch 19  d_loss: 0.202598  g_loss: 3.504999\n",
      "batch 20  d_loss: 0.266343  g_loss: 2.758612\n",
      "batch 21  d_loss: 0.157298  g_loss: 2.104892\n",
      "batch 22  d_loss: 0.119322  g_loss: 2.472661\n",
      "batch 23  d_loss: 0.245663  g_loss: 2.478181\n",
      "batch 24  d_loss: 0.159516  g_loss: 3.167155\n",
      "batch 25  d_loss: 0.187602  g_loss: 3.293288\n",
      "batch 26  d_loss: 0.147207  g_loss: 2.832764\n",
      "batch 27  d_loss: 0.184483  g_loss: 2.879267\n",
      "batch 28  d_loss: 0.237260  g_loss: 2.877081\n",
      "batch 29  d_loss: 0.208160  g_loss: 1.851200\n",
      "batch 30  d_loss: 0.268830  g_loss: 1.899412\n",
      "batch 31  d_loss: 0.279713  g_loss: 2.357391\n",
      "batch 32  d_loss: 0.326855  g_loss: 2.361247\n",
      "batch 33  d_loss: 0.291861  g_loss: 2.475970\n",
      "batch 34  d_loss: 0.283797  g_loss: 2.302376\n",
      "batch 35  d_loss: 0.313357  g_loss: 2.720752\n",
      "batch 36  d_loss: 0.289028  g_loss: 2.722047\n",
      "batch 37  d_loss: 0.188863  g_loss: 2.273685\n",
      "batch 38  d_loss: 0.215079  g_loss: 2.526165\n",
      "batch 39  d_loss: 0.112243  g_loss: 3.008395\n",
      "batch 40  d_loss: 0.149254  g_loss: 3.018826\n",
      "batch 41  d_loss: 0.163615  g_loss: 3.008125\n",
      "batch 42  d_loss: 0.155676  g_loss: 2.731264\n",
      "batch 43  d_loss: 0.121084  g_loss: 2.546485\n",
      "batch 44  d_loss: 0.131902  g_loss: 2.454491\n",
      "batch 45  d_loss: 0.191998  g_loss: 3.233514\n",
      "Epoch is 9\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.169923  g_loss: 4.040663\n",
      "batch 1  d_loss: 0.154128  g_loss: 3.874933\n",
      "batch 2  d_loss: 0.090260  g_loss: 2.919186\n",
      "batch 3  d_loss: 0.077402  g_loss: 3.192801\n",
      "batch 4  d_loss: 0.107275  g_loss: 2.606177\n",
      "batch 5  d_loss: 0.105087  g_loss: 3.138678\n",
      "batch 6  d_loss: 0.145303  g_loss: 3.151310\n",
      "batch 7  d_loss: 0.255980  g_loss: 3.239958\n",
      "batch 8  d_loss: 0.180025  g_loss: 2.439307\n",
      "batch 9  d_loss: 0.164022  g_loss: 2.825652\n",
      "batch 10  d_loss: 0.077024  g_loss: 3.066477\n",
      "batch 11  d_loss: 0.179852  g_loss: 2.820893\n",
      "batch 12  d_loss: 0.153711  g_loss: 3.083578\n",
      "batch 13  d_loss: 0.159457  g_loss: 3.680217\n",
      "batch 14  d_loss: 0.085476  g_loss: 3.879222\n",
      "batch 15  d_loss: 0.231946  g_loss: 3.494098\n",
      "batch 16  d_loss: 0.200273  g_loss: 2.339797\n",
      "batch 17  d_loss: 0.137719  g_loss: 2.160730\n",
      "batch 18  d_loss: 0.104808  g_loss: 1.815602\n",
      "batch 19  d_loss: 0.190720  g_loss: 2.949543\n",
      "batch 20  d_loss: 0.126522  g_loss: 4.157073\n",
      "batch 21  d_loss: 0.188148  g_loss: 4.131267\n",
      "batch 22  d_loss: 0.126214  g_loss: 3.686391\n",
      "batch 23  d_loss: 0.176681  g_loss: 3.245708\n",
      "batch 24  d_loss: 0.077595  g_loss: 2.716604\n",
      "batch 25  d_loss: 0.211687  g_loss: 2.041727\n",
      "batch 26  d_loss: 0.223815  g_loss: 2.620676\n",
      "batch 27  d_loss: 0.160708  g_loss: 3.752856\n",
      "batch 28  d_loss: 0.216558  g_loss: 4.110184\n",
      "batch 29  d_loss: 0.263477  g_loss: 3.678814\n",
      "batch 30  d_loss: 0.183550  g_loss: 2.905991\n",
      "batch 31  d_loss: 0.183940  g_loss: 2.293553\n",
      "batch 32  d_loss: 0.369980  g_loss: 1.546044\n",
      "batch 33  d_loss: 0.392038  g_loss: 2.297784\n",
      "batch 34  d_loss: 0.214755  g_loss: 3.284413\n",
      "batch 35  d_loss: 0.241230  g_loss: 3.579693\n",
      "batch 36  d_loss: 0.498869  g_loss: 2.371966\n",
      "batch 37  d_loss: 0.161955  g_loss: 1.827083\n",
      "batch 38  d_loss: 0.267332  g_loss: 1.793210\n",
      "batch 39  d_loss: 0.246878  g_loss: 2.740795\n",
      "batch 40  d_loss: 0.219378  g_loss: 3.876154\n",
      "batch 41  d_loss: 0.336480  g_loss: 3.152730\n",
      "batch 42  d_loss: 0.164158  g_loss: 2.512889\n",
      "batch 43  d_loss: 0.199426  g_loss: 1.876937\n",
      "batch 44  d_loss: 0.237300  g_loss: 2.864640\n",
      "batch 45  d_loss: 0.125503  g_loss: 3.682171\n",
      "Epoch is 10\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.196443  g_loss: 3.578394\n",
      "batch 1  d_loss: 0.159035  g_loss: 3.197873\n",
      "batch 2  d_loss: 0.172768  g_loss: 1.796797\n",
      "batch 3  d_loss: 0.395550  g_loss: 2.738746\n",
      "batch 4  d_loss: 0.286417  g_loss: 2.789261\n",
      "batch 5  d_loss: 0.334121  g_loss: 2.191314\n",
      "batch 6  d_loss: 0.225018  g_loss: 1.629283\n",
      "batch 7  d_loss: 0.308957  g_loss: 1.661451\n",
      "batch 8  d_loss: 0.336563  g_loss: 2.734544\n",
      "batch 9  d_loss: 0.204789  g_loss: 2.966144\n",
      "batch 10  d_loss: 0.236868  g_loss: 2.525441\n",
      "batch 11  d_loss: 0.235770  g_loss: 2.079099\n",
      "batch 12  d_loss: 0.187647  g_loss: 2.528219\n",
      "batch 13  d_loss: 0.159852  g_loss: 2.596206\n",
      "batch 14  d_loss: 0.146065  g_loss: 3.148158\n",
      "batch 15  d_loss: 0.224758  g_loss: 3.317854\n",
      "batch 16  d_loss: 0.177182  g_loss: 2.771250\n",
      "batch 17  d_loss: 0.130521  g_loss: 2.023853\n",
      "batch 18  d_loss: 0.171321  g_loss: 2.138519\n",
      "batch 19  d_loss: 0.222654  g_loss: 3.125695\n",
      "batch 20  d_loss: 0.100858  g_loss: 4.339392\n",
      "batch 21  d_loss: 0.079581  g_loss: 4.738918\n",
      "batch 22  d_loss: 0.137135  g_loss: 4.511458\n",
      "batch 23  d_loss: 0.069564  g_loss: 4.746923\n",
      "batch 24  d_loss: 0.074038  g_loss: 3.909357\n",
      "batch 25  d_loss: 0.046504  g_loss: 3.975605\n",
      "batch 26  d_loss: 0.069169  g_loss: 3.170575\n",
      "batch 27  d_loss: 0.150084  g_loss: 3.682115\n",
      "batch 28  d_loss: 0.088755  g_loss: 4.420764\n",
      "batch 29  d_loss: 0.101560  g_loss: 4.507240\n",
      "batch 30  d_loss: 0.057011  g_loss: 4.546244\n",
      "batch 31  d_loss: 0.131274  g_loss: 4.394979\n",
      "batch 32  d_loss: 0.112749  g_loss: 4.164139\n",
      "batch 33  d_loss: 0.080919  g_loss: 3.406419\n",
      "batch 34  d_loss: 0.132322  g_loss: 3.723612\n",
      "batch 35  d_loss: 0.073193  g_loss: 3.399660\n",
      "batch 36  d_loss: 0.394450  g_loss: 2.797306\n",
      "batch 37  d_loss: 0.158177  g_loss: 3.397593\n",
      "batch 38  d_loss: 0.159436  g_loss: 3.553594\n",
      "batch 39  d_loss: 0.180306  g_loss: 3.604218\n",
      "batch 40  d_loss: 0.222326  g_loss: 4.055065\n",
      "batch 41  d_loss: 0.283614  g_loss: 3.228249\n",
      "batch 42  d_loss: 0.183704  g_loss: 3.215840\n",
      "batch 43  d_loss: 0.305300  g_loss: 2.510391\n",
      "batch 44  d_loss: 0.254251  g_loss: 3.153387\n",
      "batch 45  d_loss: 0.229978  g_loss: 3.452950\n",
      "Epoch is 11\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.345716  g_loss: 3.096517\n",
      "batch 1  d_loss: 0.259476  g_loss: 2.517724\n",
      "batch 2  d_loss: 0.192775  g_loss: 2.344028\n",
      "batch 3  d_loss: 0.223116  g_loss: 2.644622\n",
      "batch 4  d_loss: 0.384351  g_loss: 1.790290\n",
      "batch 5  d_loss: 0.517185  g_loss: 2.786680\n",
      "batch 6  d_loss: 0.271767  g_loss: 3.263561\n",
      "batch 7  d_loss: 1.226272  g_loss: 1.391203\n",
      "batch 8  d_loss: 0.529201  g_loss: 0.766168\n",
      "batch 9  d_loss: 0.653722  g_loss: 1.402068\n",
      "batch 10  d_loss: 0.293333  g_loss: 2.176839\n",
      "batch 11  d_loss: 0.418454  g_loss: 2.417863\n",
      "batch 12  d_loss: 0.550813  g_loss: 1.804643\n",
      "batch 13  d_loss: 0.390877  g_loss: 1.131485\n",
      "batch 14  d_loss: 0.367998  g_loss: 1.275444\n",
      "batch 15  d_loss: 0.418392  g_loss: 1.415082\n",
      "batch 16  d_loss: 0.386231  g_loss: 2.032333\n",
      "batch 17  d_loss: 0.440480  g_loss: 1.994076\n",
      "batch 18  d_loss: 0.385962  g_loss: 2.344999\n",
      "batch 19  d_loss: 0.299329  g_loss: 1.736473\n",
      "batch 20  d_loss: 0.309498  g_loss: 1.767861\n",
      "batch 21  d_loss: 0.283266  g_loss: 1.588103\n",
      "batch 22  d_loss: 0.235163  g_loss: 2.247724\n",
      "batch 23  d_loss: 0.213980  g_loss: 2.611414\n",
      "batch 24  d_loss: 0.215206  g_loss: 2.545679\n",
      "batch 25  d_loss: 0.178476  g_loss: 2.411469\n",
      "batch 26  d_loss: 0.202260  g_loss: 2.564553\n",
      "batch 27  d_loss: 0.127375  g_loss: 2.389414\n",
      "batch 28  d_loss: 0.188415  g_loss: 2.198063\n",
      "batch 29  d_loss: 0.235302  g_loss: 2.114274\n",
      "batch 30  d_loss: 0.192996  g_loss: 2.817320\n",
      "batch 31  d_loss: 0.199019  g_loss: 2.944718\n",
      "batch 32  d_loss: 0.394841  g_loss: 2.920398\n",
      "batch 33  d_loss: 0.276473  g_loss: 2.701544\n",
      "batch 34  d_loss: 0.180376  g_loss: 1.829917\n",
      "batch 35  d_loss: 0.215578  g_loss: 1.963115\n",
      "batch 36  d_loss: 0.373201  g_loss: 2.415868\n",
      "batch 37  d_loss: 0.239087  g_loss: 2.430029\n",
      "batch 38  d_loss: 0.171158  g_loss: 2.567116\n",
      "batch 39  d_loss: 0.256334  g_loss: 2.353184\n",
      "batch 40  d_loss: 0.314938  g_loss: 2.470911\n",
      "batch 41  d_loss: 0.203986  g_loss: 1.916491\n",
      "batch 42  d_loss: 0.142074  g_loss: 2.368891\n",
      "batch 43  d_loss: 0.302307  g_loss: 2.444784\n",
      "batch 44  d_loss: 0.300602  g_loss: 2.610801\n",
      "batch 45  d_loss: 0.148774  g_loss: 3.063715\n",
      "Epoch is 12\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.223721  g_loss: 2.843597\n",
      "batch 1  d_loss: 0.248375  g_loss: 2.653350\n",
      "batch 2  d_loss: 0.196983  g_loss: 2.406222\n",
      "batch 3  d_loss: 0.253758  g_loss: 2.088706\n",
      "batch 4  d_loss: 0.366608  g_loss: 3.144989\n",
      "batch 5  d_loss: 0.203109  g_loss: 3.825510\n",
      "batch 6  d_loss: 0.278284  g_loss: 2.888020\n",
      "batch 7  d_loss: 0.598869  g_loss: 2.159843\n",
      "batch 8  d_loss: 0.371818  g_loss: 1.458407\n",
      "batch 9  d_loss: 0.383688  g_loss: 1.651653\n",
      "batch 10  d_loss: 0.295495  g_loss: 2.061196\n",
      "batch 11  d_loss: 0.295249  g_loss: 2.792360\n",
      "batch 12  d_loss: 0.320498  g_loss: 2.860543\n",
      "batch 13  d_loss: 0.265395  g_loss: 2.096381\n",
      "batch 14  d_loss: 0.226217  g_loss: 2.031387\n",
      "batch 15  d_loss: 0.155877  g_loss: 2.044502\n",
      "batch 16  d_loss: 0.200343  g_loss: 2.239817\n",
      "batch 17  d_loss: 0.239010  g_loss: 2.372248\n",
      "batch 18  d_loss: 0.226454  g_loss: 2.383853\n",
      "batch 19  d_loss: 0.269636  g_loss: 2.649846\n",
      "batch 20  d_loss: 0.296642  g_loss: 2.906389\n",
      "batch 21  d_loss: 0.294019  g_loss: 2.714331\n",
      "batch 22  d_loss: 0.294601  g_loss: 2.026642\n",
      "batch 23  d_loss: 0.241620  g_loss: 2.077898\n",
      "batch 24  d_loss: 0.263069  g_loss: 2.679170\n",
      "batch 25  d_loss: 0.381524  g_loss: 2.725394\n",
      "batch 26  d_loss: 0.300164  g_loss: 2.214809\n",
      "batch 27  d_loss: 0.250354  g_loss: 1.878788\n",
      "batch 28  d_loss: 0.294582  g_loss: 1.667336\n",
      "batch 29  d_loss: 0.361209  g_loss: 1.970522\n",
      "batch 30  d_loss: 0.254225  g_loss: 2.793120\n",
      "batch 31  d_loss: 0.285515  g_loss: 2.862407\n",
      "batch 32  d_loss: 0.402597  g_loss: 2.285598\n",
      "batch 33  d_loss: 0.205991  g_loss: 1.627945\n",
      "batch 34  d_loss: 0.197986  g_loss: 1.603623\n",
      "batch 35  d_loss: 0.283989  g_loss: 2.179382\n",
      "batch 36  d_loss: 0.237334  g_loss: 2.625613\n",
      "batch 37  d_loss: 0.224825  g_loss: 3.000794\n",
      "batch 38  d_loss: 0.240648  g_loss: 3.084700\n",
      "batch 39  d_loss: 0.235331  g_loss: 2.793900\n",
      "batch 40  d_loss: 0.237850  g_loss: 1.957321\n",
      "batch 41  d_loss: 0.369148  g_loss: 2.363438\n",
      "batch 42  d_loss: 0.263693  g_loss: 2.802104\n",
      "batch 43  d_loss: 0.380655  g_loss: 2.835654\n",
      "batch 44  d_loss: 0.307115  g_loss: 2.505836\n",
      "batch 45  d_loss: 0.207019  g_loss: 2.498203\n",
      "Epoch is 13\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.274026  g_loss: 2.492592\n",
      "batch 1  d_loss: 0.249036  g_loss: 2.159242\n",
      "batch 2  d_loss: 0.273031  g_loss: 2.229795\n",
      "batch 3  d_loss: 0.287559  g_loss: 2.894015\n",
      "batch 4  d_loss: 0.319714  g_loss: 2.740310\n",
      "batch 5  d_loss: 0.407896  g_loss: 2.323019\n",
      "batch 6  d_loss: 0.187061  g_loss: 2.207213\n",
      "batch 7  d_loss: 0.562390  g_loss: 1.469028\n",
      "batch 8  d_loss: 0.387172  g_loss: 1.694655\n",
      "batch 9  d_loss: 0.267305  g_loss: 2.280507\n",
      "batch 10  d_loss: 0.212953  g_loss: 3.184629\n",
      "batch 11  d_loss: 0.472291  g_loss: 2.593346\n",
      "batch 12  d_loss: 0.371206  g_loss: 1.662992\n",
      "batch 13  d_loss: 0.337635  g_loss: 1.184905\n",
      "batch 14  d_loss: 0.372135  g_loss: 1.796234\n",
      "batch 15  d_loss: 0.412971  g_loss: 1.918814\n",
      "batch 16  d_loss: 0.317419  g_loss: 2.400489\n",
      "batch 17  d_loss: 0.518813  g_loss: 1.921031\n",
      "batch 18  d_loss: 0.262450  g_loss: 1.696405\n",
      "batch 19  d_loss: 0.321145  g_loss: 1.770970\n",
      "batch 20  d_loss: 0.297898  g_loss: 1.814198\n",
      "batch 21  d_loss: 0.276827  g_loss: 2.265900\n",
      "batch 22  d_loss: 0.257988  g_loss: 2.583978\n",
      "batch 23  d_loss: 0.315498  g_loss: 2.451243\n",
      "batch 24  d_loss: 0.330417  g_loss: 2.238375\n",
      "batch 25  d_loss: 0.356754  g_loss: 1.738920\n",
      "batch 26  d_loss: 0.385422  g_loss: 1.856016\n",
      "batch 27  d_loss: 0.363243  g_loss: 2.098857\n",
      "batch 28  d_loss: 0.384729  g_loss: 1.657656\n",
      "batch 29  d_loss: 0.457514  g_loss: 2.411754\n",
      "batch 30  d_loss: 0.377127  g_loss: 1.688406\n",
      "batch 31  d_loss: 0.447014  g_loss: 1.733088\n",
      "batch 32  d_loss: 0.392152  g_loss: 1.234284\n",
      "batch 33  d_loss: 0.395145  g_loss: 1.499076\n",
      "batch 34  d_loss: 0.278247  g_loss: 1.694639\n",
      "batch 35  d_loss: 0.336182  g_loss: 2.118975\n",
      "batch 36  d_loss: 0.348334  g_loss: 2.389487\n",
      "batch 37  d_loss: 0.303376  g_loss: 2.608813\n",
      "batch 38  d_loss: 0.274023  g_loss: 3.040434\n",
      "batch 39  d_loss: 0.438496  g_loss: 2.566955\n",
      "batch 40  d_loss: 0.379619  g_loss: 2.156211\n",
      "batch 41  d_loss: 0.273405  g_loss: 1.734007\n",
      "batch 42  d_loss: 0.276036  g_loss: 2.009982\n",
      "batch 43  d_loss: 0.420856  g_loss: 2.270641\n",
      "batch 44  d_loss: 0.311258  g_loss: 2.118902\n",
      "batch 45  d_loss: 0.198518  g_loss: 2.219613\n",
      "Epoch is 14\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.350745  g_loss: 2.356098\n",
      "batch 1  d_loss: 0.334737  g_loss: 2.361837\n",
      "batch 2  d_loss: 0.365803  g_loss: 2.675036\n",
      "batch 3  d_loss: 0.325848  g_loss: 2.474744\n",
      "batch 4  d_loss: 0.324689  g_loss: 2.328482\n",
      "batch 5  d_loss: 0.286999  g_loss: 2.017765\n",
      "batch 6  d_loss: 0.270292  g_loss: 2.174577\n",
      "batch 7  d_loss: 0.547747  g_loss: 1.748619\n",
      "batch 8  d_loss: 0.400418  g_loss: 1.637563\n",
      "batch 9  d_loss: 0.343625  g_loss: 1.946581\n",
      "batch 10  d_loss: 0.290441  g_loss: 2.383388\n",
      "batch 11  d_loss: 0.421561  g_loss: 2.412739\n",
      "batch 12  d_loss: 0.290829  g_loss: 1.938741\n",
      "batch 13  d_loss: 0.272428  g_loss: 1.612293\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161604,
     "status": "ok",
     "timestamp": 1577108551920,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "a5111998-3cc3-4703-91a8-29bda39e4b3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748881</td>\n",
       "      <td>1.145698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>5.427390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>8.828770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043294</td>\n",
       "      <td>11.825085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>12.381811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch    d_loss     g_loss\n",
       "0      0      0  0.748881   1.145698\n",
       "1      0      1  0.177903   5.427390\n",
       "2      0      2  0.006019   8.828770\n",
       "3      0      3  0.043294  11.825085\n",
       "4      0      4  0.008178  12.381811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.420332</td>\n",
       "      <td>1.928989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.257629</td>\n",
       "      <td>2.067645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>0.264990</td>\n",
       "      <td>2.195216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>0.274583</td>\n",
       "      <td>2.521642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>0.138739</td>\n",
       "      <td>2.946192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  batch    d_loss    g_loss\n",
       "2295     49     41  0.420332  1.928989\n",
       "2296     49     42  0.257629  2.067645\n",
       "2297     49     43  0.264990  2.195216\n",
       "2298     49     44  0.274583  2.521642\n",
       "2299     49     45  0.138739  2.946192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161597,
     "status": "ok",
     "timestamp": 1577108551921,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "6a3ae744-3d69-4f76-900e-a70adc2e3381"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using models with labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVaimUR9xqtm"
   },
   "outputs": [],
   "source": [
    "def generate_from_model_digits(batch_size, n_digits, n_noise,\n",
    "                               model_file=None, height=None):\n",
    "    if model_file is None:\n",
    "        generator = generator_model()\n",
    "        #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "        generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "        generator.load_weights(\"generator\")\n",
    "    else:\n",
    "        print('model_file:', model_file)\n",
    "        generator = load_model(model_file)\n",
    "\n",
    "    noise = np.zeros((batch_size*n_digits, n_noise))\n",
    "    labels = np.zeros((batch_size*n_digits, n_digits))\n",
    "    #print('batch:', batch_size)\n",
    "    #print('digits:', n_digits)\n",
    "    for i in range(batch_size):\n",
    "        noise1 = np.random.uniform(-1, 1, n_noise)\n",
    "        for d in range(n_digits):\n",
    "            label1 = to_categorical(d, n_digits)\n",
    "            #print('label1:', d, label1)\n",
    "            noise[i*n_digits+d, :] = noise1\n",
    "            labels[i*n_digits+d:, :] = label1\n",
    "    #print(noise)\n",
    "    #print(labels)\n",
    "    generated_images = generator.predict([noise, labels], verbose=1)\n",
    "    if height is None:\n",
    "        height = batchsize\n",
    "    image = combine_images_digits(generated_images, n_digits,\n",
    "                                  height=height)\n",
    "    image = image*127.5+127.5\n",
    "    png = \"generated_image_from_model.png\"\n",
    "    Image.fromarray(image.astype(np.uint8)).save(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177570,
     "status": "ok",
     "timestamp": 1577108567908,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "nHEojYucxqto",
    "outputId": "16e6d73e-581d-40eb-fdc0-c26ff1d5f891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file: model_cdcgan-b32_g-d48.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "generate_from_model_digits(batch_size, n_digits, n_noise, model_file=model_g, height=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "c-dcgan-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
