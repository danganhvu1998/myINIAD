{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "source": [
    "### Sample program for c-DCGAN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EXAkF3qMCcVi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 22:24:31.695873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-01-16 22:24:31.695930: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from PIL import Image\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation\n",
    "from tensorflow.keras.layers import Reshape, Flatten, concatenate\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import UpSampling2D\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(17)\n",
    "tf.random.set_seed(19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1264,
     "status": "ok",
     "timestamp": 1577108391508,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "xLeQXXYjCcVm",
    "outputId": "c592030f-9708-4c4c-cc40-1767a4d8a59f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 0, 8: 1}\n"
     ]
    }
   ],
   "source": [
    "used_digits = [4, 8]\n",
    "n_digits = len(used_digits)\n",
    "digit2idx = { x:i for i,x in enumerate(used_digits) }\n",
    "print(digit2idx)\n",
    "digits_str = ''.join([str(x) for x in used_digits])\n",
    "\n",
    "n_data = 1500\n",
    "n_epoch = 50\n",
    "n_noise = 100\n",
    "batch_size = 32\n",
    "\n",
    "img_dir = 'images_cdcgan'\n",
    "model_g = 'model_cdcgan-b{}_g-d{}.h5'.format(batch_size, digits_str)\n",
    "model_d = 'model_cdcgan-b{}_d-d{}.h5'.format(batch_size, digits_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove old img_dir and create new one  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1257,
     "status": "ok",
     "timestamp": 1577108391509,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "IOF5fZwICcVo",
    "outputId": "53708760-2253-4bf5-9c88-ce1bdedd32b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: OK\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "if os.path.exists(img_dir):\n",
    "    shutil.rmtree(img_dir)\n",
    "\n",
    "cnt = 10\n",
    "while cnt > 0:\n",
    "    try:\n",
    "        os.makedirs(img_dir)\n",
    "        break\n",
    "    except:\n",
    "        sleep(1)\n",
    "    cnt -= 1\n",
    "    \n",
    "if cnt <= 0:\n",
    "    print('Cannot mkdir:', img_dir)\n",
    "else:\n",
    "    print('mkdir: OK')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BZPQUi7nCcVq"
   },
   "outputs": [],
   "source": [
    "def generator_model():\n",
    "    in1 = Input(shape=(n_noise,))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    in12 = concatenate([in1, in2])\n",
    "    x = Dense(256, activation='tanh')(in12)\n",
    "    x = Dense(64 * 7 * 7)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('tanh')(x)\n",
    "    x = Reshape((7, 7, 64), input_shape=(7 * 7 * 64,))(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(32, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    x = Conv2D(1, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discriminator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1-YSMHxCcVs"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    in1 = Input(shape=(28, 28, 1))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    in2_up = Reshape((1, 1, n_digits))(in2)\n",
    "    in2_up = UpSampling2D((28, 28))(in2_up)\n",
    "    in12 = concatenate([in1, in2_up])\n",
    "    x = Conv2D(32, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(in12)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Conv2D(64, (5, 5), padding='same', activation='tanh',\n",
    "               data_format='channels_last')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, activation='tanh')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D(G(z))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X1XiZSpXCcVu"
   },
   "outputs": [],
   "source": [
    "def generator_containing_discriminator(generator, discriminator):\n",
    "    in1 = Input(shape=(n_noise,))\n",
    "    in2 = Input(shape=(n_digits,))\n",
    "    x = generator([in1, in2])\n",
    "    discriminator.trainable = False\n",
    "    x = discriminator([x, in2])\n",
    "    model = Model(inputs=[in1, in2], outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VPt6Y6j3CcVw"
   },
   "outputs": [],
   "source": [
    "def combine_images(generated_images):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    num = generated_images.shape[0]\n",
    "    width = int(math.sqrt(num))\n",
    "    height = int(math.ceil(float(num) / width))\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For output image samples with labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPL73pZG8mny"
   },
   "outputs": [],
   "source": [
    "def combine_images_digits(generated_images, n_digits, height=None):\n",
    "    generated_images = generated_images.reshape(generated_images.shape[0],\n",
    "                                                generated_images.shape[3],\n",
    "                                                generated_images.shape[1],\n",
    "                                                generated_images.shape[2])\n",
    "    if height is not None:\n",
    "        generated_images = generated_images[:height*n_digits]\n",
    "    else:\n",
    "        height = generated_images.shape[0]\n",
    "    width = n_digits\n",
    "    shape = generated_images.shape[2:]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[0, :, :]\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HWQB7J9BCcVy"
   },
   "outputs": [],
   "source": [
    "def train(BATCH_SIZE):\n",
    "    (X_train, y_train), (X_test, y_test) = shuffle(mnist.load_data())\n",
    "    X_train = X_train[ np.isin(y_train, used_digits) ]\n",
    "    y_train = y_train[ np.isin(y_train, used_digits) ]\n",
    "    X_train = X_train[:n_data]\n",
    "    y_train = y_train[:n_data]\n",
    "    X_train = (X_train.astype(np.float32) - 127.5)/127.5\n",
    "    X_train = X_train.reshape((X_train.shape[0], 1) + X_train.shape[1:])\n",
    "    y_train = np.array([digit2idx[x] for x in y_train])\n",
    "    y_train = to_categorical(y_train, n_digits)\n",
    "    discriminator = discriminator_model()\n",
    "    generator = generator_model()\n",
    "    discriminator_on_generator = \\\n",
    "        generator_containing_discriminator(generator, discriminator)\n",
    "    #d_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #g_optim = SGD(lr=0.0005, momentum=0.9, nesterov=True)\n",
    "    #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "    d_optim = Adam()\n",
    "    g_optim = Adam()\n",
    "    generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "    discriminator_on_generator.compile(\n",
    "        loss=\"binary_crossentropy\", optimizer=g_optim)\n",
    "    discriminator.trainable = True\n",
    "    discriminator.compile(loss=\"binary_crossentropy\", optimizer=d_optim)\n",
    "    noise = np.zeros((BATCH_SIZE, n_noise))\n",
    "    ret = []\n",
    "    for epoch in range(n_epoch):\n",
    "        print(\"Epoch is\", epoch)\n",
    "        print(\"Number of batches\", int(X_train.shape[0]/BATCH_SIZE))\n",
    "        n_index = int(X_train.shape[0]/BATCH_SIZE)\n",
    "        for index in range(n_index):\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            image_batch = X_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            image_batch = image_batch.reshape(image_batch.shape[0],\n",
    "                                              image_batch.shape[2],\n",
    "                                              image_batch.shape[3],\n",
    "                                              image_batch.shape[1])\n",
    "            labels = y_train[index*BATCH_SIZE:(index+1)*BATCH_SIZE]\n",
    "            generated_images = generator.predict([noise, labels], verbose=0)\n",
    "            if (epoch == 0 and index == 0) or index == (n_index-1):\n",
    "                image = combine_images(generated_images)\n",
    "                image = image*127.5+127.5\n",
    "                img_file = str(epoch)+\"_\"+str(index)+\".png\"\n",
    "                img_file = os.path.join(img_dir, img_file)\n",
    "                Image.fromarray(image.astype(np.uint8)).save(img_file)\n",
    "\n",
    "            X_img = np.concatenate((image_batch, generated_images))\n",
    "            X_lbl = np.concatenate((labels, labels))\n",
    "            y = [1] * BATCH_SIZE + [0] * BATCH_SIZE\n",
    "            d_loss = discriminator.train_on_batch([X_img, X_lbl], y)\n",
    "            for i in range(BATCH_SIZE):\n",
    "                noise[i, :] = np.random.uniform(-1, 1, n_noise)\n",
    "            discriminator.trainable = False\n",
    "            g_loss = discriminator_on_generator.train_on_batch(\n",
    "                [noise, labels], [1] * BATCH_SIZE)\n",
    "            discriminator.trainable = True\n",
    "            loss_msg = \"batch {:d}  d_loss: {:f}\".format(index, d_loss)\n",
    "            loss_msg += \"  g_loss: {:f}\".format(g_loss)\n",
    "            print(loss_msg)\n",
    "            ret.append((epoch, index, d_loss, g_loss))\n",
    "            if index % 10 == 9:\n",
    "                generator.save_weights(\"generator\", True)\n",
    "                discriminator.save_weights(\"discriminator\", True)\n",
    "                \n",
    "    generator.save(model_g)\n",
    "    discriminator.save(model_d)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do training (learning)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161609,
     "status": "ok",
     "timestamp": 1577108551916,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CKY-NRPqCcV4",
    "outputId": "ceedb4fd-8000-4006-b0ab-1ef90fd7a83c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/anhvu/.local/lib/python3.9/site-packages/keras/layers/normalization/batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-16 22:24:37.097140: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-01-16 22:24:37.097174: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-01-16 22:24:37.097197: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (anhvu): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch is 0\n",
      "Number of batches 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "2022-01-16 22:24:37.600450: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0  d_loss: 0.748881  g_loss: 1.145698\n",
      "batch 1  d_loss: 0.177903  g_loss: 5.427390\n",
      "batch 2  d_loss: 0.006019  g_loss: 8.828770\n",
      "batch 3  d_loss: 0.043294  g_loss: 11.825085\n",
      "batch 4  d_loss: 0.008178  g_loss: 12.381811\n",
      "batch 5  d_loss: 0.002399  g_loss: 12.446604\n",
      "batch 6  d_loss: 0.243566  g_loss: 13.121792\n",
      "batch 7  d_loss: 1.153916  g_loss: 11.764465\n",
      "batch 8  d_loss: 0.384261  g_loss: 12.854314\n",
      "batch 9  d_loss: 0.151743  g_loss: 11.617856\n",
      "batch 10  d_loss: 0.019597  g_loss: 12.372681\n",
      "batch 11  d_loss: 0.001314  g_loss: 11.467209\n",
      "batch 12  d_loss: 0.001084  g_loss: 10.938767\n",
      "batch 13  d_loss: 0.368134  g_loss: 11.724192\n",
      "batch 14  d_loss: 0.015735  g_loss: 11.766214\n",
      "batch 15  d_loss: 0.120713  g_loss: 10.046049\n",
      "batch 16  d_loss: 0.740187  g_loss: 9.569216\n",
      "batch 17  d_loss: 0.712215  g_loss: 10.993944\n",
      "batch 18  d_loss: 0.230840  g_loss: 11.409792\n",
      "batch 19  d_loss: 0.123556  g_loss: 12.100167\n",
      "batch 20  d_loss: 0.780475  g_loss: 13.004476\n",
      "batch 21  d_loss: 0.187651  g_loss: 13.408035\n",
      "batch 22  d_loss: 0.352767  g_loss: 12.289024\n",
      "batch 23  d_loss: 0.606079  g_loss: 11.614554\n",
      "batch 24  d_loss: 0.160139  g_loss: 12.697385\n",
      "batch 25  d_loss: 0.435349  g_loss: 11.147728\n",
      "batch 26  d_loss: 0.193550  g_loss: 8.922274\n",
      "batch 27  d_loss: 0.468302  g_loss: 10.435842\n",
      "batch 28  d_loss: 0.986708  g_loss: 12.204395\n",
      "batch 29  d_loss: 0.779698  g_loss: 11.324141\n",
      "batch 30  d_loss: 0.569003  g_loss: 10.752115\n",
      "batch 31  d_loss: 0.118828  g_loss: 10.437303\n",
      "batch 32  d_loss: 0.165174  g_loss: 8.672188\n",
      "batch 33  d_loss: 0.564890  g_loss: 9.032113\n",
      "batch 34  d_loss: 0.475412  g_loss: 9.027976\n",
      "batch 35  d_loss: 0.512355  g_loss: 9.528649\n",
      "batch 36  d_loss: 0.241544  g_loss: 9.667492\n",
      "batch 37  d_loss: 0.154199  g_loss: 9.828798\n",
      "batch 38  d_loss: 0.190307  g_loss: 9.653856\n",
      "batch 39  d_loss: 0.202544  g_loss: 9.941969\n",
      "batch 40  d_loss: 0.186058  g_loss: 8.753938\n",
      "batch 41  d_loss: 0.236017  g_loss: 7.863711\n",
      "batch 42  d_loss: 0.273402  g_loss: 7.404457\n",
      "batch 43  d_loss: 0.204879  g_loss: 7.684356\n",
      "batch 44  d_loss: 0.334653  g_loss: 9.074665\n",
      "batch 45  d_loss: 0.145317  g_loss: 8.371260\n",
      "Epoch is 1\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.139156  g_loss: 8.845014\n",
      "batch 1  d_loss: 0.074605  g_loss: 8.300600\n",
      "batch 2  d_loss: 0.134237  g_loss: 8.714743\n",
      "batch 3  d_loss: 0.145034  g_loss: 7.856215\n",
      "batch 4  d_loss: 0.145228  g_loss: 8.890984\n",
      "batch 5  d_loss: 0.107726  g_loss: 7.907373\n",
      "batch 6  d_loss: 0.160703  g_loss: 8.527884\n",
      "batch 7  d_loss: 0.112969  g_loss: 6.994576\n",
      "batch 8  d_loss: 0.060354  g_loss: 8.103942\n",
      "batch 9  d_loss: 0.067118  g_loss: 6.115269\n",
      "batch 10  d_loss: 0.194966  g_loss: 6.636945\n",
      "batch 11  d_loss: 0.128427  g_loss: 7.031261\n",
      "batch 12  d_loss: 0.136310  g_loss: 7.326098\n",
      "batch 13  d_loss: 0.086615  g_loss: 8.340933\n",
      "batch 14  d_loss: 0.129026  g_loss: 9.585687\n",
      "batch 15  d_loss: 0.192100  g_loss: 9.264102\n",
      "batch 16  d_loss: 0.116177  g_loss: 9.869282\n",
      "batch 17  d_loss: 0.067255  g_loss: 8.889172\n",
      "batch 18  d_loss: 0.039182  g_loss: 9.532929\n",
      "batch 19  d_loss: 0.055953  g_loss: 8.881128\n",
      "batch 20  d_loss: 0.065151  g_loss: 8.502703\n",
      "batch 21  d_loss: 0.107252  g_loss: 8.400245\n",
      "batch 22  d_loss: 0.146892  g_loss: 7.511922\n",
      "batch 23  d_loss: 0.146829  g_loss: 7.794581\n",
      "batch 24  d_loss: 0.253448  g_loss: 8.791154\n",
      "batch 25  d_loss: 0.046372  g_loss: 8.759460\n",
      "batch 26  d_loss: 0.145617  g_loss: 9.463837\n",
      "batch 27  d_loss: 0.161475  g_loss: 10.233223\n",
      "batch 28  d_loss: 0.235914  g_loss: 9.764252\n",
      "batch 29  d_loss: 0.335790  g_loss: 8.736547\n",
      "batch 30  d_loss: 0.174583  g_loss: 8.319274\n",
      "batch 31  d_loss: 0.291067  g_loss: 8.425736\n",
      "batch 32  d_loss: 0.242189  g_loss: 8.391035\n",
      "batch 33  d_loss: 0.250633  g_loss: 8.179307\n",
      "batch 34  d_loss: 0.116263  g_loss: 8.116113\n",
      "batch 35  d_loss: 0.346345  g_loss: 8.676320\n",
      "batch 36  d_loss: 0.453421  g_loss: 7.916178\n",
      "batch 37  d_loss: 0.289822  g_loss: 7.953673\n",
      "batch 38  d_loss: 0.208293  g_loss: 7.574359\n",
      "batch 39  d_loss: 0.165315  g_loss: 7.102381\n",
      "batch 40  d_loss: 0.225486  g_loss: 7.777745\n",
      "batch 41  d_loss: 0.201031  g_loss: 7.848609\n",
      "batch 42  d_loss: 0.258243  g_loss: 7.913427\n",
      "batch 43  d_loss: 0.278847  g_loss: 8.287544\n",
      "batch 44  d_loss: 0.370664  g_loss: 7.751723\n",
      "batch 45  d_loss: 0.144316  g_loss: 8.324759\n",
      "Epoch is 2\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.272016  g_loss: 8.268894\n",
      "batch 1  d_loss: 0.212853  g_loss: 8.223763\n",
      "batch 2  d_loss: 0.377659  g_loss: 8.017743\n",
      "batch 3  d_loss: 0.259385  g_loss: 7.686338\n",
      "batch 4  d_loss: 0.314478  g_loss: 7.920118\n",
      "batch 5  d_loss: 0.289233  g_loss: 8.193146\n",
      "batch 6  d_loss: 0.238903  g_loss: 8.279875\n",
      "batch 7  d_loss: 0.480600  g_loss: 8.137049\n",
      "batch 8  d_loss: 0.328869  g_loss: 7.521226\n",
      "batch 9  d_loss: 0.400800  g_loss: 7.522600\n",
      "batch 10  d_loss: 0.395270  g_loss: 7.518556\n",
      "batch 11  d_loss: 0.302195  g_loss: 8.296596\n",
      "batch 12  d_loss: 0.358223  g_loss: 7.737604\n",
      "batch 13  d_loss: 0.243715  g_loss: 7.832184\n",
      "batch 14  d_loss: 0.189583  g_loss: 7.464191\n",
      "batch 15  d_loss: 0.293841  g_loss: 7.535603\n",
      "batch 16  d_loss: 0.275330  g_loss: 6.345644\n",
      "batch 17  d_loss: 0.270007  g_loss: 6.830247\n",
      "batch 18  d_loss: 0.351906  g_loss: 7.113439\n",
      "batch 19  d_loss: 0.251910  g_loss: 8.019935\n",
      "batch 20  d_loss: 0.505426  g_loss: 7.629587\n",
      "batch 21  d_loss: 0.365507  g_loss: 6.530165\n",
      "batch 22  d_loss: 0.265636  g_loss: 6.780992\n",
      "batch 23  d_loss: 0.288440  g_loss: 7.043227\n",
      "batch 24  d_loss: 0.349362  g_loss: 6.900106\n",
      "batch 25  d_loss: 0.310038  g_loss: 6.908253\n",
      "batch 26  d_loss: 0.342915  g_loss: 7.351852\n",
      "batch 27  d_loss: 0.336376  g_loss: 7.876987\n",
      "batch 28  d_loss: 0.285956  g_loss: 7.357324\n",
      "batch 29  d_loss: 0.239848  g_loss: 7.038691\n",
      "batch 30  d_loss: 0.272636  g_loss: 6.900703\n",
      "batch 31  d_loss: 0.279831  g_loss: 6.594828\n",
      "batch 32  d_loss: 0.297376  g_loss: 5.824530\n",
      "batch 33  d_loss: 0.375590  g_loss: 7.046716\n",
      "batch 34  d_loss: 0.239327  g_loss: 6.511890\n",
      "batch 35  d_loss: 0.210832  g_loss: 7.697762\n",
      "batch 36  d_loss: 0.277681  g_loss: 6.641214\n",
      "batch 37  d_loss: 0.250956  g_loss: 6.248837\n",
      "batch 38  d_loss: 0.246539  g_loss: 7.163463\n",
      "batch 39  d_loss: 0.350383  g_loss: 7.330882\n",
      "batch 40  d_loss: 0.449402  g_loss: 7.023703\n",
      "batch 41  d_loss: 0.341105  g_loss: 6.289858\n",
      "batch 42  d_loss: 0.261420  g_loss: 6.996060\n",
      "batch 43  d_loss: 0.305818  g_loss: 5.942326\n",
      "batch 44  d_loss: 0.370606  g_loss: 6.908154\n",
      "batch 45  d_loss: 0.335193  g_loss: 5.826478\n",
      "Epoch is 3\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.417833  g_loss: 6.596247\n",
      "batch 1  d_loss: 0.326018  g_loss: 6.024913\n",
      "batch 2  d_loss: 0.234217  g_loss: 6.589293\n",
      "batch 3  d_loss: 0.349300  g_loss: 6.132785\n",
      "batch 4  d_loss: 0.402989  g_loss: 5.977544\n",
      "batch 5  d_loss: 0.237069  g_loss: 5.465777\n",
      "batch 6  d_loss: 0.386705  g_loss: 5.603475\n",
      "batch 7  d_loss: 0.406357  g_loss: 5.793500\n",
      "batch 8  d_loss: 0.261003  g_loss: 5.399755\n",
      "batch 9  d_loss: 0.264284  g_loss: 6.470823\n",
      "batch 10  d_loss: 0.223086  g_loss: 5.659119\n",
      "batch 11  d_loss: 0.279050  g_loss: 5.586883\n",
      "batch 12  d_loss: 0.360849  g_loss: 4.959851\n",
      "batch 13  d_loss: 0.236158  g_loss: 4.814085\n",
      "batch 14  d_loss: 0.155341  g_loss: 4.894112\n",
      "batch 15  d_loss: 0.260599  g_loss: 4.914813\n",
      "batch 16  d_loss: 0.254214  g_loss: 5.118354\n",
      "batch 17  d_loss: 0.497424  g_loss: 5.261536\n",
      "batch 18  d_loss: 0.264662  g_loss: 4.915133\n",
      "batch 19  d_loss: 0.197753  g_loss: 5.723336\n",
      "batch 20  d_loss: 0.174555  g_loss: 6.365734\n",
      "batch 21  d_loss: 0.115148  g_loss: 5.272987\n",
      "batch 22  d_loss: 0.179668  g_loss: 5.721474\n",
      "batch 23  d_loss: 0.241948  g_loss: 6.025047\n",
      "batch 24  d_loss: 0.090395  g_loss: 5.436265\n",
      "batch 25  d_loss: 0.097395  g_loss: 5.776584\n",
      "batch 26  d_loss: 0.162520  g_loss: 6.194028\n",
      "batch 27  d_loss: 0.084191  g_loss: 5.716988\n",
      "batch 28  d_loss: 0.177547  g_loss: 6.533433\n",
      "batch 29  d_loss: 0.108384  g_loss: 6.145789\n",
      "batch 30  d_loss: 0.170172  g_loss: 5.894362\n",
      "batch 31  d_loss: 0.100883  g_loss: 5.534099\n",
      "batch 32  d_loss: 0.252073  g_loss: 5.282873\n",
      "batch 33  d_loss: 0.329703  g_loss: 5.739394\n",
      "batch 34  d_loss: 0.170328  g_loss: 6.154231\n",
      "batch 35  d_loss: 0.082438  g_loss: 6.716823\n",
      "batch 36  d_loss: 0.190938  g_loss: 8.239406\n",
      "batch 37  d_loss: 0.100651  g_loss: 7.450440\n",
      "batch 38  d_loss: 0.120399  g_loss: 6.743742\n",
      "batch 39  d_loss: 0.143387  g_loss: 6.804245\n",
      "batch 40  d_loss: 0.140129  g_loss: 6.742514\n",
      "batch 41  d_loss: 0.264902  g_loss: 6.936424\n",
      "batch 42  d_loss: 0.101444  g_loss: 6.392416\n",
      "batch 43  d_loss: 0.227392  g_loss: 6.767175\n",
      "batch 44  d_loss: 0.223921  g_loss: 7.129731\n",
      "batch 45  d_loss: 0.050480  g_loss: 7.415423\n",
      "Epoch is 4\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.179463  g_loss: 6.440628\n",
      "batch 1  d_loss: 0.139800  g_loss: 7.538387\n",
      "batch 2  d_loss: 0.375750  g_loss: 7.847020\n",
      "batch 3  d_loss: 0.314281  g_loss: 6.519320\n",
      "batch 4  d_loss: 0.110916  g_loss: 6.404800\n",
      "batch 5  d_loss: 0.414288  g_loss: 5.945767\n",
      "batch 6  d_loss: 0.229034  g_loss: 7.382581\n",
      "batch 7  d_loss: 0.109021  g_loss: 7.448734\n",
      "batch 8  d_loss: 0.169603  g_loss: 7.975798\n",
      "batch 9  d_loss: 0.119459  g_loss: 7.609687\n",
      "batch 10  d_loss: 0.136549  g_loss: 7.532984\n",
      "batch 11  d_loss: 0.212262  g_loss: 6.698622\n",
      "batch 12  d_loss: 0.159929  g_loss: 7.181629\n",
      "batch 13  d_loss: 0.209780  g_loss: 6.764770\n",
      "batch 14  d_loss: 0.170849  g_loss: 6.553221\n",
      "batch 15  d_loss: 0.147776  g_loss: 6.906879\n",
      "batch 16  d_loss: 0.172281  g_loss: 6.129823\n",
      "batch 17  d_loss: 0.228501  g_loss: 7.386306\n",
      "batch 18  d_loss: 0.141064  g_loss: 8.168427\n",
      "batch 19  d_loss: 0.120428  g_loss: 7.176360\n",
      "batch 20  d_loss: 0.350368  g_loss: 7.342021\n",
      "batch 21  d_loss: 0.200922  g_loss: 6.015265\n",
      "batch 22  d_loss: 0.129717  g_loss: 5.263673\n",
      "batch 23  d_loss: 0.146573  g_loss: 6.699780\n",
      "batch 24  d_loss: 0.212323  g_loss: 6.861713\n",
      "batch 25  d_loss: 0.159952  g_loss: 7.761384\n",
      "batch 26  d_loss: 0.171127  g_loss: 7.535263\n",
      "batch 27  d_loss: 0.101652  g_loss: 7.381868\n",
      "batch 28  d_loss: 0.164414  g_loss: 6.683506\n",
      "batch 29  d_loss: 0.241154  g_loss: 6.696154\n",
      "batch 30  d_loss: 0.207013  g_loss: 6.988431\n",
      "batch 31  d_loss: 0.195671  g_loss: 6.538006\n",
      "batch 32  d_loss: 0.301124  g_loss: 6.996441\n",
      "batch 33  d_loss: 0.118676  g_loss: 6.221969\n",
      "batch 34  d_loss: 0.182671  g_loss: 6.060344\n",
      "batch 35  d_loss: 0.227598  g_loss: 5.834889\n",
      "batch 36  d_loss: 0.334026  g_loss: 6.340512\n",
      "batch 37  d_loss: 0.156952  g_loss: 6.568113\n",
      "batch 38  d_loss: 0.198058  g_loss: 6.784748\n",
      "batch 39  d_loss: 0.206111  g_loss: 6.936172\n",
      "batch 40  d_loss: 0.176301  g_loss: 6.751444\n",
      "batch 41  d_loss: 0.267903  g_loss: 7.247769\n",
      "batch 42  d_loss: 0.235759  g_loss: 5.601254\n",
      "batch 43  d_loss: 0.111400  g_loss: 6.040195\n",
      "batch 44  d_loss: 0.131701  g_loss: 5.866881\n",
      "batch 45  d_loss: 0.046027  g_loss: 6.080573\n",
      "Epoch is 5\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.282130  g_loss: 6.839221\n",
      "batch 1  d_loss: 0.308011  g_loss: 6.568729\n",
      "batch 2  d_loss: 0.143850  g_loss: 7.909439\n",
      "batch 3  d_loss: 0.111420  g_loss: 7.919993\n",
      "batch 4  d_loss: 0.157018  g_loss: 8.158623\n",
      "batch 5  d_loss: 0.135464  g_loss: 8.489319\n",
      "batch 6  d_loss: 0.191667  g_loss: 7.670673\n",
      "batch 7  d_loss: 0.278017  g_loss: 7.643087\n",
      "batch 8  d_loss: 0.280927  g_loss: 7.395784\n",
      "batch 9  d_loss: 0.123964  g_loss: 5.945493\n",
      "batch 10  d_loss: 0.142234  g_loss: 6.711456\n",
      "batch 11  d_loss: 0.282389  g_loss: 5.967194\n",
      "batch 12  d_loss: 0.240294  g_loss: 7.437402\n",
      "batch 13  d_loss: 0.434785  g_loss: 7.103966\n",
      "batch 14  d_loss: 0.192400  g_loss: 7.015779\n",
      "batch 15  d_loss: 0.334422  g_loss: 7.061699\n",
      "batch 16  d_loss: 0.227158  g_loss: 6.561412\n",
      "batch 17  d_loss: 0.318717  g_loss: 6.433480\n",
      "batch 18  d_loss: 0.202344  g_loss: 5.440854\n",
      "batch 19  d_loss: 0.218935  g_loss: 6.378899\n",
      "batch 20  d_loss: 0.313561  g_loss: 5.310874\n",
      "batch 21  d_loss: 0.261365  g_loss: 4.913116\n",
      "batch 22  d_loss: 0.251869  g_loss: 5.638943\n",
      "batch 23  d_loss: 0.305902  g_loss: 6.041498\n",
      "batch 24  d_loss: 0.245458  g_loss: 5.925309\n",
      "batch 25  d_loss: 0.338844  g_loss: 6.186202\n",
      "batch 26  d_loss: 0.224331  g_loss: 5.941911\n",
      "batch 27  d_loss: 0.149931  g_loss: 5.481433\n",
      "batch 28  d_loss: 0.294337  g_loss: 5.236036\n",
      "batch 29  d_loss: 0.221274  g_loss: 5.819487\n",
      "batch 30  d_loss: 0.212997  g_loss: 5.858447\n",
      "batch 31  d_loss: 0.309923  g_loss: 6.510149\n",
      "batch 32  d_loss: 0.265324  g_loss: 5.744254\n",
      "batch 33  d_loss: 0.203521  g_loss: 5.702823\n",
      "batch 34  d_loss: 0.201751  g_loss: 5.562280\n",
      "batch 35  d_loss: 0.263529  g_loss: 4.845301\n",
      "batch 36  d_loss: 0.246915  g_loss: 4.833359\n",
      "batch 37  d_loss: 0.123438  g_loss: 4.573404\n",
      "batch 38  d_loss: 0.292949  g_loss: 4.086784\n",
      "batch 39  d_loss: 0.226986  g_loss: 4.559981\n",
      "batch 40  d_loss: 0.150796  g_loss: 4.791594\n",
      "batch 41  d_loss: 0.191380  g_loss: 5.174048\n",
      "batch 42  d_loss: 0.170642  g_loss: 5.231623\n",
      "batch 43  d_loss: 0.158060  g_loss: 4.863961\n",
      "batch 44  d_loss: 0.237256  g_loss: 4.126591\n",
      "batch 45  d_loss: 0.141398  g_loss: 3.883373\n",
      "Epoch is 6\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.315259  g_loss: 3.757400\n",
      "batch 1  d_loss: 0.249920  g_loss: 4.229493\n",
      "batch 2  d_loss: 0.258049  g_loss: 4.794380\n",
      "batch 3  d_loss: 0.247612  g_loss: 4.674614\n",
      "batch 4  d_loss: 0.270809  g_loss: 4.739165\n",
      "batch 5  d_loss: 0.257947  g_loss: 3.925720\n",
      "batch 6  d_loss: 0.236267  g_loss: 4.249337\n",
      "batch 7  d_loss: 0.483964  g_loss: 4.206079\n",
      "batch 8  d_loss: 0.416731  g_loss: 4.198591\n",
      "batch 9  d_loss: 0.455267  g_loss: 3.831767\n",
      "batch 10  d_loss: 0.200988  g_loss: 4.810163\n",
      "batch 11  d_loss: 0.340400  g_loss: 4.532497\n",
      "batch 12  d_loss: 0.304073  g_loss: 4.383255\n",
      "batch 13  d_loss: 0.305106  g_loss: 4.397410\n",
      "batch 14  d_loss: 0.284131  g_loss: 3.839076\n",
      "batch 15  d_loss: 0.297559  g_loss: 3.894059\n",
      "batch 16  d_loss: 0.237213  g_loss: 4.293887\n",
      "batch 17  d_loss: 0.285412  g_loss: 4.195253\n",
      "batch 18  d_loss: 0.211169  g_loss: 4.211419\n",
      "batch 19  d_loss: 0.213439  g_loss: 3.986208\n",
      "batch 20  d_loss: 0.230552  g_loss: 4.332719\n",
      "batch 21  d_loss: 0.161463  g_loss: 4.602117\n",
      "batch 22  d_loss: 0.177933  g_loss: 4.271920\n",
      "batch 23  d_loss: 0.161879  g_loss: 4.753069\n",
      "batch 24  d_loss: 0.145685  g_loss: 4.442506\n",
      "batch 25  d_loss: 0.100912  g_loss: 4.484375\n",
      "batch 26  d_loss: 0.101990  g_loss: 3.866991\n",
      "batch 27  d_loss: 0.183853  g_loss: 4.630265\n",
      "batch 28  d_loss: 0.135907  g_loss: 4.841512\n",
      "batch 29  d_loss: 0.170389  g_loss: 4.948293\n",
      "batch 30  d_loss: 0.178120  g_loss: 4.511363\n",
      "batch 31  d_loss: 0.178883  g_loss: 4.287505\n",
      "batch 32  d_loss: 0.129122  g_loss: 4.142007\n",
      "batch 33  d_loss: 0.217104  g_loss: 4.044329\n",
      "batch 34  d_loss: 0.304176  g_loss: 4.231252\n",
      "batch 35  d_loss: 0.143614  g_loss: 4.283898\n",
      "batch 36  d_loss: 0.295197  g_loss: 4.537985\n",
      "batch 37  d_loss: 0.233253  g_loss: 3.715976\n",
      "batch 38  d_loss: 0.189204  g_loss: 4.235025\n",
      "batch 39  d_loss: 0.184874  g_loss: 3.851473\n",
      "batch 40  d_loss: 0.182526  g_loss: 4.334727\n",
      "batch 41  d_loss: 0.277739  g_loss: 4.216990\n",
      "batch 42  d_loss: 0.186557  g_loss: 3.885443\n",
      "batch 43  d_loss: 0.195424  g_loss: 3.773226\n",
      "batch 44  d_loss: 0.201208  g_loss: 4.115861\n",
      "batch 45  d_loss: 0.162604  g_loss: 3.983714\n",
      "Epoch is 7\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.153807  g_loss: 4.188195\n",
      "batch 1  d_loss: 0.061723  g_loss: 4.660564\n",
      "batch 2  d_loss: 0.226833  g_loss: 4.050577\n",
      "batch 3  d_loss: 0.161190  g_loss: 3.877399\n",
      "batch 4  d_loss: 0.166634  g_loss: 3.659077\n",
      "batch 5  d_loss: 0.223579  g_loss: 3.499526\n",
      "batch 6  d_loss: 0.159055  g_loss: 3.483147\n",
      "batch 7  d_loss: 0.229439  g_loss: 4.443707\n",
      "batch 8  d_loss: 0.140192  g_loss: 4.156006\n",
      "batch 9  d_loss: 0.128109  g_loss: 4.406796\n",
      "batch 10  d_loss: 0.188075  g_loss: 4.407948\n",
      "batch 11  d_loss: 0.129454  g_loss: 4.081747\n",
      "batch 12  d_loss: 0.093298  g_loss: 3.579566\n",
      "batch 13  d_loss: 0.171163  g_loss: 3.868272\n",
      "batch 14  d_loss: 0.154540  g_loss: 3.648933\n",
      "batch 15  d_loss: 0.147263  g_loss: 3.684855\n",
      "batch 16  d_loss: 0.155747  g_loss: 4.055500\n",
      "batch 17  d_loss: 0.160407  g_loss: 4.574853\n",
      "batch 18  d_loss: 0.091424  g_loss: 4.361046\n",
      "batch 19  d_loss: 0.138783  g_loss: 3.872693\n",
      "batch 20  d_loss: 0.092617  g_loss: 4.308429\n",
      "batch 21  d_loss: 0.110123  g_loss: 4.375156\n",
      "batch 22  d_loss: 0.118540  g_loss: 3.694267\n",
      "batch 23  d_loss: 0.097835  g_loss: 3.668938\n",
      "batch 24  d_loss: 0.158032  g_loss: 4.051409\n",
      "batch 25  d_loss: 0.081489  g_loss: 4.490846\n",
      "batch 26  d_loss: 0.100406  g_loss: 4.419322\n",
      "batch 27  d_loss: 0.077521  g_loss: 4.913964\n",
      "batch 28  d_loss: 0.110298  g_loss: 4.746173\n",
      "batch 29  d_loss: 0.131185  g_loss: 4.340104\n",
      "batch 30  d_loss: 0.081585  g_loss: 3.985283\n",
      "batch 31  d_loss: 0.140706  g_loss: 4.251157\n",
      "batch 32  d_loss: 0.216671  g_loss: 3.184616\n",
      "batch 33  d_loss: 0.275507  g_loss: 3.391074\n",
      "batch 34  d_loss: 0.160961  g_loss: 3.423601\n",
      "batch 35  d_loss: 0.229507  g_loss: 4.038669\n",
      "batch 36  d_loss: 0.312027  g_loss: 3.932697\n",
      "batch 37  d_loss: 0.151990  g_loss: 3.228553\n",
      "batch 38  d_loss: 0.179626  g_loss: 3.445977\n",
      "batch 39  d_loss: 0.176124  g_loss: 3.584887\n",
      "batch 40  d_loss: 0.192570  g_loss: 3.966381\n",
      "batch 41  d_loss: 0.192603  g_loss: 4.419842\n",
      "batch 42  d_loss: 0.213152  g_loss: 3.841131\n",
      "batch 43  d_loss: 0.137371  g_loss: 4.135378\n",
      "batch 44  d_loss: 0.222704  g_loss: 3.971144\n",
      "batch 45  d_loss: 0.163190  g_loss: 3.626886\n",
      "Epoch is 8\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.162440  g_loss: 4.176176\n",
      "batch 1  d_loss: 0.149491  g_loss: 3.899724\n",
      "batch 2  d_loss: 0.183481  g_loss: 4.082015\n",
      "batch 3  d_loss: 0.112267  g_loss: 4.083549\n",
      "batch 4  d_loss: 0.192754  g_loss: 3.805266\n",
      "batch 5  d_loss: 0.233920  g_loss: 3.685841\n",
      "batch 6  d_loss: 0.151514  g_loss: 3.960266\n",
      "batch 7  d_loss: 0.666376  g_loss: 2.862494\n",
      "batch 8  d_loss: 0.261940  g_loss: 1.849334\n",
      "batch 9  d_loss: 0.323252  g_loss: 2.612060\n",
      "batch 10  d_loss: 0.292968  g_loss: 2.852344\n",
      "batch 11  d_loss: 0.185621  g_loss: 3.721562\n",
      "batch 12  d_loss: 0.228283  g_loss: 3.532792\n",
      "batch 13  d_loss: 0.236169  g_loss: 2.883813\n",
      "batch 14  d_loss: 0.177636  g_loss: 2.731738\n",
      "batch 15  d_loss: 0.227156  g_loss: 1.918215\n",
      "batch 16  d_loss: 0.243638  g_loss: 2.069764\n",
      "batch 17  d_loss: 0.211651  g_loss: 2.876832\n",
      "batch 18  d_loss: 0.149097  g_loss: 3.171374\n",
      "batch 19  d_loss: 0.202598  g_loss: 3.504999\n",
      "batch 20  d_loss: 0.266343  g_loss: 2.758612\n",
      "batch 21  d_loss: 0.157298  g_loss: 2.104892\n",
      "batch 22  d_loss: 0.119322  g_loss: 2.472661\n",
      "batch 23  d_loss: 0.245663  g_loss: 2.478181\n",
      "batch 24  d_loss: 0.159516  g_loss: 3.167155\n",
      "batch 25  d_loss: 0.187602  g_loss: 3.293288\n",
      "batch 26  d_loss: 0.147207  g_loss: 2.832764\n",
      "batch 27  d_loss: 0.184483  g_loss: 2.879267\n",
      "batch 28  d_loss: 0.237260  g_loss: 2.877081\n",
      "batch 29  d_loss: 0.208160  g_loss: 1.851200\n",
      "batch 30  d_loss: 0.268830  g_loss: 1.899412\n",
      "batch 31  d_loss: 0.279713  g_loss: 2.357391\n",
      "batch 32  d_loss: 0.326855  g_loss: 2.361247\n",
      "batch 33  d_loss: 0.291861  g_loss: 2.475970\n",
      "batch 34  d_loss: 0.283797  g_loss: 2.302376\n",
      "batch 35  d_loss: 0.313357  g_loss: 2.720752\n",
      "batch 36  d_loss: 0.289028  g_loss: 2.722047\n",
      "batch 37  d_loss: 0.188863  g_loss: 2.273685\n",
      "batch 38  d_loss: 0.215079  g_loss: 2.526165\n",
      "batch 39  d_loss: 0.112243  g_loss: 3.008395\n",
      "batch 40  d_loss: 0.149254  g_loss: 3.018826\n",
      "batch 41  d_loss: 0.163615  g_loss: 3.008125\n",
      "batch 42  d_loss: 0.155676  g_loss: 2.731264\n",
      "batch 43  d_loss: 0.121084  g_loss: 2.546485\n",
      "batch 44  d_loss: 0.131902  g_loss: 2.454491\n",
      "batch 45  d_loss: 0.191998  g_loss: 3.233514\n",
      "Epoch is 9\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.169923  g_loss: 4.040663\n",
      "batch 1  d_loss: 0.154128  g_loss: 3.874933\n",
      "batch 2  d_loss: 0.090260  g_loss: 2.919186\n",
      "batch 3  d_loss: 0.077402  g_loss: 3.192801\n",
      "batch 4  d_loss: 0.107275  g_loss: 2.606177\n",
      "batch 5  d_loss: 0.105087  g_loss: 3.138678\n",
      "batch 6  d_loss: 0.145303  g_loss: 3.151310\n",
      "batch 7  d_loss: 0.255980  g_loss: 3.239958\n",
      "batch 8  d_loss: 0.180025  g_loss: 2.439307\n",
      "batch 9  d_loss: 0.164022  g_loss: 2.825652\n",
      "batch 10  d_loss: 0.077024  g_loss: 3.066477\n",
      "batch 11  d_loss: 0.179852  g_loss: 2.820893\n",
      "batch 12  d_loss: 0.153711  g_loss: 3.083578\n",
      "batch 13  d_loss: 0.159457  g_loss: 3.680217\n",
      "batch 14  d_loss: 0.085476  g_loss: 3.879222\n",
      "batch 15  d_loss: 0.231946  g_loss: 3.494098\n",
      "batch 16  d_loss: 0.200273  g_loss: 2.339797\n",
      "batch 17  d_loss: 0.137719  g_loss: 2.160730\n",
      "batch 18  d_loss: 0.104808  g_loss: 1.815602\n",
      "batch 19  d_loss: 0.190720  g_loss: 2.949543\n",
      "batch 20  d_loss: 0.126522  g_loss: 4.157073\n",
      "batch 21  d_loss: 0.188148  g_loss: 4.131267\n",
      "batch 22  d_loss: 0.126214  g_loss: 3.686391\n",
      "batch 23  d_loss: 0.176681  g_loss: 3.245708\n",
      "batch 24  d_loss: 0.077595  g_loss: 2.716604\n",
      "batch 25  d_loss: 0.211687  g_loss: 2.041727\n",
      "batch 26  d_loss: 0.223815  g_loss: 2.620676\n",
      "batch 27  d_loss: 0.160708  g_loss: 3.752856\n",
      "batch 28  d_loss: 0.216558  g_loss: 4.110184\n",
      "batch 29  d_loss: 0.263477  g_loss: 3.678814\n",
      "batch 30  d_loss: 0.183550  g_loss: 2.905991\n",
      "batch 31  d_loss: 0.183940  g_loss: 2.293553\n",
      "batch 32  d_loss: 0.369980  g_loss: 1.546044\n",
      "batch 33  d_loss: 0.392038  g_loss: 2.297784\n",
      "batch 34  d_loss: 0.214755  g_loss: 3.284413\n",
      "batch 35  d_loss: 0.241230  g_loss: 3.579693\n",
      "batch 36  d_loss: 0.498869  g_loss: 2.371966\n",
      "batch 37  d_loss: 0.161955  g_loss: 1.827083\n",
      "batch 38  d_loss: 0.267332  g_loss: 1.793210\n",
      "batch 39  d_loss: 0.246878  g_loss: 2.740795\n",
      "batch 40  d_loss: 0.219378  g_loss: 3.876154\n",
      "batch 41  d_loss: 0.336480  g_loss: 3.152730\n",
      "batch 42  d_loss: 0.164158  g_loss: 2.512889\n",
      "batch 43  d_loss: 0.199426  g_loss: 1.876937\n",
      "batch 44  d_loss: 0.237300  g_loss: 2.864640\n",
      "batch 45  d_loss: 0.125503  g_loss: 3.682171\n",
      "Epoch is 10\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.196443  g_loss: 3.578394\n",
      "batch 1  d_loss: 0.159035  g_loss: 3.197873\n",
      "batch 2  d_loss: 0.172768  g_loss: 1.796797\n",
      "batch 3  d_loss: 0.395550  g_loss: 2.738746\n",
      "batch 4  d_loss: 0.286417  g_loss: 2.789261\n",
      "batch 5  d_loss: 0.334121  g_loss: 2.191314\n",
      "batch 6  d_loss: 0.225018  g_loss: 1.629283\n",
      "batch 7  d_loss: 0.308957  g_loss: 1.661451\n",
      "batch 8  d_loss: 0.336563  g_loss: 2.734544\n",
      "batch 9  d_loss: 0.204789  g_loss: 2.966144\n",
      "batch 10  d_loss: 0.236868  g_loss: 2.525441\n",
      "batch 11  d_loss: 0.235770  g_loss: 2.079099\n",
      "batch 12  d_loss: 0.187647  g_loss: 2.528219\n",
      "batch 13  d_loss: 0.159852  g_loss: 2.596206\n",
      "batch 14  d_loss: 0.146065  g_loss: 3.148158\n",
      "batch 15  d_loss: 0.224758  g_loss: 3.317854\n",
      "batch 16  d_loss: 0.177182  g_loss: 2.771250\n",
      "batch 17  d_loss: 0.130521  g_loss: 2.023853\n",
      "batch 18  d_loss: 0.171321  g_loss: 2.138519\n",
      "batch 19  d_loss: 0.222654  g_loss: 3.125695\n",
      "batch 20  d_loss: 0.100858  g_loss: 4.339392\n",
      "batch 21  d_loss: 0.079581  g_loss: 4.738918\n",
      "batch 22  d_loss: 0.137135  g_loss: 4.511458\n",
      "batch 23  d_loss: 0.069564  g_loss: 4.746923\n",
      "batch 24  d_loss: 0.074038  g_loss: 3.909357\n",
      "batch 25  d_loss: 0.046504  g_loss: 3.975605\n",
      "batch 26  d_loss: 0.069169  g_loss: 3.170575\n",
      "batch 27  d_loss: 0.150084  g_loss: 3.682115\n",
      "batch 28  d_loss: 0.088755  g_loss: 4.420764\n",
      "batch 29  d_loss: 0.101560  g_loss: 4.507240\n",
      "batch 30  d_loss: 0.057011  g_loss: 4.546244\n",
      "batch 31  d_loss: 0.131274  g_loss: 4.394979\n",
      "batch 32  d_loss: 0.112749  g_loss: 4.164139\n",
      "batch 33  d_loss: 0.080919  g_loss: 3.406419\n",
      "batch 34  d_loss: 0.132322  g_loss: 3.723612\n",
      "batch 35  d_loss: 0.073193  g_loss: 3.399660\n",
      "batch 36  d_loss: 0.394450  g_loss: 2.797306\n",
      "batch 37  d_loss: 0.158177  g_loss: 3.397593\n",
      "batch 38  d_loss: 0.159436  g_loss: 3.553594\n",
      "batch 39  d_loss: 0.180306  g_loss: 3.604218\n",
      "batch 40  d_loss: 0.222326  g_loss: 4.055065\n",
      "batch 41  d_loss: 0.283614  g_loss: 3.228249\n",
      "batch 42  d_loss: 0.183704  g_loss: 3.215840\n",
      "batch 43  d_loss: 0.305300  g_loss: 2.510391\n",
      "batch 44  d_loss: 0.254251  g_loss: 3.153387\n",
      "batch 45  d_loss: 0.229978  g_loss: 3.452950\n",
      "Epoch is 11\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.345716  g_loss: 3.096517\n",
      "batch 1  d_loss: 0.259476  g_loss: 2.517724\n",
      "batch 2  d_loss: 0.192775  g_loss: 2.344028\n",
      "batch 3  d_loss: 0.223116  g_loss: 2.644622\n",
      "batch 4  d_loss: 0.384351  g_loss: 1.790290\n",
      "batch 5  d_loss: 0.517185  g_loss: 2.786680\n",
      "batch 6  d_loss: 0.271767  g_loss: 3.263561\n",
      "batch 7  d_loss: 1.226272  g_loss: 1.391203\n",
      "batch 8  d_loss: 0.529201  g_loss: 0.766168\n",
      "batch 9  d_loss: 0.653722  g_loss: 1.402068\n",
      "batch 10  d_loss: 0.293333  g_loss: 2.176839\n",
      "batch 11  d_loss: 0.418454  g_loss: 2.417863\n",
      "batch 12  d_loss: 0.550813  g_loss: 1.804643\n",
      "batch 13  d_loss: 0.390877  g_loss: 1.131485\n",
      "batch 14  d_loss: 0.367998  g_loss: 1.275444\n",
      "batch 15  d_loss: 0.418392  g_loss: 1.415082\n",
      "batch 16  d_loss: 0.386231  g_loss: 2.032333\n",
      "batch 17  d_loss: 0.440480  g_loss: 1.994076\n",
      "batch 18  d_loss: 0.385962  g_loss: 2.344999\n",
      "batch 19  d_loss: 0.299329  g_loss: 1.736473\n",
      "batch 20  d_loss: 0.309498  g_loss: 1.767861\n",
      "batch 21  d_loss: 0.283266  g_loss: 1.588103\n",
      "batch 22  d_loss: 0.235163  g_loss: 2.247724\n",
      "batch 23  d_loss: 0.213980  g_loss: 2.611414\n",
      "batch 24  d_loss: 0.215206  g_loss: 2.545679\n",
      "batch 25  d_loss: 0.178476  g_loss: 2.411469\n",
      "batch 26  d_loss: 0.202260  g_loss: 2.564553\n",
      "batch 27  d_loss: 0.127375  g_loss: 2.389414\n",
      "batch 28  d_loss: 0.188415  g_loss: 2.198063\n",
      "batch 29  d_loss: 0.235302  g_loss: 2.114274\n",
      "batch 30  d_loss: 0.192996  g_loss: 2.817320\n",
      "batch 31  d_loss: 0.199019  g_loss: 2.944718\n",
      "batch 32  d_loss: 0.394841  g_loss: 2.920398\n",
      "batch 33  d_loss: 0.276473  g_loss: 2.701544\n",
      "batch 34  d_loss: 0.180376  g_loss: 1.829917\n",
      "batch 35  d_loss: 0.215578  g_loss: 1.963115\n",
      "batch 36  d_loss: 0.373201  g_loss: 2.415868\n",
      "batch 37  d_loss: 0.239087  g_loss: 2.430029\n",
      "batch 38  d_loss: 0.171158  g_loss: 2.567116\n",
      "batch 39  d_loss: 0.256334  g_loss: 2.353184\n",
      "batch 40  d_loss: 0.314938  g_loss: 2.470911\n",
      "batch 41  d_loss: 0.203986  g_loss: 1.916491\n",
      "batch 42  d_loss: 0.142074  g_loss: 2.368891\n",
      "batch 43  d_loss: 0.302307  g_loss: 2.444784\n",
      "batch 44  d_loss: 0.300602  g_loss: 2.610801\n",
      "batch 45  d_loss: 0.148774  g_loss: 3.063715\n",
      "Epoch is 12\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.223721  g_loss: 2.843597\n",
      "batch 1  d_loss: 0.248375  g_loss: 2.653350\n",
      "batch 2  d_loss: 0.196983  g_loss: 2.406222\n",
      "batch 3  d_loss: 0.253758  g_loss: 2.088706\n",
      "batch 4  d_loss: 0.366608  g_loss: 3.144989\n",
      "batch 5  d_loss: 0.203109  g_loss: 3.825510\n",
      "batch 6  d_loss: 0.278284  g_loss: 2.888020\n",
      "batch 7  d_loss: 0.598869  g_loss: 2.159843\n",
      "batch 8  d_loss: 0.371818  g_loss: 1.458407\n",
      "batch 9  d_loss: 0.383688  g_loss: 1.651653\n",
      "batch 10  d_loss: 0.295495  g_loss: 2.061196\n",
      "batch 11  d_loss: 0.295249  g_loss: 2.792360\n",
      "batch 12  d_loss: 0.320498  g_loss: 2.860543\n",
      "batch 13  d_loss: 0.265395  g_loss: 2.096381\n",
      "batch 14  d_loss: 0.226217  g_loss: 2.031387\n",
      "batch 15  d_loss: 0.155877  g_loss: 2.044502\n",
      "batch 16  d_loss: 0.200343  g_loss: 2.239817\n",
      "batch 17  d_loss: 0.239010  g_loss: 2.372248\n",
      "batch 18  d_loss: 0.226454  g_loss: 2.383853\n",
      "batch 19  d_loss: 0.269636  g_loss: 2.649846\n",
      "batch 20  d_loss: 0.296642  g_loss: 2.906389\n",
      "batch 21  d_loss: 0.294019  g_loss: 2.714331\n",
      "batch 22  d_loss: 0.294601  g_loss: 2.026642\n",
      "batch 23  d_loss: 0.241620  g_loss: 2.077898\n",
      "batch 24  d_loss: 0.263069  g_loss: 2.679170\n",
      "batch 25  d_loss: 0.381524  g_loss: 2.725394\n",
      "batch 26  d_loss: 0.300164  g_loss: 2.214809\n",
      "batch 27  d_loss: 0.250354  g_loss: 1.878788\n",
      "batch 28  d_loss: 0.294582  g_loss: 1.667336\n",
      "batch 29  d_loss: 0.361209  g_loss: 1.970522\n",
      "batch 30  d_loss: 0.254225  g_loss: 2.793120\n",
      "batch 31  d_loss: 0.285515  g_loss: 2.862407\n",
      "batch 32  d_loss: 0.402597  g_loss: 2.285598\n",
      "batch 33  d_loss: 0.205991  g_loss: 1.627945\n",
      "batch 34  d_loss: 0.197986  g_loss: 1.603623\n",
      "batch 35  d_loss: 0.283989  g_loss: 2.179382\n",
      "batch 36  d_loss: 0.237334  g_loss: 2.625613\n",
      "batch 37  d_loss: 0.224825  g_loss: 3.000794\n",
      "batch 38  d_loss: 0.240648  g_loss: 3.084700\n",
      "batch 39  d_loss: 0.235331  g_loss: 2.793900\n",
      "batch 40  d_loss: 0.237850  g_loss: 1.957321\n",
      "batch 41  d_loss: 0.369148  g_loss: 2.363438\n",
      "batch 42  d_loss: 0.263693  g_loss: 2.802104\n",
      "batch 43  d_loss: 0.380655  g_loss: 2.835654\n",
      "batch 44  d_loss: 0.307115  g_loss: 2.505836\n",
      "batch 45  d_loss: 0.207019  g_loss: 2.498203\n",
      "Epoch is 13\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.274026  g_loss: 2.492592\n",
      "batch 1  d_loss: 0.249036  g_loss: 2.159242\n",
      "batch 2  d_loss: 0.273031  g_loss: 2.229795\n",
      "batch 3  d_loss: 0.287559  g_loss: 2.894015\n",
      "batch 4  d_loss: 0.319714  g_loss: 2.740310\n",
      "batch 5  d_loss: 0.407896  g_loss: 2.323019\n",
      "batch 6  d_loss: 0.187061  g_loss: 2.207213\n",
      "batch 7  d_loss: 0.562390  g_loss: 1.469028\n",
      "batch 8  d_loss: 0.387172  g_loss: 1.694655\n",
      "batch 9  d_loss: 0.267305  g_loss: 2.280507\n",
      "batch 10  d_loss: 0.212953  g_loss: 3.184629\n",
      "batch 11  d_loss: 0.472291  g_loss: 2.593346\n",
      "batch 12  d_loss: 0.371206  g_loss: 1.662992\n",
      "batch 13  d_loss: 0.337635  g_loss: 1.184905\n",
      "batch 14  d_loss: 0.372135  g_loss: 1.796234\n",
      "batch 15  d_loss: 0.412971  g_loss: 1.918814\n",
      "batch 16  d_loss: 0.317419  g_loss: 2.400489\n",
      "batch 17  d_loss: 0.518813  g_loss: 1.921031\n",
      "batch 18  d_loss: 0.262450  g_loss: 1.696405\n",
      "batch 19  d_loss: 0.321145  g_loss: 1.770970\n",
      "batch 20  d_loss: 0.297898  g_loss: 1.814198\n",
      "batch 21  d_loss: 0.276827  g_loss: 2.265900\n",
      "batch 22  d_loss: 0.257988  g_loss: 2.583978\n",
      "batch 23  d_loss: 0.315498  g_loss: 2.451243\n",
      "batch 24  d_loss: 0.330417  g_loss: 2.238375\n",
      "batch 25  d_loss: 0.356754  g_loss: 1.738920\n",
      "batch 26  d_loss: 0.385422  g_loss: 1.856016\n",
      "batch 27  d_loss: 0.363243  g_loss: 2.098857\n",
      "batch 28  d_loss: 0.384729  g_loss: 1.657656\n",
      "batch 29  d_loss: 0.457514  g_loss: 2.411754\n",
      "batch 30  d_loss: 0.377127  g_loss: 1.688406\n",
      "batch 31  d_loss: 0.447014  g_loss: 1.733088\n",
      "batch 32  d_loss: 0.392152  g_loss: 1.234284\n",
      "batch 33  d_loss: 0.395145  g_loss: 1.499076\n",
      "batch 34  d_loss: 0.278247  g_loss: 1.694639\n",
      "batch 35  d_loss: 0.336182  g_loss: 2.118975\n",
      "batch 36  d_loss: 0.348334  g_loss: 2.389487\n",
      "batch 37  d_loss: 0.303376  g_loss: 2.608813\n",
      "batch 38  d_loss: 0.274023  g_loss: 3.040434\n",
      "batch 39  d_loss: 0.438496  g_loss: 2.566955\n",
      "batch 40  d_loss: 0.379619  g_loss: 2.156211\n",
      "batch 41  d_loss: 0.273405  g_loss: 1.734007\n",
      "batch 42  d_loss: 0.276036  g_loss: 2.009982\n",
      "batch 43  d_loss: 0.420856  g_loss: 2.270641\n",
      "batch 44  d_loss: 0.311258  g_loss: 2.118902\n",
      "batch 45  d_loss: 0.198518  g_loss: 2.219613\n",
      "Epoch is 14\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.350745  g_loss: 2.356098\n",
      "batch 1  d_loss: 0.334737  g_loss: 2.361837\n",
      "batch 2  d_loss: 0.365803  g_loss: 2.675036\n",
      "batch 3  d_loss: 0.325848  g_loss: 2.474744\n",
      "batch 4  d_loss: 0.324689  g_loss: 2.328482\n",
      "batch 5  d_loss: 0.286999  g_loss: 2.017765\n",
      "batch 6  d_loss: 0.270292  g_loss: 2.174577\n",
      "batch 7  d_loss: 0.547747  g_loss: 1.748619\n",
      "batch 8  d_loss: 0.400418  g_loss: 1.637563\n",
      "batch 9  d_loss: 0.343625  g_loss: 1.946581\n",
      "batch 10  d_loss: 0.290441  g_loss: 2.383388\n",
      "batch 11  d_loss: 0.421561  g_loss: 2.412739\n",
      "batch 12  d_loss: 0.290829  g_loss: 1.938741\n",
      "batch 13  d_loss: 0.272428  g_loss: 1.612293\n",
      "batch 14  d_loss: 0.247255  g_loss: 1.521038\n",
      "batch 15  d_loss: 0.338995  g_loss: 1.838450\n",
      "batch 16  d_loss: 0.299930  g_loss: 2.252443\n",
      "batch 17  d_loss: 0.382746  g_loss: 2.409475\n",
      "batch 18  d_loss: 0.215339  g_loss: 2.297625\n",
      "batch 19  d_loss: 0.217806  g_loss: 2.227870\n",
      "batch 20  d_loss: 0.334877  g_loss: 1.847772\n",
      "batch 21  d_loss: 0.213412  g_loss: 2.263928\n",
      "batch 22  d_loss: 0.243016  g_loss: 2.241436\n",
      "batch 23  d_loss: 0.235247  g_loss: 2.082436\n",
      "batch 24  d_loss: 0.186914  g_loss: 2.566045\n",
      "batch 25  d_loss: 0.323304  g_loss: 2.189825\n",
      "batch 26  d_loss: 0.252282  g_loss: 2.107642\n",
      "batch 27  d_loss: 0.154199  g_loss: 2.189132\n",
      "batch 28  d_loss: 0.370690  g_loss: 2.051984\n",
      "batch 29  d_loss: 0.412404  g_loss: 1.585680\n",
      "batch 30  d_loss: 0.285333  g_loss: 1.922693\n",
      "batch 31  d_loss: 0.256986  g_loss: 2.530671\n",
      "batch 32  d_loss: 0.255838  g_loss: 2.400722\n",
      "batch 33  d_loss: 0.288164  g_loss: 1.461144\n",
      "batch 34  d_loss: 0.202070  g_loss: 1.612973\n",
      "batch 35  d_loss: 0.298126  g_loss: 1.726429\n",
      "batch 36  d_loss: 0.290538  g_loss: 2.233205\n",
      "batch 37  d_loss: 0.224596  g_loss: 2.848797\n",
      "batch 38  d_loss: 0.308261  g_loss: 2.109681\n",
      "batch 39  d_loss: 0.205148  g_loss: 1.906776\n",
      "batch 40  d_loss: 0.251836  g_loss: 2.144294\n",
      "batch 41  d_loss: 0.401611  g_loss: 2.776118\n",
      "batch 42  d_loss: 0.228411  g_loss: 2.986990\n",
      "batch 43  d_loss: 0.327136  g_loss: 2.422916\n",
      "batch 44  d_loss: 0.254352  g_loss: 1.641947\n",
      "batch 45  d_loss: 0.331673  g_loss: 1.973336\n",
      "Epoch is 15\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.454005  g_loss: 2.536278\n",
      "batch 1  d_loss: 0.306756  g_loss: 1.851325\n",
      "batch 2  d_loss: 0.278591  g_loss: 2.057365\n",
      "batch 3  d_loss: 0.491635  g_loss: 2.639951\n",
      "batch 4  d_loss: 0.432318  g_loss: 2.602990\n",
      "batch 5  d_loss: 0.357333  g_loss: 2.228337\n",
      "batch 6  d_loss: 0.386285  g_loss: 1.720109\n",
      "batch 7  d_loss: 0.431896  g_loss: 1.396073\n",
      "batch 8  d_loss: 0.392729  g_loss: 1.324795\n",
      "batch 9  d_loss: 0.294552  g_loss: 2.116652\n",
      "batch 10  d_loss: 0.193386  g_loss: 2.798277\n",
      "batch 11  d_loss: 0.362672  g_loss: 2.575314\n",
      "batch 12  d_loss: 0.390872  g_loss: 2.091306\n",
      "batch 13  d_loss: 0.204490  g_loss: 1.960863\n",
      "batch 14  d_loss: 0.320825  g_loss: 2.047527\n",
      "batch 15  d_loss: 0.268115  g_loss: 2.288589\n",
      "batch 16  d_loss: 0.238981  g_loss: 2.861073\n",
      "batch 17  d_loss: 0.413057  g_loss: 2.393444\n",
      "batch 18  d_loss: 0.252541  g_loss: 2.464171\n",
      "batch 19  d_loss: 0.295366  g_loss: 2.056102\n",
      "batch 20  d_loss: 0.350489  g_loss: 1.643556\n",
      "batch 21  d_loss: 0.300463  g_loss: 1.839753\n",
      "batch 22  d_loss: 0.285417  g_loss: 2.000592\n",
      "batch 23  d_loss: 0.226809  g_loss: 2.826379\n",
      "batch 24  d_loss: 0.249591  g_loss: 3.240842\n",
      "batch 25  d_loss: 0.368762  g_loss: 2.478733\n",
      "batch 26  d_loss: 0.188317  g_loss: 2.250423\n",
      "batch 27  d_loss: 0.222448  g_loss: 1.973633\n",
      "batch 28  d_loss: 0.229696  g_loss: 2.265188\n",
      "batch 29  d_loss: 0.340586  g_loss: 2.616029\n",
      "batch 30  d_loss: 0.218699  g_loss: 3.034003\n",
      "batch 31  d_loss: 0.202038  g_loss: 2.767533\n",
      "batch 32  d_loss: 0.255601  g_loss: 2.876911\n",
      "batch 33  d_loss: 0.290187  g_loss: 2.220559\n",
      "batch 34  d_loss: 0.210408  g_loss: 1.977872\n",
      "batch 35  d_loss: 0.225306  g_loss: 2.285975\n",
      "batch 36  d_loss: 0.320094  g_loss: 2.528224\n",
      "batch 37  d_loss: 0.218799  g_loss: 2.551384\n",
      "batch 38  d_loss: 0.169271  g_loss: 2.646611\n",
      "batch 39  d_loss: 0.310856  g_loss: 2.745373\n",
      "batch 40  d_loss: 0.221514  g_loss: 2.563840\n",
      "batch 41  d_loss: 0.305203  g_loss: 2.132664\n",
      "batch 42  d_loss: 0.344193  g_loss: 3.000236\n",
      "batch 43  d_loss: 0.243412  g_loss: 2.760186\n",
      "batch 44  d_loss: 0.210084  g_loss: 2.779071\n",
      "batch 45  d_loss: 0.237632  g_loss: 2.896396\n",
      "Epoch is 16\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.179758  g_loss: 2.732862\n",
      "batch 1  d_loss: 0.216454  g_loss: 3.051342\n",
      "batch 2  d_loss: 0.230829  g_loss: 2.537477\n",
      "batch 3  d_loss: 0.287023  g_loss: 2.755698\n",
      "batch 4  d_loss: 0.373678  g_loss: 1.712398\n",
      "batch 5  d_loss: 0.421752  g_loss: 2.153399\n",
      "batch 6  d_loss: 0.316141  g_loss: 2.851316\n",
      "batch 7  d_loss: 1.073078  g_loss: 3.081233\n",
      "batch 8  d_loss: 0.541061  g_loss: 2.056455\n",
      "batch 9  d_loss: 0.301641  g_loss: 2.133354\n",
      "batch 10  d_loss: 0.254053  g_loss: 2.218781\n",
      "batch 11  d_loss: 0.325476  g_loss: 2.495640\n",
      "batch 12  d_loss: 0.255201  g_loss: 1.763300\n",
      "batch 13  d_loss: 0.271315  g_loss: 1.630989\n",
      "batch 14  d_loss: 0.308367  g_loss: 1.604940\n",
      "batch 15  d_loss: 0.334018  g_loss: 2.001840\n",
      "batch 16  d_loss: 0.295953  g_loss: 2.341957\n",
      "batch 17  d_loss: 0.368320  g_loss: 2.345604\n",
      "batch 18  d_loss: 0.249071  g_loss: 2.014163\n",
      "batch 19  d_loss: 0.356966  g_loss: 1.905748\n",
      "batch 20  d_loss: 0.357105  g_loss: 1.568380\n",
      "batch 21  d_loss: 0.277706  g_loss: 1.692041\n",
      "batch 22  d_loss: 0.206802  g_loss: 2.197590\n",
      "batch 23  d_loss: 0.205471  g_loss: 2.859103\n",
      "batch 24  d_loss: 0.406702  g_loss: 2.699290\n",
      "batch 25  d_loss: 0.222407  g_loss: 1.988311\n",
      "batch 26  d_loss: 0.199715  g_loss: 1.752837\n",
      "batch 27  d_loss: 0.221881  g_loss: 2.004300\n",
      "batch 28  d_loss: 0.243047  g_loss: 2.394788\n",
      "batch 29  d_loss: 0.208445  g_loss: 3.025183\n",
      "batch 30  d_loss: 0.236627  g_loss: 2.992559\n",
      "batch 31  d_loss: 0.112965  g_loss: 2.793695\n",
      "batch 32  d_loss: 0.126951  g_loss: 2.832609\n",
      "batch 33  d_loss: 0.183780  g_loss: 2.594715\n",
      "batch 34  d_loss: 0.174825  g_loss: 2.993501\n",
      "batch 35  d_loss: 0.185938  g_loss: 2.513748\n",
      "batch 36  d_loss: 0.269974  g_loss: 2.908852\n",
      "batch 37  d_loss: 0.267774  g_loss: 2.661400\n",
      "batch 38  d_loss: 0.145094  g_loss: 2.202881\n",
      "batch 39  d_loss: 0.215919  g_loss: 2.590586\n",
      "batch 40  d_loss: 0.228776  g_loss: 3.196262\n",
      "batch 41  d_loss: 0.230251  g_loss: 3.556291\n",
      "batch 42  d_loss: 0.254387  g_loss: 3.287678\n",
      "batch 43  d_loss: 0.324240  g_loss: 3.537379\n",
      "batch 44  d_loss: 0.261023  g_loss: 3.223414\n",
      "batch 45  d_loss: 0.253589  g_loss: 3.519358\n",
      "Epoch is 17\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.260224  g_loss: 3.003838\n",
      "batch 1  d_loss: 0.325488  g_loss: 2.218102\n",
      "batch 2  d_loss: 0.267551  g_loss: 2.371424\n",
      "batch 3  d_loss: 0.208372  g_loss: 2.522779\n",
      "batch 4  d_loss: 0.279472  g_loss: 1.827789\n",
      "batch 5  d_loss: 0.238558  g_loss: 2.454376\n",
      "batch 6  d_loss: 0.174165  g_loss: 2.821883\n",
      "batch 7  d_loss: 0.619664  g_loss: 2.349880\n",
      "batch 8  d_loss: 0.424524  g_loss: 1.982643\n",
      "batch 9  d_loss: 0.209084  g_loss: 2.965544\n",
      "batch 10  d_loss: 0.193291  g_loss: 2.723354\n",
      "batch 11  d_loss: 0.250376  g_loss: 3.023375\n",
      "batch 12  d_loss: 0.279777  g_loss: 3.022461\n",
      "batch 13  d_loss: 0.209843  g_loss: 2.318575\n",
      "batch 14  d_loss: 0.241255  g_loss: 2.047957\n",
      "batch 15  d_loss: 0.239803  g_loss: 2.256043\n",
      "batch 16  d_loss: 0.242999  g_loss: 2.090522\n",
      "batch 17  d_loss: 0.351490  g_loss: 2.157987\n",
      "batch 18  d_loss: 0.219179  g_loss: 3.176850\n",
      "batch 19  d_loss: 0.194014  g_loss: 3.306115\n",
      "batch 20  d_loss: 0.301775  g_loss: 2.508366\n",
      "batch 21  d_loss: 0.193317  g_loss: 2.407850\n",
      "batch 22  d_loss: 0.205512  g_loss: 2.192380\n",
      "batch 23  d_loss: 0.164630  g_loss: 1.631855\n",
      "batch 24  d_loss: 0.297807  g_loss: 2.266077\n",
      "batch 25  d_loss: 0.306721  g_loss: 2.634766\n",
      "batch 26  d_loss: 0.340227  g_loss: 2.223543\n",
      "batch 27  d_loss: 0.258291  g_loss: 2.213354\n",
      "batch 28  d_loss: 0.277859  g_loss: 2.093474\n",
      "batch 29  d_loss: 0.277209  g_loss: 2.063815\n",
      "batch 30  d_loss: 0.173964  g_loss: 2.125132\n",
      "batch 31  d_loss: 0.153141  g_loss: 2.873892\n",
      "batch 32  d_loss: 0.168848  g_loss: 3.066334\n",
      "batch 33  d_loss: 0.175082  g_loss: 3.186845\n",
      "batch 34  d_loss: 0.177178  g_loss: 2.453881\n",
      "batch 35  d_loss: 0.185582  g_loss: 2.720438\n",
      "batch 36  d_loss: 0.209722  g_loss: 2.359860\n",
      "batch 37  d_loss: 0.210389  g_loss: 3.047166\n",
      "batch 38  d_loss: 0.189063  g_loss: 3.081474\n",
      "batch 39  d_loss: 0.167423  g_loss: 2.986010\n",
      "batch 40  d_loss: 0.187612  g_loss: 2.300435\n",
      "batch 41  d_loss: 0.333132  g_loss: 2.311711\n",
      "batch 42  d_loss: 0.340546  g_loss: 2.804352\n",
      "batch 43  d_loss: 0.226676  g_loss: 2.889321\n",
      "batch 44  d_loss: 0.248803  g_loss: 2.007826\n",
      "batch 45  d_loss: 0.309881  g_loss: 1.844758\n",
      "Epoch is 18\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.324410  g_loss: 1.660925\n",
      "batch 1  d_loss: 0.360514  g_loss: 2.015188\n",
      "batch 2  d_loss: 0.330368  g_loss: 2.649880\n",
      "batch 3  d_loss: 0.410668  g_loss: 2.110336\n",
      "batch 4  d_loss: 0.266991  g_loss: 1.441023\n",
      "batch 5  d_loss: 0.362602  g_loss: 1.857719\n",
      "batch 6  d_loss: 0.230036  g_loss: 2.527047\n",
      "batch 7  d_loss: 0.572768  g_loss: 2.466773\n",
      "batch 8  d_loss: 0.363205  g_loss: 1.982753\n",
      "batch 9  d_loss: 0.259101  g_loss: 1.994994\n",
      "batch 10  d_loss: 0.186931  g_loss: 2.264972\n",
      "batch 11  d_loss: 0.304158  g_loss: 2.363110\n",
      "batch 12  d_loss: 0.268511  g_loss: 2.565506\n",
      "batch 13  d_loss: 0.159828  g_loss: 2.556000\n",
      "batch 14  d_loss: 0.144644  g_loss: 2.839289\n",
      "batch 15  d_loss: 0.181134  g_loss: 2.271185\n",
      "batch 16  d_loss: 0.142470  g_loss: 2.057730\n",
      "batch 17  d_loss: 0.140643  g_loss: 2.211721\n",
      "batch 18  d_loss: 0.171068  g_loss: 2.100771\n",
      "batch 19  d_loss: 0.163374  g_loss: 2.692725\n",
      "batch 20  d_loss: 0.173929  g_loss: 2.868834\n",
      "batch 21  d_loss: 0.149857  g_loss: 2.873736\n",
      "batch 22  d_loss: 0.150893  g_loss: 2.975136\n",
      "batch 23  d_loss: 0.160353  g_loss: 2.555100\n",
      "batch 24  d_loss: 0.144270  g_loss: 2.421970\n",
      "batch 25  d_loss: 0.218218  g_loss: 2.138727\n",
      "batch 26  d_loss: 0.277841  g_loss: 2.390876\n",
      "batch 27  d_loss: 0.215003  g_loss: 2.831334\n",
      "batch 28  d_loss: 0.260437  g_loss: 2.597762\n",
      "batch 29  d_loss: 0.306753  g_loss: 2.097023\n",
      "batch 30  d_loss: 0.222621  g_loss: 1.858499\n",
      "batch 31  d_loss: 0.255550  g_loss: 2.699661\n",
      "batch 32  d_loss: 0.209033  g_loss: 3.070383\n",
      "batch 33  d_loss: 0.306129  g_loss: 2.423677\n",
      "batch 34  d_loss: 0.314298  g_loss: 2.196350\n",
      "batch 35  d_loss: 0.306993  g_loss: 2.192249\n",
      "batch 36  d_loss: 0.430000  g_loss: 2.927852\n",
      "batch 37  d_loss: 0.456184  g_loss: 2.441639\n",
      "batch 38  d_loss: 0.228964  g_loss: 3.043863\n",
      "batch 39  d_loss: 0.234176  g_loss: 2.599583\n",
      "batch 40  d_loss: 0.159373  g_loss: 2.988244\n",
      "batch 41  d_loss: 0.222282  g_loss: 2.581724\n",
      "batch 42  d_loss: 0.169547  g_loss: 2.108047\n",
      "batch 43  d_loss: 0.287514  g_loss: 1.940853\n",
      "batch 44  d_loss: 0.226296  g_loss: 2.794676\n",
      "batch 45  d_loss: 0.184098  g_loss: 3.370940\n",
      "Epoch is 19\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.183627  g_loss: 3.240210\n",
      "batch 1  d_loss: 0.256856  g_loss: 2.502349\n",
      "batch 2  d_loss: 0.275587  g_loss: 1.990584\n",
      "batch 3  d_loss: 0.299179  g_loss: 2.045879\n",
      "batch 4  d_loss: 0.318898  g_loss: 2.918239\n",
      "batch 5  d_loss: 0.323962  g_loss: 3.253031\n",
      "batch 6  d_loss: 0.286368  g_loss: 3.530170\n",
      "batch 7  d_loss: 1.050393  g_loss: 2.050661\n",
      "batch 8  d_loss: 0.602355  g_loss: 1.236763\n",
      "batch 9  d_loss: 0.393429  g_loss: 1.276572\n",
      "batch 10  d_loss: 0.587931  g_loss: 1.982068\n",
      "batch 11  d_loss: 0.471942  g_loss: 2.703579\n",
      "batch 12  d_loss: 0.661973  g_loss: 2.281995\n",
      "batch 13  d_loss: 0.500561  g_loss: 1.480194\n",
      "batch 14  d_loss: 0.327732  g_loss: 0.991389\n",
      "batch 15  d_loss: 0.505520  g_loss: 0.916482\n",
      "batch 16  d_loss: 0.460504  g_loss: 1.649017\n",
      "batch 17  d_loss: 0.386801  g_loss: 2.226079\n",
      "batch 18  d_loss: 0.312166  g_loss: 2.807350\n",
      "batch 19  d_loss: 0.322471  g_loss: 2.891432\n",
      "batch 20  d_loss: 0.402151  g_loss: 2.727878\n",
      "batch 21  d_loss: 0.167764  g_loss: 1.945386\n",
      "batch 22  d_loss: 0.249766  g_loss: 1.863595\n",
      "batch 23  d_loss: 0.316300  g_loss: 1.841451\n",
      "batch 24  d_loss: 0.184387  g_loss: 2.153876\n",
      "batch 25  d_loss: 0.271690  g_loss: 2.303350\n",
      "batch 26  d_loss: 0.196647  g_loss: 2.474507\n",
      "batch 27  d_loss: 0.131533  g_loss: 2.806260\n",
      "batch 28  d_loss: 0.334548  g_loss: 2.431104\n",
      "batch 29  d_loss: 0.361041  g_loss: 2.283110\n",
      "batch 30  d_loss: 0.285851  g_loss: 1.812428\n",
      "batch 31  d_loss: 0.234767  g_loss: 1.668024\n",
      "batch 32  d_loss: 0.233233  g_loss: 1.412033\n",
      "batch 33  d_loss: 0.311273  g_loss: 2.406645\n",
      "batch 34  d_loss: 0.317499  g_loss: 1.905288\n",
      "batch 35  d_loss: 0.235134  g_loss: 2.144180\n",
      "batch 36  d_loss: 0.381516  g_loss: 2.514622\n",
      "batch 37  d_loss: 0.263028  g_loss: 2.011734\n",
      "batch 38  d_loss: 0.359720  g_loss: 2.161495\n",
      "batch 39  d_loss: 0.323871  g_loss: 2.010427\n",
      "batch 40  d_loss: 0.202244  g_loss: 2.440052\n",
      "batch 41  d_loss: 0.235756  g_loss: 2.928659\n",
      "batch 42  d_loss: 0.253060  g_loss: 2.379078\n",
      "batch 43  d_loss: 0.277895  g_loss: 2.169579\n",
      "batch 44  d_loss: 0.307319  g_loss: 2.121422\n",
      "batch 45  d_loss: 0.222441  g_loss: 2.819315\n",
      "Epoch is 20\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.300635  g_loss: 2.743511\n",
      "batch 1  d_loss: 0.242622  g_loss: 2.932702\n",
      "batch 2  d_loss: 0.333591  g_loss: 2.226677\n",
      "batch 3  d_loss: 0.236970  g_loss: 1.914500\n",
      "batch 4  d_loss: 0.241696  g_loss: 1.461187\n",
      "batch 5  d_loss: 0.402354  g_loss: 1.960830\n",
      "batch 6  d_loss: 0.267077  g_loss: 2.930584\n",
      "batch 7  d_loss: 0.582668  g_loss: 2.642345\n",
      "batch 8  d_loss: 0.392914  g_loss: 3.127508\n",
      "batch 9  d_loss: 0.241532  g_loss: 2.873371\n",
      "batch 10  d_loss: 0.373139  g_loss: 1.971779\n",
      "batch 11  d_loss: 0.261538  g_loss: 1.879900\n",
      "batch 12  d_loss: 0.371834  g_loss: 3.092758\n",
      "batch 13  d_loss: 0.179283  g_loss: 3.412354\n",
      "batch 14  d_loss: 0.289829  g_loss: 3.127428\n",
      "batch 15  d_loss: 0.452545  g_loss: 2.623811\n",
      "batch 16  d_loss: 0.344874  g_loss: 1.929425\n",
      "batch 17  d_loss: 0.316981  g_loss: 1.498826\n",
      "batch 18  d_loss: 0.308345  g_loss: 1.632112\n",
      "batch 19  d_loss: 0.279690  g_loss: 2.624164\n",
      "batch 20  d_loss: 0.260535  g_loss: 2.554842\n",
      "batch 21  d_loss: 0.285932  g_loss: 2.785054\n",
      "batch 22  d_loss: 0.321278  g_loss: 3.064928\n",
      "batch 23  d_loss: 0.209863  g_loss: 1.983294\n",
      "batch 24  d_loss: 0.222941  g_loss: 1.897862\n",
      "batch 25  d_loss: 0.214922  g_loss: 2.089956\n",
      "batch 26  d_loss: 0.272167  g_loss: 2.229496\n",
      "batch 27  d_loss: 0.144406  g_loss: 2.862064\n",
      "batch 28  d_loss: 0.279270  g_loss: 2.312456\n",
      "batch 29  d_loss: 0.455821  g_loss: 1.925616\n",
      "batch 30  d_loss: 0.230920  g_loss: 2.065248\n",
      "batch 31  d_loss: 0.260978  g_loss: 2.325378\n",
      "batch 32  d_loss: 0.321384  g_loss: 3.616793\n",
      "batch 33  d_loss: 0.403871  g_loss: 2.683534\n",
      "batch 34  d_loss: 0.269639  g_loss: 1.248489\n",
      "batch 35  d_loss: 0.265745  g_loss: 1.240778\n",
      "batch 36  d_loss: 0.404461  g_loss: 2.441537\n",
      "batch 37  d_loss: 0.309078  g_loss: 3.209600\n",
      "batch 38  d_loss: 0.307589  g_loss: 3.166295\n",
      "batch 39  d_loss: 0.287238  g_loss: 2.501911\n",
      "batch 40  d_loss: 0.143387  g_loss: 1.704358\n",
      "batch 41  d_loss: 0.357348  g_loss: 1.171646\n",
      "batch 42  d_loss: 0.373210  g_loss: 2.393164\n",
      "batch 43  d_loss: 0.302135  g_loss: 3.088238\n",
      "batch 44  d_loss: 0.304333  g_loss: 3.545107\n",
      "batch 45  d_loss: 0.198926  g_loss: 3.293571\n",
      "Epoch is 21\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.225541  g_loss: 2.934442\n",
      "batch 1  d_loss: 0.368654  g_loss: 2.283360\n",
      "batch 2  d_loss: 0.275070  g_loss: 1.567026\n",
      "batch 3  d_loss: 0.338000  g_loss: 1.984271\n",
      "batch 4  d_loss: 0.331963  g_loss: 2.007755\n",
      "batch 5  d_loss: 0.405565  g_loss: 3.019054\n",
      "batch 6  d_loss: 0.235206  g_loss: 2.555982\n",
      "batch 7  d_loss: 0.553354  g_loss: 2.172751\n",
      "batch 8  d_loss: 0.382649  g_loss: 1.133833\n",
      "batch 9  d_loss: 0.351671  g_loss: 1.265044\n",
      "batch 10  d_loss: 0.372721  g_loss: 1.519413\n",
      "batch 11  d_loss: 0.318787  g_loss: 1.949644\n",
      "batch 12  d_loss: 0.338033  g_loss: 2.507351\n",
      "batch 13  d_loss: 0.247195  g_loss: 2.532318\n",
      "batch 14  d_loss: 0.224806  g_loss: 2.243494\n",
      "batch 15  d_loss: 0.320961  g_loss: 1.992767\n",
      "batch 16  d_loss: 0.274686  g_loss: 1.575738\n",
      "batch 17  d_loss: 0.292004  g_loss: 1.849108\n",
      "batch 18  d_loss: 0.203358  g_loss: 2.170292\n",
      "batch 19  d_loss: 0.183026  g_loss: 2.664780\n",
      "batch 20  d_loss: 0.365065  g_loss: 2.887819\n",
      "batch 21  d_loss: 0.207329  g_loss: 2.265812\n",
      "batch 22  d_loss: 0.225917  g_loss: 1.856911\n",
      "batch 23  d_loss: 0.224073  g_loss: 1.626989\n",
      "batch 24  d_loss: 0.437626  g_loss: 1.952789\n",
      "batch 25  d_loss: 0.275447  g_loss: 2.922095\n",
      "batch 26  d_loss: 0.196046  g_loss: 2.964054\n",
      "batch 27  d_loss: 0.276149  g_loss: 3.141171\n",
      "batch 28  d_loss: 0.460115  g_loss: 2.677662\n",
      "batch 29  d_loss: 0.380509  g_loss: 1.968781\n",
      "batch 30  d_loss: 0.215531  g_loss: 1.587875\n",
      "batch 31  d_loss: 0.352480  g_loss: 1.723819\n",
      "batch 32  d_loss: 0.278854  g_loss: 2.052385\n",
      "batch 33  d_loss: 0.371923  g_loss: 2.259608\n",
      "batch 34  d_loss: 0.403033  g_loss: 2.207178\n",
      "batch 35  d_loss: 0.332322  g_loss: 1.905337\n",
      "batch 36  d_loss: 0.423251  g_loss: 1.400277\n",
      "batch 37  d_loss: 0.407985  g_loss: 1.716766\n",
      "batch 38  d_loss: 0.353667  g_loss: 2.176440\n",
      "batch 39  d_loss: 0.269879  g_loss: 2.528718\n",
      "batch 40  d_loss: 0.282826  g_loss: 3.180997\n",
      "batch 41  d_loss: 0.331705  g_loss: 3.058912\n",
      "batch 42  d_loss: 0.382304  g_loss: 2.776677\n",
      "batch 43  d_loss: 0.332554  g_loss: 2.584731\n",
      "batch 44  d_loss: 0.331447  g_loss: 1.927142\n",
      "batch 45  d_loss: 0.259330  g_loss: 1.805551\n",
      "Epoch is 22\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.454026  g_loss: 1.857539\n",
      "batch 1  d_loss: 0.401868  g_loss: 2.957841\n",
      "batch 2  d_loss: 0.430359  g_loss: 3.062350\n",
      "batch 3  d_loss: 0.310095  g_loss: 2.581817\n",
      "batch 4  d_loss: 0.308017  g_loss: 2.266982\n",
      "batch 5  d_loss: 0.257892  g_loss: 1.393952\n",
      "batch 6  d_loss: 0.226416  g_loss: 1.555944\n",
      "batch 7  d_loss: 0.428285  g_loss: 1.942166\n",
      "batch 8  d_loss: 0.401949  g_loss: 2.290890\n",
      "batch 9  d_loss: 0.244167  g_loss: 2.403909\n",
      "batch 10  d_loss: 0.267317  g_loss: 3.097581\n",
      "batch 11  d_loss: 0.390261  g_loss: 2.633897\n",
      "batch 12  d_loss: 0.379821  g_loss: 1.789028\n",
      "batch 13  d_loss: 0.421047  g_loss: 1.562716\n",
      "batch 14  d_loss: 0.439184  g_loss: 2.261916\n",
      "batch 15  d_loss: 0.365720  g_loss: 2.982388\n",
      "batch 16  d_loss: 0.408600  g_loss: 2.693296\n",
      "batch 17  d_loss: 0.390151  g_loss: 2.560430\n",
      "batch 18  d_loss: 0.346029  g_loss: 1.856661\n",
      "batch 19  d_loss: 0.330580  g_loss: 1.380225\n",
      "batch 20  d_loss: 0.471688  g_loss: 1.310352\n",
      "batch 21  d_loss: 0.375107  g_loss: 1.586478\n",
      "batch 22  d_loss: 0.267662  g_loss: 2.378460\n",
      "batch 23  d_loss: 0.221498  g_loss: 2.786719\n",
      "batch 24  d_loss: 0.311442  g_loss: 2.876578\n",
      "batch 25  d_loss: 0.259334  g_loss: 2.450583\n",
      "batch 26  d_loss: 0.211767  g_loss: 2.199854\n",
      "batch 27  d_loss: 0.155030  g_loss: 1.751533\n",
      "batch 28  d_loss: 0.244469  g_loss: 2.392525\n",
      "batch 29  d_loss: 0.251076  g_loss: 2.535743\n",
      "batch 30  d_loss: 0.169959  g_loss: 3.175146\n",
      "batch 31  d_loss: 0.191647  g_loss: 3.064614\n",
      "batch 32  d_loss: 0.257503  g_loss: 2.929072\n",
      "batch 33  d_loss: 0.323849  g_loss: 2.103905\n",
      "batch 34  d_loss: 0.283206  g_loss: 2.223998\n",
      "batch 35  d_loss: 0.221478  g_loss: 2.699998\n",
      "batch 36  d_loss: 0.338912  g_loss: 2.687181\n",
      "batch 37  d_loss: 0.306363  g_loss: 2.335266\n",
      "batch 38  d_loss: 0.242324  g_loss: 2.350351\n",
      "batch 39  d_loss: 0.211878  g_loss: 2.268911\n",
      "batch 40  d_loss: 0.204263  g_loss: 2.969133\n",
      "batch 41  d_loss: 0.217171  g_loss: 2.786511\n",
      "batch 42  d_loss: 0.207926  g_loss: 2.718237\n",
      "batch 43  d_loss: 0.273216  g_loss: 2.474785\n",
      "batch 44  d_loss: 0.228388  g_loss: 2.308608\n",
      "batch 45  d_loss: 0.142651  g_loss: 2.959934\n",
      "Epoch is 23\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.198028  g_loss: 2.470928\n",
      "batch 1  d_loss: 0.392920  g_loss: 2.456745\n",
      "batch 2  d_loss: 0.304444  g_loss: 2.302403\n",
      "batch 3  d_loss: 0.270952  g_loss: 2.363506\n",
      "batch 4  d_loss: 0.215595  g_loss: 2.693441\n",
      "batch 5  d_loss: 0.279591  g_loss: 2.087104\n",
      "batch 6  d_loss: 0.211366  g_loss: 2.203085\n",
      "batch 7  d_loss: 0.605608  g_loss: 1.967922\n",
      "batch 8  d_loss: 0.366235  g_loss: 2.187675\n",
      "batch 9  d_loss: 0.394636  g_loss: 1.774643\n",
      "batch 10  d_loss: 0.237907  g_loss: 2.466200\n",
      "batch 11  d_loss: 0.289180  g_loss: 2.749104\n",
      "batch 12  d_loss: 0.251846  g_loss: 2.399751\n",
      "batch 13  d_loss: 0.241927  g_loss: 2.444951\n",
      "batch 14  d_loss: 0.240644  g_loss: 2.370577\n",
      "batch 15  d_loss: 0.314349  g_loss: 2.467629\n",
      "batch 16  d_loss: 0.225313  g_loss: 2.677141\n",
      "batch 17  d_loss: 0.478013  g_loss: 2.466635\n",
      "batch 18  d_loss: 0.259097  g_loss: 2.168587\n",
      "batch 19  d_loss: 0.247322  g_loss: 2.107043\n",
      "batch 20  d_loss: 0.428309  g_loss: 2.725430\n",
      "batch 21  d_loss: 0.297871  g_loss: 2.878091\n",
      "batch 22  d_loss: 0.217039  g_loss: 2.537101\n",
      "batch 23  d_loss: 0.192080  g_loss: 2.272886\n",
      "batch 24  d_loss: 0.181998  g_loss: 2.067195\n",
      "batch 25  d_loss: 0.214531  g_loss: 2.169223\n",
      "batch 26  d_loss: 0.312241  g_loss: 2.558611\n",
      "batch 27  d_loss: 0.193797  g_loss: 3.420597\n",
      "batch 28  d_loss: 0.270440  g_loss: 4.175610\n",
      "batch 29  d_loss: 0.556811  g_loss: 2.902057\n",
      "batch 30  d_loss: 0.211956  g_loss: 1.806682\n",
      "batch 31  d_loss: 0.263897  g_loss: 1.473175\n",
      "batch 32  d_loss: 0.316027  g_loss: 1.602710\n",
      "batch 33  d_loss: 0.356728  g_loss: 2.137873\n",
      "batch 34  d_loss: 0.199160  g_loss: 2.521012\n",
      "batch 35  d_loss: 0.273665  g_loss: 3.216291\n",
      "batch 36  d_loss: 0.413838  g_loss: 2.582534\n",
      "batch 37  d_loss: 0.355422  g_loss: 1.814131\n",
      "batch 38  d_loss: 0.213140  g_loss: 1.225192\n",
      "batch 39  d_loss: 0.413908  g_loss: 1.525618\n",
      "batch 40  d_loss: 0.276978  g_loss: 2.317120\n",
      "batch 41  d_loss: 0.279887  g_loss: 3.406046\n",
      "batch 42  d_loss: 0.439120  g_loss: 3.388783\n",
      "batch 43  d_loss: 0.324068  g_loss: 3.001568\n",
      "batch 44  d_loss: 0.285966  g_loss: 2.372682\n",
      "batch 45  d_loss: 0.253343  g_loss: 1.958636\n",
      "Epoch is 24\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.282142  g_loss: 2.051176\n",
      "batch 1  d_loss: 0.300658  g_loss: 2.005183\n",
      "batch 2  d_loss: 0.287560  g_loss: 2.161309\n",
      "batch 3  d_loss: 0.219348  g_loss: 2.300532\n",
      "batch 4  d_loss: 0.384901  g_loss: 2.060127\n",
      "batch 5  d_loss: 0.315629  g_loss: 1.823306\n",
      "batch 6  d_loss: 0.344950  g_loss: 2.570787\n",
      "batch 7  d_loss: 0.655990  g_loss: 2.269600\n",
      "batch 8  d_loss: 0.392086  g_loss: 2.278250\n",
      "batch 9  d_loss: 0.272575  g_loss: 1.941704\n",
      "batch 10  d_loss: 0.287202  g_loss: 2.057059\n",
      "batch 11  d_loss: 0.317705  g_loss: 2.146974\n",
      "batch 12  d_loss: 0.295861  g_loss: 2.097177\n",
      "batch 13  d_loss: 0.258215  g_loss: 1.893249\n",
      "batch 14  d_loss: 0.199056  g_loss: 2.340237\n",
      "batch 15  d_loss: 0.195462  g_loss: 2.442435\n",
      "batch 16  d_loss: 0.137497  g_loss: 2.033155\n",
      "batch 17  d_loss: 0.262247  g_loss: 2.372131\n",
      "batch 18  d_loss: 0.161940  g_loss: 2.595907\n",
      "batch 19  d_loss: 0.233923  g_loss: 2.848071\n",
      "batch 20  d_loss: 0.240851  g_loss: 2.955221\n",
      "batch 21  d_loss: 0.148496  g_loss: 2.452852\n",
      "batch 22  d_loss: 0.174142  g_loss: 2.369707\n",
      "batch 23  d_loss: 0.192718  g_loss: 3.019929\n",
      "batch 24  d_loss: 0.230899  g_loss: 2.966972\n",
      "batch 25  d_loss: 0.384687  g_loss: 2.402510\n",
      "batch 26  d_loss: 0.336108  g_loss: 2.379516\n",
      "batch 27  d_loss: 0.221037  g_loss: 2.462058\n",
      "batch 28  d_loss: 0.300042  g_loss: 2.939696\n",
      "batch 29  d_loss: 0.518839  g_loss: 2.276882\n",
      "batch 30  d_loss: 0.269554  g_loss: 2.409565\n",
      "batch 31  d_loss: 0.242755  g_loss: 2.521228\n",
      "batch 32  d_loss: 0.246700  g_loss: 2.959346\n",
      "batch 33  d_loss: 0.275566  g_loss: 2.871122\n",
      "batch 34  d_loss: 0.272375  g_loss: 1.512966\n",
      "batch 35  d_loss: 0.372561  g_loss: 2.665312\n",
      "batch 36  d_loss: 0.470492  g_loss: 3.242440\n",
      "batch 37  d_loss: 0.505349  g_loss: 3.802454\n",
      "batch 38  d_loss: 0.270142  g_loss: 3.075164\n",
      "batch 39  d_loss: 0.383906  g_loss: 2.425128\n",
      "batch 40  d_loss: 0.308722  g_loss: 1.708668\n",
      "batch 41  d_loss: 0.541334  g_loss: 2.095809\n",
      "batch 42  d_loss: 0.238529  g_loss: 3.313718\n",
      "batch 43  d_loss: 0.255791  g_loss: 2.912233\n",
      "batch 44  d_loss: 0.309697  g_loss: 2.737551\n",
      "batch 45  d_loss: 0.149553  g_loss: 3.137295\n",
      "Epoch is 25\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.196501  g_loss: 2.559043\n",
      "batch 1  d_loss: 0.253665  g_loss: 2.569676\n",
      "batch 2  d_loss: 0.168057  g_loss: 2.953902\n",
      "batch 3  d_loss: 0.167987  g_loss: 3.566579\n",
      "batch 4  d_loss: 0.227205  g_loss: 3.605618\n",
      "batch 5  d_loss: 0.376549  g_loss: 3.735245\n",
      "batch 6  d_loss: 0.111810  g_loss: 3.670157\n",
      "batch 7  d_loss: 1.099318  g_loss: 2.366407\n",
      "batch 8  d_loss: 0.354364  g_loss: 0.950491\n",
      "batch 9  d_loss: 0.749445  g_loss: 1.690101\n",
      "batch 10  d_loss: 0.206014  g_loss: 3.290510\n",
      "batch 11  d_loss: 0.289234  g_loss: 3.825276\n",
      "batch 12  d_loss: 0.324976  g_loss: 3.203808\n",
      "batch 13  d_loss: 0.317465  g_loss: 2.169943\n",
      "batch 14  d_loss: 0.253968  g_loss: 1.634902\n",
      "batch 15  d_loss: 0.376194  g_loss: 1.534453\n",
      "batch 16  d_loss: 0.338874  g_loss: 1.309080\n",
      "batch 17  d_loss: 0.388045  g_loss: 1.729054\n",
      "batch 18  d_loss: 0.242015  g_loss: 2.507334\n",
      "batch 19  d_loss: 0.263376  g_loss: 2.745963\n",
      "batch 20  d_loss: 0.479755  g_loss: 2.315111\n",
      "batch 21  d_loss: 0.279084  g_loss: 1.814872\n",
      "batch 22  d_loss: 0.223931  g_loss: 2.361152\n",
      "batch 23  d_loss: 0.219141  g_loss: 2.502816\n",
      "batch 24  d_loss: 0.154991  g_loss: 2.914939\n",
      "batch 25  d_loss: 0.218631  g_loss: 2.841476\n",
      "batch 26  d_loss: 0.358576  g_loss: 2.672903\n",
      "batch 27  d_loss: 0.147094  g_loss: 2.288898\n",
      "batch 28  d_loss: 0.296470  g_loss: 1.901838\n",
      "batch 29  d_loss: 0.469999  g_loss: 1.734634\n",
      "batch 30  d_loss: 0.302843  g_loss: 1.761715\n",
      "batch 31  d_loss: 0.356625  g_loss: 2.406473\n",
      "batch 32  d_loss: 0.311714  g_loss: 3.192880\n",
      "batch 33  d_loss: 0.517963  g_loss: 1.536284\n",
      "batch 34  d_loss: 0.265191  g_loss: 1.403634\n",
      "batch 35  d_loss: 0.334769  g_loss: 1.057066\n",
      "batch 36  d_loss: 0.547182  g_loss: 1.692979\n",
      "batch 37  d_loss: 0.358149  g_loss: 2.138518\n",
      "batch 38  d_loss: 0.196944  g_loss: 2.362761\n",
      "batch 39  d_loss: 0.195189  g_loss: 2.875181\n",
      "batch 40  d_loss: 0.187176  g_loss: 2.762974\n",
      "batch 41  d_loss: 0.333143  g_loss: 2.425149\n",
      "batch 42  d_loss: 0.324399  g_loss: 1.841006\n",
      "batch 43  d_loss: 0.280165  g_loss: 1.437691\n",
      "batch 44  d_loss: 0.360504  g_loss: 1.736327\n",
      "batch 45  d_loss: 0.316782  g_loss: 2.013395\n",
      "Epoch is 26\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.226326  g_loss: 2.712976\n",
      "batch 1  d_loss: 0.292912  g_loss: 2.886153\n",
      "batch 2  d_loss: 0.278607  g_loss: 2.522959\n",
      "batch 3  d_loss: 0.215602  g_loss: 1.889663\n",
      "batch 4  d_loss: 0.272766  g_loss: 1.558670\n",
      "batch 5  d_loss: 0.350530  g_loss: 1.898991\n",
      "batch 6  d_loss: 0.236921  g_loss: 2.436922\n",
      "batch 7  d_loss: 0.716060  g_loss: 2.243357\n",
      "batch 8  d_loss: 0.480406  g_loss: 2.133986\n",
      "batch 9  d_loss: 0.234039  g_loss: 2.553437\n",
      "batch 10  d_loss: 0.340884  g_loss: 1.797007\n",
      "batch 11  d_loss: 0.475931  g_loss: 1.935341\n",
      "batch 12  d_loss: 0.345034  g_loss: 1.599728\n",
      "batch 13  d_loss: 0.448322  g_loss: 1.565339\n",
      "batch 14  d_loss: 0.303192  g_loss: 2.130328\n",
      "batch 15  d_loss: 0.324671  g_loss: 2.511895\n",
      "batch 16  d_loss: 0.401745  g_loss: 2.195139\n",
      "batch 17  d_loss: 0.535108  g_loss: 1.872740\n",
      "batch 18  d_loss: 0.172247  g_loss: 1.439679\n",
      "batch 19  d_loss: 0.298545  g_loss: 1.682791\n",
      "batch 20  d_loss: 0.318296  g_loss: 1.345468\n",
      "batch 21  d_loss: 0.285866  g_loss: 1.920955\n",
      "batch 22  d_loss: 0.248962  g_loss: 2.392014\n",
      "batch 23  d_loss: 0.279755  g_loss: 2.769189\n",
      "batch 24  d_loss: 0.237369  g_loss: 2.598922\n",
      "batch 25  d_loss: 0.299098  g_loss: 2.147302\n",
      "batch 26  d_loss: 0.285616  g_loss: 1.502889\n",
      "batch 27  d_loss: 0.239468  g_loss: 2.035224\n",
      "batch 28  d_loss: 0.368227  g_loss: 2.432610\n",
      "batch 29  d_loss: 0.397280  g_loss: 2.584991\n",
      "batch 30  d_loss: 0.316783  g_loss: 2.545182\n",
      "batch 31  d_loss: 0.259932  g_loss: 2.921294\n",
      "batch 32  d_loss: 0.190439  g_loss: 2.506809\n",
      "batch 33  d_loss: 0.349873  g_loss: 2.378679\n",
      "batch 34  d_loss: 0.373977  g_loss: 1.810646\n",
      "batch 35  d_loss: 0.376334  g_loss: 2.038317\n",
      "batch 36  d_loss: 0.555332  g_loss: 2.058877\n",
      "batch 37  d_loss: 0.376367  g_loss: 2.071606\n",
      "batch 38  d_loss: 0.267428  g_loss: 2.603872\n",
      "batch 39  d_loss: 0.263078  g_loss: 2.377611\n",
      "batch 40  d_loss: 0.295466  g_loss: 1.967147\n",
      "batch 41  d_loss: 0.309574  g_loss: 1.941513\n",
      "batch 42  d_loss: 0.328376  g_loss: 2.247671\n",
      "batch 43  d_loss: 0.215393  g_loss: 2.378495\n",
      "batch 44  d_loss: 0.327646  g_loss: 2.643271\n",
      "batch 45  d_loss: 0.154200  g_loss: 2.752138\n",
      "Epoch is 27\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.219942  g_loss: 2.332326\n",
      "batch 1  d_loss: 0.318312  g_loss: 2.062943\n",
      "batch 2  d_loss: 0.177839  g_loss: 1.933802\n",
      "batch 3  d_loss: 0.135643  g_loss: 2.158268\n",
      "batch 4  d_loss: 0.171509  g_loss: 2.204225\n",
      "batch 5  d_loss: 0.336677  g_loss: 2.468750\n",
      "batch 6  d_loss: 0.243900  g_loss: 3.404799\n",
      "batch 7  d_loss: 0.918871  g_loss: 3.034932\n",
      "batch 8  d_loss: 0.479902  g_loss: 2.301955\n",
      "batch 9  d_loss: 0.241209  g_loss: 1.739627\n",
      "batch 10  d_loss: 0.240118  g_loss: 2.032310\n",
      "batch 11  d_loss: 0.326903  g_loss: 2.025286\n",
      "batch 12  d_loss: 0.444919  g_loss: 1.738431\n",
      "batch 13  d_loss: 0.254928  g_loss: 1.972610\n",
      "batch 14  d_loss: 0.222705  g_loss: 2.023045\n",
      "batch 15  d_loss: 0.299123  g_loss: 2.074982\n",
      "batch 16  d_loss: 0.370246  g_loss: 2.354587\n",
      "batch 17  d_loss: 0.362760  g_loss: 2.027025\n",
      "batch 18  d_loss: 0.266222  g_loss: 1.819868\n",
      "batch 19  d_loss: 0.397572  g_loss: 1.590259\n",
      "batch 20  d_loss: 0.326988  g_loss: 1.658513\n",
      "batch 21  d_loss: 0.202399  g_loss: 2.266571\n",
      "batch 22  d_loss: 0.287743  g_loss: 2.053032\n",
      "batch 23  d_loss: 0.215483  g_loss: 2.282115\n",
      "batch 24  d_loss: 0.230673  g_loss: 2.388124\n",
      "batch 25  d_loss: 0.235250  g_loss: 2.172514\n",
      "batch 26  d_loss: 0.273993  g_loss: 2.153672\n",
      "batch 27  d_loss: 0.176677  g_loss: 2.074356\n",
      "batch 28  d_loss: 0.203471  g_loss: 2.294125\n",
      "batch 29  d_loss: 0.344570  g_loss: 2.032507\n",
      "batch 30  d_loss: 0.176727  g_loss: 2.135635\n",
      "batch 31  d_loss: 0.205619  g_loss: 2.488363\n",
      "batch 32  d_loss: 0.156451  g_loss: 2.947185\n",
      "batch 33  d_loss: 0.263263  g_loss: 2.965302\n",
      "batch 34  d_loss: 0.200793  g_loss: 2.882241\n",
      "batch 35  d_loss: 0.175614  g_loss: 2.266763\n",
      "batch 36  d_loss: 0.444158  g_loss: 1.653882\n",
      "batch 37  d_loss: 0.354164  g_loss: 2.031075\n",
      "batch 38  d_loss: 0.360947  g_loss: 1.993496\n",
      "batch 39  d_loss: 0.299154  g_loss: 3.065094\n",
      "batch 40  d_loss: 0.293956  g_loss: 3.639184\n",
      "batch 41  d_loss: 0.412387  g_loss: 2.951227\n",
      "batch 42  d_loss: 0.319354  g_loss: 1.895689\n",
      "batch 43  d_loss: 0.256240  g_loss: 1.240114\n",
      "batch 44  d_loss: 0.257203  g_loss: 1.560425\n",
      "batch 45  d_loss: 0.363917  g_loss: 2.524727\n",
      "Epoch is 28\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.242382  g_loss: 2.884910\n",
      "batch 1  d_loss: 0.331732  g_loss: 3.586996\n",
      "batch 2  d_loss: 0.408760  g_loss: 3.135504\n",
      "batch 3  d_loss: 0.311269  g_loss: 2.566442\n",
      "batch 4  d_loss: 0.223902  g_loss: 1.919600\n",
      "batch 5  d_loss: 0.254658  g_loss: 1.503062\n",
      "batch 6  d_loss: 0.244706  g_loss: 1.762642\n",
      "batch 7  d_loss: 0.554008  g_loss: 1.953467\n",
      "batch 8  d_loss: 0.314073  g_loss: 2.123739\n",
      "batch 9  d_loss: 0.211324  g_loss: 2.849859\n",
      "batch 10  d_loss: 0.205936  g_loss: 3.123480\n",
      "batch 11  d_loss: 0.358955  g_loss: 2.596959\n",
      "batch 12  d_loss: 0.422520  g_loss: 1.871701\n",
      "batch 13  d_loss: 0.353652  g_loss: 1.646143\n",
      "batch 14  d_loss: 0.333670  g_loss: 1.877724\n",
      "batch 15  d_loss: 0.293497  g_loss: 2.797713\n",
      "batch 16  d_loss: 0.340278  g_loss: 3.360218\n",
      "batch 17  d_loss: 0.423981  g_loss: 2.770133\n",
      "batch 18  d_loss: 0.250093  g_loss: 2.241320\n",
      "batch 19  d_loss: 0.303504  g_loss: 1.649456\n",
      "batch 20  d_loss: 0.324497  g_loss: 1.705566\n",
      "batch 21  d_loss: 0.371750  g_loss: 1.689017\n",
      "batch 22  d_loss: 0.232417  g_loss: 2.251989\n",
      "batch 23  d_loss: 0.186500  g_loss: 2.884948\n",
      "batch 24  d_loss: 0.169033  g_loss: 3.808238\n",
      "batch 25  d_loss: 0.301827  g_loss: 3.330655\n",
      "batch 26  d_loss: 0.378278  g_loss: 2.888340\n",
      "batch 27  d_loss: 0.114459  g_loss: 1.983614\n",
      "batch 28  d_loss: 0.256669  g_loss: 1.678963\n",
      "batch 29  d_loss: 0.453866  g_loss: 1.998703\n",
      "batch 30  d_loss: 0.406453  g_loss: 2.885055\n",
      "batch 31  d_loss: 0.200328  g_loss: 3.661441\n",
      "batch 32  d_loss: 0.268951  g_loss: 3.807903\n",
      "batch 33  d_loss: 0.350302  g_loss: 3.037486\n",
      "batch 34  d_loss: 0.322511  g_loss: 2.010665\n",
      "batch 35  d_loss: 0.208873  g_loss: 1.588455\n",
      "batch 36  d_loss: 0.460233  g_loss: 1.413709\n",
      "batch 37  d_loss: 0.357475  g_loss: 2.107884\n",
      "batch 38  d_loss: 0.309193  g_loss: 2.915594\n",
      "batch 39  d_loss: 0.376429  g_loss: 3.240849\n",
      "batch 40  d_loss: 0.327546  g_loss: 2.716720\n",
      "batch 41  d_loss: 0.262252  g_loss: 1.962044\n",
      "batch 42  d_loss: 0.266189  g_loss: 2.035212\n",
      "batch 43  d_loss: 0.234735  g_loss: 1.862834\n",
      "batch 44  d_loss: 0.257548  g_loss: 2.645165\n",
      "batch 45  d_loss: 0.122755  g_loss: 2.805446\n",
      "Epoch is 29\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.241477  g_loss: 3.481831\n",
      "batch 1  d_loss: 0.301342  g_loss: 2.642732\n",
      "batch 2  d_loss: 0.177052  g_loss: 2.713653\n",
      "batch 3  d_loss: 0.150776  g_loss: 2.168856\n",
      "batch 4  d_loss: 0.207451  g_loss: 2.697689\n",
      "batch 5  d_loss: 0.278934  g_loss: 3.125983\n",
      "batch 6  d_loss: 0.177538  g_loss: 3.261752\n",
      "batch 7  d_loss: 0.526268  g_loss: 3.083669\n",
      "batch 8  d_loss: 0.382034  g_loss: 2.201912\n",
      "batch 9  d_loss: 0.216769  g_loss: 1.904686\n",
      "batch 10  d_loss: 0.281112  g_loss: 1.764077\n",
      "batch 11  d_loss: 0.335412  g_loss: 2.091726\n",
      "batch 12  d_loss: 0.219549  g_loss: 2.226779\n",
      "batch 13  d_loss: 0.296083  g_loss: 2.400713\n",
      "batch 14  d_loss: 0.272652  g_loss: 2.578128\n",
      "batch 15  d_loss: 0.311316  g_loss: 2.630156\n",
      "batch 16  d_loss: 0.295301  g_loss: 2.873026\n",
      "batch 17  d_loss: 0.255744  g_loss: 2.192093\n",
      "batch 18  d_loss: 0.151255  g_loss: 2.341444\n",
      "batch 19  d_loss: 0.275360  g_loss: 2.071247\n",
      "batch 20  d_loss: 0.384275  g_loss: 2.512156\n",
      "batch 21  d_loss: 0.311772  g_loss: 2.775859\n",
      "batch 22  d_loss: 0.324897  g_loss: 2.735267\n",
      "batch 23  d_loss: 0.315068  g_loss: 2.824063\n",
      "batch 24  d_loss: 0.161681  g_loss: 2.728103\n",
      "batch 25  d_loss: 0.282377  g_loss: 2.589065\n",
      "batch 26  d_loss: 0.287422  g_loss: 2.463832\n",
      "batch 27  d_loss: 0.163078  g_loss: 2.618579\n",
      "batch 28  d_loss: 0.221823  g_loss: 2.557030\n",
      "batch 29  d_loss: 0.362574  g_loss: 2.748751\n",
      "batch 30  d_loss: 0.228802  g_loss: 2.594573\n",
      "batch 31  d_loss: 0.263472  g_loss: 2.865780\n",
      "batch 32  d_loss: 0.176905  g_loss: 2.596440\n",
      "batch 33  d_loss: 0.237672  g_loss: 2.784895\n",
      "batch 34  d_loss: 0.157363  g_loss: 2.765974\n",
      "batch 35  d_loss: 0.396834  g_loss: 1.782151\n",
      "batch 36  d_loss: 0.305827  g_loss: 1.891118\n",
      "batch 37  d_loss: 0.302998  g_loss: 2.300838\n",
      "batch 38  d_loss: 0.288978  g_loss: 2.872824\n",
      "batch 39  d_loss: 0.121298  g_loss: 3.839100\n",
      "batch 40  d_loss: 0.200154  g_loss: 4.330882\n",
      "batch 41  d_loss: 0.193504  g_loss: 3.763829\n",
      "batch 42  d_loss: 0.174028  g_loss: 3.002639\n",
      "batch 43  d_loss: 0.232731  g_loss: 2.050812\n",
      "batch 44  d_loss: 0.172956  g_loss: 2.219896\n",
      "batch 45  d_loss: 0.361187  g_loss: 3.108456\n",
      "Epoch is 30\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.136509  g_loss: 3.326645\n",
      "batch 1  d_loss: 0.274021  g_loss: 3.488682\n",
      "batch 2  d_loss: 0.151991  g_loss: 3.630126\n",
      "batch 3  d_loss: 0.170230  g_loss: 3.013380\n",
      "batch 4  d_loss: 0.273741  g_loss: 2.949338\n",
      "batch 5  d_loss: 0.320546  g_loss: 2.762419\n",
      "batch 6  d_loss: 0.212849  g_loss: 2.656706\n",
      "batch 7  d_loss: 0.960325  g_loss: 2.534472\n",
      "batch 8  d_loss: 0.540208  g_loss: 2.013131\n",
      "batch 9  d_loss: 0.281317  g_loss: 2.383860\n",
      "batch 10  d_loss: 0.347338  g_loss: 2.681109\n",
      "batch 11  d_loss: 0.403773  g_loss: 2.740175\n",
      "batch 12  d_loss: 0.415672  g_loss: 2.465848\n",
      "batch 13  d_loss: 0.350666  g_loss: 1.811872\n",
      "batch 14  d_loss: 0.318790  g_loss: 1.848607\n",
      "batch 15  d_loss: 0.396090  g_loss: 2.162489\n",
      "batch 16  d_loss: 0.291957  g_loss: 2.597050\n",
      "batch 17  d_loss: 0.347884  g_loss: 2.667417\n",
      "batch 18  d_loss: 0.274369  g_loss: 2.792359\n",
      "batch 19  d_loss: 0.318314  g_loss: 3.149791\n",
      "batch 20  d_loss: 0.303605  g_loss: 2.159289\n",
      "batch 21  d_loss: 0.286178  g_loss: 1.937788\n",
      "batch 22  d_loss: 0.303112  g_loss: 2.572466\n",
      "batch 23  d_loss: 0.232593  g_loss: 2.817441\n",
      "batch 24  d_loss: 0.267602  g_loss: 3.089412\n",
      "batch 25  d_loss: 0.259613  g_loss: 2.360977\n",
      "batch 26  d_loss: 0.324068  g_loss: 1.887374\n",
      "batch 27  d_loss: 0.175413  g_loss: 1.948173\n",
      "batch 28  d_loss: 0.245438  g_loss: 2.756294\n",
      "batch 29  d_loss: 0.540054  g_loss: 2.663977\n",
      "batch 30  d_loss: 0.397139  g_loss: 2.732422\n",
      "batch 31  d_loss: 0.333837  g_loss: 2.298441\n",
      "batch 32  d_loss: 0.283786  g_loss: 2.445699\n",
      "batch 33  d_loss: 0.314986  g_loss: 2.589367\n",
      "batch 34  d_loss: 0.451026  g_loss: 2.356445\n",
      "batch 35  d_loss: 0.317966  g_loss: 1.686526\n",
      "batch 36  d_loss: 0.445257  g_loss: 1.820255\n",
      "batch 37  d_loss: 0.481800  g_loss: 1.869790\n",
      "batch 38  d_loss: 0.310842  g_loss: 3.184059\n",
      "batch 39  d_loss: 0.239978  g_loss: 3.526678\n",
      "batch 40  d_loss: 0.283888  g_loss: 3.218257\n",
      "batch 41  d_loss: 0.453390  g_loss: 2.588630\n",
      "batch 42  d_loss: 0.311960  g_loss: 2.222745\n",
      "batch 43  d_loss: 0.269245  g_loss: 1.909038\n",
      "batch 44  d_loss: 0.227956  g_loss: 2.305171\n",
      "batch 45  d_loss: 0.203912  g_loss: 2.706836\n",
      "Epoch is 31\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.277581  g_loss: 2.950549\n",
      "batch 1  d_loss: 0.354334  g_loss: 1.943677\n",
      "batch 2  d_loss: 0.210678  g_loss: 1.597336\n",
      "batch 3  d_loss: 0.183471  g_loss: 2.014886\n",
      "batch 4  d_loss: 0.299215  g_loss: 2.599902\n",
      "batch 5  d_loss: 0.223693  g_loss: 2.867676\n",
      "batch 6  d_loss: 0.156723  g_loss: 3.262294\n",
      "batch 7  d_loss: 0.691701  g_loss: 2.848195\n",
      "batch 8  d_loss: 0.426517  g_loss: 1.779655\n",
      "batch 9  d_loss: 0.191390  g_loss: 1.175324\n",
      "batch 10  d_loss: 0.379381  g_loss: 1.427435\n",
      "batch 11  d_loss: 0.331933  g_loss: 1.833973\n",
      "batch 12  d_loss: 0.227005  g_loss: 2.775530\n",
      "batch 13  d_loss: 0.389421  g_loss: 2.678912\n",
      "batch 14  d_loss: 0.217318  g_loss: 2.628486\n",
      "batch 15  d_loss: 0.272004  g_loss: 2.777055\n",
      "batch 16  d_loss: 0.303189  g_loss: 2.540709\n",
      "batch 17  d_loss: 0.378416  g_loss: 1.660461\n",
      "batch 18  d_loss: 0.259587  g_loss: 2.321296\n",
      "batch 19  d_loss: 0.348180  g_loss: 2.468637\n",
      "batch 20  d_loss: 0.355537  g_loss: 2.744978\n",
      "batch 21  d_loss: 0.361218  g_loss: 2.353041\n",
      "batch 22  d_loss: 0.178704  g_loss: 2.055465\n",
      "batch 23  d_loss: 0.237324  g_loss: 2.586668\n",
      "batch 24  d_loss: 0.329503  g_loss: 2.604959\n",
      "batch 25  d_loss: 0.286344  g_loss: 2.253862\n",
      "batch 26  d_loss: 0.295992  g_loss: 2.006715\n",
      "batch 27  d_loss: 0.232524  g_loss: 1.685260\n",
      "batch 28  d_loss: 0.370198  g_loss: 2.090461\n",
      "batch 29  d_loss: 0.437817  g_loss: 1.813354\n",
      "batch 30  d_loss: 0.295525  g_loss: 1.761492\n",
      "batch 31  d_loss: 0.288113  g_loss: 2.096699\n",
      "batch 32  d_loss: 0.227082  g_loss: 2.331701\n",
      "batch 33  d_loss: 0.255336  g_loss: 2.346692\n",
      "batch 34  d_loss: 0.343183  g_loss: 2.264972\n",
      "batch 35  d_loss: 0.410043  g_loss: 1.804324\n",
      "batch 36  d_loss: 0.326332  g_loss: 1.931476\n",
      "batch 37  d_loss: 0.345937  g_loss: 1.479623\n",
      "batch 38  d_loss: 0.379434  g_loss: 2.404902\n",
      "batch 39  d_loss: 0.312604  g_loss: 2.469581\n",
      "batch 40  d_loss: 0.292774  g_loss: 2.653782\n",
      "batch 41  d_loss: 0.340202  g_loss: 2.502617\n",
      "batch 42  d_loss: 0.340978  g_loss: 2.543698\n",
      "batch 43  d_loss: 0.364117  g_loss: 1.563935\n",
      "batch 44  d_loss: 0.380223  g_loss: 1.781473\n",
      "batch 45  d_loss: 0.178355  g_loss: 2.021265\n",
      "Epoch is 32\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.266940  g_loss: 2.136786\n",
      "batch 1  d_loss: 0.244334  g_loss: 2.648506\n",
      "batch 2  d_loss: 0.296077  g_loss: 2.617600\n",
      "batch 3  d_loss: 0.209137  g_loss: 2.821655\n",
      "batch 4  d_loss: 0.200611  g_loss: 2.587807\n",
      "batch 5  d_loss: 0.206435  g_loss: 2.147397\n",
      "batch 6  d_loss: 0.126046  g_loss: 2.602609\n",
      "batch 7  d_loss: 0.757867  g_loss: 2.296892\n",
      "batch 8  d_loss: 0.313314  g_loss: 2.295054\n",
      "batch 9  d_loss: 0.247766  g_loss: 2.677814\n",
      "batch 10  d_loss: 0.183458  g_loss: 3.132454\n",
      "batch 11  d_loss: 0.320577  g_loss: 3.359511\n",
      "batch 12  d_loss: 0.438500  g_loss: 3.267022\n",
      "batch 13  d_loss: 0.323832  g_loss: 2.341747\n",
      "batch 14  d_loss: 0.219301  g_loss: 2.105749\n",
      "batch 15  d_loss: 0.334631  g_loss: 2.090648\n",
      "batch 16  d_loss: 0.281274  g_loss: 2.381062\n",
      "batch 17  d_loss: 0.198173  g_loss: 3.206027\n",
      "batch 18  d_loss: 0.078429  g_loss: 3.717145\n",
      "batch 19  d_loss: 0.154050  g_loss: 4.688451\n",
      "batch 20  d_loss: 0.249027  g_loss: 4.373156\n",
      "batch 21  d_loss: 0.227893  g_loss: 3.679323\n",
      "batch 22  d_loss: 0.121527  g_loss: 3.498886\n",
      "batch 23  d_loss: 0.175992  g_loss: 2.771318\n",
      "batch 24  d_loss: 0.178761  g_loss: 2.466534\n",
      "batch 25  d_loss: 0.184513  g_loss: 2.885136\n",
      "batch 26  d_loss: 0.216108  g_loss: 2.724221\n",
      "batch 27  d_loss: 0.125881  g_loss: 3.219531\n",
      "batch 28  d_loss: 0.188728  g_loss: 3.510920\n",
      "batch 29  d_loss: 0.314474  g_loss: 3.226732\n",
      "batch 30  d_loss: 0.323486  g_loss: 2.528183\n",
      "batch 31  d_loss: 0.268926  g_loss: 2.366979\n",
      "batch 32  d_loss: 0.166013  g_loss: 2.773175\n",
      "batch 33  d_loss: 0.153591  g_loss: 3.108123\n",
      "batch 34  d_loss: 0.198790  g_loss: 3.428967\n",
      "batch 35  d_loss: 0.190970  g_loss: 2.833934\n",
      "batch 36  d_loss: 0.301496  g_loss: 2.549140\n",
      "batch 37  d_loss: 0.259441  g_loss: 1.807484\n",
      "batch 38  d_loss: 0.276964  g_loss: 1.889986\n",
      "batch 39  d_loss: 0.282805  g_loss: 2.634741\n",
      "batch 40  d_loss: 0.208020  g_loss: 3.141505\n",
      "batch 41  d_loss: 0.291294  g_loss: 3.842348\n",
      "batch 42  d_loss: 0.486997  g_loss: 2.978707\n",
      "batch 43  d_loss: 0.332417  g_loss: 2.389763\n",
      "batch 44  d_loss: 0.303742  g_loss: 1.900475\n",
      "batch 45  d_loss: 0.363577  g_loss: 1.973793\n",
      "Epoch is 33\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.313705  g_loss: 2.782656\n",
      "batch 1  d_loss: 0.351347  g_loss: 3.372455\n",
      "batch 2  d_loss: 0.251333  g_loss: 3.615099\n",
      "batch 3  d_loss: 0.288276  g_loss: 3.823319\n",
      "batch 4  d_loss: 0.273642  g_loss: 2.410256\n",
      "batch 5  d_loss: 0.233971  g_loss: 2.130766\n",
      "batch 6  d_loss: 0.268887  g_loss: 1.465533\n",
      "batch 7  d_loss: 0.430628  g_loss: 1.023210\n",
      "batch 8  d_loss: 0.452427  g_loss: 1.675623\n",
      "batch 9  d_loss: 0.280972  g_loss: 2.724536\n",
      "batch 10  d_loss: 0.313448  g_loss: 3.396205\n",
      "batch 11  d_loss: 0.412738  g_loss: 3.538678\n",
      "batch 12  d_loss: 0.526683  g_loss: 2.311039\n",
      "batch 13  d_loss: 0.264263  g_loss: 1.488521\n",
      "batch 14  d_loss: 0.369707  g_loss: 1.229265\n",
      "batch 15  d_loss: 0.439661  g_loss: 2.214094\n",
      "batch 16  d_loss: 0.316308  g_loss: 3.464341\n",
      "batch 17  d_loss: 0.312169  g_loss: 3.713177\n",
      "batch 18  d_loss: 0.159546  g_loss: 3.996119\n",
      "batch 19  d_loss: 0.264281  g_loss: 3.046443\n",
      "batch 20  d_loss: 0.229575  g_loss: 2.224920\n",
      "batch 21  d_loss: 0.217487  g_loss: 1.783678\n",
      "batch 22  d_loss: 0.298181  g_loss: 1.977836\n",
      "batch 23  d_loss: 0.346689  g_loss: 1.998658\n",
      "batch 24  d_loss: 0.276453  g_loss: 2.596362\n",
      "batch 25  d_loss: 0.205158  g_loss: 3.115628\n",
      "batch 26  d_loss: 0.263135  g_loss: 3.026293\n",
      "batch 27  d_loss: 0.180264  g_loss: 2.295249\n",
      "batch 28  d_loss: 0.275992  g_loss: 2.249466\n",
      "batch 29  d_loss: 0.399325  g_loss: 1.590534\n",
      "batch 30  d_loss: 0.369075  g_loss: 1.516156\n",
      "batch 31  d_loss: 0.316067  g_loss: 1.297836\n",
      "batch 32  d_loss: 0.315605  g_loss: 2.162070\n",
      "batch 33  d_loss: 0.287840  g_loss: 2.936044\n",
      "batch 34  d_loss: 0.393360  g_loss: 2.812367\n",
      "batch 35  d_loss: 0.552192  g_loss: 2.048363\n",
      "batch 36  d_loss: 0.345815  g_loss: 1.512438\n",
      "batch 37  d_loss: 0.366940  g_loss: 1.562044\n",
      "batch 38  d_loss: 0.427871  g_loss: 1.751539\n",
      "batch 39  d_loss: 0.256540  g_loss: 2.650668\n",
      "batch 40  d_loss: 0.307882  g_loss: 3.502726\n",
      "batch 41  d_loss: 0.281338  g_loss: 3.292765\n",
      "batch 42  d_loss: 0.399531  g_loss: 3.807203\n",
      "batch 43  d_loss: 0.258723  g_loss: 2.803815\n",
      "batch 44  d_loss: 0.328095  g_loss: 2.011721\n",
      "batch 45  d_loss: 0.215424  g_loss: 2.365408\n",
      "Epoch is 34\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.385333  g_loss: 1.523002\n",
      "batch 1  d_loss: 0.411568  g_loss: 2.218400\n",
      "batch 2  d_loss: 0.278750  g_loss: 2.723730\n",
      "batch 3  d_loss: 0.272262  g_loss: 2.979240\n",
      "batch 4  d_loss: 0.287768  g_loss: 2.647278\n",
      "batch 5  d_loss: 0.290255  g_loss: 2.356143\n",
      "batch 6  d_loss: 0.289902  g_loss: 2.153207\n",
      "batch 7  d_loss: 0.568729  g_loss: 1.593619\n",
      "batch 8  d_loss: 0.384756  g_loss: 1.336734\n",
      "batch 9  d_loss: 0.414484  g_loss: 1.362714\n",
      "batch 10  d_loss: 0.272493  g_loss: 2.309071\n",
      "batch 11  d_loss: 0.435853  g_loss: 2.657113\n",
      "batch 12  d_loss: 0.474154  g_loss: 2.685339\n",
      "batch 13  d_loss: 0.504426  g_loss: 2.022344\n",
      "batch 14  d_loss: 0.252139  g_loss: 1.455579\n",
      "batch 15  d_loss: 0.305778  g_loss: 1.494367\n",
      "batch 16  d_loss: 0.410753  g_loss: 1.772093\n",
      "batch 17  d_loss: 0.364573  g_loss: 1.866188\n",
      "batch 18  d_loss: 0.178517  g_loss: 2.692372\n",
      "batch 19  d_loss: 0.182084  g_loss: 2.935005\n",
      "batch 20  d_loss: 0.242557  g_loss: 3.352165\n",
      "batch 21  d_loss: 0.210612  g_loss: 2.755157\n",
      "batch 22  d_loss: 0.269702  g_loss: 2.888294\n",
      "batch 23  d_loss: 0.267733  g_loss: 2.164431\n",
      "batch 24  d_loss: 0.247632  g_loss: 1.683059\n",
      "batch 25  d_loss: 0.324841  g_loss: 1.801200\n",
      "batch 26  d_loss: 0.230187  g_loss: 1.948090\n",
      "batch 27  d_loss: 0.224985  g_loss: 2.502166\n",
      "batch 28  d_loss: 0.399258  g_loss: 3.045630\n",
      "batch 29  d_loss: 0.478924  g_loss: 2.406203\n",
      "batch 30  d_loss: 0.277518  g_loss: 1.891230\n",
      "batch 31  d_loss: 0.392774  g_loss: 1.964024\n",
      "batch 32  d_loss: 0.347466  g_loss: 2.227130\n",
      "batch 33  d_loss: 0.317574  g_loss: 3.140063\n",
      "batch 34  d_loss: 0.234483  g_loss: 2.970475\n",
      "batch 35  d_loss: 0.383956  g_loss: 2.420403\n",
      "batch 36  d_loss: 0.431318  g_loss: 1.443704\n",
      "batch 37  d_loss: 0.376638  g_loss: 1.466456\n",
      "batch 38  d_loss: 0.338351  g_loss: 1.565758\n",
      "batch 39  d_loss: 0.317186  g_loss: 2.009719\n",
      "batch 40  d_loss: 0.274642  g_loss: 3.001995\n",
      "batch 41  d_loss: 0.258072  g_loss: 3.183658\n",
      "batch 42  d_loss: 0.284083  g_loss: 3.438149\n",
      "batch 43  d_loss: 0.294129  g_loss: 3.243990\n",
      "batch 44  d_loss: 0.286846  g_loss: 1.962187\n",
      "batch 45  d_loss: 0.176934  g_loss: 2.119230\n",
      "Epoch is 35\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.253982  g_loss: 1.593453\n",
      "batch 1  d_loss: 0.276237  g_loss: 1.928424\n",
      "batch 2  d_loss: 0.190581  g_loss: 2.815569\n",
      "batch 3  d_loss: 0.188088  g_loss: 3.166827\n",
      "batch 4  d_loss: 0.282191  g_loss: 3.373639\n",
      "batch 5  d_loss: 0.205830  g_loss: 2.690189\n",
      "batch 6  d_loss: 0.179448  g_loss: 2.892800\n",
      "batch 7  d_loss: 0.420276  g_loss: 2.077244\n",
      "batch 8  d_loss: 0.351911  g_loss: 2.183603\n",
      "batch 9  d_loss: 0.279256  g_loss: 1.665589\n",
      "batch 10  d_loss: 0.355575  g_loss: 2.137084\n",
      "batch 11  d_loss: 0.365623  g_loss: 2.372720\n",
      "batch 12  d_loss: 0.407338  g_loss: 2.342691\n",
      "batch 13  d_loss: 0.234377  g_loss: 2.069719\n",
      "batch 14  d_loss: 0.341709  g_loss: 2.342202\n",
      "batch 15  d_loss: 0.346038  g_loss: 2.071346\n",
      "batch 16  d_loss: 0.287849  g_loss: 1.778490\n",
      "batch 17  d_loss: 0.429460  g_loss: 1.884465\n",
      "batch 18  d_loss: 0.285056  g_loss: 2.006611\n",
      "batch 19  d_loss: 0.374701  g_loss: 2.204639\n",
      "batch 20  d_loss: 0.343584  g_loss: 2.358660\n",
      "batch 21  d_loss: 0.326215  g_loss: 2.798264\n",
      "batch 22  d_loss: 0.271586  g_loss: 2.771407\n",
      "batch 23  d_loss: 0.297205  g_loss: 2.591298\n",
      "batch 24  d_loss: 0.409403  g_loss: 2.352448\n",
      "batch 25  d_loss: 0.263506  g_loss: 2.291598\n",
      "batch 26  d_loss: 0.279775  g_loss: 2.285893\n",
      "batch 27  d_loss: 0.269449  g_loss: 2.652160\n",
      "batch 28  d_loss: 0.293369  g_loss: 2.639158\n",
      "batch 29  d_loss: 0.473299  g_loss: 2.303908\n",
      "batch 30  d_loss: 0.231208  g_loss: 2.241371\n",
      "batch 31  d_loss: 0.220918  g_loss: 1.791141\n",
      "batch 32  d_loss: 0.218216  g_loss: 2.041514\n",
      "batch 33  d_loss: 0.281884  g_loss: 1.958043\n",
      "batch 34  d_loss: 0.338995  g_loss: 2.229840\n",
      "batch 35  d_loss: 0.225411  g_loss: 2.539353\n",
      "batch 36  d_loss: 0.297259  g_loss: 2.822963\n",
      "batch 37  d_loss: 0.218552  g_loss: 2.704184\n",
      "batch 38  d_loss: 0.252781  g_loss: 2.523230\n",
      "batch 39  d_loss: 0.237884  g_loss: 2.355055\n",
      "batch 40  d_loss: 0.286044  g_loss: 2.326056\n",
      "batch 41  d_loss: 0.268029  g_loss: 2.393670\n",
      "batch 42  d_loss: 0.205628  g_loss: 3.077278\n",
      "batch 43  d_loss: 0.272873  g_loss: 3.221767\n",
      "batch 44  d_loss: 0.329554  g_loss: 3.248770\n",
      "batch 45  d_loss: 0.176704  g_loss: 3.158962\n",
      "Epoch is 36\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.328234  g_loss: 2.974522\n",
      "batch 1  d_loss: 0.303083  g_loss: 2.437067\n",
      "batch 2  d_loss: 0.275056  g_loss: 2.553454\n",
      "batch 3  d_loss: 0.247271  g_loss: 2.904869\n",
      "batch 4  d_loss: 0.254682  g_loss: 2.955624\n",
      "batch 5  d_loss: 0.338841  g_loss: 2.838991\n",
      "batch 6  d_loss: 0.160666  g_loss: 2.648630\n",
      "batch 7  d_loss: 0.795963  g_loss: 1.818842\n",
      "batch 8  d_loss: 0.485534  g_loss: 1.286531\n",
      "batch 9  d_loss: 0.361846  g_loss: 1.561500\n",
      "batch 10  d_loss: 0.282283  g_loss: 2.672922\n",
      "batch 11  d_loss: 0.410496  g_loss: 3.317640\n",
      "batch 12  d_loss: 0.556745  g_loss: 2.399066\n",
      "batch 13  d_loss: 0.333157  g_loss: 1.965199\n",
      "batch 14  d_loss: 0.308694  g_loss: 1.799075\n",
      "batch 15  d_loss: 0.339641  g_loss: 1.636683\n",
      "batch 16  d_loss: 0.227282  g_loss: 2.398287\n",
      "batch 17  d_loss: 0.343757  g_loss: 3.196684\n",
      "batch 18  d_loss: 0.206251  g_loss: 3.218991\n",
      "batch 19  d_loss: 0.354308  g_loss: 2.508737\n",
      "batch 20  d_loss: 0.362564  g_loss: 1.906192\n",
      "batch 21  d_loss: 0.270349  g_loss: 1.174323\n",
      "batch 22  d_loss: 0.373026  g_loss: 1.488487\n",
      "batch 23  d_loss: 0.274065  g_loss: 2.345314\n",
      "batch 24  d_loss: 0.387534  g_loss: 3.118194\n",
      "batch 25  d_loss: 0.254734  g_loss: 2.693751\n",
      "batch 26  d_loss: 0.355949  g_loss: 2.357874\n",
      "batch 27  d_loss: 0.258297  g_loss: 2.280617\n",
      "batch 28  d_loss: 0.484730  g_loss: 1.950258\n",
      "batch 29  d_loss: 0.582936  g_loss: 1.144452\n",
      "batch 30  d_loss: 0.496166  g_loss: 1.283064\n",
      "batch 31  d_loss: 0.388149  g_loss: 2.396701\n",
      "batch 32  d_loss: 0.278281  g_loss: 3.451218\n",
      "batch 33  d_loss: 0.375463  g_loss: 3.114837\n",
      "batch 34  d_loss: 0.339077  g_loss: 2.709411\n",
      "batch 35  d_loss: 0.165174  g_loss: 2.075973\n",
      "batch 36  d_loss: 0.320582  g_loss: 2.080790\n",
      "batch 37  d_loss: 0.227272  g_loss: 2.129385\n",
      "batch 38  d_loss: 0.272645  g_loss: 2.580215\n",
      "batch 39  d_loss: 0.167562  g_loss: 3.612963\n",
      "batch 40  d_loss: 0.250590  g_loss: 4.006227\n",
      "batch 41  d_loss: 0.294935  g_loss: 3.613485\n",
      "batch 42  d_loss: 0.238799  g_loss: 3.436875\n",
      "batch 43  d_loss: 0.203593  g_loss: 2.928169\n",
      "batch 44  d_loss: 0.380271  g_loss: 2.053510\n",
      "batch 45  d_loss: 0.162006  g_loss: 3.016876\n",
      "Epoch is 37\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.272736  g_loss: 3.774501\n",
      "batch 1  d_loss: 0.261523  g_loss: 3.504742\n",
      "batch 2  d_loss: 0.488045  g_loss: 3.161152\n",
      "batch 3  d_loss: 0.347077  g_loss: 2.740538\n",
      "batch 4  d_loss: 0.397865  g_loss: 2.390844\n",
      "batch 5  d_loss: 0.316716  g_loss: 1.880516\n",
      "batch 6  d_loss: 0.285317  g_loss: 1.848063\n",
      "batch 7  d_loss: 0.344679  g_loss: 2.152304\n",
      "batch 8  d_loss: 0.368067  g_loss: 2.708631\n",
      "batch 9  d_loss: 0.244730  g_loss: 2.518355\n",
      "batch 10  d_loss: 0.270454  g_loss: 2.769291\n",
      "batch 11  d_loss: 0.299555  g_loss: 2.200887\n",
      "batch 12  d_loss: 0.380332  g_loss: 1.723722\n",
      "batch 13  d_loss: 0.347838  g_loss: 2.015864\n",
      "batch 14  d_loss: 0.269862  g_loss: 2.354491\n",
      "batch 15  d_loss: 0.289928  g_loss: 2.620919\n",
      "batch 16  d_loss: 0.250581  g_loss: 2.351549\n",
      "batch 17  d_loss: 0.246756  g_loss: 2.131828\n",
      "batch 18  d_loss: 0.170827  g_loss: 2.259296\n",
      "batch 19  d_loss: 0.216638  g_loss: 2.840003\n",
      "batch 20  d_loss: 0.222969  g_loss: 2.335672\n",
      "batch 21  d_loss: 0.175986  g_loss: 2.804052\n",
      "batch 22  d_loss: 0.220591  g_loss: 3.343089\n",
      "batch 23  d_loss: 0.252257  g_loss: 2.498478\n",
      "batch 24  d_loss: 0.288110  g_loss: 2.487846\n",
      "batch 25  d_loss: 0.222802  g_loss: 2.228206\n",
      "batch 26  d_loss: 0.267409  g_loss: 1.939285\n",
      "batch 27  d_loss: 0.169167  g_loss: 2.941008\n",
      "batch 28  d_loss: 0.239328  g_loss: 3.085394\n",
      "batch 29  d_loss: 0.366418  g_loss: 2.634575\n",
      "batch 30  d_loss: 0.257352  g_loss: 2.342780\n",
      "batch 31  d_loss: 0.228934  g_loss: 2.260329\n",
      "batch 32  d_loss: 0.279744  g_loss: 2.285313\n",
      "batch 33  d_loss: 0.245523  g_loss: 2.035050\n",
      "batch 34  d_loss: 0.207978  g_loss: 2.083234\n",
      "batch 35  d_loss: 0.279941  g_loss: 2.452195\n",
      "batch 36  d_loss: 0.300213  g_loss: 2.977922\n",
      "batch 37  d_loss: 0.350217  g_loss: 2.689184\n",
      "batch 38  d_loss: 0.313814  g_loss: 2.350446\n",
      "batch 39  d_loss: 0.372435  g_loss: 1.918638\n",
      "batch 40  d_loss: 0.219210  g_loss: 2.420673\n",
      "batch 41  d_loss: 0.290917  g_loss: 2.592798\n",
      "batch 42  d_loss: 0.302378  g_loss: 2.988570\n",
      "batch 43  d_loss: 0.243911  g_loss: 2.825888\n",
      "batch 44  d_loss: 0.251662  g_loss: 2.189474\n",
      "batch 45  d_loss: 0.155890  g_loss: 2.317553\n",
      "Epoch is 38\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.247835  g_loss: 1.692150\n",
      "batch 1  d_loss: 0.285907  g_loss: 2.034880\n",
      "batch 2  d_loss: 0.182222  g_loss: 2.580028\n",
      "batch 3  d_loss: 0.190414  g_loss: 2.949758\n",
      "batch 4  d_loss: 0.206913  g_loss: 3.576846\n",
      "batch 5  d_loss: 0.222171  g_loss: 3.315145\n",
      "batch 6  d_loss: 0.106282  g_loss: 2.917993\n",
      "batch 7  d_loss: 0.366933  g_loss: 2.432600\n",
      "batch 8  d_loss: 0.208545  g_loss: 2.182723\n",
      "batch 9  d_loss: 0.178750  g_loss: 2.244601\n",
      "batch 10  d_loss: 0.234962  g_loss: 2.465881\n",
      "batch 11  d_loss: 0.241030  g_loss: 2.623961\n",
      "batch 12  d_loss: 0.335288  g_loss: 2.945318\n",
      "batch 13  d_loss: 0.334938  g_loss: 2.556529\n",
      "batch 14  d_loss: 0.249689  g_loss: 1.725973\n",
      "batch 15  d_loss: 0.246527  g_loss: 2.147800\n",
      "batch 16  d_loss: 0.305040  g_loss: 2.716196\n",
      "batch 17  d_loss: 0.248201  g_loss: 2.884270\n",
      "batch 18  d_loss: 0.187514  g_loss: 3.189780\n",
      "batch 19  d_loss: 0.307971  g_loss: 3.082955\n",
      "batch 20  d_loss: 0.453816  g_loss: 2.589380\n",
      "batch 21  d_loss: 0.223159  g_loss: 1.986738\n",
      "batch 22  d_loss: 0.173334  g_loss: 1.845542\n",
      "batch 23  d_loss: 0.218199  g_loss: 1.951062\n",
      "batch 24  d_loss: 0.235436  g_loss: 2.022660\n",
      "batch 25  d_loss: 0.224227  g_loss: 2.661858\n",
      "batch 26  d_loss: 0.312928  g_loss: 2.348258\n",
      "batch 27  d_loss: 0.191895  g_loss: 2.443703\n",
      "batch 28  d_loss: 0.250202  g_loss: 2.298257\n",
      "batch 29  d_loss: 0.466062  g_loss: 1.708381\n",
      "batch 30  d_loss: 0.204399  g_loss: 1.637647\n",
      "batch 31  d_loss: 0.377785  g_loss: 1.851276\n",
      "batch 32  d_loss: 0.215879  g_loss: 2.886352\n",
      "batch 33  d_loss: 0.364436  g_loss: 3.181500\n",
      "batch 34  d_loss: 0.423243  g_loss: 3.083519\n",
      "batch 35  d_loss: 0.283054  g_loss: 2.419335\n",
      "batch 36  d_loss: 0.418202  g_loss: 1.448831\n",
      "batch 37  d_loss: 0.483244  g_loss: 1.569524\n",
      "batch 38  d_loss: 0.582455  g_loss: 2.538649\n",
      "batch 39  d_loss: 0.232045  g_loss: 3.533331\n",
      "batch 40  d_loss: 0.224247  g_loss: 4.152055\n",
      "batch 41  d_loss: 0.304246  g_loss: 4.078346\n",
      "batch 42  d_loss: 0.395842  g_loss: 3.551362\n",
      "batch 43  d_loss: 0.162437  g_loss: 1.980318\n",
      "batch 44  d_loss: 0.284723  g_loss: 1.534709\n",
      "batch 45  d_loss: 0.316182  g_loss: 1.876544\n",
      "Epoch is 39\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.238329  g_loss: 2.374055\n",
      "batch 1  d_loss: 0.227272  g_loss: 2.936970\n",
      "batch 2  d_loss: 0.268770  g_loss: 3.118159\n",
      "batch 3  d_loss: 0.262013  g_loss: 3.038052\n",
      "batch 4  d_loss: 0.374534  g_loss: 2.467415\n",
      "batch 5  d_loss: 0.312302  g_loss: 2.404644\n",
      "batch 6  d_loss: 0.256232  g_loss: 2.177470\n",
      "batch 7  d_loss: 0.724426  g_loss: 1.865865\n",
      "batch 8  d_loss: 0.452682  g_loss: 1.656183\n",
      "batch 9  d_loss: 0.404183  g_loss: 2.734496\n",
      "batch 10  d_loss: 0.200185  g_loss: 2.663701\n",
      "batch 11  d_loss: 0.443627  g_loss: 2.907641\n",
      "batch 12  d_loss: 0.459143  g_loss: 2.597807\n",
      "batch 13  d_loss: 0.293428  g_loss: 2.349435\n",
      "batch 14  d_loss: 0.289622  g_loss: 2.190750\n",
      "batch 15  d_loss: 0.240786  g_loss: 2.189533\n",
      "batch 16  d_loss: 0.179887  g_loss: 2.260562\n",
      "batch 17  d_loss: 0.445430  g_loss: 2.578803\n",
      "batch 18  d_loss: 0.198624  g_loss: 2.858733\n",
      "batch 19  d_loss: 0.241387  g_loss: 2.539072\n",
      "batch 20  d_loss: 0.337224  g_loss: 2.506478\n",
      "batch 21  d_loss: 0.282717  g_loss: 2.050019\n",
      "batch 22  d_loss: 0.188015  g_loss: 2.345357\n",
      "batch 23  d_loss: 0.210763  g_loss: 2.558964\n",
      "batch 24  d_loss: 0.210678  g_loss: 3.205473\n",
      "batch 25  d_loss: 0.236743  g_loss: 3.038542\n",
      "batch 26  d_loss: 0.327121  g_loss: 2.888729\n",
      "batch 27  d_loss: 0.222900  g_loss: 1.960317\n",
      "batch 28  d_loss: 0.377408  g_loss: 2.133057\n",
      "batch 29  d_loss: 0.350432  g_loss: 1.835240\n",
      "batch 30  d_loss: 0.337685  g_loss: 1.978608\n",
      "batch 31  d_loss: 0.311199  g_loss: 2.135088\n",
      "batch 32  d_loss: 0.226278  g_loss: 2.747694\n",
      "batch 33  d_loss: 0.323439  g_loss: 2.022352\n",
      "batch 34  d_loss: 0.462463  g_loss: 1.957708\n",
      "batch 35  d_loss: 0.404806  g_loss: 1.731184\n",
      "batch 36  d_loss: 0.347195  g_loss: 1.672414\n",
      "batch 37  d_loss: 0.372758  g_loss: 1.665653\n",
      "batch 38  d_loss: 0.325451  g_loss: 1.688675\n",
      "batch 39  d_loss: 0.286420  g_loss: 2.608162\n",
      "batch 40  d_loss: 0.258900  g_loss: 2.586421\n",
      "batch 41  d_loss: 0.259008  g_loss: 2.803707\n",
      "batch 42  d_loss: 0.310644  g_loss: 2.794864\n",
      "batch 43  d_loss: 0.275037  g_loss: 2.669299\n",
      "batch 44  d_loss: 0.347292  g_loss: 2.268237\n",
      "batch 45  d_loss: 0.264374  g_loss: 2.636418\n",
      "Epoch is 40\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.271801  g_loss: 2.574147\n",
      "batch 1  d_loss: 0.363071  g_loss: 2.609151\n",
      "batch 2  d_loss: 0.296471  g_loss: 2.511064\n",
      "batch 3  d_loss: 0.211638  g_loss: 2.949800\n",
      "batch 4  d_loss: 0.190182  g_loss: 3.130198\n",
      "batch 5  d_loss: 0.144929  g_loss: 3.804657\n",
      "batch 6  d_loss: 0.107705  g_loss: 3.301850\n",
      "batch 7  d_loss: 0.681913  g_loss: 2.652474\n",
      "batch 8  d_loss: 0.392499  g_loss: 2.095488\n",
      "batch 9  d_loss: 0.142280  g_loss: 1.980474\n",
      "batch 10  d_loss: 0.226016  g_loss: 2.419884\n",
      "batch 11  d_loss: 0.273114  g_loss: 2.840948\n",
      "batch 12  d_loss: 0.392192  g_loss: 3.154061\n",
      "batch 13  d_loss: 0.252915  g_loss: 3.270006\n",
      "batch 14  d_loss: 0.197766  g_loss: 2.982715\n",
      "batch 15  d_loss: 0.274129  g_loss: 3.587289\n",
      "batch 16  d_loss: 0.299063  g_loss: 2.800005\n",
      "batch 17  d_loss: 0.507190  g_loss: 2.732929\n",
      "batch 18  d_loss: 0.326190  g_loss: 2.809725\n",
      "batch 19  d_loss: 0.383001  g_loss: 2.801081\n",
      "batch 20  d_loss: 0.384971  g_loss: 3.428285\n",
      "batch 21  d_loss: 0.296242  g_loss: 3.214151\n",
      "batch 22  d_loss: 0.298522  g_loss: 3.413906\n",
      "batch 23  d_loss: 0.208440  g_loss: 2.452663\n",
      "batch 24  d_loss: 0.269687  g_loss: 2.146401\n",
      "batch 25  d_loss: 0.220732  g_loss: 1.954018\n",
      "batch 26  d_loss: 0.269886  g_loss: 2.083246\n",
      "batch 27  d_loss: 0.222032  g_loss: 2.208427\n",
      "batch 28  d_loss: 0.295982  g_loss: 2.560569\n",
      "batch 29  d_loss: 0.299459  g_loss: 2.713733\n",
      "batch 30  d_loss: 0.239099  g_loss: 2.802316\n",
      "batch 31  d_loss: 0.291641  g_loss: 2.553376\n",
      "batch 32  d_loss: 0.266233  g_loss: 2.266872\n",
      "batch 33  d_loss: 0.219051  g_loss: 2.365004\n",
      "batch 34  d_loss: 0.373806  g_loss: 1.907159\n",
      "batch 35  d_loss: 0.279709  g_loss: 1.716151\n",
      "batch 36  d_loss: 0.347351  g_loss: 1.559353\n",
      "batch 37  d_loss: 0.374422  g_loss: 1.815568\n",
      "batch 38  d_loss: 0.325586  g_loss: 2.411079\n",
      "batch 39  d_loss: 0.342128  g_loss: 2.677503\n",
      "batch 40  d_loss: 0.481794  g_loss: 2.462645\n",
      "batch 41  d_loss: 0.295460  g_loss: 1.895743\n",
      "batch 42  d_loss: 0.307292  g_loss: 1.770511\n",
      "batch 43  d_loss: 0.325101  g_loss: 1.691774\n",
      "batch 44  d_loss: 0.315205  g_loss: 2.024853\n",
      "batch 45  d_loss: 0.203482  g_loss: 2.386395\n",
      "Epoch is 41\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.199386  g_loss: 2.988704\n",
      "batch 1  d_loss: 0.293366  g_loss: 2.741239\n",
      "batch 2  d_loss: 0.214408  g_loss: 2.499935\n",
      "batch 3  d_loss: 0.173694  g_loss: 2.464446\n",
      "batch 4  d_loss: 0.329928  g_loss: 2.134389\n",
      "batch 5  d_loss: 0.311338  g_loss: 1.798329\n",
      "batch 6  d_loss: 0.273631  g_loss: 1.675200\n",
      "batch 7  d_loss: 0.549462  g_loss: 2.095111\n",
      "batch 8  d_loss: 0.478009  g_loss: 2.237978\n",
      "batch 9  d_loss: 0.320788  g_loss: 2.187892\n",
      "batch 10  d_loss: 0.248579  g_loss: 2.000022\n",
      "batch 11  d_loss: 0.417384  g_loss: 1.896776\n",
      "batch 12  d_loss: 0.431293  g_loss: 1.896167\n",
      "batch 13  d_loss: 0.376917  g_loss: 1.805601\n",
      "batch 14  d_loss: 0.277706  g_loss: 2.458181\n",
      "batch 15  d_loss: 0.224483  g_loss: 2.667990\n",
      "batch 16  d_loss: 0.274967  g_loss: 2.763189\n",
      "batch 17  d_loss: 0.298339  g_loss: 2.389095\n",
      "batch 18  d_loss: 0.154484  g_loss: 2.506392\n",
      "batch 19  d_loss: 0.276651  g_loss: 2.330002\n",
      "batch 20  d_loss: 0.330047  g_loss: 2.087989\n",
      "batch 21  d_loss: 0.191931  g_loss: 1.946808\n",
      "batch 22  d_loss: 0.346373  g_loss: 2.746260\n",
      "batch 23  d_loss: 0.359510  g_loss: 2.677092\n",
      "batch 24  d_loss: 0.398113  g_loss: 2.499541\n",
      "batch 25  d_loss: 0.308270  g_loss: 1.909053\n",
      "batch 26  d_loss: 0.366393  g_loss: 2.384532\n",
      "batch 27  d_loss: 0.324198  g_loss: 2.576581\n",
      "batch 28  d_loss: 0.270745  g_loss: 2.551646\n",
      "batch 29  d_loss: 0.266038  g_loss: 2.373707\n",
      "batch 30  d_loss: 0.211056  g_loss: 2.469251\n",
      "batch 31  d_loss: 0.219079  g_loss: 2.000078\n",
      "batch 32  d_loss: 0.137208  g_loss: 2.390898\n",
      "batch 33  d_loss: 0.322987  g_loss: 2.467227\n",
      "batch 34  d_loss: 0.260743  g_loss: 3.012282\n",
      "batch 35  d_loss: 0.196591  g_loss: 2.962129\n",
      "batch 36  d_loss: 0.438477  g_loss: 2.514055\n",
      "batch 37  d_loss: 0.411936  g_loss: 1.941380\n",
      "batch 38  d_loss: 0.215275  g_loss: 2.060041\n",
      "batch 39  d_loss: 0.202784  g_loss: 2.305059\n",
      "batch 40  d_loss: 0.304228  g_loss: 3.296492\n",
      "batch 41  d_loss: 0.224782  g_loss: 3.664562\n",
      "batch 42  d_loss: 0.303375  g_loss: 3.672200\n",
      "batch 43  d_loss: 0.246238  g_loss: 3.675114\n",
      "batch 44  d_loss: 0.270718  g_loss: 2.959389\n",
      "batch 45  d_loss: 0.232349  g_loss: 2.984692\n",
      "Epoch is 42\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.256320  g_loss: 2.858024\n",
      "batch 1  d_loss: 0.237522  g_loss: 2.699443\n",
      "batch 2  d_loss: 0.277934  g_loss: 2.576132\n",
      "batch 3  d_loss: 0.229507  g_loss: 3.417579\n",
      "batch 4  d_loss: 0.238850  g_loss: 2.157946\n",
      "batch 5  d_loss: 0.331652  g_loss: 2.292102\n",
      "batch 6  d_loss: 0.403399  g_loss: 1.840317\n",
      "batch 7  d_loss: 0.547719  g_loss: 1.575649\n",
      "batch 8  d_loss: 0.527905  g_loss: 1.922797\n",
      "batch 9  d_loss: 0.290633  g_loss: 2.239936\n",
      "batch 10  d_loss: 0.284419  g_loss: 2.799141\n",
      "batch 11  d_loss: 0.547124  g_loss: 2.326723\n",
      "batch 12  d_loss: 0.380140  g_loss: 1.776628\n",
      "batch 13  d_loss: 0.298354  g_loss: 1.544644\n",
      "batch 14  d_loss: 0.276429  g_loss: 1.560012\n",
      "batch 15  d_loss: 0.284439  g_loss: 1.583561\n",
      "batch 16  d_loss: 0.267559  g_loss: 2.032570\n",
      "batch 17  d_loss: 0.341967  g_loss: 2.397457\n",
      "batch 18  d_loss: 0.184206  g_loss: 2.779945\n",
      "batch 19  d_loss: 0.201914  g_loss: 3.394711\n",
      "batch 20  d_loss: 0.318222  g_loss: 3.414304\n",
      "batch 21  d_loss: 0.177894  g_loss: 3.022261\n",
      "batch 22  d_loss: 0.141704  g_loss: 2.176712\n",
      "batch 23  d_loss: 0.270021  g_loss: 2.244107\n",
      "batch 24  d_loss: 0.331408  g_loss: 2.400075\n",
      "batch 25  d_loss: 0.259490  g_loss: 3.158303\n",
      "batch 26  d_loss: 0.201336  g_loss: 3.040547\n",
      "batch 27  d_loss: 0.140918  g_loss: 2.705585\n",
      "batch 28  d_loss: 0.311448  g_loss: 2.240502\n",
      "batch 29  d_loss: 0.677478  g_loss: 1.573025\n",
      "batch 30  d_loss: 0.466906  g_loss: 1.407658\n",
      "batch 31  d_loss: 0.356683  g_loss: 1.847875\n",
      "batch 32  d_loss: 0.266491  g_loss: 2.302405\n",
      "batch 33  d_loss: 0.302079  g_loss: 3.182630\n",
      "batch 34  d_loss: 0.433097  g_loss: 3.084915\n",
      "batch 35  d_loss: 0.367835  g_loss: 2.438162\n",
      "batch 36  d_loss: 0.491342  g_loss: 1.441008\n",
      "batch 37  d_loss: 0.661800  g_loss: 1.396953\n",
      "batch 38  d_loss: 0.315338  g_loss: 1.971128\n",
      "batch 39  d_loss: 0.304232  g_loss: 2.791242\n",
      "batch 40  d_loss: 0.318484  g_loss: 3.020088\n",
      "batch 41  d_loss: 0.486651  g_loss: 3.001533\n",
      "batch 42  d_loss: 0.548149  g_loss: 2.222491\n",
      "batch 43  d_loss: 0.356728  g_loss: 1.512502\n",
      "batch 44  d_loss: 0.402720  g_loss: 1.508518\n",
      "batch 45  d_loss: 0.468517  g_loss: 1.845394\n",
      "Epoch is 43\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.363528  g_loss: 2.049048\n",
      "batch 1  d_loss: 0.271346  g_loss: 3.037189\n",
      "batch 2  d_loss: 0.333281  g_loss: 3.226187\n",
      "batch 3  d_loss: 0.296132  g_loss: 2.160272\n",
      "batch 4  d_loss: 0.192737  g_loss: 2.677656\n",
      "batch 5  d_loss: 0.215235  g_loss: 1.966642\n",
      "batch 6  d_loss: 0.201291  g_loss: 2.301831\n",
      "batch 7  d_loss: 0.505802  g_loss: 2.565611\n",
      "batch 8  d_loss: 0.297696  g_loss: 2.255430\n",
      "batch 9  d_loss: 0.277324  g_loss: 2.712715\n",
      "batch 10  d_loss: 0.290261  g_loss: 2.289836\n",
      "batch 11  d_loss: 0.431597  g_loss: 2.076303\n",
      "batch 12  d_loss: 0.293292  g_loss: 1.807356\n",
      "batch 13  d_loss: 0.414721  g_loss: 2.205972\n",
      "batch 14  d_loss: 0.388227  g_loss: 2.027755\n",
      "batch 15  d_loss: 0.367187  g_loss: 2.306940\n",
      "batch 16  d_loss: 0.356033  g_loss: 2.044127\n",
      "batch 17  d_loss: 0.329014  g_loss: 1.953835\n",
      "batch 18  d_loss: 0.222855  g_loss: 1.932239\n",
      "batch 19  d_loss: 0.311828  g_loss: 2.163719\n",
      "batch 20  d_loss: 0.409483  g_loss: 2.404764\n",
      "batch 21  d_loss: 0.424065  g_loss: 2.199448\n",
      "batch 22  d_loss: 0.294156  g_loss: 2.194897\n",
      "batch 23  d_loss: 0.369071  g_loss: 2.252642\n",
      "batch 24  d_loss: 0.341979  g_loss: 2.745695\n",
      "batch 25  d_loss: 0.455103  g_loss: 2.002079\n",
      "batch 26  d_loss: 0.444922  g_loss: 2.382169\n",
      "batch 27  d_loss: 0.232939  g_loss: 2.411371\n",
      "batch 28  d_loss: 0.336418  g_loss: 2.532301\n",
      "batch 29  d_loss: 0.530500  g_loss: 1.446929\n",
      "batch 30  d_loss: 0.370735  g_loss: 1.364839\n",
      "batch 31  d_loss: 0.416775  g_loss: 2.320954\n",
      "batch 32  d_loss: 0.317916  g_loss: 3.766129\n",
      "batch 33  d_loss: 0.363130  g_loss: 3.925145\n",
      "batch 34  d_loss: 0.338518  g_loss: 3.614441\n",
      "batch 35  d_loss: 0.240413  g_loss: 2.248656\n",
      "batch 36  d_loss: 0.377069  g_loss: 1.945374\n",
      "batch 37  d_loss: 0.592607  g_loss: 1.382803\n",
      "batch 38  d_loss: 0.382456  g_loss: 1.928159\n",
      "batch 39  d_loss: 0.432354  g_loss: 3.224470\n",
      "batch 40  d_loss: 0.474963  g_loss: 2.980633\n",
      "batch 41  d_loss: 0.316383  g_loss: 2.657496\n",
      "batch 42  d_loss: 0.414879  g_loss: 2.503841\n",
      "batch 43  d_loss: 0.352731  g_loss: 2.219964\n",
      "batch 44  d_loss: 0.524311  g_loss: 2.347130\n",
      "batch 45  d_loss: 0.168136  g_loss: 3.153796\n",
      "Epoch is 44\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.466289  g_loss: 2.311976\n",
      "batch 1  d_loss: 0.275965  g_loss: 2.081386\n",
      "batch 2  d_loss: 0.300095  g_loss: 1.850660\n",
      "batch 3  d_loss: 0.310292  g_loss: 1.490243\n",
      "batch 4  d_loss: 0.299171  g_loss: 1.864579\n",
      "batch 5  d_loss: 0.374167  g_loss: 1.747393\n",
      "batch 6  d_loss: 0.210227  g_loss: 2.181856\n",
      "batch 7  d_loss: 0.566992  g_loss: 2.412925\n",
      "batch 8  d_loss: 0.378161  g_loss: 2.010785\n",
      "batch 9  d_loss: 0.294505  g_loss: 1.719689\n",
      "batch 10  d_loss: 0.273237  g_loss: 1.743304\n",
      "batch 11  d_loss: 0.356388  g_loss: 1.814806\n",
      "batch 12  d_loss: 0.412193  g_loss: 1.995394\n",
      "batch 13  d_loss: 0.459838  g_loss: 2.369104\n",
      "batch 14  d_loss: 0.328103  g_loss: 2.123435\n",
      "batch 15  d_loss: 0.404664  g_loss: 2.134315\n",
      "batch 16  d_loss: 0.251573  g_loss: 2.123732\n",
      "batch 17  d_loss: 0.405355  g_loss: 2.315419\n",
      "batch 18  d_loss: 0.161455  g_loss: 2.522959\n",
      "batch 19  d_loss: 0.176096  g_loss: 2.672138\n",
      "batch 20  d_loss: 0.329226  g_loss: 2.323469\n",
      "batch 21  d_loss: 0.217859  g_loss: 1.708482\n",
      "batch 22  d_loss: 0.274962  g_loss: 2.161875\n",
      "batch 23  d_loss: 0.202336  g_loss: 2.401007\n",
      "batch 24  d_loss: 0.243222  g_loss: 2.994671\n",
      "batch 25  d_loss: 0.259341  g_loss: 3.162504\n",
      "batch 26  d_loss: 0.390768  g_loss: 2.951394\n",
      "batch 27  d_loss: 0.156253  g_loss: 2.755627\n",
      "batch 28  d_loss: 0.395392  g_loss: 1.885939\n",
      "batch 29  d_loss: 0.440694  g_loss: 1.449850\n",
      "batch 30  d_loss: 0.450986  g_loss: 1.786100\n",
      "batch 31  d_loss: 0.544376  g_loss: 2.468592\n",
      "batch 32  d_loss: 0.359037  g_loss: 2.644163\n",
      "batch 33  d_loss: 0.545882  g_loss: 3.098368\n",
      "batch 34  d_loss: 0.405106  g_loss: 2.464593\n",
      "batch 35  d_loss: 0.341108  g_loss: 1.594423\n",
      "batch 36  d_loss: 0.395083  g_loss: 1.392530\n",
      "batch 37  d_loss: 0.414141  g_loss: 1.055363\n",
      "batch 38  d_loss: 0.723123  g_loss: 1.954739\n",
      "batch 39  d_loss: 0.312985  g_loss: 2.516407\n",
      "batch 40  d_loss: 0.334057  g_loss: 3.033670\n",
      "batch 41  d_loss: 0.300670  g_loss: 2.787300\n",
      "batch 42  d_loss: 0.380677  g_loss: 2.660595\n",
      "batch 43  d_loss: 0.262658  g_loss: 1.972462\n",
      "batch 44  d_loss: 0.225289  g_loss: 1.631240\n",
      "batch 45  d_loss: 0.274087  g_loss: 1.711710\n",
      "Epoch is 45\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.235170  g_loss: 2.230823\n",
      "batch 1  d_loss: 0.294372  g_loss: 2.585087\n",
      "batch 2  d_loss: 0.280218  g_loss: 2.528735\n",
      "batch 3  d_loss: 0.283759  g_loss: 2.780941\n",
      "batch 4  d_loss: 0.247963  g_loss: 3.588987\n",
      "batch 5  d_loss: 0.323633  g_loss: 2.883842\n",
      "batch 6  d_loss: 0.156925  g_loss: 2.168503\n",
      "batch 7  d_loss: 0.356005  g_loss: 2.158957\n",
      "batch 8  d_loss: 0.289373  g_loss: 2.495266\n",
      "batch 9  d_loss: 0.252954  g_loss: 1.850793\n",
      "batch 10  d_loss: 0.241177  g_loss: 2.010281\n",
      "batch 11  d_loss: 0.296682  g_loss: 2.296495\n",
      "batch 12  d_loss: 0.252394  g_loss: 2.189585\n",
      "batch 13  d_loss: 0.410074  g_loss: 1.763716\n",
      "batch 14  d_loss: 0.274299  g_loss: 1.952780\n",
      "batch 15  d_loss: 0.281636  g_loss: 2.026625\n",
      "batch 16  d_loss: 0.197525  g_loss: 2.864200\n",
      "batch 17  d_loss: 0.364407  g_loss: 2.645219\n",
      "batch 18  d_loss: 0.167220  g_loss: 2.933046\n",
      "batch 19  d_loss: 0.314216  g_loss: 3.241422\n",
      "batch 20  d_loss: 0.391913  g_loss: 2.616125\n",
      "batch 21  d_loss: 0.336518  g_loss: 1.733293\n",
      "batch 22  d_loss: 0.302935  g_loss: 2.103692\n",
      "batch 23  d_loss: 0.291423  g_loss: 2.173231\n",
      "batch 24  d_loss: 0.264115  g_loss: 2.781544\n",
      "batch 25  d_loss: 0.274656  g_loss: 3.019170\n",
      "batch 26  d_loss: 0.288270  g_loss: 3.192770\n",
      "batch 27  d_loss: 0.177795  g_loss: 3.238364\n",
      "batch 28  d_loss: 0.344832  g_loss: 2.683482\n",
      "batch 29  d_loss: 0.690383  g_loss: 2.002250\n",
      "batch 30  d_loss: 0.284184  g_loss: 1.462853\n",
      "batch 31  d_loss: 0.456230  g_loss: 2.193687\n",
      "batch 32  d_loss: 0.259671  g_loss: 2.971335\n",
      "batch 33  d_loss: 0.431710  g_loss: 2.957182\n",
      "batch 34  d_loss: 0.205952  g_loss: 3.304237\n",
      "batch 35  d_loss: 0.215582  g_loss: 3.189410\n",
      "batch 36  d_loss: 0.518516  g_loss: 2.859559\n",
      "batch 37  d_loss: 0.349057  g_loss: 2.498466\n",
      "batch 38  d_loss: 0.378216  g_loss: 2.330153\n",
      "batch 39  d_loss: 0.208407  g_loss: 2.843841\n",
      "batch 40  d_loss: 0.168848  g_loss: 3.191504\n",
      "batch 41  d_loss: 0.215631  g_loss: 3.508232\n",
      "batch 42  d_loss: 0.313154  g_loss: 3.528228\n",
      "batch 43  d_loss: 0.269347  g_loss: 2.627259\n",
      "batch 44  d_loss: 0.231961  g_loss: 2.386122\n",
      "batch 45  d_loss: 0.354371  g_loss: 2.013980\n",
      "Epoch is 46\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.393623  g_loss: 1.944918\n",
      "batch 1  d_loss: 0.322304  g_loss: 2.019659\n",
      "batch 2  d_loss: 0.351198  g_loss: 2.817595\n",
      "batch 3  d_loss: 0.245647  g_loss: 2.424848\n",
      "batch 4  d_loss: 0.262454  g_loss: 2.889992\n",
      "batch 5  d_loss: 0.383193  g_loss: 1.970993\n",
      "batch 6  d_loss: 0.254747  g_loss: 1.852924\n",
      "batch 7  d_loss: 0.618286  g_loss: 1.504708\n",
      "batch 8  d_loss: 0.432040  g_loss: 1.289136\n",
      "batch 9  d_loss: 0.508995  g_loss: 1.464634\n",
      "batch 10  d_loss: 0.385362  g_loss: 1.927112\n",
      "batch 11  d_loss: 0.377897  g_loss: 2.772714\n",
      "batch 12  d_loss: 0.441179  g_loss: 2.806167\n",
      "batch 13  d_loss: 0.240918  g_loss: 2.249013\n",
      "batch 14  d_loss: 0.201999  g_loss: 1.793994\n",
      "batch 15  d_loss: 0.279924  g_loss: 1.602937\n",
      "batch 16  d_loss: 0.306508  g_loss: 1.598358\n",
      "batch 17  d_loss: 0.340407  g_loss: 1.999080\n",
      "batch 18  d_loss: 0.187219  g_loss: 2.314940\n",
      "batch 19  d_loss: 0.217234  g_loss: 2.749705\n",
      "batch 20  d_loss: 0.311166  g_loss: 3.339462\n",
      "batch 21  d_loss: 0.151838  g_loss: 2.875894\n",
      "batch 22  d_loss: 0.227032  g_loss: 2.669803\n",
      "batch 23  d_loss: 0.280519  g_loss: 2.265920\n",
      "batch 24  d_loss: 0.222873  g_loss: 2.213879\n",
      "batch 25  d_loss: 0.274087  g_loss: 2.176902\n",
      "batch 26  d_loss: 0.283669  g_loss: 2.550799\n",
      "batch 27  d_loss: 0.147271  g_loss: 3.029810\n",
      "batch 28  d_loss: 0.169831  g_loss: 3.426835\n",
      "batch 29  d_loss: 0.292498  g_loss: 2.644105\n",
      "batch 30  d_loss: 0.277478  g_loss: 3.105557\n",
      "batch 31  d_loss: 0.188337  g_loss: 1.850530\n",
      "batch 32  d_loss: 0.268401  g_loss: 1.979920\n",
      "batch 33  d_loss: 0.183420  g_loss: 2.466681\n",
      "batch 34  d_loss: 0.178385  g_loss: 2.678340\n",
      "batch 35  d_loss: 0.289460  g_loss: 2.939147\n",
      "batch 36  d_loss: 0.333340  g_loss: 2.456723\n",
      "batch 37  d_loss: 0.276581  g_loss: 2.843287\n",
      "batch 38  d_loss: 0.300888  g_loss: 2.020138\n",
      "batch 39  d_loss: 0.397998  g_loss: 2.107258\n",
      "batch 40  d_loss: 0.368504  g_loss: 1.747600\n",
      "batch 41  d_loss: 0.205891  g_loss: 2.004313\n",
      "batch 42  d_loss: 0.272488  g_loss: 2.990066\n",
      "batch 43  d_loss: 0.185267  g_loss: 4.073842\n",
      "batch 44  d_loss: 0.301952  g_loss: 3.677161\n",
      "batch 45  d_loss: 0.099831  g_loss: 3.713999\n",
      "Epoch is 47\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.324692  g_loss: 2.418435\n",
      "batch 1  d_loss: 0.292577  g_loss: 2.105311\n",
      "batch 2  d_loss: 0.429018  g_loss: 2.947686\n",
      "batch 3  d_loss: 0.277910  g_loss: 3.369630\n",
      "batch 4  d_loss: 0.501233  g_loss: 3.419607\n",
      "batch 5  d_loss: 0.456050  g_loss: 2.272027\n",
      "batch 6  d_loss: 0.287770  g_loss: 2.007524\n",
      "batch 7  d_loss: 0.450379  g_loss: 1.910349\n",
      "batch 8  d_loss: 0.395592  g_loss: 1.386877\n",
      "batch 9  d_loss: 0.381036  g_loss: 2.030692\n",
      "batch 10  d_loss: 0.302872  g_loss: 2.845900\n",
      "batch 11  d_loss: 0.308778  g_loss: 2.978647\n",
      "batch 12  d_loss: 0.352287  g_loss: 3.187160\n",
      "batch 13  d_loss: 0.298722  g_loss: 2.981975\n",
      "batch 14  d_loss: 0.295359  g_loss: 1.940185\n",
      "batch 15  d_loss: 0.270309  g_loss: 1.878980\n",
      "batch 16  d_loss: 0.286665  g_loss: 2.337972\n",
      "batch 17  d_loss: 0.277131  g_loss: 1.722577\n",
      "batch 18  d_loss: 0.214810  g_loss: 2.437989\n",
      "batch 19  d_loss: 0.271208  g_loss: 2.525944\n",
      "batch 20  d_loss: 0.285402  g_loss: 2.980687\n",
      "batch 21  d_loss: 0.190783  g_loss: 3.042341\n",
      "batch 22  d_loss: 0.224371  g_loss: 3.327184\n",
      "batch 23  d_loss: 0.236694  g_loss: 2.634102\n",
      "batch 24  d_loss: 0.175753  g_loss: 3.004574\n",
      "batch 25  d_loss: 0.243837  g_loss: 2.918889\n",
      "batch 26  d_loss: 0.219784  g_loss: 2.908189\n",
      "batch 27  d_loss: 0.124193  g_loss: 2.254299\n",
      "batch 28  d_loss: 0.192069  g_loss: 2.278256\n",
      "batch 29  d_loss: 0.391017  g_loss: 1.898960\n",
      "batch 30  d_loss: 0.280793  g_loss: 1.914099\n",
      "batch 31  d_loss: 0.292912  g_loss: 2.465489\n",
      "batch 32  d_loss: 0.192742  g_loss: 2.562109\n",
      "batch 33  d_loss: 0.368107  g_loss: 2.450187\n",
      "batch 34  d_loss: 0.240257  g_loss: 2.311918\n",
      "batch 35  d_loss: 0.329179  g_loss: 2.417555\n",
      "batch 36  d_loss: 0.635447  g_loss: 1.615231\n",
      "batch 37  d_loss: 0.670182  g_loss: 1.499704\n",
      "batch 38  d_loss: 0.483884  g_loss: 1.618026\n",
      "batch 39  d_loss: 0.586022  g_loss: 2.432758\n",
      "batch 40  d_loss: 0.462125  g_loss: 2.933703\n",
      "batch 41  d_loss: 0.318178  g_loss: 3.386941\n",
      "batch 42  d_loss: 0.433099  g_loss: 3.850825\n",
      "batch 43  d_loss: 0.304789  g_loss: 2.278829\n",
      "batch 44  d_loss: 0.399364  g_loss: 1.386718\n",
      "batch 45  d_loss: 0.298593  g_loss: 1.897241\n",
      "Epoch is 48\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.461079  g_loss: 1.596929\n",
      "batch 1  d_loss: 0.329813  g_loss: 2.342915\n",
      "batch 2  d_loss: 0.376026  g_loss: 2.314140\n",
      "batch 3  d_loss: 0.371513  g_loss: 2.536047\n",
      "batch 4  d_loss: 0.387955  g_loss: 2.096086\n",
      "batch 5  d_loss: 0.222466  g_loss: 1.667285\n",
      "batch 6  d_loss: 0.310140  g_loss: 1.529199\n",
      "batch 7  d_loss: 0.497233  g_loss: 1.357879\n",
      "batch 8  d_loss: 0.477734  g_loss: 1.834356\n",
      "batch 9  d_loss: 0.357420  g_loss: 1.928830\n",
      "batch 10  d_loss: 0.256984  g_loss: 2.007196\n",
      "batch 11  d_loss: 0.348866  g_loss: 1.706217\n",
      "batch 12  d_loss: 0.244669  g_loss: 1.486206\n",
      "batch 13  d_loss: 0.297633  g_loss: 1.581958\n",
      "batch 14  d_loss: 0.267712  g_loss: 2.045584\n",
      "batch 15  d_loss: 0.273700  g_loss: 1.700750\n",
      "batch 16  d_loss: 0.215061  g_loss: 2.791639\n",
      "batch 17  d_loss: 0.364896  g_loss: 2.089222\n",
      "batch 18  d_loss: 0.196100  g_loss: 2.708449\n",
      "batch 19  d_loss: 0.219995  g_loss: 2.427688\n",
      "batch 20  d_loss: 0.252769  g_loss: 2.418172\n",
      "batch 21  d_loss: 0.187731  g_loss: 2.447399\n",
      "batch 22  d_loss: 0.256937  g_loss: 2.557568\n",
      "batch 23  d_loss: 0.217748  g_loss: 2.071677\n",
      "batch 24  d_loss: 0.283461  g_loss: 2.351930\n",
      "batch 25  d_loss: 0.318958  g_loss: 2.337306\n",
      "batch 26  d_loss: 0.369161  g_loss: 1.816348\n",
      "batch 27  d_loss: 0.211788  g_loss: 2.077647\n",
      "batch 28  d_loss: 0.384918  g_loss: 2.750715\n",
      "batch 29  d_loss: 0.382003  g_loss: 3.089314\n",
      "batch 30  d_loss: 0.338278  g_loss: 2.283056\n",
      "batch 31  d_loss: 0.374896  g_loss: 2.075431\n",
      "batch 32  d_loss: 0.249339  g_loss: 1.937044\n",
      "batch 33  d_loss: 0.394453  g_loss: 2.546054\n",
      "batch 34  d_loss: 0.319123  g_loss: 2.657071\n",
      "batch 35  d_loss: 0.472348  g_loss: 2.441683\n",
      "batch 36  d_loss: 0.411685  g_loss: 2.086671\n",
      "batch 37  d_loss: 0.362245  g_loss: 1.883065\n",
      "batch 38  d_loss: 0.382488  g_loss: 2.002852\n",
      "batch 39  d_loss: 0.294804  g_loss: 1.969241\n",
      "batch 40  d_loss: 0.242201  g_loss: 2.099200\n",
      "batch 41  d_loss: 0.290190  g_loss: 3.143140\n",
      "batch 42  d_loss: 0.344983  g_loss: 3.775695\n",
      "batch 43  d_loss: 0.313317  g_loss: 2.784265\n",
      "batch 44  d_loss: 0.300219  g_loss: 2.544683\n",
      "batch 45  d_loss: 0.254756  g_loss: 2.628688\n",
      "Epoch is 49\n",
      "Number of batches 46\n",
      "batch 0  d_loss: 0.231530  g_loss: 2.222588\n",
      "batch 1  d_loss: 0.288749  g_loss: 2.712587\n",
      "batch 2  d_loss: 0.209784  g_loss: 3.200440\n",
      "batch 3  d_loss: 0.209259  g_loss: 2.913844\n",
      "batch 4  d_loss: 0.246285  g_loss: 2.665021\n",
      "batch 5  d_loss: 0.205269  g_loss: 2.066006\n",
      "batch 6  d_loss: 0.204990  g_loss: 2.644305\n",
      "batch 7  d_loss: 0.556543  g_loss: 1.907095\n",
      "batch 8  d_loss: 0.368158  g_loss: 1.667633\n",
      "batch 9  d_loss: 0.254705  g_loss: 2.144255\n",
      "batch 10  d_loss: 0.269699  g_loss: 2.504618\n",
      "batch 11  d_loss: 0.365211  g_loss: 2.695861\n",
      "batch 12  d_loss: 0.487194  g_loss: 2.574528\n",
      "batch 13  d_loss: 0.290248  g_loss: 2.234793\n",
      "batch 14  d_loss: 0.211062  g_loss: 2.407998\n",
      "batch 15  d_loss: 0.290102  g_loss: 2.682418\n",
      "batch 16  d_loss: 0.389293  g_loss: 2.374200\n",
      "batch 17  d_loss: 0.563708  g_loss: 2.131272\n",
      "batch 18  d_loss: 0.241924  g_loss: 1.952552\n",
      "batch 19  d_loss: 0.300808  g_loss: 2.194297\n",
      "batch 20  d_loss: 0.219748  g_loss: 1.890638\n",
      "batch 21  d_loss: 0.233488  g_loss: 2.529502\n",
      "batch 22  d_loss: 0.344933  g_loss: 2.254630\n",
      "batch 23  d_loss: 0.378480  g_loss: 2.527666\n",
      "batch 24  d_loss: 0.302159  g_loss: 1.820106\n",
      "batch 25  d_loss: 0.252035  g_loss: 1.534376\n",
      "batch 26  d_loss: 0.310893  g_loss: 1.662624\n",
      "batch 27  d_loss: 0.238304  g_loss: 2.563986\n",
      "batch 28  d_loss: 0.322747  g_loss: 2.896807\n",
      "batch 29  d_loss: 0.376876  g_loss: 2.075609\n",
      "batch 30  d_loss: 0.271516  g_loss: 1.825494\n",
      "batch 31  d_loss: 0.295091  g_loss: 1.609450\n",
      "batch 32  d_loss: 0.259651  g_loss: 2.110665\n",
      "batch 33  d_loss: 0.359996  g_loss: 2.434154\n",
      "batch 34  d_loss: 0.294038  g_loss: 2.813995\n",
      "batch 35  d_loss: 0.381469  g_loss: 2.384593\n",
      "batch 36  d_loss: 0.339502  g_loss: 1.537153\n",
      "batch 37  d_loss: 0.388608  g_loss: 1.622547\n",
      "batch 38  d_loss: 0.358811  g_loss: 2.238374\n",
      "batch 39  d_loss: 0.353311  g_loss: 2.655370\n",
      "batch 40  d_loss: 0.407149  g_loss: 2.653252\n",
      "batch 41  d_loss: 0.420332  g_loss: 1.928989\n",
      "batch 42  d_loss: 0.257629  g_loss: 2.067645\n",
      "batch 43  d_loss: 0.264990  g_loss: 2.195216\n",
      "batch 44  d_loss: 0.274583  g_loss: 2.521642\n",
      "batch 45  d_loss: 0.138739  g_loss: 2.946192\n",
      "CPU times: user 27min 28s, sys: 33.2 s, total: 28min 1s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_log = train(BATCH_SIZE=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check train_log  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161604,
     "status": "ok",
     "timestamp": 1577108551920,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "CVig749FCcV7",
    "outputId": "a5111998-3cc3-4703-91a8-29bda39e4b3d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.748881</td>\n",
       "      <td>1.145698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.177903</td>\n",
       "      <td>5.427390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>8.828770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.043294</td>\n",
       "      <td>11.825085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.008178</td>\n",
       "      <td>12.381811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch  batch    d_loss     g_loss\n",
       "0      0      0  0.748881   1.145698\n",
       "1      0      1  0.177903   5.427390\n",
       "2      0      2  0.006019   8.828770\n",
       "3      0      3  0.043294  11.825085\n",
       "4      0      4  0.008178  12.381811"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>batch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>49</td>\n",
       "      <td>41</td>\n",
       "      <td>0.420332</td>\n",
       "      <td>1.928989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2296</th>\n",
       "      <td>49</td>\n",
       "      <td>42</td>\n",
       "      <td>0.257629</td>\n",
       "      <td>2.067645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>49</td>\n",
       "      <td>43</td>\n",
       "      <td>0.264990</td>\n",
       "      <td>2.195216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2298</th>\n",
       "      <td>49</td>\n",
       "      <td>44</td>\n",
       "      <td>0.274583</td>\n",
       "      <td>2.521642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2299</th>\n",
       "      <td>49</td>\n",
       "      <td>45</td>\n",
       "      <td>0.138739</td>\n",
       "      <td>2.946192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      epoch  batch    d_loss    g_loss\n",
       "2295     49     41  0.420332  1.928989\n",
       "2296     49     42  0.257629  2.067645\n",
       "2297     49     43  0.264990  2.195216\n",
       "2298     49     44  0.274583  2.521642\n",
       "2299     49     45  0.138739  2.946192"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fit = pd.DataFrame(train_log)\n",
    "df_fit.columns = ['epoch', 'batch', 'd_loss', 'g_loss']\n",
    "display(df_fit.head())\n",
    "display(df_fit.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 161597,
     "status": "ok",
     "timestamp": 1577108551921,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "rNAG9r_5CcV9",
    "outputId": "6a3ae744-3d69-4f76-900e-a70adc2e3381"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_fit.index, df_fit['d_loss'], label='d_loss')\n",
    "plt.plot(df_fit.index, df_fit['g_loss'], label='g_loss')\n",
    "plt.xlabel('Batches')\n",
    "plt.ylabel('Losses')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate images using models with labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uVaimUR9xqtm"
   },
   "outputs": [],
   "source": [
    "def generate_from_model_digits(batch_size, n_digits, n_noise,\n",
    "                               model_file=None, height=None):\n",
    "    if model_file is None:\n",
    "        generator = generator_model()\n",
    "        #generator.compile(loss=\"binary_crossentropy\", optimizer=\"SGD\")\n",
    "        generator.compile(loss=\"binary_crossentropy\", optimizer=\"Adam\")\n",
    "        generator.load_weights(\"generator\")\n",
    "    else:\n",
    "        print('model_file:', model_file)\n",
    "        generator = load_model(model_file)\n",
    "\n",
    "    noise = np.zeros((batch_size*n_digits, n_noise))\n",
    "    labels = np.zeros((batch_size*n_digits, n_digits))\n",
    "    #print('batch:', batch_size)\n",
    "    #print('digits:', n_digits)\n",
    "    for i in range(batch_size):\n",
    "        noise1 = np.random.uniform(-1, 1, n_noise)\n",
    "        for d in range(n_digits):\n",
    "            label1 = to_categorical(d, n_digits)\n",
    "            #print('label1:', d, label1)\n",
    "            noise[i*n_digits+d, :] = noise1\n",
    "            labels[i*n_digits+d:, :] = label1\n",
    "    #print(noise)\n",
    "    #print(labels)\n",
    "    generated_images = generator.predict([noise, labels], verbose=1)\n",
    "    if height is None:\n",
    "        height = batchsize\n",
    "    image = combine_images_digits(generated_images, n_digits,\n",
    "                                  height=height)\n",
    "    image = image*127.5+127.5\n",
    "    png = \"generated_image_from_model.png\"\n",
    "    Image.fromarray(image.astype(np.uint8)).save(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate image by using Generator  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 177570,
     "status": "ok",
     "timestamp": 1577108567908,
     "user": {
      "displayName": "nakamura shugo",
      "photoUrl": "",
      "userId": "03438779614787203073"
     },
     "user_tz": -540
    },
    "id": "nHEojYucxqto",
    "outputId": "16e6d73e-581d-40eb-fdc0-c26ff1d5f891"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_file: model_cdcgan-b32_g-d48.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anhvu/.local/lib/python3.9/site-packages/keras/engine/training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    }
   ],
   "source": [
    "generate_from_model_digits(batch_size, n_digits, n_noise, model_file=model_g, height=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "c-dcgan-colab.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
