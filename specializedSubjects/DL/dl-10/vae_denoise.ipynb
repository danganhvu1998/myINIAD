{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample program for VAE denoising (Dense)   \n",
    "- For train: input: with noise / output: without noise  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "#from keras import backend as K\n",
    "from tensorflow.keras.layers import Lambda, Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import  os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True' \n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "np.random.seed(17)\n",
    "tf.random.set_seed(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_digits = 5\n",
    "n_train = 4800\n",
    "n_test = 800"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for Z-sampling between encoder and decoder  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reparameterization trick\n",
    "# instead of sampling from Q(z|X), sample epsilon = N(0,I)\n",
    "# z = z_mean + sqrt(var) * epsilon\n",
    "def sampling(args):\n",
    "    \"\"\"Reparameterization trick by sampling from an isotropic unit Gaussian.\n",
    "\n",
    "    # Arguments\n",
    "        args (tensor): mean and log of variance of Q(z|X)\n",
    "\n",
    "    # Returns\n",
    "        z (tensor): sampled latent vector\n",
    "    \"\"\"\n",
    "\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim),\n",
    "                              mean=0., stddev=1. )\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function for visualization of data in latent space  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(models, data, batch_size=128):\n",
    "    \"\"\"Plots labels and MNIST digits as a function of the 2D latent vector\n",
    "\n",
    "    # Arguments\n",
    "        models (tuple): encoder and decoder models\n",
    "        data (tuple): test data and label\n",
    "        batch_size (int): prediction batch size\n",
    "    \"\"\"\n",
    "\n",
    "    encoder, decoder = models\n",
    "    test_data, test_label = data\n",
    "\n",
    "    # display a 2D manifold of digits\n",
    "    z_mean1, _, _ = encoder.predict(test_data,\n",
    "                                    batch_size=batch_size)\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    plt.scatter(z_mean1[:, 0], z_mean1[:, 1], c=test_label)\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"z1\")\n",
    "    plt.ylabel(\"z2\")\n",
    "    plt.xlim(-4, 4)\n",
    "    plt.ylim(-4, 4)\n",
    "    plt.show()\n",
    "\n",
    "    # display a 2D manifold of digits\n",
    "    n = 15\n",
    "    figure = np.zeros((img_h * n, img_w * n))\n",
    "    # linearly spaced coordinates corresponding to the 2D plot\n",
    "    # of digit classes in the latent space\n",
    "    grid_x = np.linspace(-4, 4, n)\n",
    "    grid_y = np.linspace(-4, 4, n)[::-1]\n",
    "\n",
    "    for i, yi in enumerate(grid_y):\n",
    "        for j, xi in enumerate(grid_x):\n",
    "            z_sample = np.array([[xi, yi]])\n",
    "            x_decoded = decoder.predict(z_sample)\n",
    "            digit = x_decoded[0].reshape(img_h, img_w)\n",
    "            figure[i * img_h: (i + 1) * img_h,\n",
    "                   j * img_w: (j + 1) * img_w] = digit\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    start_range_x = img_w // 2\n",
    "    end_range_x = (n - 1) * img_w + start_range_x + 1\n",
    "    pixel_range_x = np.arange(start_range_x, end_range_x, img_w)\n",
    "    start_range_y = img_h // 2\n",
    "    end_range_y = (n - 1) * img_h + start_range_y + 1\n",
    "    pixel_range_y = np.arange(start_range_y, end_range_y, img_h)\n",
    "    sample_range_x = np.round(grid_x, 1)\n",
    "    sample_range_y = np.round(grid_y, 1)\n",
    "    plt.xticks(pixel_range_x, sample_range_x)\n",
    "    plt.yticks(pixel_range_y, sample_range_y)\n",
    "    plt.xlabel(\"z1\")\n",
    "    plt.ylabel(\"z2\")\n",
    "    plt.imshow(figure, cmap='Greys_r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load MNIST  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only 0..(n_train/test_digits-1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[ y_train < n_digits ]\n",
    "y_train = y_train[ y_train < n_digits ]\n",
    "x_test = x_test[ y_test < n_digits ]\n",
    "y_test = y_test[ y_test < n_digits ]\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of each label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_train).value_counts())\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reduce the number of data (for shorter calculation time)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:n_train]\n",
    "y_train = y_train[:n_train]\n",
    "x_test = x_test[:n_test]\n",
    "y_test = y_test[:n_test]\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the number of each label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.Series(y_train).value_counts())\n",
    "print(pd.Series(y_test).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtain size of image  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_h = x_train.shape[1]\n",
    "img_w = x_train.shape[2]\n",
    "original_dim = img_h * img_w\n",
    "print(img_h, img_w, original_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-scale data (0..1) and flatten  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32') / 255\n",
    "x_train = x_train.reshape(-1, original_dim)\n",
    "print(x_train.shape)\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, original_dim)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate data with noise  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_train = np.random.normal(loc=0.15, scale=0.3,\n",
    "                               size=x_train.shape)\n",
    "noise_test = np.random.normal(loc=0.15, scale=0.3,\n",
    "                              size=x_test.shape)\n",
    "\n",
    "x_train_noisy = np.clip(x_train+noise_train, 0, 1)\n",
    "print(x_train_noisy.shape)\n",
    "x_test_noisy = np.clip(x_test+noise_test, 0, 1)\n",
    "print(x_test_noisy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See images without noise  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))  # don't move to other cell\n",
    "tile_h = 5\n",
    "tile_w = 5\n",
    "for i in range(tile_h*tile_w):\n",
    "    fig.add_subplot(tile_h, tile_w, i+1, xticks=[], yticks=[])\n",
    "    plt.imshow(x_train[i].reshape((img_h, img_w)), cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### See images with noise  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 8))  # don't move to other cell\n",
    "tile_h = 5\n",
    "tile_w = 5\n",
    "for i in range(tile_h*tile_w):\n",
    "    fig.add_subplot(tile_h, tile_w, i+1, xticks=[], yticks=[])\n",
    "    plt.imshow(x_train_noisy[i].reshape((img_h, img_w)), cmap='gray')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start VAE calculation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters for dense and latent space  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (original_dim, )\n",
    "intermediate_dim = 512\n",
    "latent_dim = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build VAE model = encoder + decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build encoder model\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Dense(intermediate_dim, activation='relu')(inputs)\n",
    "x = Dense(intermediate_dim, activation='relu')(x)\n",
    "x = Dense(intermediate_dim, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "# use reparameterization trick to push the sampling out as input\n",
    "z = Lambda(sampling, name='z')([z_mean, z_log_var])\n",
    "\n",
    "# instantiate encoder model\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder model\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(intermediate_dim, activation='relu')(latent_inputs)\n",
    "x = Dense(intermediate_dim, activation='relu')(x)\n",
    "x = Dense(intermediate_dim, activation='relu')(x)\n",
    "outputs = Dense(original_dim, activation='sigmoid')(x)\n",
    "\n",
    "# instantiate decoder model\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the whole model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate VAE model\n",
    "outputs = decoder(encoder(inputs)[2])  # encoder(input)[2]: z\n",
    "vae = Model(inputs, outputs, name='vae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to calculate loss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vae_loss(y_true, y_pred):\n",
    "    reconstruction_loss = binary_crossentropy(y_true,\n",
    "                                              y_pred)\n",
    "    reconstruction_loss *= original_dim\n",
    "    kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "    kl_loss = K.sum(kl_loss, axis=-1) / 2\n",
    "    ret = K.mean(reconstruction_loss - kl_loss)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set optimization parameters  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae.compile(optimizer='adam', loss=vae_loss,\n",
    "            experimental_run_tf_function=False)\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exec learning (training)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 40\n",
    "val_split = 0.1\n",
    "input_data = x_train_noisy\n",
    "teacher_data = x_train\n",
    "input_test_data = x_test_noisy\n",
    "true_test_data = x_test\n",
    "true_test_label = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fit_log = vae.fit(input_data, teacher_data,\n",
    "                  epochs=epochs,\n",
    "                  batch_size=batch_size,\n",
    "                  validation_split=val_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot of loss/val_loss vs epochs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(fit_log.history['loss'], label='train')\n",
    "plt.plot(fit_log.history['val_loss'], label='valid')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of the results   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (encoder, decoder)\n",
    "data = (input_test_data, y_test)\n",
    "\n",
    "plot_results(models, data,\n",
    "             batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Obtain output for test_data      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vae.predict(input_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show sample images  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(12, 4))\n",
    "for i in range(n):\n",
    "    # Show input test image\n",
    "    ax = plt.subplot(3, n, i+1)\n",
    "    plt.imshow(input_test_data[i].reshape(img_h, img_w))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    " \n",
    "    # Show output test image\n",
    "    ax = plt.subplot(3, n, i+1+n)\n",
    "    plt.imshow(pred[i].reshape(img_h, img_w))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    \n",
    "    # Obtain diff between images\n",
    "    diff_img = true_test_data[i] - pred[i]\n",
    "    \n",
    "    # Obtain total value of diff between images  \n",
    "    diff_score = np.sum(np.abs(true_test_data[i]-pred[i]))\n",
    "        \n",
    "    # Show results  \n",
    "    ax = plt.subplot(3, n, i+1+n*2)\n",
    "    plt.imshow(diff_img.reshape(img_h, img_w))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False) \n",
    "    ax.set_xlabel('score:{:.2f}'.format(diff_score), fontsize=8)    \n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Show distribution of scores  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_scores = []\n",
    "diff_labels = []\n",
    "for i in range(len(input_test_data)):   \n",
    "    # Obtain total value of diff between images  \n",
    "    diff_score = np.sum(np.abs(true_test_data[i]-pred[i]))\n",
    "    diff_scores.append(diff_score)\n",
    "    diff_labels.append(true_test_label[i])\n",
    "\n",
    "diff_scores = np.array(diff_scores)\n",
    "diff_labels = np.array(diff_labels)\n",
    "\n",
    "for i in range(n_digits):\n",
    "    plt.hist(diff_scores[ diff_labels==i ], label=str(i), density=True, alpha=0.2)\n",
    "plt.xlabel('Scores')\n",
    "plt.ylabel('Prob')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
